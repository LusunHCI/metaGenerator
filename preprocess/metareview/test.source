Reject. rating score: 4. rating score: 5. rating score: 6. rating score: 6. <BRK>This paper applied self supervised learning (wav2vec 2.0) to multilingual speech recognition task. This is a well written and interesting paper. So I don t think it fit to ICLR and suggest it resubmit to a speech conference.<BRK>This paper proposes to apply a state of the art self supervised training method (wav2vec 2.0) to multilingual ASR. The paper also has some comparisons with the other reports in the same setup. This multilingual ASR scenario is one of the most straightforward applications of self supervised training, and this paper has significant contributions to the ASR research communities.<BRK>The basic idea does make a lot of sense, where all the data, irrespective of the language, is pushed through the representation learning task. We are anyways talking about human speech, so it is reasonable to assume that learning one language can help in learning the other language. My main criticism is that technical novelty appears to be limited.<BRK>This paper proposes an unsupervised cross lingual speech representation learning algorithm for multi lingual automatic speech recognition. The main building block is based on an existing study (wav2vec series). Cons:1.Since the building block is from an existing study: wav2vec 2.0 and there is no improvement to it, this paper lacks of novelty in theoretical part. The authors mentioned "Weights of the feature encoder are not updated at fine tuning time". Is there a specific reason?
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 5. <BRK>This paper presents the results of a NN trained to learn symmetries in physics, specifically, to learn and preserve quantities that are preserved (e.g., energy, angular momentum). The input is a sequence generated from a Hamiltonian dynamics. There is some customization of the training networks to incorporate "cyclic" coordinates. With today s advances, and NN finding success in almost every area with data, it is not clear what the contribution of this paper is. Why is this result interesting? the outputs are close but do not perfectly periodic.<BRK>The paper proposes a set of loss functions that can make neural networks learn Hamiltonian dynamics with conserved quantities. In some parts, information is missing or misleading and the graphics need some improvements. Concrete problems:  the number of conserved coordinates has to be known      here I think it would be possible to show what happens when the number of conserved quantities is scanned through. It only has the knowledge about how many conserved quantities are the system. Also, the qualitative predictions in Fig 3 are not really convincing. In any case, it might also be a good baseline. It would be valuable to know whether the inductive bias of a functional form or the conserved quantities is more effective. (Upvote from 4 >5)<BRK>This submission explores the question of identifying conserved quantities in Hamiltonian dynamics for physical systems by attempting to learn canonical transformations. Perhaps the main observation is that some of the cyclic coordinates identified by the network have a clear relation to the underlying conserved quantities. What is more, the weight of the additional terms in the loss was not systematically varied, so was not left with much sense of the extent to which it was affecting the optimization.<BRK>** The authors propose using a neural network to learn a canonical transformation of the data coordinates before learning a Hamiltonian. This is a novel contribution in that previous work has shown how to learn Hamiltonians with neural networks but it has not shown how to learn the proper canonical transformation. The paper cannot be accepted to ICLR as is. The core idea is a good one and it leads to promising (although entirely qualitative) results. Is the idea that this regularization will hopefully force two to be constant while the other two are not? But the authors make another change: they force the learned canonical transformation to be linear by construction. There should be more discussion regarding the system of coupled oscillators.
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. <BRK>I enjoyed reading this paper and the idea of combining normalizing flow density models with conditional sampling seems natural, useful and has interesting potential applications to missing data problems.<BRK>The normalizing flows are learnt via a MC EM approach for incomplete training data. Positives:The combination of normalizing flows and MCMC sampling for conditional sampling is new as far as I am aware and is an interesting approach. Qualitative experimental results on different data sets seem promising with quantitative results indicating that it performs competitively (better reconstruction RMSE compared to MisGAN, closely matching the performance of MIWAE).<BRK>SummaryThis paper proposes a stochastic expectation maximisation (EM) algorithm. This does not seem novel; such algorithms have been around for decades. The authors should explain why they need for extending the space to include $y_O$ instead of just mapping $\xi$ to $y_M$.
Reject. rating score: 3. rating score: 4. rating score: 5. rating score: 5. rating score: 5. <BRK>Given that this is not clear to me, it makes it hard for me to understand if  the paper provides some approaches to improve it. What do the authors exactly mean by “reliable” predictive probabilities, which is at the core of this paper? 6.Below Eq 4, \tau^\star is defined in a maximization problem.<BRK>Although the paper makes some interesting remarks, the idea of looking at the predictive probability rather than classification error is certainly not new. This may be part of the story, but is unlikely to a central one. In particular, this does not explain why overparametrized models may still generalize well in the regression setting. The score usually means the derivative of the log likelihood. Update: I appreciate the authors’ response and, in particular, providing more explanations about eq.(3) (now eq.(5)).However, the explanations are still largely heuristic and based on unproven claims.<BRK>I believe the title overreaches a little   the results of the paper are interesting and compelling, but they fall short of demonstrating that regularization in deep learning models is “required” for reliable predictive probability. The experiments show convincing results on the ability of explicit regularization to improve the quality of uncertainty of neural network classifiers.<BRK>The authors use a cyclic argument to explain why neural nets are overly confident on their predictions. The main contribution of this paper is to propose new regularization methods in deep neural networks that produce well calibrated probability scores. There are two forms of regularization that the authors propose: (1) regularizing in the function space, and (2) in the probability space. The experimental results are interesting.<BRK>b.It is claimed that improving the expectation in the third sentence of page 4 is challenging due to many complex factors, therefore it is not directly connected to improving this expectation on unseen samples. The empirical results of this paper look promising and show that indeed adding explicit regularization terms improves both the accuracy and the calibration. The analysis of the log likelihood is very unclear.
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 6. <BRK>This papers develops theory trying to explain this by showing the finite width correction (FWC) for DNNs. The results look very interesting. First of all, the paper is talking about the FWC. And why can it be eliminated? And it is not clear to me about the sentence below eq.4: why the rhs of eq.4 equals the kernel of the NNGP only in highly over parameterized DNNs? I think f corresponds to the DNN? I am not sure how these results are useful? 6.Paragraph above Figure 1: it says "the above cubic term would lose its explicit dependence on n", but I think there is still a quadratic term, which still depends on n. How can it say that the FWC is negligible in the large n regime? Overall, I found this paper addressing an important and interesting problem, but the current presentation cannot convince me a pass.<BRK>This paper shows a correspondence between deep neural networks (DNN) trained with noisy gradients and NNGP. This paper is written in a physics style which makes it hard to read. For the third claimed contribution, I feel that the authors over claimed what their results can suggest. The derivation of the finite width correction of the NNGP could indeed be a concrete contribution, but the result is presented in a very ambiguous way. There are many other places where the quantities are not concretely defined and I can only guess what do these notations mean in order to follow the results. Although the finite width correction of NNGP (if properly written) could be an interesting result, due to the ambiguous writing style of the paper, I don t think it achieves the goal of clearly presenting the results.<BRK> In this paper, the authors propose an analytical framework for DNN training with noisy gradient descent and weight decay. For infinite width, the authors have established a correspondence between DNNs trained withnoisy gradients and the NNGP, and for finite width, the authors introduce a finite width correction (FWC). Overall, the paper is quite interesting and well organized. However, I still have several concerns. The authors may want to comment on these papers. My other minor concerns are as follows:1. 2.The analysis in this paper highly depends on the ergodicity of the dynamics. It would be better if the authors can explain more about why the ACT can imply ergodicity. (2019).Mean field theory of two layers neural networks: dimension free bounds and kernel limit.<BRK>This paper studies equivalence between neural networks and Gaussian process. The authors make three main contributions: (1) they prove that infinite width DNNs trained with noisy gradients are corresponded to neural network Gaussian process (NNGP), not neural tangent kernel (NTK); (2) they prove that the finite width correction (FWC) for DNNs with arbitrary activation functions and depth has a general analytical form which can help predict the outputs of empirical finite networks with high accuracy; and (3) they show how these FWCs can improve the performance of finite convolutional neural networks (CNNs) on image classification tasks. Overall, I vote for accepting. Pros:+ The paper takes one of the most important problem in deep learning theory – the correspondence between neural networks and Gaussian kernels. Cons:  The presentation can be improved. For example, Sections 2 and 3 would better if the contents can be further organized into smaller parts. Could you please give detailed proof skeletons in the manuscript and discussion the differences with related works?
Reject. rating score: 3. rating score: 5. rating score: 6. rating score: 7. rating score: 8. <BRK>This paper aimed to understand the self supervised learning algorithm under a teacher student network setting. Also, the presentation is weird. The assumption can be too strong while some explanations are too intuitive. What does the authors want to say on that? 3.I would like to say that the assumption for Theorem 3, i.e.the gradient of the negative samples are identical, are too strong and unrealistic.<BRK>The paper also needs experiments about the magnitude of the covariance operator and the training time. However, there are several issues. The paper should explain the motivation to choose simCLR for analysis. The experiment setting should be listed.<BRK>This paper provided in depth theoretical analysis of self supervised learning, focusing on two network structures (SimCLR, BYOL). The paper is well written, with rigorous mathematical derivations. What would be a good augmentation transform?<BRK>The analysis and conclusion seem promising. 	This paper made a theoretically analysis on BYOL and conducted a variety of ablation studies to study the impacts of BN layer and predictor in BYOL. And some interesting experimental results and conclusions are presented, which sheds light on the further explorations on self supervised learning. I wonder if the improvements will gradually decrease or even vanish for longer training epochs.<BRK>Summary: This paper does theoretical analysis about self supervised learning (SSL), esp. I d ask the authors, does this invalidate your analysis about BYOL?
Reject. rating score: 4. rating score: 6. rating score: 6. <BRK>This paper studies the self supervised code functional representation learning and proposes a method called ContraCode. ContraCode utilizes some code functionality invariant transformations to generate positive pairs from the same code and negative pairs from different codes. Experiment results based on two tasks are reported. Pros: 	The task of  code functional representation learning is important and valuable.<BRK>This work proposes to combine contrastive learning with code representation. The different transformations of code snippets are inspried by static complier. I agree with the claim about programs with the same functionality should have the same underlying representation. Whether on earth MLM loss is good for this task? For example, [1] and [2] for code summerazation task .<BRK>The guiding principle for contrastivelearning is that programs with the same functionality should have the samerepresentation. ## Pros  A very nice and intuitive application of Momentum Contrast to code  representation learning. The use of source to source compilers for contrastive learning. The results are consistently better than previous state of the art on two  different downstream tasks. This is reinforced by the fact that Acc@1 and Acc@5  is exactly the same for CheckJS in Table 2.
Accept (Spotlight). rating score: 8. rating score: 7. rating score: 7. rating score: 6. <BRK>They suggest using piece wise linear RNNs (PLRNNs) with a novel regularization technique. The paper is well written and is very thorough with the necessary theoretical foundation, numerical experiments and analysis. I think the theory and results of this paper are significant and will be relevant to further our understanding of RNNs and system identification.<BRK>This paper proposes a type of regularization for piecewise linear RNNs (PLRNNs) that encourages the network to learn line or plane attractors. Major concern:I found the paper interesting. should be `automatize  and `classical . (e.g.RNNs seem like instead of RNN seem like; or RNNs in their vanilla form instead of RNN in their vanilla form)<BRK>This paper proposes a regularization scheme for training vanilla Relu RNN to tackle the exploding and vanishing gradients issue. I disagree that the space is neurally stable since all the states are sensitive to perturbation and cannot persist a stable memory. The idea of tackling the issue  while keeping the simplicity sounds very interesting and useful.<BRK>The paper proposes a novel regularization term to PLRNN. I also appreciate the theoretical analysis. And the presentation of the neuron model is not sufficient enough to prove that rPLRNN find interesting and interpretable dynamics. I would say making this point more explicit in the intro would be helpful.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. rating score: 5. <BRK>This paper presents a novel approach to structure learning for cause effect models, focussing on the influence of mediators. This approach is supported with an algorithm, which is implemented and tested on various datasets. The authors summarize important preliminaries and recap related approaches. Overall, the paper is very well structured, the accompanying appendix is detailed and provides extensive supplemental material. \The choice of COVID 19 data as experimental data adds a good final touch,  taking a recent and prevalent real world example into account.<BRK>This paper combines two contributions to causal inference: a definition of and distinction between direct and indirect mediator effects to take account of cases of more than one mediator on a mediating path and how to identify them in linear structural equation models, and a modification of the DAG GNN method for learning causal structure to incorporate certain background knowledge. In addition, the paper applies the concepts and the method to some interesting COVID19 data. Some specific comments/questions:1. It s unclear to me how this issue is handled in the experiments. Did the authors notice any causal direction that does not make much sense or accord with the known migration trend? And how about categorical mediators? This remark is a little misleading.<BRK>### SummaryThe authors propose a framework to analyse causal effects, considering interactions between mediators. The causal structure learning includes a temporal causal relationships of variables. Also, the authors validated the framework on real world data set, in particular the Chinese coronavirus outbreak near Hubei. ### Reasons for scoreThe paper proposes an interesting and useful framework. The problem is clear and well motivated. The proposed approach seems to be an extension of the DAG GNN. Also, the latter is shown to have similar results in the analysis (fig 3). One main difference proposed by the authors is that ANOCE CVAE can handle non linear cases, contrarily to DAG GNN. Probably a way to improve the paper would be adding more details on the contribution with respect to the state of the art.<BRK>Its main contribution is to decompose the indirect effect by teasing out the causal contribution of a set of mediators. In a series of experiments with simulated data the authors show that the proposed method, ANOCE, outperforms other comparison partners. The manuscript also contains an analysis of real world data that describes the causal effects of the lockdown of cities in the Hubei province (China) to reduce the spread of COVID 19. ##### 2.Rationale for the scoreThe paper is well structured and very well written.
Reject. rating score: 5. rating score: 5. rating score: 5. rating score: 5. rating score: 5. <BRK>##########################################################################Pros: Well pitched experiment, especially the use of snap shotting to show improvement over time. If the trained model is only accurate for single agent search, is it not possible to train a model that is compatible with multi agent search under different settings for max range? Applying your approach in these experiments would make a stronger case for elevation of the state of the art than the 6 card variant. The experimental setup requires significantly more details on the hardware used for training, testing and validating. It may be insightful to compare the effects of different feature spaces. However, even with a comparison on just single agent search this work is a fine fit for ICLR.<BRK>##########################################################################Reasons for score:  Overall, I d vote for rejection of the paper. ##########################################################################Pros:  1.The idea that using a learned belief model to replace exact sampling is interesting in general. The motivation of the proposed method is clear and sound. As an improvement over SPARTA, LBS has addressed one of the main issues of scalability. It is natural that LBS will work If the belief model is perfect. But not vice versa.<BRK>This paper proposes a new approach to search in POMDP environments. The main idea is to extend a previous SPARTA search technique with a belief learning ability, called Learned Belief Search (LBS). While the existing work maintains explicit belief representation, LBS is an approximate auto regressive counterfactual belief learning method that is based on supervised learning. While I found belief learning is commmon in single agent POMDP tasks, the motivation of why LBS can be challenging and useful for DEC POMDP or the multi agent game domains is not convincing. It would also be helpful if a brief description of the Hanabi game can be included in Appendix too.<BRK>The proposed a learned belief search (LBS) and use auto regression model to learn the belief distribution of unobserved information. They evaluate the method on Hanabi and obtain 60\% benefit of the exact search with $35\times$ reduction in computation cost. However, it seems that there are many typos or technique issues, i think this paper needs proofreading before it can be accepted. especially, there is a large variance in rollout, do you use any variance reduction technique? I am not sure whether the improvement are specially designed for this particular game. (3) This paper is not well written.<BRK>**Summary**This paper is an extension of previous work SPARTA, with two improvements: one is to use a learned belief model to sample in a large state space; the other is to improve the efficiency by replacing full rollouts with partial rollouts that bootstrap from a value function after a specific number of steps. BP is not given the full name. It is hard to understand without domain knowledge. On page 3, there is a typo about the reference of SAD, with a symbol ‘?’
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 6. <BRK>The experiments are generally rigorous and well executed, however my main problem with the paper is that it seems a bit too incremental to justify another paper.<BRK>The main novel contribution is that the authors use generative models for several tasks but on the feature space and not the input pixel space.<BRK>What is the model supposed todo?<BRK>Please make it clear what this distribution is for the experiments.
Reject. rating score: 5. rating score: 5. rating score: 6. rating score: 7. <BRK>The paper is stuffed with mathematical theorems which makes it almost impossible for me to evaluate the contribution of the work without going through the proofs in the appendix, making this paper more suited for a journal than a conference with 8 pages limit in my opinion. They consider additive Gaussian noise as a data augmentation technique for mini batch SGD over a simple linear regression with Frobenius loss. The main contribution of the work, as far as I understood, is to derive a range of possible annealing learning rate and additive noise power in Theorem 6.2 that can guarantee convergence of SGD to the global minima of the Frobenius linear regression loss which is convex. But I m not sure about the derivation; for instance, take x y 0.4 and e 0.3, then $W_t$ does not necessarily converge to $W_{min}$ in Theorem 6.2, right? Anyway, my biggest problem with the paper is the generality of the proposed framework, which only takes into consideration additive noise and depends strictly on the calculation of gradients as the Frobenius loss illustrates. The author tried to explain a rough idea about how to handle a nonlinear case on Page 4, but this approach can be dramatically cumbersome for the deep neural networks as it needs the calculation of Hessian and gradient with respect to the input x even! Besides, the derivations strictly depend on the additive noise power model $\sigma_t$, but the author claims that their framework is applicable to advanced data augmentation techniques such as Mixup. This is not possible in my opinion. For instance, take a data augmentation technique like Mixup which is not totally data agnostic such as additive noise. In other words, there is no parameter like the noise power $\sigma_t$ that you can control during each step of SGD. There is only $\alpha$ which is not quite flexible either in Mixup as it usually takes a value around 0.2. Therefore, I strongly doubt the universality of the proposed framework to deal with various networks and data augmentation techniques that are mostly used by practitioners nowadays and do not see the paper as a good fit for a conference like ICLR. After rebuttal: I thank the author for their response and have raised my rating by one after reading the author s response, but my concern still holds unfortunately regarding the whole approach that the author has taken to analyze the effect of data augmentation.<BRK>This paper proposes a framework that re interprets data augmentation as stochastic optimization for a time varying sequence of objectives. The paper also provides a theoretical analysis of the simple case of over parameterized linear regression. In section 4, the paper claims that the gradient descent will not converge to W_min because gradient descent “cannot see” the directions in the e in the orthogonal complement of the column span of XX^T. However, it’s easy to choose an initial point W_0 which is in the column span of XX^T. Then the gradient descent may converge to W_min. The authors should point out the situation where data augmentation is necessary. 3.Thm 5.1 and Thm 5.2 requires some conditions on W_t, which depends on the algorithm rather than the data. For example, the experiments can compare the performance of gradient descent and data augmentation with Gaussian noise.<BRK>The paper considers stochastic gradient descent with noisy gradients. In contrast to the standard setting (e.g., gradient Langevin dynamics) where additive Gaussian noise is added to the model gradient, this work focuses on additive perturbations of data instances. As a result of this, the optimization objective changes throughout the training process because the data is no longer static/fixed but assumed to be sampled from some distribution governing the perturbation process (see Eq.3.3).Section 4 restricts its consideration to multi output linear models. A review of prior works shows that stochastic gradient descent with Gaussian perturbations of the inputs is in that setting equivalent (under suitable conditions on the loss) to optimizing regularized objective with the squared Frobenius norm of the weight matrix acting as a regularizer. The problem is then how to characterize the relation between the standard deviation of the Gaussian perturbation measure and learning rate. The main result is further extended in Theorem 6.1 to mini batch stochastic gradient descent. # clarityI find that the paper is to a certain extent well written. Still there are parts which are difficult to follow and a revision would be required. For example, I have had problems below Eq.5.3 when referring to $Q_{||}$. It is not clear what is being projected to $V_{||}$. # originalityThe title of this work is miss leading and not really sure why this is the case. Given that I am not an expert on numerous settings and versions of stochastic gradient descent it is difficult to assess the originality. Still, I think that the setting with input perturbations is interesting and worth studying. # qualityI find the theoretical contribution non trivial and technical. The first reason for this is in the quite robust nature of Theorem 5.1. The work attempts to give a more readable result in, for example, Theorem 4.1. Are they assumed to hold? I am also not convinced about the related work on data augmentation and stochastic gradient descent with noisy gradients. Dao et al.<BRK>** Authors present a novel theoretical framework for assessing the effect of data augmentation (e.g.mini batch SGD), noise addition and the learning rate setup in gradient based optimization with overparametrized models. Despite the analysis is only performed for linear regression, results extend the well known Monro Robbins theorem on rates of convergence. ** The paper is extremely well written and even being theoretical, authors did an effort for making it fully understandable to non familiar readers. i.e.first paragraphs in section 4. The organization of the paper is good as well, first presenting the type of regression model to be analyzed, the fact of augmenting data, second with the noise additive models and their implications and finally, connecting all the previous insights with the Moneo Robbins theorem for a general result that authors fit with mini batch SGD. Authors recognize the limitations of their analysis since it is focused in linear models, but to me, this is not an issue for this type of paper. The results, focused on three trending methods as data augmentation, learning rate selection and additive noise are elegant, and as authors mention it only relies on first order moments. ** The main weaknesses (to me) in the paper are:[W1]. Data augmentation is described in a very general way during the first 5 6 papers without much description, and, in the last page, authors focus on the particular case of mini batch SGD. I understand the reasons for doing this, but preferably, a comment on the application to the mini batch SGD case would help at the beginning. So, connections are difficult to establish with the results and the argumentation. Could authors enumerate or describe cases/examples of data augmentation different from mini batch SGD? Just a silly question, in this case, could the expectation operator work as a lower bound? [Q5].I do not see why V_{||} in Eq.5.3 is independent of t as mentioned below Eq.(5.4).The expected value remains stable? [Rec2].Similarly as Rec1, a bit more of description about Eq.5.12 and the intrinsic time would help. I lost myself a bit on that part. This is an opinion. In my particular review, they answered and solved the questions that I did. I understand the points addressed by the other reviewers and the theoretical limitations of the method. However, I still have a positive opinion about the paper, and I believe that the aforementioned limitations are well indicated in the paper, something that is valuable. For these reasons, I keep my score.
Reject. rating score: 5. rating score: 5. rating score: 6. rating score: 6. <BRK>Summary: this paper proposes a method for learning with label noise. This paper shows that the combination of these methods are effective for label noise learning. Strength: this paper studies an important problem; the combination of existing methods is intuitive, and each method plays an important role; the paper is mostly well written and easy to follow. It is fine as long as the experimental results are strong, which I am not fully convinced. 4.How important is AugMix to the model s performance? 5.The results in Table 5 (robustness to data shift under label noise) is expected because AugMix does not consider label noise. Hence it is hard to justify the value of this experiment. Experiments on synthetic noisy datasets alone cannot fully justify the effectiveness of the method, because real world noise can be more complicated.<BRK>A lot of details about experiments are provided in the main paper. The label noise is modeled using a probabilistic (and conditionally independent) transition matrix that changes the label of one class to another one. perhaps toy examples with diagrams could be helpful. Suggestions:  The paper would improve if Table 1 and the ablation study can include the results for ImageNet as a more realistic dataset as well .<BRK>Hopefully the authors will address these concerns in the rebuttal period. Positions the proposed approach on how the existing techniques are combined and further improved. + Solid experimental results, although having results on other benchmarks does not hurt. However the ImageNet results dominate. Cons:  Motivation for this work can be further improved (In the Introduction in Paragraph 1). The proposed technique is a combination of methods in literature. From the results, it does not appear that way, i) please clarify, ii) if not setting those noise ratios might benefit the paper even more because the baselines might perform even worse.<BRK>They show that on CIFAR 10, CIFAR 100 (with 40% and 80% corruption) and ImageNet (with 40%) corruption, their approach outperforms all baselines, often by a considerable margin. **Positives:**   This approach clearly outperforms all the compared baselines (to my knowledge, they aren’t missing any comparisons)   The experiments are quite extensive. **Recommendation:**The main contribution of this work is the ECR term, which uses an idea from semi supervised learning to match the prediction to a “mean teacher”. By extending it to use multiple augmentations, they improve results over using a single augmentation (without mean teacher Laine & Alia, 2017) or without augmentations (vs. a mean teacher, Tarvainen & Valpola, 2017). The question is whether this combination of loss terms is a significant enough contribution. I think it’s borderline, but since the performance gain is so significant and since I can’t think of any way to improve the work, I’ll lean toward accepting.
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. rating score: 5. <BRK>Summary: The paper proposes a method to protect deep neural networks against model stealing. The propose defense trains an ensemble of classifiers using two losses one targeting accuracy and the other diversity of the ensemble. Despite the concerns below, I vote for accepting the paper. The addressed issue is relevant, the proposed method is interesting.<BRK>This paper proposes a simple but effective way to avoid model stealing. To the best of my knowledge, the idea is novel. The writing of this paper is quite clear and experimental results also show the effectiveness of proposed method. By introducing diversity loss, the model ensemble tends to produces discontinuous outputs which is hard to be distilled. I still have some questions:1.<BRK>The approach introduces discontinuities in the input prediction space by (i) training an ensemble of models such that for a given OOD input, the predictions are randomized (ii) at inference time hashing an input to a particular input in the diverse ensemble. As a result, I wonder if an attacker can exploit the hashing function to recover whether the output is clean/poisoned   such as by aggregating predictions over a set of transformed inputs. This is also shared by some other reviewers. However, going by Fig.6 it does not necessarily seem to be the case.<BRK>This paper proposed an Ensemble of Diverse Model to provide diversity prediction for the adversary’s OOD query. 4.The query budget of the adversary is set as 50,000. Pros:1.The idea of using ensemble of diverse models to create discontinuous predictions on OOD datasets is interesting. 2.As mentioned in the paper, the hashing function requires transformation invariance, so that the adversaries cannot get the average prediction.
Reject. rating score: 4. rating score: 6. rating score: 6. rating score: 7. <BRK>The set kernel representation of a bag is obtained by weighted averaging of item embeddings, where the item specific weight is the output of an exponential family model. The conclusion is that transformers learn a kernel or similarity function that can be assigned to a reproducing kernel Banach space. The section 5 concludes with a representer theorem and regularized risk minimization problem in reproducing kernel Banach spaces. Again, this is a completely disconnected part of the paper from the introduction and provided motivation. Related work on learning with similarity measures, indefinite symmetric kernels, and general similarity functions seems to be well covered. It is unclear to me why this work would be associated with attention models and transformers. The story just does not hold and it does not explain the scaled dot product attention.<BRK>In this paper, the authors treat a particular Transformer, "dot product attention", as  an RKBS kernel called "exponentiated query key kernel". The problem and the correponding representer theorem is new due to its extension to Banach space. Pros:The idea of understanding how Transformers work with the help of non mercer binary kernel  is interesting. As for the theoretical side, authors provide representer theorem to binary kernel learning for Banach space rather than Hilbert space. I think the proof is just a generalization of kernel learning problems on RKBS, without too much difficulty.<BRK>Review: This paper demonstrates that transformer models with dot product attention based scores are inherentlylearning feature representations in reproducing kernel Banach spaces. It would have been nice to see more experimental results (see below). +Positives: + The paper for the most part is clearly written and establishes a connection between the recent method and the classicalmethod. I have skimmed through most of the proofs and they seem to be correct. Concerns:   The experimental section is fairly limited since the majority of the paper focuses on more theoretical aspects of transformers. In particular, it would be interesting to see the authors expand upon whether exponentiated dot products are better onmore datasets. The theoretical contributions in this paper are interesting but mainly pieces together results. Minor comments: * Proposition 1 has typos in Equation 7a and 7b.<BRK>The paper aims at making a link between kernels in RKBS (indefinite and asymmetric kernels) and the dot product attention of Transformers. The paper contains several contributions on top of this link : it provides a novel kernel machine that can deal with data from 2 distinct input domains and a cross domain output, it show that Transformer can learn such kernels, and it also give hints on what make Transformer efficient. From the transformer s perspective, being able to plug any well designed kernel in place of the dot product attention can have some interesting practical application. It might have been a paper by itself. I vote for accepting the paper, as I find the idea interesting, I can see some applications and the theoretical part seems correct to me. My main concern is about section 6, which contains only one experiment. It illustrates the fact that one can change the kernel in transformers, but not much more.
Accept (Poster). rating score: 8. rating score: 7. rating score: 6. rating score: 5. <BRK>#####################Summary and contributions:The paper provides a novel approach to normalizing flows. It models a normalizing flow as the gradient map of a convex potential function. The paper is very well written. The motivation for using CP flow is well explained. 3.The claims are well supported by theoretical proofs and empirical studies.<BRK>By parameterizing the flow as the gradient of a convex potential function ($R^d \rightarrow R$), this method improves the parameter efficiency of invertible models. The theoretical results are supported by the empirical evaluation which, despite lacking scale, is sufficient to demonstrate the potential of the proposed method. Concretely, an optimal transport map is constructed for the quadratic transport cost. I believe the paper is a good contribution to the literature on normalizing flows; therefore, I firmly vote for acceptance.<BRK>In particular, the push forward map that generates the desired distribution is characterized by the gradient of a strongly convex potential function. The proposed CP flows are proved to be universal density approximators and are optimal in the OT (2 Wasserstein) sense. This limits the novelty of this paper. Another contribution of this paper is to study universality of the CP flow model as a density approximators. 3.More on the writing of the paper.<BRK>### SummaryThe authors introduce CP Flows, a way to parameterize normalizing flows by constructing an input convex neural net with softplus type activation functions and considering its gradient as the flow. Using convex optimization techniques their method only needs access to convex optimization solvers. ### Strong/Weak Points+ The ideas described in the paper are simple and easy to understand. + The paper is generally well written (with exceptions detailed below). + All the results are asymptotic. It s Monge s formulation for optimal transportation.
Reject. rating score: 6. rating score: 6. rating score: 6. rating score: 6. <BRK>#################################Summary:The paper proposed to adopt differentiable network architecture search (DARTS) for the co design of the sensor (a lensless camera) and the deep model for visual recognition tasks, so as to maximize the accuracy and minimize the energy consumption. #################################Justification for score:Overall, this is a paper with a very interesting idea and solid experiments. Yet, the problem setting is limited and the modeling has some issues.<BRK>The proposed method optimizes both the PhlatCam sensor and the backend CNN model simultaneously. That is, the coded mask in Phlatcam and neural network weights are regarded as learnable parameters. Extensive experiments and ablation studies are presented to show the effectiveness of the method. Overall,  I think the paper is interesting and properly designed. The derivation and formulation look interesting.<BRK>##########################################################################Summary: SACoD presents a novel attempt to integrate the computational capabilities of a lensless imaging system, PhlatCam, with the search for the optimal convolutional neural network design for a given task. SACoD provides a framework which enables joint optimization of sensor and CNN resulting in IoT devices that achieve higher task accuracy’s with limited resource budgets of a typical IoT system. The proposed solution is unique in attempting to utilize the computation capability of PhlatCam imaging system. ##########################################################################Reasons for score:  The paper presents a sound theoretical description of the SACoD approach along with their optical layer design.<BRK>The paper addresses the practical application level problem with joint optimization from front end sensor to back end CNN algorithms. As it is not specified in the paper, I assume you adopt the default search space, which contains only the 10 operations, and I wonder what is the best set of operations among them that best for the sensor data?
Accept (Poster). rating score: 8. rating score: 7. rating score: 7. rating score: 6. <BRK>The results on Sigmorphon are strong in the sense of obtaining comparable accuracy to simple rule based approach, which itself is very simple and has many incorrect examples it constructs, but do not clearly outperform it. This paper presents a prototype based method for data augmentation based on a generative model without rule/template based requirements.<BRK>Summary: The paper proposes an interesting approach to systematically generate new examples and augment the training data with these examples. The paper addresses one of the interesting and important shortcomings of current neural models: the ability to generalize to rare and unseen sequences. The design of the prototype based data augmentation method is reasonable and interesting.<BRK>Summary:* Motivated by the fact that certain datasets require modeling compositional phenomena, the lack of flexibility of highly structured models, and the strong performance of large unstructured models on unstructured data, this paper approaches the problem of getting unstructured models to generalize on compositional data. * Prior work showed that a simple rule based data augmentation approach could allow unstructured models to generalize on compositional data. This provides a path forward by continuing to iterate on the augmentation procedure. The method is simple and is broken down cleanly into recombination and resampling.<BRK>####Summary: To tackle situations where compositionality is mostly required at inference time, the paper proposes a novel data augmentation method with an RNN based generator (recombination); to make the generator generate highly compositional patterns, the paper proposes a resampling method. The authors say in the introduction that the approach (Andreas, 2020) is task specific which seems not correct. The paper has explained and empirically showed that this learned generator needs a resampler.
Accept (Poster). rating score: 7. rating score: 7. rating score: 7. rating score: 6. <BRK>The paper tackles the optimization speed of the deep neural networks. This interesting paper may help expedite the compilation time of the deep neural networks. As such, this paper tackles on a very important problem. Modeling uncertainty to understand the gains of optimizing a particular operator is very interesting, and the way it leverages this to schedule the optimization process itself is novel. It seems that the approach can be generically combined with different optimization frameworks such as genetic algorithms.<BRK>The three drawbacks of the existing approach/challenges in DNN compilation highlighted in the paper are (1) optimizing individual tensor operator performance instead of that of the entire model, (2) Static scheduling is oblivious to the optimization behavior, (3) extrapolating estimated performance while tuning. These curves capture the variability of operators across training duration, which helps with (1) and (2). The authors then design the DynaTune Algorithm base on a well known UCB algorithm to solve this problem. Pros:The problem of optimizing DL architectures is an important problem, as they are ubiquitous. However, I am not sure if a better baseline is available.<BRK>In this paper, the authors develop DynaTune which achieves faster convergence speed to optimize a DNN model when compared to the state of the art DL compiler, AutoTVM. The key idea is a time slot based scheduling method based on UCB type multi armed bandit policy. The idea of using MAB in DL compiler is very interesting. My concerns are as follows.<BRK>##########################################################################Summary:The paper proposes an algorithm to optimize the auto tuning time for compiling neural networks. It dynamically allocates time to different operators with a multi armed bandit algorithm and a Bayesian belief model. The code of this method is merged into the TVM project (https://github.com/apache/incubator tvm/blob/main/python/tvm/auto_scheduler/task_scheduler.py), which is the baseline of DynaTune. The weight of an operator is the number of the appearance of it in the network. This is not true because different operators can share a cost model. ##########################################################################Suggestion for improvement:The authors can improve their formulation and add a comparison with the related paper I mentioned.
Reject. rating score: 3. rating score: 5. rating score: 6. rating score: 7. <BRK>Pros: The paper addresses an important problem of causal discovery from heterogeneous data. Cons:I have doubts about the correctness of many conclusions in the paper. For example, it looks to me that for Theorem 1 to be true, the pooled data $D_C$ must be i.i.d.samples from distribution P(V,C). The problem setup simply assumes we are given $n$ data sets from $n$ domains. However, this may not be a realistic setting, and is not how the problem is set up in the paper.<BRK>This paper studies an interesting problem of causal discovery from heterogeneous data, and does a comprehensive survey of related literature. The difficulty of causal discovery in multiple domains is not clearly shown in the experiments. 3.There might still be some important aspects of the method left to evaluate. This paper studies a problem of causal discovery from heterogeneous data, the problem is well motivated, and the authors give a comprehensive survey of the related work. Here are some concerns about this paper:1. 2.As for the writing, some parts of the paper are not very easy to follow for non experts.<BRK>The proposed criteria are interesting. Algorithm 2 and Section 2.4 need more details. Questions: The authors tell that the proposed criterion can identify more causal directions compared to the state of the art. I did not really find any confirmation of this statement. Section 2.3: Why do we need $\theta$? I see that it is also the formulation adopted by Huang et al., 2019, but why the  augmented  graph is needed? Section 2.3: "the dependence can be described with covariance": I agree but what about causality? (Section 2.4) In experiments: is a CPDAG a causal graph? We need at least some assumptions.<BRK>The authors address this problem by augmenting the dataset with an indicator variable which indicates membership to  dataset. (3) Can the authors provide intuition on whether this degeneracy will also become an issue if there are errors in the skeleton detection algorithm? Overall, I think this is a sensible idea and contains some nice results. I do have a couple of questions: (1) In the paper the authors explicitly limit the algorithm to the case where all domains observe the same variables, however it seems like this need not be the case?
Accept (Oral). rating score: 8. rating score: 7. rating score: 7. rating score: 7. <BRK>The paper proposes MONGOOSE, which is equipped with a scheduler to adaptively perform LSH updates and learnable hash functions to improve query efficiency. Experiments demonstrates the effectiveness of the proposed method, and ablation studies give the readers further insights. +++Cons.The paper is overall good, but with some minors, such as “Figure 5 shows P@1 and P@5 for MONGOOSE and other baselines during the training process.” in Section 4.1.1. By the way, I’m curious about why you named your method “MONGOOSE”?<BRK>This paper studies how to do this in a principled way using data dependent LSH updates and backs it up with experimental data. The paper also talks about how to identify the layers that benefit the most from this scheme. then it goes on to show the training time benefits of the smart scheduler and the update scheme on extreme classifications tasks as well as transfomers. Why is LSH the better choice for ANNS here? I would more strongly recommend this paper if these questions  can be addressed.<BRK>Pros:1.First of all, I like the problem the authors focus on. Does it have any connection with \epsilon_{mds}? Efficient NN training is very necessary. The idea of using LSH for acceleration is a good direction. The authors also conduct many experiments to validate this observation. In summary, I like the motivation and the observation in this paper, and the method Mongoose looks good, but I still have many concerns about the idea. 3.The presentation is not very clear. Update: Thank you for your new experiments and detailed feedback. Thus, I raise my rating and recommend this paper to be accepted.<BRK>Clarity and the presentation can be improved significantly. I believe the figure 1 should clarify the LSH update scheduling, but it is not very clear. Originality and significance:I believe that the ideas presented in this paper adds nice contributions to the ICLR community. are there any quantifiable properties? I am willing to increase my score if the concerns mentioned above are properly addressed. I believe the idea of using LSH for efficient training has a lot of promise and this paper brings a possible way to do this into light.
Reject. rating score: 3. rating score: 4. rating score: 5. rating score: 9. <BRK>The authors present an approach to pre training of an ANN which utilizes a purportedly novel approach. The paper is well written and his mathematically rigorous. The mathematics appears to be correct. It is a concept paper, which I appreciate. The paper puts the proposed approach in juxtaposition with the greedy, layer by layer approach. The authors show improved performance on a handful of tasks against some baseline tasks. The authors provide some experimental data analysis showing that the features learned by the hidden layers in the proposed approach are more easily interpretable by humans. Are these methods unrelated in some way? This work should be tied back to these approaches.<BRK>The theory is conducted under linear cases while the authors claim it can be applied to more complicated scenarios such as higher dimension and with nonlinearity. The experiments demonstrate the performance of proposed model on classification tasks and generative tasks. Several baselines are compared. The theory does not apply to higher dimensional cases or nonlinear cases. The discussion seems trivial. Throughout the paper, the "pretraining" process is not clarified. The authors have clarified the method in their response. I tend to agree this is a promising idea and worth explored. The method in the paper needs to be clarified.<BRK>This paper proposes an auto encoder pre training approach for regularising the neural network parameters, which can be used in many different existing neural models. The proposed approach is build based on the unsupervised auto encoder pre training and the orthogonality constraints. The writing of the paper needs to be improved. 3.The motivation of the proposed models but not utilize other models for the problem is not clear. 4.My main concern is the organisation of this paper, where the current version is not suitable for general readers in different domains. Overall, this is good work that uses a simple method to improve the generalising capabilities of many models, but there is a number of weaknesses as indicated above. However, not of all my concerns are well addressed.<BRK>The authors also show a highly efficient way to integrate the actually computational very expensive loss into neural networks. OriginalityThe proposed is, while inspired by previous orthogonalization approaches, a novel idea and its relation to previous work is discussed appropriately. SignificanceUnsupervised pretraining in itself has a large significance for deep learning, even though it lost in popularity due to other approaches that achieved a similar result without the extra preparation phase of the neural network training. It is important and useful to keep the research in this area alive and the authors contributed very valuable knowledge with this paper. Pros:  very promising approach for pretraining of neural networks  well written paper with good illustrations  large experimental evaluationCons  derivation only for networks without activation function  evaluation very much focused on image tasks  Figure 5: legend hardly readable (kind of true for many figures)  source code not referenced (might be due to remain anonymous during review)
Reject. rating score: 4. rating score: 6. rating score: 6. rating score: 6. <BRK>The key idea is to evaluate an architectural setting on a miniaturized network as opposed to the original network. Much of the paper is not well written, and difficult to understand. However the authors combine the petri dish with ground truth evaluations (Sec.3.3) but this is not clearly presented in the introduction. I note that evaluation was not performed for CNNs. Also it would be nice to see the performance of this approach on standard NAS benchmarks such as NASBench. Another shortcoming with the proposed approach is that the authors haven t proposed a  general purpose  method to create petri dishes, and only width reduction is explored. Cons: See above.<BRK>tHe paper proposes a method for quickly and cheaply determining the value of aparticular motif in neural architecture search by isolating it in a "petri dish"that allows it to be evaluated without having to train an entire network. The idea is interesting and seems very promising. As the authors say, itaddresses one of the bottlenecks in neural architecture search   the presentedresearch deals with an important problem.<BRK>##########################################################################Summary: The paper provides a novel surrogate model method for Neural Architecture Search. Authors explains the concept of evaluation of small motifs with synthetic learned training and validation data that can predict the performance of larger network. Leveraging this, authors proposes speeding up the problem of Neural Architecture Search. Also I think the idea of motif for architecture search deserves more attention. Result section is also well structured. Although the paper puts a lot of importance on motifs, but it does not explain a standard way to generate the motifs for any kind of networks, which makes the scope a bit narrow. I thought that would have shown more impact in the result. What is its best performance?<BRK>The current search methods are often too prohibitive computationally, so this is a useful contribution. The idea is well motivated, and also quite general in terms of its applicability. It would be very interesting to see the performance of the method across different datasets as well as across different hyper parameters.
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 6. <BRK>The paper proposes a method to optimize the parameters of the Hybrid Monte Carlo (HMC) algorithm (the step size and the diagonal of momentum s covariance matrix). In order to do that, the authors consider the distribution of samples q_T() obtained after T iterations of the algorithm (T accept/reject steps) starting from some distribution q_0(). However, the evaluation of the KL divergence includes the entropy of q_T(), whose density is intractable due to numerous accept/reject steps. The proposed solution to this difficulty is to ignore the entropy term and maximize the log density of the target on samples from q_T(). This paper proposes a more general objective for parameter optimization explicitly fostering high entropy of the proposal. Moreover, in contrast with the learning step of q_0(), it operates in an adaptive manner, not requiring any pretraining steps. 3.Given the limited theoretical novelty, I would expect the ICLR paper to demonstrate highly successful empirical results. However, it is not the case for the current submission. I don t find the comparison of marginal distributions on the 60d problem to be a convincing way to compare samplers  performance.<BRK>Summary:The paper introduces a gradient based approach for tuning the step size and the diagonal mass matrix of HMC together with the parameters of an initial distribution for the Markov chain. The approach is illustrated on 2 d toy models, deep latent Gaussian models on (Fashion) MNIST and molecular configurations. The paper argues that “Since HMC, by construction, cannot collapse to such a point mass, we argue that the entropy term can be dropped provided the initial distribution of the chain has enough coverage of the target”. While this might be an unrealistic example, it is not clear to me how such situations can be avoided in general. The ideas proposed in the paper are indeed interesting. Can this be backed up more concretely?<BRK>Summary: the article proposes to tune an HMC sampler by maximising E_\param[\log target(X_T)] over the parameters of the HMC sampler. Furthermore, the article studies the influence of the initial distribution. While the approach is certainly interesting, I have not found the empirical studies satisfying enough. The article considers a vector \epsilon as well as a mass matrix. I have found this part of the paper not extremely well explained. 2.It is indeed also difficult to choose L, and that is mainly what the no U turn method tries to automate. It would have been very interesting to investigate how the proposed method can be used **in conjunction with** no U turn type strategies. 6.Finally, while the 2D examples are certainly very interesting, I am not convinced that directly going from 2D to super difficult target is the right approach to understand the properties of the proposed methods. In summary, I think that the authors are proposing an interesting line of research, but more careful numerical investigations are necessary to really understand the worth of the methodology.<BRK>### Summary:This paper proposes a variational inference based framework to tune some of the hyper parameters of HMC algorithms automatically. The authors drop the entropy term from regular ELBO formulation, which facilitates a gradient based approach. While dropping the entropy term from ELBO decomposition is heuristic based, the explanations are well formulated, and Figure 1 does an excellent job of getting the point across. ### Concerns:My main concern with the work is that it is often on par with the competing methods I understand that a new method doesn t need to be SOTA on every benchmark and the SKSD enabled variants that achieve this performance are prohibitively slow (see Tables 6 and 9.) I could not help but feel concerned when no discussion was offered for an almost tenfold increase in the computational time for training DLGMs. Alternatively, authors can choose to restructure this some other way; however, it is too important to be left in its current form. If possible, authors can also consider a more careful ablation study to establish the relevance of each component on this toy model. Further, the authors offered explanations for the training time aberrations; if possible, authors can consider including the equally fast variants in the revision to be more convincing.
Reject. rating score: 5. rating score: 5. rating score: 5. rating score: 6. <BRK>3.The construction of the distance matrix for CONFETTI is interesting, but there is no effort in understanding in which sense such construction is efficient, optimal or even why it seems to be a reasonable choice. I do not think that the presented theory is helpful for understanding when the method would work well or not. On synthetic data, the proposed methods perform to the level of ctSNE as well as a second baseline sLLE 1. Removing unwanted variation from high dimensional data with negative controls.<BRK>Description:This paper aims to "factor out" existing prior knowledge from embeddings, by adapting a tSNE objective or from other methods by operating on input distances. A metric property of the definition is proven, and a proof that independent prior distances would not on expectation change the neighborhoods. On flower data, there are no comparisons to others except unmodified tSNE, but the proposed methods may be able to show structure beyond the prior as claimed. Evaluation:The idea of factoring out prior knowledge seems very meaningful, although not completely new. The distance editing seems rather ad hoc; while the result may have a metric property, it is hard to say in what sense this is the "right" way to combine the prior information to the distances.<BRK>The paper presents JEDI and CONFETTI, two approaches to the task of factoring prior knowledge when creating low dimensional embeddings for data exploration. The task is interesting and paper is well presented. I found the experiments interesting   the three case studies are well thought out. In this case, I think the paper would benefit from not comparing to those methods but to use simple baselines of projections that de bias the embeddings to illustrate the advantages of using either JEDI or CONFETTI. Finally, I would like to have seen a discussion on how realistic it is that the prior knowledge would come in the form expected by the authors in real world problems.<BRK>Two algorithms are proposed for factoring out prior knowledge. Given the ubiquity of low dimensional embeddings these days, the paper addresses an important problem of factoring out prior information from the embeddings. Is it even convex? 2).How is the beta parameter of pJSD chosen? 4).The formulation of the CONFETTI method seems a little arbitrary. 5).It seems that, as an application, the proposed methods can also be used for factoring out demographic information from word embeddings. For such applications how would one define the prior distance matrix? The datasets used in the paper and the broader setup seems a little contrived.
Reject. rating score: 5. rating score: 6. rating score: 6. rating score: 6. <BRK>**Summary**This paper proposes a model based black box function optimization on purely categorical variables. Two different representations for categorical variables are proposed, one is an improved pseudo boolean function form capable of representing non binary categorical variables in a compact way and another is to rely on (mathematical) group representation theory after mapping each categorical variable to a cyclic group. Maybe on Eterna 100 dataset, COMBO is not applicable? Even though the test problems are divided into generic BBO and design problems, it seems that both SA and MCTS can be used in all experiments. 4.Up to the experiment section, the paper is presented in a way that the ultimate goal is to find an optimum as few evaluations as possible. However, in synthetic benchmarks, EGO F/G are argued to be better than baselines because of the computational efficiency, which sounds a bit contradicting. In regard to weakness 2, the correspondence between categorical values of a categorical variable and the elements of a group seems arbitrary. Does this mapping affect performance?<BRK>The paper proposes two representations, namely one hot encoded Boolean expansion and group theoretical Fourier expansion, for the surrogate model used for the black box evaluations on purely categorical variables. With the two surrogate models, the authors tackle both the black box optimization problem and the design problem. My concerns are three folds. Also, the simulated annealing and Monte Carlo Tree Search are not fully novel and I seem not to fully see the major changes to these methods. It would be great if the authors could list the major changes to these algorithms to fully show novelty. It seems critical to identify the superb properties of these functions than other alternatives, and a rough range of the problems that work better with these surrogate functions. The variable $j$ is overloaded in Eq (7), as it is both the complex number unit and the integer pair.<BRK>Paper SummaryThe paper considers the problem of black box optimization of expensive functions defined over categorical variables. Fourier representations are proposed as surrogate model by treating the categorical input as the direct sum of cyclic groups Z/kZ (k is the arity/category size). The coefficients of this representation are learned via exponentially weighted update rule. The selection of each subsequent input for evaluation is performed via direct optimization of the surrogate model built over inputs collected previously. Experiments are performed on two synthetic problems and RNA sequence optimization. Detailed Comments  The paper considers an important problem which has multiple applications (for e.g.biological sequence design) in practice. They are very relevant to the paper because all of them consider the setting of "small" data with expensive function evaluations. Tree structured Parzen Estimator (TPE) [2] is another approach that can easily handle categorical variables. Please provide a quantitative description of this reduction of number of terms.<BRK>Here are some scattered thoughts, for whatever they re worth. On the one hand, assuming a surrogate function that is equipped with this ability to generalize, leveraging MCTS and the UCT selection criterion as an acquisition function seems reasonable to me. On the other hand, it seems to me that using SA, targeting a tempered surrogate, might be too greedy and not align with the latest approaches in black box optimization, where some measure of uncertainty is used in the acquisition decision making process. In terms of experimentation, since this paper introduces a new decomposition that is complete and unique, I would ve expected to see some results concerning how well a truncated decomposition fits a known function of categorical variables. As I cannot pass judgement on the novel aspects of this paper, I will be generous with my score and let my confidence score reflect my lack of expertise.
Accept (Poster). rating score: 6. rating score: 6. rating score: 5. rating score: 4. <BRK>Thus it is not clear if the targeted setting involves few or many examples per task. If so, please include those results as well. **Originality and Significance**While the problem of hyperparameter optimization is extremely important and well studied, the main contribution of this work appear to be some modifications to the transfer learning based approaches that leverage the performance of hyperparameter settings on related tasks to tune the hyperparameters for a new task. Please explain the mutation and crossover operations in the Warm Start approach more clearly (preferably with an example).<BRK>Compared to few shot regression in a meta learning framework, I didn’t find the benefits of the proposed approach. But, I couldn’t find the hyperparameter setting for AdaBoos, GLMNet, and SVM in the paper.<BRK>This paper aims to solve the expensive Bayesian optimization from the view of few shot learning by resorting to the usage of deep kernel learning for hyperparameter optimization.<BRK>This paper proposes to simply learn/optimize the deep kernel parameters and hyperparameters of the GP using the data from all tasks (equation 9) and use such a deep GP kernel for BO. This seems to be in disagreement with the setting of BO where the unknown objective functions are expected to be costly to evaluate (e.g., in hyperparameter optimization). How do the results compare when only a few shots are used?
Accept (Poster). rating score: 9. rating score: 7. rating score: 6. rating score: 4. <BRK>Summary The paper extends soft actor critic (SAC) to the batch RL setting, replacing the policy entropy in the objective function with the KL divergence from the behavioral policy. Decision I vote for accepting the paper. The idea of annealing the KL constraint is simple and elegant. Although it is very similar to other constrained policy update methods discussed in the Related Work section, the evaluation in the batch RL setting and demonstration of the improved convergence properties is novel. The execution is of high quality, with evaluations on tabular problems, MuJoCo, Atari, and a contextual bandit problem for movie recommendation. Can one give some criteria when the method is expected to work well?<BRK>The algorithm is tested in several domains (MuJoCo, Atari, and a recommender task). Strengths:  Although the theoretical results are mostly straightforward extensions of existing results, they provide a solid backing to the method. Although code is missing, the method and experiments are reproducible with the provided descriptions. Weaknesses:  There is one very glaring weakness to this paper  the proposed KL regularized approach for offline RL already exists (Wu et al., 2019) & related (Jacques, et al., 2019). On second thought, however, as suggested by the authors in the introduction, gradually reducing $\tau$ provides a mechanism for searching for the "optimal" value which trades between the constraint and learning on top of the proposed benefits of continuation for optimization. I think this is an interesting component of the method. 2019.**Post RebuttalThe authors have addressed most of my concerns. Although the additional experiments on the variance/checkpointing are helpful I would still like to see more discussion in the paper itself.<BRK>Summary of the paper:This paper proposed a new batch RL algorithm based on the continuation method in numerical optimization. Experiments on Mojoco, atari, and a recommender data set shows that the proposed algorithm is effective. The intuition from the continuation method provides a justification for using a decreasing temperature. I think the main merit of this paper is the solid experiment, in simulation tasks with discrete actions and continuous actions, and in a real data set. This contribution seems solid, but I have some concerns about Theorem 1 and important related work that is missed. Later theoretical analysis and practical approximation are all based on the policy iteration algorithm, but Theorem 1 seems to be based on policy gradient. 2.The proposed algorithm seems to be very related to the BRAC framework and the algorithm BRAC with the KL value penalty.<BRK>However, for me the narrative doesn t hold when the authors motivate their method in the context of offline batch policy gradient methods. As soon as the policy parameters are updated, the distributional shift should be addressed via an appropriate change of measure (or via a model). To me, this is the main challenge in the off policy setting and the proposed continuation based solution does not address this issue. Perhaps the paper should have been named differently because the remaining theoretical contributions in the paper do not pertain to "continuation" per se. Theorem 1 provides a bound on the policy gradient methods with a softmax policy (this is different from the "soft" optimality equations).
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 7. rating score: 9. <BRK>This submission integrates the encoder only and encoder decoder Transformer for both understanding and generation tasks through parameter sharing. The authors present a variable encoder decoder pre training approach to unify the two mainstreams in pre training tasks. Comments:First of all, the VECO approach provides impressive results on the different benchmark datasets including both language understanding and generation. It outperforms the previous methods in a non trivial margin, which demonstrates the effectiveness of the approach. Also, the studies and the detailed statements are mostly enough to make evaluations. Despite its effectiveness, I do have several concerns and problems:* In terms of the technical contribution, the relation between VECO and previous works is hard to make a strong difference, for example, BART, UniLM. Therefore, I feel a little bit unsatisfied with the contributions. * As for the shared pertaining method, it is a little bit confused about the parameter updating. For the CS MLM loss, the decoder will reuse the hidden states of encoder output, are these hidden states fixed during the decoder update? Or they will still be updated to the encoder (I know the parameters are shared)? The implementation detail is not so clear. If the encoder continues updating, how can the GPU memory cost differ from the MT fine tuning procedure? * The results are compared in a clear way, however, the parameters are not clearly compared with previous works. It seems the 662M model size is bigger than previous works. This is not the main weakness. Generally speaking, this work is good for benchmark tasks to achieve strong results or a good technical report. Post update:Thanks to the authors for your response.<BRK>In this paper, the authors propose variable encoder decoder (VECO), a pre training strategy for both NLU and NLG tasks. The paper is mostly well written and nicely presented. The authors show extensive results in various downstream understanding and generation tasks, improves performances in most cases. The proposed method is simple and straightforward; and can be readily reproduced in any existing toolkit. I have some doubts on the motivation of separate pre training tasks for encoder and encoder decoder. The authors claims that for previous encoder decoder pre training like MASS and mBART, "it usually requires more computation and memory to match the performance of the encoder only models". What exactly is the additional computation and memory required here? And how is the empirical comparison on these approaches against the proposed one in terms of both model performance and computation/memory cost? Some more comparison with previous pre training approaches should be presented as well, e.g.MASS, BART, MMTE[1], etc. In general, I think the authors did an excellent job validating their method on various different NLU/NMT datasets. However, I m skeptical about the novelty and the general contribution/impact of the paper. Misc:* Table 3, why comparing with different number of encoder/decoder layers for previous methods (e.g.24/6 for XLM R, 12/12 for mBART)? * Table 3, do you also share parameters (self attn, ffn) for baseline methods? How much does parameter sharing contribute in terms of performance and training efficiency?<BRK>This paper targets to unify the advantages of encoder only model and encoder decoder model for multilingual pre training. Given three types of parameters in transformer blocks including Self Attention, Cross Attention and FFN, this paper proposes to train the model for understanding and generation tasks at the same time, where Self Attention and FFN weights are shared and trained for both understanding and generation tasks and Cross Attention weights are trained for generation tasks only. Strengths: (1) The approaches are clear and easy to reproduce. (2) The performance on XTREME and WMT are good. Weakness: (1) Based on my understanding, this approach equals to sharing Self Attention and FFN weights between MLM encoder, MT encoder and MT decoder, which is not innovative enough. (2) More baseline settings could be added for a more solid comparison. For example, for XTREME, what s the performance of IS MLM + TLM, which is pre trained using the full training corpus? (3) what kind of training data is used in the CS MLM task? I cannot find the data detail from the paper. Is  it the MT data? (1) For task IS MLM and CS MLM, do they use both monolingual data and bilingual data? If yes, which type of data is more useful? (3) If the answer to question (2) is yes, then the first line (XLM_{SMALL}) in Table 2 corresponds to XLM R in Table 1 and the fourth line (VECO_{SMALL}) corresponds to VECO in table 2. What caused this difference? (4) In Table 3, different models use different hyperparameter settings, especially encoder/decoder with different layers. This would help to verify that the gain comes from the new pre training strategy, instead of a deeper model. For example, add a baseline model pre trained by XLM R and TLM in Table 1. (2) XGLUE, a concurrent work of XTREMEM, includes both multilingual understanding and generation tasks. I suggest the paper can provide the results of VECO on the multilingual NLG tasks in XGLUE.<BRK>This paper proposes a **unified** cross lingual pretraining method that works well for both natural language *understanding* (NLU) typically done using *encoder only* architectures like mBERT and XLM and conditional natural language *generation* (NLG) tasks like machine translation typically done using *encoder decoder* architectures like mBART. What does "detach" mean here, and how does it relate to optimising the two objectives in isolation? 7.In page 8, "... and then *continue train* ..."  > "continue to train". 2.The paper does a great job of analysing whether the improvements come from the proposed approach which benefits from the encoder decoder parameter sharing and a loss function that takes into account both intra sequence masked language modelling and sequence to sequence mapping or simply from more bilingual data. Disentangling the gains from the proposed approach vs more data is really important to understand and enable better progress in the field, which unfortunately is not always done in prior work. **Bottom line**Overall, I think the pros outweigh the cons and this paper can be useful for the community, although addressing some of the concerns I raised above can make the paper stronger. **Update after the authors  response**The authors have provided a comprehensive response that address most of my comments, and clearly clarified the novelty and key differences with prior work such as mBART (which also seems to be a key concern in the other reviews). Overall, I believe this paper presents a good contribution to the field. In my understanding, the difference between the proposed approach and mBART (which also unifies cross lingual NLU and NLG) is pretty minimal the second paragraph of page 4 mentions that the key difference here is the parameter sharing between the encoder and decoder. Could the stronger performance of the model compared to mBART be simply due to training on more bilingual data? Repeating the ablation experiments as done in Table 2, but comparing with mBART rather than only XLM, would help make the empirical setup much stronger. and $\mathbf{y}$ "He is very gentle.". The pronoun "He" in $\mathbf{y}$ is allowed since there is already an antecedent, Clyde, in the previous sentence $\mathbf{x}$. Could you please say more about this? 3.In practice, the model parameters seem to be initialised from XLM R (except for the cross attention part that XLM R does not have). Having equally positive results where the model is trained from scratch can help make the empirical results stronger. More details below. In page 3, "... is that $\mathbf{Q}   \mathbf{K}   \mathbf{V} ...$".<BRK>These components are then used to either build a encoder only model or an encoder decoder model. They present results on XTREME for cross lingual understanding and on MT for generation. The results on both tasks are quite competitive and clearly shows the benefit of using both monolingual and parallel data with IS_MLM and CS MLM. The paper initializes from XLM R and then fine tunes it on monolingual and parallel data in 50 languages. The authors get +3 average gain over the previous best system on XTREME and were ranked #1 at the time of submission. One of the concerns I have is that the authors are not upfront about their model being in just 50 languages and hence might not be comparable to other models like XLM R which support 100+ languages.xCons:  As mentioned above, please be upfront about training only on 50 languages. This needs to be mentioned in the main text and maybe even in the results table. What would happen if VECO was trained on 100 languages from XLM R? That result would be interesting to see in Table 1. I would personally like to see more ablation experiments: experiments where the amount of pre trained monolingual and parallel data were reduced independently to see the impact it has performance. Minor comments:In Section 4.1, kindly cite all the representative tasks in XTREME as suggested here:https://github.com/google research/xtreme#paper  It would be great if the authors stated the number of monolingual and parallel examples explicitly in Section 3. Appendix A doesn t provide the number of examples but just the size (1TB) of parallel data used. How many languages do you get monolingual data in? It s not clear from the paper. Also, please be explicit about the number of languages supported in the model (50). One can argue that this is not a fair comparison against XLM R since it s trained on 100+ languages. Change "Ours implementation" to "Our implementation" everywhere.
Reject. rating score: 4. rating score: 4. rating score: 4. rating score: 4. <BRK>### Summary of the paperThis paper proposes to improve retrosynthesis models with pre training and self training techniques. The pre training based approach greatly improves the seq2seq retrosynthesis model and achieves comparable performance against graph based methods. For pre training, authors try different options of the pre training dataset (USPTO, USPTO MIT). It is simply training on a larger training set, leveraging additional data. The self training approach is not novel either   it is a simple application of back translation, which is well studied in machine translation in NLP. From Table 2, we can see that current state of the art are graph to graph based approaches. ### Overall evaluation and suggestionsI vote for rejection. I am afraid the technical novelty is too weak for ICLR. To improve the paper, authors should try to apply pre training to graph to graph models, which may lead to new state of the art results.<BRK>This work examines different datasets and strategies for pretraining a Transformer model to perform one step retrosynthesis as a SMILES to SMILES translation task. It may behoove the authors to move some of the results and discussion from the appendix to the main text and shorten the introduction in a revision/resubmission. My major concern is that the pre training + fine tuning approach might not be a reasonable approach to use with these datasets. This is a relatively minor domain shift, so it’s not surprising that the pretraining approach works well. However, there is no way to evaluate this because—as far as I can tell—this data is not contained in the submission.<BRK>Concern \#1: Limited contribution  This paper just applies the simplest transfer methods to the existing seq to seq model. Although transfer learning for retrosynthesis is an interesting topic, I think the methodology contribution is very limited. Additionally, there is no insightful (experimental) analysis. I want to note that the transfer learning literature in other domains often experiments with various scenarios (e.g., different architectures, tasks, datasets) to demonstrate the effectiveness. In vision tasks, pre training can improve robustness [Hendrycks 19]. If other metrics (e.g., diversity [Schwaller 19]) are evaluated, the paper would be stronger. More extensive experiments/analyses and/or a novel transfer technique specialized in retrosynthesis should be presented.<BRK>While promising, however, the work is still premature. Unfortunately, the performed experiments do not fully support the claims made, in particular, the investigation is neither "systematic and intensive". With additional experiments, the paper might be better suited for a good chemoinformatics journal where it would find an expert audience, however, for a leading ML conference, this is too little. regarding the experimental setup used and data:The USPTO50k dataset the authors use for validation is a random subset of the larger USPTO full dataset. It is therefore no surprise that a model (pre)trained on the full dataset performs better than a model trained only on a subset of that dataset. Why do the authors not compare the performance on the full dataset then directly?
Accept (Poster). rating score: 8. rating score: 7. rating score: 6. rating score: 5. <BRK>Finally, they propose a simple approach for mitigating the rank collapse and show that this improves the performance of the learned policy in some cases. # Reason for scoreThe authors isolate an interesting phenomenon and present some compelling empirical evidence. # Pros* The main contributions of this work might help us better understand the effects of using bootstrapping with function approximation and gradient descent, a critical aspect of many RL methods. Can these observations be explained by the fact that more updates results in the parameters traveling further from their initial values? * The experiments are well designed and relevant to the main thesis. # Cons* After a very productive and enlightening discussion with the authors, the only noteworthy issue is that this paper contains too many contributions for the format making some of them hard to appreciate. # ConclusionI strongly support the acceptance of this submission. Why would the parameters change at all if I reuse the results of the previous minimization as targets? This is interesting work and I am more than willing to adjust my review if the authors can assuage my concerns. # Cons* This did not feel like an 8 page paper. This is not conveyed in the main body of the paper but seems to be a fairly strong assumption on the form of the bootstrapped targets.<BRK>Identifying feature rank collapse problem in RL algorithms using bootstrapping and gradient descent optimization for value function estimation and pinning down this problem to these two factors. 2.Theoretical analysis of rank collapse based on Neural Tangent Kernel framework and ideas from analysis of continuous time differential equations. In particular, the authors showed that rank collapses near optimal point when fitting resembles self distillation. Overall, the paper contains a very extensive experimental part, theoretical part and very well motivated idea. I understand how the derivative was computed, but I am not sure that I understand what 0 means in dL_0(W_{N:1})/dW_{N:1}. 8.I am a bit puzzled by the fact that Rainbow performance increased, while DQN performance decreased in online settings.<BRK>It is found that after an initial learning period, the effective rank of the feature matrix keeps decreasing. The authors call it a type of implicit under parameterization. ###Pros:The paper is well written, and I can follow the idea very smoothly. The implicit under parameterization phenomenon seems very intriguing and useful for designing better bootstrapping based deep RL methods. This implies  $c 0$ in Eq.(1), which would make the subsequent analysis problematic. It would be much helpful if some extra experiments with kernel models can be added, for which we can directly compare the experimental results and the theoretical analysis. 2018.### Post rebuttal CommentsI thank the authors for the response and the efforts to update the drafts.<BRK>This paper discusses a phenomenon wherein the feature vectors of the learned value function in reinforcement learning (RL) lose their diversity as training progresses. The paper argues that bootstrapping results in reduction of the rank of the feature matrix as training progresses for these models. I have concerns about the experimental findings of this paper and correctness of its theoretical claims, which are discussed below. I am willing to increase my score if the authors can convincingly argue otherwise. Broadly, I agree this is an interesting direction but current manuscript does not convince the reader that rank collapse is indeed the cause of degradation of performance. This suggests that there are other factors which are causing the drop in performance instead of/in addition to the rank. 3.The narrative will benefit from being more precise.
Reject. rating score: 5. rating score: 5. rating score: 5. rating score: 6. <BRK>This paper analyzes the behavior of Bellman update in cooperative multi agent setting, when the value function has the form of a linear value decomposition of individual Q function per agent. The theory proposed in the paper looks interesting. It can be a good contribution to the research community. I don’t see very strong connections between the theoretical analysis and the empirical studies. Shouldn’t we compare the two terms with relative error? It looks like a lot of ablation studies are needed to make the connection clear. Without relaxing this assumption, I have concerns that the theory is not substantial (which are also concerns from other reviewers like R3). I thank the authors for additional experiments. Note that in addition to the proposed theory, there are many possible explanations of the empirical results presented by the authors. Without detailed analysis, it is hard to tell.<BRK>The theoretical understanding of MARL with linear value decomposition is limited at the moment. This paper is inspired by the current limit of the understanding and it provides a series of theoretical characterizations. The greatest contribution of this paper lies in that it proposes a closed form solution to the Bellman error minimization derived in FQI LVD up to some term in s. Implication 1 is rather obvious, and Implication 2 is an interesting explanation of the current limitation of linear decomposition. As the paper does not propose a new algorithmic approach, these theoretical implications can be limited. I believe that the information included in this paper might not be very sufficient. Pros:1. this paper is of clear logic. b).The results and conclusions are solid verified by comparing the performance of different algorithms. However, in the literature review part, VDN also realized a multi agent credit assignment. Or, is there a connection or difference between the credit assignment of the two solutions? I think the author should make more elaborations here.<BRK>Strengths:+ The paper captures an important essence of lasting and meaningful research to deconstruct and provide some understanding of some of the latest MARL methods. In that aspect, the reviewer sees the need for more papers like this. It reads as though the assumptions are excessively strong to the point that the theoretical results that follow are natural corollaries. For example, if the transitions do not carry any stochasticity (as in Assumption 1), what need would there be for any non linear value decomposition? The reviewer would very much like to be presented with explanation beyond "decomposition for the sake of decomposition". What kinds of insight can we gather from making a rather strong assumption and further deciding to carry out value decomposition? The connection made between FQI and the more recent works should be explained in more detail. in the eyes of linear value decomposition.<BRK>This paper is largely a theoretical undertaking and focuses on bringing new insights into the currently popular value decomposition schemes like VDN, QMIX etc. for multi agent reinforcement learning. There are some minor issues in the presentation. It would be useful to also draw connections to coordination graphs and their pairwise and higher order interactions of value functions (like that of DCG for example [1]). [1] https://arxiv.org/abs/1910.00091Post discussion: I ll defer to R2 and R4 for judging the theoretical contributions and am convinced that they are not as significant.
Reject. rating score: 5. rating score: 5. rating score: 6. <BRK>While for MNIST this is surely difficult due to the number of writers (and their anonymity), for medical images we will likely have a limited number of raters. It improves on the Prob. This can potentially make interpreting the probabilities more difficult than claimed in the paper, especially since the model is trained with a large number of codes. The discrete model may have a better fit, and make the argument that it is better specified, but this doesn t mean you _can t_ evaluate the Gaussian VAE.<BRK>The paper proposes a conditional VAE like framework to learn the one to many mappings between input and output, leading to an application of uncertainty estimation. 2.Using discrete latent code is not new in VAE community.<BRK>This paper introduces a novel conditional generative model for high dimensional data with multimodal output distributions. The proposed method, called modal uncertainty estimation (MUE), is a conditional VAE but with discrete latent representations. Minor typo:3rd paragraph of the introduction: two consecutive commas
Reject. rating score: 4. rating score: 4. rating score: 8. <BRK>Strengths:+ The proposed method is very interesting. Compared with the 1D NSE, its technical contribution is incremental, and the novelty is limited. Even though the Z order curve can locality information, it is not clear whether the spatial information in 2D data can be preserved. It should be compared in the experimental studies. In addition, it is true that the vanilla version of attention has O(n^4) complexity but there are several improved variants with competitive performance but lower computational cost. The proposed method is also applied to graph data and is compared with GIN. However, for graph data, I would suggest conducting experiments on benchmark datasets. Update after rebuttal I have read the authors  rebuttal.<BRK>Experiments on synthetic data show that the proposed model can outperform baselines. While I believe the extension of NSE to 2D domains is a worthwhile pursuit, I do not believe this paper represents significant progress is this regard. > "All tasks, except matrix squaring, **have** simple O(n2) algorithms." The overall contributions are limited. While flattening 2D data using a z order curve is interesting, it is a well known technique for spatial indexing. For example, [1, 2] also use z order curves in the context of 2D data, and [3] in the context of 3D data. 3.The experiments are limited, consisting exclusively of synthetic data and a single baseline for each task. 5.Child, Rewon, et al."Generating long sequences with sparse transformers." This is concerning as CV seems like a natural domain for exploration, especially given overlapping motivation  between this work and recent literature exploring transformers in the vision domain [4, 5]. As such, while the results are promising, they are not enough to convince me of that Matrix SE is likely to be useful for practical  problems of interest. 4.The presentation of technical and experimental details could be improved.<BRK>Summary: The paper proposes a network architecture called Matrix Shuffle Exchange (Matrix SE) that can learn many logical reasoning tasks on 2D data and graph. More concretely, what kind of operations can be represented by Matrix SE? The theoretical motivation seems to be from the classic result that Benes networks can represent any permutation. However, it s not clear how expressive the proposed model is. Overall, I vote for accepting. The proposed model is simple, can perform logical reasoning tasks on 2D data, and generalizes well beyond sizes that are in the training set. Additional feedback and questions:  Do all the matrices in section 5.1 have binary values? How is accuracy defined in Table 1 and 2. Does the output matrix have to match the label exactly? In Section 5.4, why is Residual SE so much slower (9x) than Matrix SE? I think it should only be 2x slower, because the depth of Residual SE is twice that of the Matrix SE.
Reject. rating score: 5. rating score: 5. rating score: 6. rating score: 6. <BRK>Summary:This paper proposes a new VAE framework for semi supervised problems, which uses the latent representation \\(z\\) to reconstruct input image \\(x\\) and to serve as the features for the classification of the label of \\(x\\). The proposed model is more stable when C increases. With those components, the complexity of the proposed model clearly increases and it seems that without those components the proposed model has no clear advantage over others. There seems to be no clear advantage of the proposed method over others in terms of performance. In the comparison, CPC is with STN but the numbers of M1/M2 are from their original papers.<BRK>The authors developed two constraints (and other techniques like using Spatial transformer, aggregate label consistency) that can better balance the generative and discriminative goals when learning VAEs and other generative models. The paper is easy to follow, the proposed methods look interesting and sound to me. Regarding the overall performance:One contribution, as highlighted in the abstract, is that the proposed method PC VAE and CPC VAE can boost semi supervised classification performance. Regarding predictive constraints:The PC VAE is very well motivated.<BRK>The paper proposes a framework for semi supervised settings to leverage both unlabeled data and (limited) labeled data where VAEs are trained subject to regularization terms from label information. More specifically, the proposed method trains a VAE and a NN classifier simultaneously by optimizing an objective that consists of the usual (unsupervised) variational lower bound, classification error for the labeled data based on the latent space, and consistency term for all data encouraging the same prediction for latent representations corresponding to the original and reconstructed version of a data point. The proposed method is compared with a few other deep generative semi supervised learning methods on three image datasets. +:The paper is well written.<BRK>############################################################################# SummaryThe paper presents a novel methodology for semi supervised learning with variational autoencoders. The model is further extended with "consistency constraints" (an extra loss component that improves the prediction quality). 4) The experiments are thorough. However,the analysis of the relationship between \epsilon and \lambda is not thorough. The issue seems to be fixed by the consistency constraints. This should be discussed and more intuition should be provided as to how these consistency constraints fix the PC VAE model.
Reject. rating score: 3. rating score: 4. rating score: 4. rating score: 5. rating score: 6. <BRK>The paper proposes an exploration scheme for RL in continuous action spaces using the principle of information maximization for globally optimal Q distribution. Further the results show little difference in performance in comparison with DSAC on the mujoco tasks, given that only 5 seeds were used in evaluation, it brings the significance of the results under question. For ex."Proposition 1. 2.A lot of algorithm adaptations are proposed without actually carrying out ablations which make it difficult to discern if the proposed MI maximization is indeed responsible for performance.<BRK>The paper proposes an information theoretic approach to exploration in model free RL, by encouraging an exploration policy that is maximally informative about the optimal (distributional) value function. However in the current form of the paper it s hard to evaluate and understand some of the key ideas of the work. The authors discuss tractable approximation to this objective which can be implemented in continuous MDPs. * There is a use of terminology which might not be clear or known for the general RL/exploration audience ("acquisition functions", "heteroscedastic aleatoric uncertainty"). UCB (and other methods) **are** provably efficient for several problems/assumptions. * Some relevant literature is missing from the related work.<BRK>The idea makes sense however the presentation and its experiment results make it hard to understand some important details. The main contribution of the paper is to introduce an approximation to distribution Q functions that are based on the epistemic and aleatoric uncertainty.<BRK>Experiments show that the proposed algorithm, MQES, outperforms the baselines (SAC, DSAC). For example, Except Sparse HalfCheetah v2, MQES_Q has almost same performance as DSAC. The paper shows that exploring using both aleatoric and epistemic uncertainty can improve the performance. What if we consider only one of them, e.g., using only aleatoric uncertainty? I d like to see this as ablation. Sparse HalfCheetah v2: Could you please provide more details about the environment? > To measure the intractable distribution of $Z^*$ during training, we use the $\hat Z^*$ for approximation Please rephrase it and say that $\hat Z^*$ will be defined later. Eq 20: This is not an unbiased estimation, as $\mathbb{E}[X^{ 1}] \neq \mathbb{E}[X]^{ 1}$.<BRK>One of the main advantages of MQES is its ability to recognise the epistemic and aleatoric uncertainty. Finally, the empirical results are not discussed at all. In general the paper is well written and can be easily followed by the reader. For instance, authors should give more details about the target policy introduced at Section 4.3.
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. rating score: 5. <BRK>*** Summary:This paper proposes a novel continuous conditional GAN which takes continuous scalars (named regression labels) as conditions. There are two problems for continuous conditional GAN: (P1) cGANs with discrete labels are trained to minimize the empirical loss, but this fails for continuous conditions, because there might be few or even zero samples for many labels values. (P2) For continuous labels, the label cannot be embedded by one hot encoding like discrete labels. (S2) The authors propose new methods of encoding the label input: element wise addition for the generator, and linear embedding layer for the discriminator.<BRK>#########################################Summary:The paper focuses on conditional image generation with continuous label. In this paper, authors reformulate the class conditional GANs, and  provide two new objectives (hard vicinal discriminator loss and soft vicinal discriminator loss ) and one generator loss. Specially the continues label never be studied, which is interesting for me. +The paper has good motivation, and is easy to follow. #########################################I have a few concerns which is as followiing:1. or Is it normal issue of training GANs and cGANs? For example, the bird dataset[1] has 555 category,and some categories are close. For example, the label embedding of BigGAN is also be updated.<BRK>##### SummaryThis paper tries to make the generative adversarial network handle continuous, scalar conditions. Specifically, in order to make it work, the author set an empirical estimate that every small perturbation to the condition y results in negligible changes to the conditional distribution. It also provides rich details with the codes in supplementary. 2.As mentioned in (P1) of this paper, there are many real world cases that there are zero or only one label exists. To alleviate such curiosity, I recommend testing it by modifying the label on one of the experiments. ##### Post rebuttal I thank the authors for their thorough comments and detailed explanations for each question. (disclaimer: I did not check the soundness of the mathematical equations thoroughly but did check all the rest)<BRK> This work proposes to perform Conditional GAN with regression labels, thus to benefit the model with data sufficient continuations generation (vs infinite distinct condition for generation). Inspired by VRM, a CcGAN model is proposed to tackle the challenges in existing methods. (Eq.(6)  > Eq.(10))  An error bound is also derived for the proposed new discriminator loss. The idea to facilitate generation with continuous conditions is interesting and insightful. Also, as you argue the deficiency of requiring large sample and condition size in baseline models, comparison regarding the different number of, or scare training data are better to be presented.
Reject. rating score: 3. rating score: 4. rating score: 5. <BRK>(d) The information provided by the images is very unclear. 2.It is very obvious that the authors do not have enough time to polish this paper. 3.The author claimed in the third contribution of their work that their method can encourage on manifold examples. (c) Some notations are absent or inconsistend.<BRK>Post rebuttal  I appreciate the response and the manuscript update, but some of the comments have not been addressed such as the code which has not been provided, and the fact that the results are still very inconsistent like R2 mentioned although the arguments made in this work seem clearer to me. Pros   The paper is well written. The paper tries to address a very important topic of adversarial attacks. The paper provides some interesting insights on dimension reduced attacks, query efficiency and reduced resolution for current methods that use zeroth order hard label attacks.<BRK>This paper studies hard label adversarial attacks, to specifically examine whether such attacks find adversarial examples that are close to the data manifold. The central questions in the paper are interesting. Overall, I think the paper needs more clarity in its experiments. * Why is FID the right manifold distance measure?
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. rating score: 4. <BRK>The authors propose a stronger lottery ticket hypothesis in this paper – the multi prize lottery ticket hypothesis. [a] It would be more convincing if the authors could further highlight the technical novelty of this work for the proof of Theorem 1. The paper has sufficient and novel contributions, both for the theoretical results on binary subnetworks and the empirical evaluations that reveal the efficiency of the algorithm on binary weight subnetworks, so that I recommend this paper for publication. Here are some minor concerns.<BRK>Are the masked weights analogous to the 0 of the ternary networks, while the unmasked weights are in { 1, 1}? Following this analogy, it is also misleading to claim that the network is "untrained", as to minimize the loss, any binarized weights can be updated to 0(masked), although indeed the weight update across 0 is forbidden. The theory works of this paper are strong and prove that the expressive power of redundant binary(or ternary?) Still, the question to clarify here is that whether "subset (lottery ticket) + binary network" equals to "ternary network". In general, the paper is well written and the theoretical and experimental works support the authors  claim.<BRK>This paper propose utilizing the existing "lottery ticket" result for constructing binary neural networks. This work has some novelty, in the sense that I haven t seen any other papers on untrained binary neural networks. The experimental results looks good. However, I have some concerns on this paper. Neither the theory nor the algorithm are well explained in the main text. The subnetwork is sparse, and can be much slower on real hardware. 3.There lacks any discussion on the real time consumption of the proposed network. Post rebuttal Thanks the authors for clarifying and revising the paper.<BRK>The paper proposes an innovate method based on lottery ticket hypothesis to prune a BNN (parameters are only  1(0) and +1, it can be viewed as an extreme case of quantization) from a dense NN. It focuses on learning a mask to prune the NN instead of the traditional method (pruning on an already trained network). Pros: The authors try to express in a way that every step of logical connections in this paper can be clearly understood by readers. So I give the “very low” score on clarity. I regard this work as a new application of LTH to binary neural networks.
Reject. rating score: 3. rating score: 4. rating score: 5. rating score: 5. <BRK>##########################################################################Summary:This paper shows a “generalized mirror descent“ converges linearly if the objective function is smooth and satisfies the Polyak Lojaciewicz condition. My point is to clarify the dependence of the convergence rate on the problem parameters. None.I have not seen a proof showing mirror descent converges linearly with the Polyak Lojaciewicz condition in literature, so this could be a novelty. 5.Isn’t the PL^* condition simply the PL condition with the objective function shifted by  f(x^*)? The "generalization" I mentioned is for the \phi function.<BRK>[Summary]This paper studies the interesting property of generalized mirror descent (GMD) and its stochastic variant for nonconvex optimization problems. First, for GMD this paper shows the linear convergence under PL* condition (in Lemma 1) and finds out a new sufficient condition for the linear convergence (in Theorem 2). Next, this work tried to extend this result to a stochastic setting (in Theorem 3).<BRK>The paper studies 1) the convergence rate; and 2) the implicit regularization of (stochastic)GMD, a generalization of (stochastic) mirror descent where mirror maps can be time dependent. Correctness: I have a problem understanding the proof of Theorem 3. Then, the result claims an exponential convergence rate for SGD to the global optima. Specifically, this theorem is proved under the assumption that f(.) + Can the monotonicity condition in Theorem 4 be restated in terms of strong/strict convexity of the potential function associated with the mirror map? + The sufficient conditions in theorems 2 and 3 are not discussed at all.<BRK>This paper studied an algorithm for solving unconstrained smooth finite sum optimization, called stochastic generalized mirror descent (SGMD). If yes, the paper should point it out explicitly, discuss such consequences and compare with the related algorithms/theoretical results. The main contribution lies in the convergence rate analysis of the algorithm SGMD based on the Polyak Lojasiewicz (PL) inequality, which in turn yields linear convergence rate results for some existing methods such as Adagrad. However, I do have some doubts about the main results.
Reject. rating score: 4. rating score: 5. rating score: 6. <BRK>As a reader and a reviewer, I am not unable to follow the main theoretical point in the paper. The proof of Theorem 1 is not properly explained with ambiguous reference to other articles. I think as a basic principle, the authors should consider readers  convenience and provide a self contained proof and intuitive explanation of the claims. At least they should specify what results from outside are used in their theoretical analysis. The careless treatment of theory makes the manuscript unreadable, and thus the present form is not qualify for an ICLR submission.<BRK>The authors exploit the piecewise linear nature of ReLU neural networks to design a new regularizer that improves the robustness of the neural network. The experimental setup is similar to the one in Croce et al.(2018), which compares the result of different adversarial defense methods on MNIST, F MNIST, and CIFAR10 on small shallow networks. (1) Novelty: The paper can be seen as a twist on Croce et al., working off some of the same intuition and using very similar experiments. Hence, this work can be viewed as incremental. (2) Experimental Results: Given that the set of regularization approaches has significantly grown since the prior paper was published, the authors should at least compare their methods with some of these. This is especially important given that the results are not much better than MMR (and worse in some cases). (3) Computational Considerations: The computation effort needed to incorporate this regularizer should be discussed explicitly so the reader can understand the trade offs between incorporating this regularizer vs. other defense methods. Side note:The authors should update the citation for Croce et al.to refer to the conference version of the paper.<BRK>The paper present some regularization schemes for ReLU networks, based in geometrical properties (polytopes and analytical centers), aiming at robustifying networks against adversarial examples. The idea is to train the network such that the partition of the input space contains many less linear regions, and such that in each region, training points are gathered around the analytical center (and thus far from boundaries), making more difficult the attack task. Doing so the authors can  give certificates for robustness. The proposed approach appears to be competitive in terms of bounds and do so with less hyper parameters than other methods. The idea of using regularization terms to make networks more robust makes sense, the particular proposed regularizers have some quite easy to catch motivation. I would have say that max(LB) min(UB) true minimal distortion ? Fig 3 is unreadable which is a pity since I think it could be some relevant information, its interpretation is quite brief too. Theoretical part seems ok, but I m not familiar with some geometric notions so I might have missed things. I tend to accept the paper but I m waiting for more explanations on the experimental results.
Reject. rating score: 4. rating score: 5. rating score: 6. rating score: 6. <BRK>Strength:  This paper studies a high significance problem of learning representation for visual based control and deep exploration. **Additional Comments**  It would be great to provide more clarification/explanation on how LVE (LOVE with $\beta 0$) and Dreamer are different. Overall, the paper is written well, with a clear motivation and a good organization of the method. Presentation in terms of pseudocode, plot, table, and hyperparameters look great.<BRK>The authors proposed latent optimistic value exploration (LOVE) as a mechanism to leverage optimistic exploration for continuous visual control. However, in its proposed form,  LOVE  is new to the best of my knowledge. However, there are many changes that can cause this improvement. For example, using an ensemble of the models with different transition, reward and value models is essentially using a bigger (i.e.with more parameters) model. Overall, the authors are on the right track.<BRK>For a more fair comparison, the ensemble of dynamics might be ablated (leaving only the ensemble of value functions), or the competing baselines could also be built on top of LVE. Decision  The submission contains little technical novelty over prior work of Seyde (2020). The paper graciously provides the comparison to the fairly tuned baseline in the appendix as Figure 9, confirming this. The fairly tuned baseline needs to be moved from the appendix to the main paper, and the contribution section and the discussion of the experiments need to be rewritten accordingly. In addition, there are two other major issues with experimental evaluation. The experimental evaluation of the paper is rather weak.<BRK>The experimental details presented in the Appendix are quite thorough and did help me understand some aspects of the work in more detail. Finally there are some points which I don’t fully understand based on my reading of the text and for which clarification would greatly help. Was this a hyperparameter? How much slower is the proposed approach to vanilla DREAMER  in terms of wall clock time? Update (Nov 25) I am happy that the authors improved the paper with reviewer feedback.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. rating score: 5. <BRK>This paper empirically studies whether Neural ODEs have a valid ODE interpretation. For instance, the authors do not establish the relationship between step size and number of steps. To address this issue, the authors propose a novel adaptive step size scheme. Pros:  + The work addresses a crucial aspect of Neural ODEs that is particularly important in the context of scientific and robotics applications. It is not intuitive why an ODE interpretation is relevant for computer vision tasks. The authors miss to discuss how their works relates to some recent theoretical results [1,2,3].<BRK>  Paper makes a good contribution by pointing an intrinsic flaw in the NeuralODE technique. The problem is that even with an  error accruing step size, the results of a NerualODE can be good, leading to a false belief that the ODE used in the construct represents the phenomena, but instead it is the dynamic behaviour arising from the mixture of the ODE and the solver that separates the classes well. It seems like a work in progress. The solution is proposed in algorithm 2,4,6 which should have been algorithm 1,2,3. It is not made clear how solvers would be able to use this algorithm. Based upon the contribution made by the authors, it seems appropriate that their results are published right now.<BRK>**Summary** The authors show that Neural ODEs exploit the ODE solver used for training to realize a dynamical system that violates the ODE vector field property of non overlapping trajectories. The authors conclude that NODEs are not real ODEs, hence the paper s title "ResNet after all.". To avoid such behavior, the authors propose to monitor the accuracy metrics using a finer ODE solver and decrease the solver s step size if a discrepancy between the two different stepsize accuracies is observed. However, I see a fundamental issue with the assumption of fixed stepsize solvers.<BRK>The paper proposes an algorithm for adapting integration step size during training so that the resulting neural ODE model is robust to changes in integration method and integration step size at test time. Strengths and weaknesses:I liked the paper as it raised an important question of whether and when we should interpret neural ODEs as having continuous semantics and gave a few examples of failure cases. 2)	Suppose we are integrating an ODE for which we have the analytic form. The results of the step size adaptive algorithm were also promising (it matched grid search but with less work).
Reject. rating score: 5. rating score: 5. rating score: 5. rating score: 7. <BRK>This paper proposes an approach to reducing the sample complexity in multi task reinforcement learning using permutation invariant policies. The main premise of the paper is that certain families of tasks exhibit approximate forms of symmetry, i.e., applying a permutation to the state/action variables would make all tasks similar in some metric sense. An reinforcement learning algorithm to learn a permutation invariant policy is derived. A few minor nits: in the statement of theorem 1, the authors present important quantities in the bound as if they were universal constants (c1, c2, c3). Also it seems that the symbol pi switches semantics a few times   first, it denotes a deterministic policy, then a stochastic policy, and finally a policy network. From a paper claiming to solve resource allocation problems efficiently, I would expect at least the following: clearly articulate the problem. Argue convincingly that this particular problem class is hard (the arguments that N may be small and the simulator may be inaccurate are true for many problem classes). The second issue concerns the application. I believe this paper would benefit from a synthetic application where the difference in Bellman operators can be controlled precisely to see that the problem behaves as predicted by the theory.<BRK>Is it exponential or not? It seems that the paper focuses on multi task learning using RL. How is portfolio optimization a multi task RL problem? The main assumption the paper makes is permutation invariance (PI). It can be formulated as a resource allocation problem but apart from maximizing long term returns what are the other task the agent must perform for this problem. In this case it seems the set is the output of policy network. But then the definition says the left hand side should be equal to both these permutations. This would mean that the rearrangement of state or actions do not change the output of the policy network. I can understand this but not the def in the paper. For what kind of problems does such an assumption/property hold? So which approach is more general, the one in Lazaric et.<BRK>This paper addresses the problem of reinforcement learning using limited training samples. In particular, they present an algorithm that exploits permutation invariance, study its theoretical properties, and propose examples where this property holds and their algorithm can be leveraged. I feel the paper could have been better presented by starting with a motivating example where the permutation invariance property holds   for example the portfolio optimization example studied in the experiments. This will make it easy to follow the multiple terminologies of tasks, entities, resources, introduced in Sec 3. The permutation invariance property is defined in Def. There is no part of the pseudo code in Alg 1 explicitly making sure that the algorithm is permutation invariant.<BRK>This paper addresses sequential resource allocation problem using reinforcement learning, where sample efficiency is the focus of the paper. The paper also designs a new algorithms that prioritizes sampling in multi task learning that addresses the bias between training and target tasks. The results demonstrate the effectiveness of the proposed approach. Some comments:1) The paper gives a good discussion of existing works and where the paper lies in the line; it would be better if the authors can briefly discuss meta RL which is close to the problem being studied in this paper2) The significance of the theorem is well discussed. 3) In the proof of the theorem, it is not clear   what is the high level intuition of the proof? How is permutation invariance property used?
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. <BRK>In the paper the authors analyzed the convergence dynamics toward a minimum of gradient descent (GD) and stochastic gradient descent (SGD). The main result of the paper concerns the fact that, with moderate learning rate, SGD approaches the minimum along the steepest direction, contrary to GD.<BRK>This paper should be rejected as is. I have two main concerns: (1) in the special case of overparametrized linear regression, Theorem 2 only shows that GD with small learning rates converge along the smallest eigenvalue direction. I also do not agree with remark 4. The example experiments (Fig 2) need more detail to be clear and are not sufficient to support the hypothesis in the paper. Questions:In section 3, doesn t Eq (3) show that GD will behave identically to SGD if the learning rate is doubled? Does this affect the results?<BRK>This study shows that, in a setting of linear regression, SGD and GD converge to different directions, which are determined by the largest/smallest eigenvectors of a data matrix when the learning rate is moderately large. Related work is sufficiently introduced. The main theoretical results (Theorems 1, 2, 4) are interesting.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. rating score: 6. <BRK>Recent literature proposed that even label smoothing improves the teacher model, it will hurt the distillation training of student models due to the information erasing. In order to clarify this idea, the paper systematically discussed the correlation between knowledge distillation and label smoothing. Several empirical discoveries are introduced, which are expected to have high impacts on the tasks of knowledge distillation. The major contributions of this paper can be concluded as:1) The paper empirically confirmed that label smoothing is well compatible with knowledge distillation, overturning previous dominant ideas. This is an important finding because it can prevent subsequent research from being misled. 3) The paper claimed that the dominating factor in knowledge distillation is the performance of the teacher and further proposed a stability metric to measure the quality of supervision. This metric is crucial in the tasks of knowledge distillation since it provides a simpler and faster way to measure distillation quality. I think there s no significant weakness on it, so I recommend a clear acceptance for this paper.<BRK>This paper is mainly based on the prior work by Muller et al., which suggests that label smoothing is incompatible with knowledge distillation. Then, this paper argues that label smoothing actually is compatible with knowledge distillation, and show several empirical results as evidence. Lastly, this paper suggests that the performance of the teacher model is a more directly related factor for determining the performance of the student model. (3) Extensive experiments on the image classification task and the neural machine translation task are provided to confirm that label smoothing is indeed compatible with the knowledge distillation framework. In all abstract, introduction and conclusion sections, this paper highlights that "we broadly discuss several circumstances wherein label smoothing will indeed lose its effectiveness". The reviewer does not think it is a good way for presenting the paper, as the appendix is mainly used for explaining some not very important details. Putting the entire discussion of an important contribution of this paper in the appendix is inappropriate.<BRK>This paper shows that the previous argument, "label smoothing is not helpful for knowledge distillation", does not always hold, and carefully re visits the missing points of the previous analysis by Muller et al.Based on this analysis, label smoothing can be helpful for knowledge distillation and can be explained using the intra class variation and between class distance within similar classes. The authors have empirically verified the arguments of the paper with various experiments. 2.The paper is well written and the contributions are clearly explained by comparing against the previous work (Muller et al.) The main analysis is based on the original knowledge distillation paper (Hinton et al., 2015), therefore, it seems to be difficult to apply to the recent knowledge distillation.<BRK>It designs a  stability metric to measure the degree of erasing information and finds that LS can be compatible with knowledge distillation except in long tailed distribution and increased number of classes. 2.Extensive experiments from image classification to NMT are conducted to reveal the relationship between LS and KD and validate the idea of the work. Even this work discusses the detailed relationship between LS and KD, but for me, the finding of this work is not enough to reach the bar of the top tier conferences. 2.The paper has many claims (Bold or Italic), some of that are well known by the KD community, but too many claims make readers lose what is the paper s key insight. [1].When does label smoothing help? In Advances in Neural Information Processing Systems, Muller, et al.After reading the response from the authors, I would like to increase my rating to 6: Marginally above acceptance threshold.
Reject. rating score: 4. rating score: 4. rating score: 7. rating score: 8. <BRK>This paper proposes momentum of memorization as a way to distinguish hard examples needed for efficient learning from noisy examples which decrease classification accuracy. The method finds confident, hard examples and updates them dynamically during model training. This is done by iteratively selecting examples with labels that agree with model predictions and then training on only the confident data. Results show improved accuracy on standard image classification datasets with both synthetic and real world label noise. qualitatively, these look well separated. For example, showing how training/validation accuracy varied with $N_{outer}$ and $N_{inner}$ would support the claim that Me Momentum is leveraging the memorization effect. For example, increasing the learning rate at each epoch would fit the colloquial/physics meaning of "traveling through hypothesis space" just as well as this approach which uses repeated fine tuning. Algorithm 1 and Section 2 would benefit from additional notation in addition to the pseudocode and text explanation  Unclear what the reader should take away from Figure 4 and 10 13 (see above)  typos: "an surrogate" should be "a surrogate", and "clothing1M" should be "Clothing1M"Pro  Nice illustrations and problem description  Results perform well against baselinesCons  Limited novelty compared to SELF and self training methods more generally  Concerns about methodology and clarity, especially wrt visualizations  Empirical methodology/analysis should be improvedQuestions:  How does the running time compare to normal neural network training, and to other baseline methods? Do Tables 1 3 show a similar improvement to Table 4 when switching to clean validation set? How sensitive is Me Momentum to hyperparameters $N_{outer}$ and $N_{inner}$? Will identifying additional confident samples lead to even higher accuracy? Self Training PCFG Grammars with Latent AnnotationsAcross Languages, EMNLP 2009 https://www.aclweb.org/anthology/D09 1087.pdf[2] Nguyen et al.SELF: learning to filter noisy labels with self ensembling, ICLR 2020. https://arxiv.org/abs/1910.01842EDIT: The author response addressed some of my concerns. In particular, it confirms that the experimental results are impressive compared to many baselines. However, I would appreciate the distinction between easy and hard confident examples much more if the authors went beyond illustrative figures and defined this concept more precisely. Without a precise definition, it s difficult to verify the paper s claims about why the method performs well. Next, the authors suggest that methods cannot distinguish hard confident examples from mislabeled examples using the "small loss trick" alone, and that their "momentum trick" is necessary. However, they do not present a principled argument or strong evidence to support the claim. Finally, the authors claim that reinitialization helps escape bad local optima. However, I do not see how low standard deviation supports this claim.<BRK>The technique proposed to extract hard confident examples in this paper is not convincing, even though the experimental results seem promising. *clarity*It is not difficult to understand the proposed method, however, the Figures in this paper are somewhat confusing to readers. *originality*In this paper, the authors focus on extracting hard confident examples from the noisy training data for learning with noisy labels. There is no method to extract hard confident examples before, the idea is novel. How to extract hard confident examples correctly still remains a challenging problem. (2).The proposed method achieves better performance than state of the art methods. Cons:(1).As for the question “How to validate the learned classifiers in Steps 3 and 5 without a clean validation set?”, the authors claim that the noisy validation set could be used as a surrogate to validate the classifiers if no clean validation set is available. (2).The confident examples can be extracted based on the memorization effect, it seems reasonable. But why hard confident examples can be extracted? The authors explained as previously extracted confident examples will help identify hard confident examples, it is so empirical and maybe another explanation is needed here. Moreover, in the corresponding paragraph, there might be some error with “Figure 6” (should be “Figure 2”?). (3).The intuition “better confident examples will result in a better classifier and a better classifier will identify better confident examples” have been mentioned many times, I wonder will the method proposed in this paper stuck in the local optimum when the two loops in Algorithm 1 execute. It would be better if the experiments with lager noise rate (e.g., > 50%) are also conducted. (5).Some minor issues, for example, “extract” should be “extracted” in the step 2 of Algorithm 1; “$\times$” and “*” are abused in Section 3; and the resolution of some Figures in this paper is not satisfactory. Generally, I feel that the method proposed in this paper is somehow too empirical, and more theoretical study is needed.<BRK>This paper propose a novel and effective method called Me Momentum to cope with noisy labels. Pros:1.Different from the existing methods, which aim to identify simple clean examples, this paper analyzes the importance of hard examples and provide a way to identify them. 2.The design of inner loop and outer loop is interesting and insightful, and is proved to be very effective. In addition, compared with SOTA SELF,  Me Momentum outperforms it by a large margin. The authors also provide an ablation study to analyze the sensitivity of the hyperparameter $tau$. Thus, the significance of the proposed method with respect to experimental results may be high in the community. Specific comments and questions:1. The authors should add them to improve this paper. I hope the author can emphasize or add some descriptions of the implementation details of the comparison methods. Some recent methods achieve great classification performance for learning with noisy labels, such as [1]. The authors can compare the proposed method with them to make the results more convincing. 3.The proposed method uses a noisy validation set to choose classifiers, and then identify confident examples with robust classifier. The authors should explain why a noisy validation dataset can be used to choose classifiers which perform well on clean datasets. This choice may not be accurate? For example, “The results are presented in Figure XX”, the authors miss the figure number.<BRK>The authors introduce an interesting approach to handling hard "confident" samples in learning with label noises. The confident samples are initialized by utilizing the memorization effect of deep networks. Then, a classifier is learned from such samples. During the learning process, hard confident data are selected progressively by looking at the classification results, which further better select confident samples. I like the fact that the core idea of the proposed approach finds its root in physics. 3.The results are very promising, in spite of the simple nature. It seems to me that sometimes it requires many rounds in the inner loop, as shown in Fig.3, for example, the number is up to 20 to 30. Please show some numbers in terms of running time and compare them with the baselines. 2.I might be missing something here but, what about the not so confident samples? 2.It would be better if the author could elaborate more on its connection with the momentum in physics.
Reject. rating score: 3. rating score: 5. rating score: 7. rating score: 7. rating score: 7. <BRK>I cannot fully follow the logic of the paper and am not convinced the controls are useful. Strengths:+ Tries to address an interesting question: why does human vision treat the periphery mainly as texture? + In depth investigation of the model and three controlsWeaknesses:  Unclear if the premise of the paper is well conceived  No evidence provided that "foveated" images are actually metameric  "Matched resource" controls are somewhat questionable  Definition of "foveation" seems strangeDetails on major issues (all of which would need to be addressed in a convincing manner for my score to change):My main issue with the paper is that I don t understand its logic. The results by Rosenholtz, Simoncelli, Wallis and others show that some information about the image is discarded in human peripheral vision and, to some extent, peripheral vision "cares" only about the texture statistics of an image rather than the detailed composition. I don t understand what s the reasoning behind this logic. I d like the authors to explain their reasoning better. Having said that, even if we put these fundamental concerns aside, there are a number of practical issues:(1) The presented images don t appear metameric to me, and the paper does not provide any psychophysical data showing that they are. Could the authors provide psychophysical evidence that this is the case? (2) I am not sure about the purpose of the "matched resource" control and why SSIM is the right metric to use here. If it s about information content in the image, I think it should be evaluated in terms of mutual information between the image and the labels (which is hard); if it s about information available to human observers, then a perceptual metric is the right approach, but SSIM is a very poor one that doesn t correspond well with human perception. (3) The claim “greater iid generalization, high spatial frequency sensitivity and robustness to occlusion emerged exclusively in our foveated texture based models” seems to be an overstatement. The only robust difference is between standard+foveation and MatchedNet+AdaGauss, where the latter seem to carry much less information (see points (1) and (2) above).<BRK>Several thorough experiments are performed to assess the benefit of foveation with reasonable control transformations. Appreciate the detailed discussion of all implementational specifics, I m fairly confident about the correctness of the experiments performed and results presented. # Some concerns I have about the claims:I agree with some of R1 s comments, the claims seem to be overstated in my opinion. This is likely because compared to Standard Net, Foveation Net has larger unoccluded information due to the nature of the foveation transform. I see that the authors have attempted to address this question in other comments below. In summary, I doubt whether foveation truly provides more robustness to occlusions in the presented sense. Fig.9C does not seem like sufficient evidence to claim that foveation promotes shape bias over texture bias. As mentioned earlier, find the topic studied to be a very interesting and an important one. I m certain this work will stimulate interesting discussions and future work to better understand the functional significance of foveation. The analyses are thorough and the reported results seem to be accurate. However I doubt whether the proposed claims are justified by the analyses. What are your thoughts on applying foveation like masking throughout the network s activations and not just at the input stage?<BRK>The authors compared Foveation Net with three other stage one visual systems: Standard Net with non foveated transform; Ada Gauss Net as a matched resource control for Foveation Net (to test the contribution of the foveation transformation comparing to other spatially varying processing); Matched Net as a matched resource control for Standard Net. Specifically, the authors did four sets of experiments on these visual systems to evaluate their generalizability, robustness, image region bias, and spatial frequency sensitivity. The results suggest some perceptual advantages and specific representational properties yielded by texture based foveation transformation. It is not clearly stated how to read the plot in Fig.5B.And why using a 20 way scene categorization task to evaluate the model performance? Then are these two visual systems more computationally efficient in general? 3.In section 3.4, the authors argued that the Foveation Net may enforce a shape bias since "these Spatial Frequency curves show similar trend as SIN". Please let me know if I misunderstood this argument. 4.What would be the effect on model performance if the fixation is not in the center for Foveation Net and Ada Gauss Net?<BRK>The paper explores how preprocessing an image with a foveated texture based rendering   where content in the periphery is transformed in a lossy manner but still perceptually equivalent   affects the training of a downstream neural network. It is shown that when equated to other lossy image transforms in terms of overall rate, that the foveated system shows better robustness to occlusion, generalization, and preservation of high spatial frequency content. The many figures are difficult to wade through because the are so compressed and cluttered with many labels and diagrams. I would recommend figuring out a way to prune these down so they are more readable and convey just central punchline that you are trying to show.<BRK>##########################################################################Summary:In this paper, authors study the functional advantages of a foveal transform of visual inputs. The method introduces a 2 two stage model of the visual system, where the first stage corresponds to the (fixed and non adaptive) foveation stage and the second stage to the higher level processing, typically associated with the categorisation operated in the ventral stream of the visual pathway. To control for the functional consequences of the foveated processing, the first stage can also be a single isotropic blurring of the image. Overall, the paper is original, technically sound and very well supported by experiments. However, there are some concerns that I highlight below. ##########################################################################Concern:The  paper is very dense and wants to say too much while perhaps losing on the main point: the foveal transform In particular, there is one point about foveation and another about metamerism (and crowding). While the first is studied in depth, the second is not studied fully, or at least not parametrically. This hinders the comprehension of the mechanisms that may be at play behind the functions of foveation. I consider the iid vs ood and occlusion results to be the most convincing, but at the end of reading the paper, I lack a comprehension of why we have such results, and what hyperparameters play the most important role. The conclusion "that foveation (in general) seems to induce a focusing mechanism (...) while the texture based computation still preserves high spatial frequency selectivity" seem to be a mechanical consequences of the foveation transform (you focus on a point while preserving cone density in the fovea)   did I miss something? Concerning the form of the paper, clarity could be improved in some sections.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. rating score: 6. rating score: 5. <BRK>MethodThe authors essentially create clusters that can anticipate unseen classes. That idea is not new in and of itself but the authors  realization of the idea through mix ups and image adaptive semantics is new and interesting. The authors get an across the board improvement over the state of the art. ClarityThe paper is clearly written and has a good logical flow. I would recommend not using adjectives like elegant and insightful for one s own work. Perhaps such assessments are best left to the reviewers.<BRK>Different from previous generative models that synthesize unseen samples for training the model, authors create virtual classes as unseen classes in the training phase. The motivation and the contribution are clearly presented in this manuscript. In general, this paper is well written. 3.The architectures of IAS and S2V are simple and effective in terms of experimental results.<BRK>The paper proposes a framework for the GZSL using the meta learning and attention mechanism. The image guided attention on the semantic space helps to adapt the better class specific semantic information. The paper learns separate expert for the seen and unseen classes. The unseen class expert is trained with the pseudo negative samples with pseudo negative labels. Meta learning based training helps to learn the model when only a few examples per class are available.<BRK>I.SummaryThe authors consider (generative) zero shot classification. Their approach, combines two main aspects: (1) generating "virtual" classes by mixup interpolation and (2) they introduce an attention mechanism, dubbed "image attentive attention" to allow their approach to model both intra  and extra  class variations. II.Strong and weak points. This is somewhat derivative. Do these extra samples work well with the virtual samples? Is the information redundant/complementary?<BRK>Summary: The authors proposed an interesting method for zero shot learning. In particular, the authors adopted an attention mechanism from the input feature in the semantic to visual mapping, to introduce intra class variations in the visual space. But more details need to be revealed to help readers understand the method (discussed below), and I hope the authors can address my concerns during the rebuttal. 3.The extensive experiments on the benchmark datasets illustrate the superiority of the proposed method. During training, since the seen expert has no data for unseen classes, the classifier is easily biased to the seen classes, even the new data is from an unseen class in the inference time.
Reject. rating score: 4. rating score: 5. rating score: 5. <BRK>The paper is overall clear and easy to follow. The image optimization on the hypersphere is just a projected dynamics, it is not a close dynamics with respect to u. In this sense, the projected dynamics is not simplified compared to the original one. No evidence is shown that L(u) is simpler than L(x). 2.The adaptive gradient methods are adaptive in at least two ways: a) the learning rate is adaptive; b) the learning rate is different for each parameter.<BRK>Or is it a setting that is not supported by the assumptions in Thm. The manuscript does not provide sufficient context to understand what the derived formulas change about our theoretical understanding of those methods or what they imply for applications.<BRK>So I think is the contributions in this work are slightly below the acceptance bar of ICLR before these concerns are solved appropriately.
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 7. <BRK>Summary: This paper introduces a new PyTorch library for computing Fisher Information Matrices and Neural Tangent Kernel (NTK) in deep learning; with applications ranging from Frobenius norm regularization, second order optimization, and generalization analysis. A brief experimental study is provided in the last part of the paper. As an aside, I do not believe there is even a good open source code for K FAC on RNNs especially given the complexity involved. I would suggest cutting down and citing [3]. Also, somewhere in the introduction, I think the authors should make a note of the distinction between the empirical Fisher matrix and the true Fisher matrix (and perhaps cite [4]); and be clear about which one they are working with. Given that this is a library concerned with computing FIM/NTK; there should be some comparisons with existing open source libraries such as JAX and Neural Tangents? This is certainly true  but I cannot see the connection of this to the NNGeometry framework.<BRK>This paper describes a new PyTorch package, NNGeometry, for computing complicated neural network objects, such as the Fisher Information Matrix (FIM) and the Neural Tangent Kernel (NTK). The package seems like a really fantastic contribution to PyTorch. On the other hand, I am worried that this is more of an engineering contribution than a research paper. To the point, all of the methods described in this paper and implemented in the package are based on methods present in other papers. Furthermore, the authors do not use the package to make any novel research contributions. It would be great if a label was included.<BRK>The paper provides a PyTorch implementation for applying Fisher information matrix and neutral tangent kernel as a linear operator. This efficient implementation relies on several existing approximation methods and computational tricks. I think the work is practical as it can be used for many applications, some of which from works that are cited in this paper. 1.I think most of the techniques in the paper are from previous work. 2.The paper focused on implementation, but surprisingly the experiments did not include any scaling/runtime results. I think the authors should show the efficiency gain, and demonstrate the type the applications that are enabled by it.<BRK>### SummaryThe Fisher information matrix and the neural tangent kernel matrix have been used in several recent papers to provide insight into deep neural networks, but operations involving these matrices have so far been less well supported in frameworks such as Tensorflow and PyTorch. The current paper describes a new library (NNGeometry) for working with these matrices in PyTorch, incorporating approximate representations from prior work that are appropriate to matrix vector product computations and evaluation of quadratic forms. However, this seems like a useful software artifact for the particular problem that it tackles. While I understand the space constraints, I would have liked to see more discussion of the concrete matrix representations (Section 2.2.2). I still believe this is worth publishing if there is room, with the caveat stated before: this is an implementation paper, and does not introduce new algorithms or analysis. If it is accepted, it should be accepted on this basis.
Reject. rating score: 3. rating score: 4. rating score: 7. rating score: 7. <BRK>### Lack of theoretical justificationThe proposed method is mostly heuristic and does not have a theoretical basis. ## Overall evaluationI do not think this paper proposes a novel idea with either a solid theoretical basis or strong empirical results. The authors should specify what changes over time. ## Post rebuttalDuring the rebuttal, the authors failed to handle the issues that I raised.<BRK>The paper has the following merits. On the other side, I have the following concerns about the submission. 2. not enough highlight for important parameters (storage and acquisition fractions, b, and a).<BRK>“ > not really specific to deep learning at all to me. I like the ablation studies and would have enjoyed more discussion of their results. Ablation studies are nice, the results of them could be discussed more. The “discovered” confused me here.<BRK>The authors propose a learning methodology designed to offset detriments to algorithm performance that arise when instances are not i.i.d (independent and identically distributed), focusing on cases in continual learning (CL) given physiological signals. Was this low number due to the computational cost of experimentation?
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 5. <BRK>Overview:Overall I find this an interesting algorithm, but have several serious concerns about the (lack of) experimental baselines. My primary concern is that, given this paper is introducing a new hyperparameter tuning algorithm, there are no comparisons to baseline hyperparameter tuning setups. For example, in Figure 3, what is the best final validation and/or test accuracies achieved by autoHyper and by random search, for the same number of trials (one could even run autoHyper first to see how many trials it takes, and then see if random search could beat it in that many trials). Additionally, the suggested initial LRs seem problematic to compare to. Using the information in Appendix D from Wilson 2017, I see they were tuned using less trials than the proposed algorithm, and using a grid search algorithm that may be worse than random search (Bergstra & Bengio (2012)). It is important to call out the negative results presented in experiments, and the authors did a good job of that (when applicable) in section 4.2Concerns: Figure 1a would be much more informative if you showed the entire training trajectory, including past the first 5 epochs, to see if the selected learning rates actually generalize noticeably better. It was initially confusing that the gradient notation was used for the constraint on Eq.5, it would be clearer if the authors stated earlier that they did not compute the literal gradients (which would require backpropagating through unrolled updates).<BRK>In this paper, the authors propose a new hyper parameter optimization method based on a new response function defined on the low rank factorization of 4D convolution weights. Although I am not an expert in this hyper parameter optimization, I think the approach has the potential to speed up and improve the hyper parameter search or neural network architecture search. In my opinion, the demonstrated experiments are less interesting because the focus is only on selecting a single initial learning rate. This is not that interesting because we normally have a learning rate scheduler that will change over time. Also, the presented work would be more interesting if it can demonstrate improvement in other hyper paramter optimization such as weight decay and convolution filter size and channels. There are some questions about the presented approach:  Are all the convolution layers in a CNN used in Eqn (4)? The definition of mode 3 and mode 4 is not clear to me.<BRK>###############################################################Summary:This paper used the knowledge gain to provide an algorithm to choose the initial learning rate. The paper explained the reason that choosing the specific response function and demonstrated the effectiveness of the algorithm by several experiments. ##############################################################pros:1, This paper proposed a dynamic tracking algorithm of low computational overhead on the order of minutes and hours to find a good initial learning rate. 2, The paper explained in detail about the reason to choose the specific response surface function, and demonstrated the reasonability of the algorithm. 2, The algorithm induces some "hyperparameter" again. Does these "hyperparameters" influence the result? 3, The initial learning rate seems only influence the convergence rate for training loss, but why it influences the testing accuracy? Is there any other work about tuning the initial learning rate? Or this paper is the first? 5, minor problems:(1) In equation 1, x is not showed in expectation function (I can only see X(train)), and also, it should be the minimum of expectation, not the expectation of minimum. It solves some of my concerns. However, combining with rebuttal and other reviewers  comment, I think only choosing the initial learning rate is not that reasonable. It may be more convincing to me that the whole parameters are chosen together.<BRK>** SummaryThe paper proposes an efficient framework to search for the optimal initial learning rate to train neural networks. ** Pros1)	The paper studies a very important problem in neural network HPO: how to efficiently model and approximate the response function. Detailed experimental settings and numerical data are also provided, which could be convenient to reproduce. ** Cons1)	The writing and presentation of the paper is not good. Furthermore, the evolving of KG during training may also vary from different layers, while in the formulation above Eq 4 it is just derived by averaging over all layers. So, I doubt whether the proposed metric is universally applicable for different situations. From the experiments, it seems the gain is not that significant. I appreciate the authors  efforts on polishing the presentation. However, after reading the rebuttal and other reviewers  comments, I still feel that the contribution of the paper is not that significant,  since the search space just includes a scalar and the empirical improvements are not strong (Table 5 to Table 8).
Accept (Poster). rating score: 8. rating score: 7. rating score: 6. rating score: 6. rating score: 6. <BRK>**Summary and Key Contributions:**This paper proposes the use of task embeddings for a novel conditional attention mechanism and various task conditioned modules. The paper also proposes the use of an entropy based multi task uncertainty sampling to automatically determine how to sample the data for training the MT architecture. The paper demonstrates the effectiveness of the proposed architecture and sampling through multiple comprehensive experiments and ablations/analyses. * Most of the modifications proposed are clean, well motivated and make a lot of intuitive sense. The overall approach also seems to work well without the need for extensive hyperparameter tuning. Evaluations on GLUE, Super GLUE show the proposed method often outperforming (or at least performing comparably to) several strong baselines, both MT based and single model/fine tuned, and with fewer parameters. However, it seems like the paper compares a CA MTL RoBERTa Base model to a BERT base baseline. This is a somewhat unfair comparison, and it might be better to either clarify or to compare the baseline to the CA MTL BERT Base model (which based on Table 2 would still be a rather impressive 1.3% better while making the comparison fairer). * While I understand that space is limited, Section 2.1 might have benefited from explaining FiLM, its use here and some intuition, to help keep the paper more self contained. And does $\bigoplus$ represent the diag operator? * In Table 5, the total data used was 66.3% (or 64.6%). How was the amount of data to be used determined? Was it perhaps meant to say "ensemble"? Thank you also for baking so much of the reviewers  feedback into your latest draft, in particular by improving how the comparisons are presented in the abstract and the rest of the paper, by updating Table 2 to make it clearer and cleaner, and by adding experiments and analyses in Section 4. As a suggestion pertaining to the latest draft, I agree with R5 that a consequence of the additions to Section 4 have made it a little crammed, although I certainly understand that the constrained spaced forced the authors to make this trade off. Overall, I continue to maintain that this is a good paper with novel ideas that are well justified by experimental results and analyses, and would like to reiterate that I believe that this work is a clear accept.<BRK>Update: see comment below for rationale behind change from 5 to 7. ## Claimed Contribution:This paper seeks to develop a multi task learning (MTL) strategy that performs competitively with single task (ST) fine tuning despite having fewer parameters per task. Some of the task specific module components are similar to the Adapters line of work, with a key difference being that the adapters are trained in a MTL setting versus in ST finetuning. The authors also introduce latent representations of tasks that feed into these different modules. The sampling strategy is well motivated and credibly improves results. ### Pros * Paper is well written, concepts are introduced clearly, related work section is well done. * Ablations in Table 5 are very useful and convincing. ### Cons* Paper tends to overclaim / have some comparisons that don’t have the necessary context. In particular:  * The abstract claim “With our base model, we attain 2.2% higher performance compared to a full fine tuned BERT large model on the GLUE benchmark, adding only 5.6% more trained parameters per task” has a  typo that makes it less impressive, as shown in Table 2. This gap is for a full fine tuned BERT base model, not large. In addition, the authors compare a BERT checkpoint to a Roberta one, which feels like something that should be mentioned upfront. It is worth mentioning in Table 3 that you are comparing a BERT large encoder only model to a ~T5 base encoder decoder. * There are no comparisons to single task finetuned Roberta models. Overall, it seems like CA MTL can capture part of the gains of MTL+ST tuning but still underperform ST tuning on tasks where little is gained by doing MTL. * There is little discussion of when this would be advantageous. ### RecommendationOverall, I think this is an interesting approach. However, some of the claimed results are not as strong when put in the proper context, which the authors sometime fail to do. As such, I think this paper is a slight reject in its current state. With a fairer presentation of the comparisons it might be a slight accept.<BRK>The paper explores a collection of strategies to improve multitask learning and bring performance on par with single task training. Abolation experiments demonstrate the value of the individual components being proposed. The results are particularly impressive given the small number of additional parameters introduced into the model and in the context of prior work that has shown mixed results from multitask training. However, despite the strong results, I still have mixed feelings about this paper. To be a strong accept for ICLR or another similar venue, it think the techniques explored in this paper deserve an alternative treatment that focus on the contribution of the individual methods first and then concludes with their combination. I d like to see the numbers that support this claim. I also found some of the comparisons in the paper somewhat confusing. For example, Table 2 compares a BERT baseline to the authors proposed bag of methods, dubbed CA MTL, combined with a RoBERTa model. If these numbers are to be meaningful, it would be good to include a RoBERTa baseline in the tables. Finally, one of the original motivations for multitask training was that it might allow us to make use of less data for each individual task. While it s great that the paper shows good performance on GLUE using a fraction of the available training data, and good domain adaption with varying amounts of training data, it would be desirable to dig a little deeper. It would be interesting to see something like Table 1 for other tasks being explore in the paper of perhaps using the whole GLUE benchmark (e.g., using less than 64% of the training data and finding the knee where performance drops off).<BRK>To deal with challenges in multitask learning/co training, the authors proposed five improvements, including modifications on the transformer layers with task conditioning and uncertainty sampling. In the experiments, the authors showed that the proposed model can outperform full fine tuned BERT large model with less parameters (adding some parameters on a single co trained model), and with less training data. This paper is very well written and easy to follow. It is also a very meaningful application as pretrain finetuning based approach could be both sub optimal and ineffiicent. The authors also conducted experiments on various types of NLP tasks including GLUE and Super GLUE, compared with baseline methods such as pretrain finetuning BERT model, adapter based approach, and T5. However, I think the paper could improve in the following aspects. Intuitively, they all target at solving multitask learning challenges mentioned earlier in this paper, e.g., capacity balancing on multiple tasks, catastrophic forgetting, negative task transfer and interference. I think more in depth discussion on how each of the 5 modeling improvements solve what aspects of those challenges can singficanlty improve the impact of this paper. For example, the conditional alignment part, inspired by Wu et al.(2020), could have some similar discussion related to the covariate shifts among different tasks. Uniquely, it is less clear such alignment matrix can learn to capture covariate distribution difference with task embeddings co learned from other model improvement components introduced in this paper. I see two lines of related work are missing. (1) There are similar research in NLP mutltiask learning that adopts mixture of expert based model architecture to do soft parameter sharing, for example:[1] https://arxiv.org/pdf/2006.16668.pdf[2] https://arxiv.org/pdf/2007.05891.pdfAnd routing/mixute of expert based task conditioning is somewhat popular in other domains. (2) Dynamic reweighting based optimization algorithms, for example:[1] https://arxiv.org/abs/1711.02257[2] https://arxiv.org/abs/1705.07115[3] https://arxiv.org/abs/1810.04650I think this line of work might be less popular in NLP based tasks but overall would be meaningful to be included in a discussion. a minor comments:It might be good to explicitly mention each of the proposed improvements in figure 1, for example, conditional attention, conditional layer norm, ..<BRK>Their goal is to reduce the amount of parameters and data needed, while improving (or maintaining) state of the art performance. The latter aims at avoiding catastrophic forgetting, while the former avoid having to share all (or no) parameters. The authors already published their code in an anonymous GitHub repository (that s great!). Overall, I like the idea of the paper: it is important to reduce the parameters needed for sets of tasks, to enable NLP models to be deployed in a larger variety of settings, and reducing the amount of data needed. Also, the authors did a great job in terms of conducting evaluations from different angles. Unfortunately, I think this particular paper might need some more work before being ready for publication. I will discuss my concerns one by one in detail:  Most importantly, the evaluation is confusing. The authors switch between using BERT_base and RoBERTa_base without being very clear about when and why, e.g., in Table 2 they have both models, but only in different sections. This makes a direct comparison impossible. However, they compare to BERT models and build themselves on RoBERTa_base; how are the results meaningful if they use a stronger model to start with? I compared their numbers explicitly to Liu et al.(2019), and RoBERTa_base outperforms their approach on nearly all tasks (and on average). The same applies to Table 3: it is unclear to me why or how the baseline T5 model has been chosen. I do understand that the main point is the reduction of the amount of parameters (per task), but this doesn t mean that the evaluation should paint a wrong picture. The authors refer to the fact that MTL can (and often does!) Granted, the final effect of MTL depends on task similarities, but that s probably the same for the proposed approach. Major contributions of the work should be described in the main paper. Additionally, there are some minor things I would add or improve:  I would add references to multi task training on different languages (e.g., Task 1 is translation from EN to FR and Task 2 is translation from EN to DE). NAACL.(And the references therein.) The paper would benefit from more proofreading.
Reject. rating score: 5. rating score: 5. rating score: 5. rating score: 6. <BRK>## SummaryIn this paper the authors introduce the notion of stable weight decay. $v_t$ goes to zero at the same speed as the gradient but with a delay of $1 / (1   \beta_2)$. But there is another explanation: Intuitively for a fixed $\beta_2$, $v_t$ goes to zero as the current gradient goes to zero, and the ratio of the gradient by $v_t$ will converge to some constant, which prevents convergence. If there is no convergence, then the gradients won t actually go to zero. This is only an idea of a possible justification and I would encourage the authors to think carefully about this stability issues in the next revisions. AdamS has the stable weight decay property, unlike Adam or AdamW. The definition of the weight decay rate can be done from equation (2). The authors introduce the notion of stable weight decay and seem to right away assume it is a desirable property. In particular, there is no theoretical justification that this is the case. It would have been interesting to see the effect of AdamS on other type of tasks. Overall I think the idea introduced by the author is interesting, although the theory is not completely coherant. what is the point of having $\beta_3$? We agreed that the methods is sound and likely to work better than AdamW, the proofs are not sufficient. In particular, the authors should strive to provide experiments on different training sets (ImageNet) with learning rate cross validation. The authors do not systematically compare across learning rates which make it hard to interpret the results as being conclusive.<BRK>Summary: This paper presents a novel weight decay regularization, stable weight decay by using the bias correction to the decoupled weight decay in adaptive gradient descent optimizer. Experimental results based on benchmark dataset show that the proposed scheme outperform the popular and advanced optimizers in generalization. Weight decay has been a basic technique in most optimizer and indeed there are not many studies for the effect on the performance. I think this paper has done a decent investigation on this topic. The overall paper is easy to follow and seems technically sound. However, one major issue in my mind is that conclusions are only supported by the empirical results, which though look promising. No formal theoretical claims or results have been reported. Even though some shallow analysis has been presented in the draft, it is not enough. For example, Statement 1 that says “Equation 1 based weight decay is unstable weight decay in the presence of learning rate scheduler.” can be quickly summarized even from an intuitive sense without any derivation, which makes it trivial. There is no need to give Definition 1 formally for Stable Weight Decay as that doesn’t sound like a definition. Stable doesn’t just mean constant, though I can completely understand what the authors really meant in the paper. However, the current theoretical analysis is not enough to support this conclusion.<BRK>In this paper, the authors study the effect of weight decay across different optimizers. When one uses weight decay, the learning rate which multiplies the weight decay is different from the effective learning rate (the term multiplies the gradient dependent contribution). The authors show that after correcting for the effective learning rate, which they call AdamS, they can get the same performance as what one gets with SGD in CIFAR10 and CIFAR100. I find the discussion about rho and R confusing (they are not defined precisely and using the small lr/lambda approximation seems unnecessary) and they do not really add much. Similarly the term unstable seems a little strong given that there is nothing bad going on with training of such models. They also make comments about reinterpreting weight decay as flattening the loss and increasing the learning rate which they don t pursue further nor connect with the main point and it seems a little out of context. The main conceptual point of the paper is simply that the weight decay should have the same effective learning rate as the gradients, it would be nice if the authors could make this more clear and more central. The paper main point then is to equate the learning rate in the weight decay coefficient by the effective learning rate and they show that this might be enough to bridge the gap between Adam and SGD. I think this is an interesting problem, but given that this is their unique point they should probably back it up with more experiments, since they only check it for CIFAR datasets (4 experiments total).<BRK>Summary:This paper presents a novel framework that alters the weight decay update rule and aims to improve generalization when applied to 1) momentum based optimizers and 2) adaptive optimizers. The framework includes the concept of “weight decay rate” and “total weight decay”, where the idea is to make the “weight decay rate” constant throughout training. Strengths:The core of the idea is novel, relatively simple, and the experiments support the claim. Weaknesses:My main complaint is that this paper is poorly written. I don’t understand the motivation behind the reparameterization of the update rule with w instead of \theta. The concept of “weight decay rate” and “total weight decay” seems to be the most critical part of the paper, but the explanation surrounding them was messy and hard to understand. The language used is not precise at some points in the text. Comments and questions:  I think the concept of weight decay rate and total weight decay should be explained better, and earlier in the paper. It seems like the main complaints of the other reviewers are in the lack of more difficult workloads, and the lack of theory. I personally don’t find the lack of theory very important. I think the novelty comes from the simple observation, which no one to my knowledge has come to before, and the experiments support the idea empirically (which I think is what actually matters). I also find it a bit uncomfortable penalizing the authors for not running experiments on ImageNet, and I think the variety in architectures that the authors tried, compensates for this. I do agree that a more modern set of workloads (transformers, or even the same setup as AdamW) would have made the paper much stronger.
Reject. rating score: 5. rating score: 5. rating score: 6. rating score: 7. <BRK>My main criticism of the work is that the results seem fairly obvious. What is happening in this paper seems more like “horizon dependent RL.” I don’t really see how the behavior in the long time horizon setting can be called “learning” while the short time horizon behavior is not. The figures are well done and clearly present the results. It’s not clear to me that the agent “learns” a new skill, since there is only exploration, and no exploitation. If the research question is "How does the optimal policy depend on task parameters such as uncertainty and horizon?" I believe Bayes adaptive work answers that question. If the question is "How do policies learned by meta RL algorithms compare to Bayes optimal policies?"<BRK>Instead, this paper studies when such adaptation is not necessary, which is an area that has not been well studied. Therefore, it is interesting and novel to bring attention to the fact that both regimes exist. This paper is generally well executed and clear. The paper does a good job at thoroughly studying what happens when each parameter (e.g., horizon length, aleatoric uncertainty, and epistemic uncertainty) varies. My primary concern with this work is significance. The optimal Bayes adaptive policy explains when it is optimal to explore a new task and learn adaptive behaviors, depending on the horizon length and amount of exploration needed, and therefore, the main claim of the paper can be framed as observing that existing meta RL agents can learn the Bayes adaptive optimal policy in simple tasks. This is an interesting observation, but prior work [2] already shows that meta RL is equivalent to learning the Bayes adaptive optimal policy. One potential takeaway is the observation that meta RL agents generalize poorly to tasks with varying horizon lengths, but it’s unclear whether this setting occurs in real tasks, and even if this _is_ necessary, then simply adding the horizon to the observation (state) and varying the horizon during meta training seems sufficient. It would be nice to report the optimal returns in Figure 5. It was possible to infer the paper’s intent from reading the experiments, but more carefully defining this could help.<BRK>Since they do this in one sentence   the last sentence   it is hard to understand what their claim is. ** The authors investigate the question of when the optimal behavior for an agent is to learn from experience versus when the optimal behavior is to apply the same (memorized) policy in every scenario. ** This paper tackles a novel question which is fundamental to the field of metalearning. The main question of the paper   when does it make more sense to learn vs. memorize a behavior   is significant to ICLR and to the field of machine learning. ** This paper is well written and the experimental setup is simple, well executed, and produces results that are relevant to the main question of the paper. There are a number of relatively minor weaknesses (as described above) but this is overall a nice paper and would be a good contribution to ICLR 2021. Overall, this paper was an interesting read. Indeed, as soon as the authors derive their analytical solution, it becomes clear that we can expect the RL^2 agent to learn the same behavior.<BRK>This paper provides an analysis of RNN based meta learning approaches. In particular, it investigates the strategies learned via meta learning, contrasting strategies involving task dependent learning vs heuristic or hard coded solutions. Empirical evidence in two sets of experiments, on a 2 armed bandit toy task and a grid world navigation task, show that hard coded strategies can be a function of training task distribution and task complexity as well as task horizon. While the experiments are simplistic, they provide a clear and thorough comparison of different agent behaviours across different training regimes. I would encourage the authors to use “memory based/RNN based meta learning” instead of “meta learning” to avoid confusion as these results might not apply more widely across different meta learning approaches (e.g.gradient based). 3.It would be nice to see error bars for the 5 independent training runs in Figure 5. Overall, I think this is an interesting contribution of perhaps limited scope but still valuable and could encourage interesting future research directions in memory based meta learning.
Reject. rating score: 4. rating score: 4. rating score: 4. rating score: 5. <BRK>To sum up, this is a good paper, but not appropriate for ICLR in its current form due to limited novelty, poor analysis, and marginal improvements. Therefore, the method in its current form is not helpful in real applications. 3.This method is problematic in real applications. Cons:1.The main disadvantage is its limited novelty.<BRK>” This seems like an important hyperparameter, yet it is not obvious where it is in the method section. The authors should clearly state the underlying assumptions about the source dataset and the target datasets for the proposed method to work. 2.The technical novelty of the paper is very limited.<BRK>Overall, I vote for rejecting the paper due to limited novelty and lack of convincing experiments. Similarly, as mentioned by the authors, source sample selection is also not new in transfer learning and has shown to be effective in Seq Train. Authors mention about reviewing exiting solutions as a contribution in the paper. Authors compare few existing method in experiments. However, there are few very related recent methods that should be compared in the experiments to verify the effectiveness of the proposed approach.<BRK>What about for NLP (e.g.BERT fine tuning)? Pros:1.The proposed method is conceptually simple and easy to understand/implement. However, although the authors include several experiments aimed at understanding XMixup’s efficacy, several key ablations are missing, and there’s a lack of diversity in experimental settings (all ImageNet  > smaller image classification set). However, all experiments are in image classification, transferring from ImageNet as the source dataset. The current draft isn t a bad start, but in agreement with the other reviewers, it needs more work before it s ready for publication. What is the dimensionality of the model output?
Reject. rating score: 4. rating score: 6. rating score: 6. rating score: 7. <BRK>The paper studies one hidden layer neural networks with fixed second layer weights. They show that the sample complexity needed for precise estimation with this algorithm is in the scale $d \ (\log d)^2$. The main ambition of the paper is to provide guarantees for the convergence of gradient descent on the cross entropy loss, for an input data which comes from a non trivial model, here a mixture of Gaussians.<BRK>This paper considers the problem of learning one hidden layer neural networks with Gaussian mixture input in the teacher student setting. There is a line of research studying such a problem, and the main contribution of the current paper is to extend the standard Gaussian input distribution to the mixture of Gaussian input distribution. The main techniques used in this paper seem to be based on existing approaches in Fu et al, 2020 and Zhong et al, 2017, and the Gaussian mixture input setting considered in this paper seems not to be very interesting and realistic. "Generalization bounds of stochastic gradient descent for wide and deep neural networks."<BRK>This paper analyzes the convergence behaviour of the general one hidden layer fully connected neural network  in the practical scenario that the input features follow a Gaussian Mixture Model (GMM) distribution. So, this assumption is not reasonable. (2).The assumptin of the Gaussian mixture model is special, not general, and its parameters are  assumed to be known a priori.<BRK>In the paper, the authors provide theoretical analysis of learning one hidden layer neural networks when the input distribution follows a mixture of location scale Gaussian distributions instead of single location scale Gaussian distribution as in the previous work. This over specification leads to the slow convergence rates of estimating weight, location, scale of Gaussian mixtures; see the references [1], [2], and [3]. For instance, the work of [1] provides convergence rate/ sample complexity for estimating unknown location and scale parameters when the data are generated from Gaussian mixtures. Furthermore, the work of [2] provide theoretical analysis of optimization algorithms, such as gradient descent/ EM/ Newton algorithms,  for learning location and scale parameters in Gaussian mixtures (Section 4.2 in this work).
Accept (Spotlight). rating score: 8. rating score: 7. rating score: 7. rating score: 6. <BRK>## Review### SummaryThe paper proposes an empirical analysis of the dimension of natural images of multiple datasets. It is sometime proposed that image patches (which are more likely to be textures) are low d (eg Brendel & Bethge ICLR 2019). That the lower the intrinsic dimension the easier the learning (for neural net)### Strengths* The paper is well written and easy to follow. I mean that in fact 3/ is more due two the low d of textures than the low d of nat.<BRK>This paper studies the intrinsic dimension of image datasets and connects it to the generalization ability of deep neural networks. There should be a explanation on why (1) is picked over the other choices, e.g., are they better choices than those used in [d, e]? A work of such provides important justifications for numerous work on understanding and designing CNNs based on low dimensional assumptions. All my concerns have been adequately addressed.<BRK>The authors suggest to use a variant of the MLE method of Levina & Bickel (2004), which is based on computing the distances to nearest neighbors in pixel space, which is fairly easy to implement and   Pros    The authors aim to investigate two relevant hypotheses for the field of representation learning. 1) intrinsic dimension of images is much lower than extrinsic dimension, and 2) extrinsic dimension has little effect on sample complexity. Since this paper is posterior to the aforementioned papers, it would be appreciated if the authors could comment on which intrinsic dimensionality shows larger correlation with generalization, and draw some relationship among them. The method proposed by the authors could have important applications, such as estimating the number of required training samples for reaching a target accuracy. *Update after discussion*: The authors have addressed all the points that I raised during the discussion.<BRK>I would guess that the intrinsic dimension of natural images is actually higher when they have a higher extrinsic dimension since there might be more fine details captured within images of high resolution. However, I do feel that the authors should perform a few additional experiments (I think they are reasonably simple) to improve the understanding of the results. I think this might be a topic of great interest to the computer vision community since this paper describes a novel application of GANs to study the sample complexity of convolutional neural networks, *ReviewPros include:innovative use of GANs to generate synthetic data of bounded intrinsic dimensionwell written and easy to readcoherent storyCons:limited analysis and discussion of the role of the image class (particularly in ImageNet) on the MLE estimate of intrinsic dimensionSome details not listed in the paper, including the metric for the distance between images used to compute the MLE ID estimateNon sequitur in the analysis of the role of image extrinsic dimension in classifier generalization; see comments below.
Reject. rating score: 3. rating score: 3. rating score: 6. rating score: 6. rating score: 7. <BRK>The submission only provides a kind of connection between GCN, GAT, PPPN and APPNP in the perspective of denoising. Compared with that, the survey paper actually connects many different GNNs. 3).In Eq.(1) to ease the discussion, the non linear activation is not included. As for Node classification, the results however are not very promising compared with current SOTA. In Pubmed, this paper reports “79.70±0.4”, however, in the ICLR paper, they report “81.2±0.3%”.<BRK>SUMMARY:This paper establishes a relation between different popular graph neural networks by mathematically proving that the feature aggregation operation of such networks can be understood as a graph signal denoising step. Moreover, the authors try to establish a general framework based on graph signal denoising that subsumes the studied architectures, developing new graph neural network (GNN) architecture under this framework. The relation between GAT and the graph signal denoising approach is not clear and should be detailed, since it is one of the main contributions of the paper. The variables used as indexes of the summation are not present in the terms inside the summation. This should be unified.<BRK>However, the unified view provided here does seem insightful and can contribute to more methodical view of their architecture design. Therefore, the paper does have merit that progresses the theory behind graph neural networks. On the other hand, it is not clear how much insight can be drawn from the presented theory, or what impact this analysis might have. In particular, it provides a unified formulation of GCN, GAT, PPNP and APPNP in these terms.<BRK>However, it seems that the objective of GNN cannot be viewed as a simple combination of graph denoising problems. Weak points: 1) I think one weakness of this paper is that: Explanations are only focused on one layer (local). The theorems do not explain the relations between layers and how nonlinear activation functions affect these theoretical findings.<BRK>The paper attempts to provide a unified picture of a number of different GNN architectures from the point of view of graph signal processing (GSP). In particular, it is argued that the aggregation operation in a number of important architectures can effectively be seen as a form of (graph) signal denoising. * The unified picture can be used for systematic comparison of architectures or for the design of new architectures, as the authors show. Cons:* It appears that despite the theoretical insights are nice for unifying the representation, but do not quite lead to a more improved GNN architecture in terms of numerical performance. For instance it is known that GNNs cannot be more expressive that the weisfeiler leman test (see Morris et al)   does the GSP lens provide any alternative perspective on this? Unifying the aggregation layer is useful, but at the end the improvements that these insights bring (in terms of UGNN) seem to somewhat small.
Reject. rating score: 4. rating score: 5. rating score: 6. <BRK>The paper studies the problem of boosting test performance of the last layer by crafting random perturbations that are orthogonal to the train feature matrix of the last layer (at least in the overparametrized case) thus leaving train performance unaffected. Main Comment:While the idea seemed interesting to me at first I find the paper overselling the results. This is even starker when looking at test performance as opposed to validation where for cifar the improvement is 0.03% 0.1%. The benefit for 2 class imagenet32 is more significant at the low sample regime but also fails to impress, and feels more like cherry picking rather than a serious experimental ablation.<BRK>##########################################################################Summary:This paper proposes LLBoost that enables adjusting the last linear layer without impacting the training accuracy under the assumption that the last linear layer is in an over parametrized situation. The reason why LLBoost does not change the training accuracy is explained as follows: In an over parametrized noiseless linear regression, a solution of a linear system $y   wX$ obtained by the gradient descent with an initial value of $w^{(0)}$ is given in a closed form of $\hat{w}   w^{(0)} (I   X(X^\top X)^\dagger X^\top) +  yX^\dagger$. The authors also present theoretical results that sampling $w^{(0)}$ uniformly on the hyper shpere of appropriate radius leads to a solution that is better than the minimum norm solution ($yX^\dagger$) with constant probability. It is interesting that LLBoost can adjust the last layer without impacting the training accuracy. As discussed in Sec.4, the low rank approximation can harm the accuracy in large problems like ImageNet. The authors show in Figure 1/2/3,  that LLBoost can improve the validation accuracy without impacting the training accuracy. 1 directly uses the validation labels (though it is denoted by  test labels  in Alg.1) to select $w_{best}$, it should be compared in terms of the  hold out  test accuracy to examine the usefulness of LLBoost. The authors propose a method to adjust the last linear layer of a DNN without impacting the training accuracy, under the assumption that the last layer is over parametrized. In practical problems to which DNNs are applied, the over parametrized assumption rarely holds. The accuracy of a  hold out  test set should also be reported. ##########################################################################Other concerns:  In line 3 of Alg. 1 includes  test feature matrix  and  test labels , they seem better denoted by  validation feature matrix  and  validation labels , respectively.<BRK>################################################################Reason for Score:This paper provides an innovative way to improve generalization performance. ################################################################pros:1, This paper gave an efficient LLBoost algorithm to quickly improve the validation accuracy. The algorithm is theoretically guaranteed. The paper considered models that have fc layer as the last layer (most of the current models have this property), and transformed the problem into a linear regression problem. This is the major concern for the paper. It should another held out test data to show the result for all the experiment. (1) why "Lemma 1 implies that LLBoost does not affect training predictions since it only ever adds a component orthogonal to the span of the training feature matrix"? But I strongly suggest the author to explain it in paper for the final version. 3, Based on my understanding of this paper, the algorithm has to be applied to an existing pretrained model which is sufficient good. I am just curious about it and hope the author to do some experiments in the future.
Reject. rating score: 3. rating score: 4. rating score: 5. <BRK>This paper aims to provide an effective augmentation strategy without the need for a separate search. 1)  RandAugment paper found that the optimal strength of augmentation depends on model size and dataset size, and found the optimal strength to be especially different for small ImageNet models such as Resnet 50 vs. large ImageNet models such as EfficientNet B7. The authors should evaluate their method on a larger model such as EfficientNet B7 or on a small dataset such as a small subset of CIFAR 10 to see the performance of NOSE Augment on different model sizes and dataset sizes. 3) It is also not clear to me what the main contribution of this paper is. This makes me think that the numbers reported as baseline are not actually the accuracies that the authors would necessarily get if they ran their experiments with just the baseline augmentation. I would urge the authors to report the results of their own baseline models in all of the relevant tables, so that the reader can directly see how much of the reported performance is due to the proposed augmentation strategy.<BRK>It seems that the performance improvements by the use of mix based augmentations are marginal. Experimental results on various tasks including not only image classification but also face recognition and text detection show that it consistently obtains improved performances over the baselines. Cons.It seems that the contribution of this work from the perspective of the algorithm novelty would be marginal from RandAugment. For example, the tuning for epoch allocation for each stage in the proposed method can be compromised with the hyperparameter search in RandAugment.<BRK>The authors propose a method for learning an augmentation pipeline for image recognition. As opposed to recent existing approaches such as AutoAugment or RandAugment, the authors do not seek for the augmentation pipeline iteratively. Instead they use a stochastic approach, where augmenters are split to three categories based on their complexity to be used by curriculum learning. Moreover, the method and the split into the three categories (BaseAug, AdAug, SuperAug) seem somewhat arbitrary, and questions the validity of the results. However, from a practical standpoint, I consider all results in Table 1 almost equal. The minor differences in accuracy are not justifying the use of the proposed method. Finally, it is critically important that the authors specify what is the baseline (also called "standard augmentation").
Reject. rating score: 4. rating score: 4. rating score: 4. rating score: 6. <BRK>## SummaryThis paper proposed a new formulation of federated learning, which balances between traditional global model and purely local models. Besides, I also have the following minor concerns:  The authors claim that [Yu et al.ICML 2019] didn t consider the heterogeneous setting. They theoretically analyzed the communication complexity of L2GD under stronly convex settings and propose several algorithmic variants. The current version could be misleading. ## Pros1.The authors developed a set of algorithms based on L2GD and provided theoretical analysis. In the paper, the authors claim that they prove for the first time local methods can improve the communication complexity of the non local cousins. It seems that the authors want to claim a lot of contributions in this single paper and they didn t organize these contributions well. However, some of my concerns are not addressed. The main concern I have is about the new insight on local update methods. They should justify the differences and compare the results. However, as discussed in the responses, L2GD is not a new algorithm.<BRK>They also discuss variants of their algorithm, which uses variance reduction techniques or considers users  partial participation. The paper is well written, and the goals, problem formulation, and contributions are all explained in detail. It seems that the authors use an unbiased estimator to solve an optimization problem with a smooth and strongly convex objective function. Second, the regularizer parameter $\lambda$ seems to be at the heart of this framework. In particular, for the latter, the authors claim that "such purely local models are rarely useful." In other words, it is not clear how we should compare the different trained models from setting different values for $\lambda$, and which range of $\lambda$ leads to a good model with respect to that measure. Third, as stated in the introduction, several methods have been recently proposed to address the heterogeneous case or achieve personalization in the federated learning problem.<BRK>***Strong	Personalization is a hardcore problem in FL. The authors target an important problem. The theory analysis seems correct, but the bound seems not tight enough. setting, local SGD training (FedAvg) can obtain similar accuracy as centralized training with a theory guarantee. But in the non I.I.D. The authors only provide results on the LR model for toy datasets (LibSVM). Without non convex experiments, it is hard to believe the proposed method works in practice given that DNN based models dominate nearly all ML tasks. The code style and readability are poor, which discourages the popularity of the proposed method. Although the authors mentioned some contributions of the proposed method, I still cannot get what’s the advantages of the new formulation over conventional Federated optimization? When should we choose this algorithm in practice? Playing with optimization analysis tricks won’t solve the personalized challenge of federated learning in practice.<BRK>Interesting insights into federated learning, possibly limited by the focus on strong convexityThis paper considers distributed training problems arising in the context of federated learning. It proposes a novel framing of the problem as a compromise between fitting a model locally to the data available at a device, and fitting a model globally to the data from all devices. This leads to the so called loopless local gradient descent (L2GD) method, which is loosely related to the popular FedAvg/LocalSGD method, and also loosely related to a randomized version of the well studied ADMM for consensus optimization problems. On the other hand, this paper focuses on convex models, both for the analysis (smooth and strongly convex) and in the experiments (l2 regularized logistic regression). Is there reason to believe it will not be possible to provide local convergence guarantees for L2GD under more relaxed assumptions (in particular, without assuming convexity)? (I.e., why the non monotonic behaviour?) (The averaged model can be computed in a secure way using DP and secure aggregation, much the same as it is in current FL implementations.)
Accept (Poster). rating score: 7. rating score: 7. rating score: 7. rating score: 6. rating score: 6. <BRK>Summary:This paper introduced the representation learning techniques into the linear bandits and showed that representation learning could improve the regret bound when multiple tasks shared a common low dimensional linear representation. The authors also proved a lower bound and extended the algorithm to the infinite action setting. They also present experiments to validate their theoretical findings. Pros:(1) The idea of representation learning + linear bandits is very interesting. Their results are also impressive which showed that combination will be better than naive algorithm. Their proof part looks good. Cons: The assumptions (1,3,4) are based on the representation learning setting. Some of them seems very strong compared to the general linear bandits, e.g.,  assumption 4. Is this fair to compare your result with naive algorithm ? Minor Comments:The author should use the better notations for bandit setting. It is strange that using T as the number of bandit tasks since T usually will be used as the time horizon of the experiments.<BRK>However, there is lot of room to include the characteristic of the learned representation into theoretical guarantee. This paper throws a light on this interesting problem. The paper is well written and the bounds look convincing. I have not gone through the detailed derivations (in the appendix), but the overall idea looks good. Cons.It would have been better if the paper could throw some light on other variants of representation learning. However, posing hand writing recognition on MNIST data as linear bandit seems to be unnatural. There are DNN based approaches that solve the problem with a great accuracy. It will be interesting to see how does the algorithm perform on a real data set of news/ad recommendation. Assumption 2 is a quite strong assumption to make. I believe the exiting work: A Contextual Bandit Approach to Personalized News Article Recommendation by Li et al (2010) deserves a citation in this paper.<BRK>For the continuous actions setting they propose an "explore then explored then commit" algorithm called E2TC. As explained on page 5 it relies on three lemma. Lemma 2 give guarantees on the low rank approximation. ## Pro:  The paper is well written  The maths seem solid  The results give a theoretical insight on the impact/benefit of representation learning in the specific case of linear bandits. ## Con:  The multi task linear bandit models rely on several assumptions and simplifications which obfuscate its realism. I did not like the bias toward improvement of the introduction: for instance, according to the bound, if k is in Omega(d), the cost of learning the low rank matrix is linear in d which results in a regret which is worse than the one of the "naive" approach for large dimensions. The authors should not be afraid to develop on the cases where the shared representation does not improve, it will not devaluate the significance of their work. This work is more about the impact of shared low rank representation and when it can improves from the naive, but much simpler, independent tasks approach. As mentioned on page 5 it requires T to be in Omega(k) to improve. p3: "line of work analyzed"  > "line of work that analyzed"p3: "as our algorithm"  > "with our algorithm"p3: "In this paper, we"  > "We"p4: "In this assumption"  > "With this assumption"p4: "for at each task"  > "for each task"p4: "In each round"  > "At each round"p4: "task are sample from"  > "task are sampled from"p5: "up to an constant error"  > "up to a constant error"p5: "we use an method of"  > "we use a method of"p6:  "value decomposition of \hat{B}"  > "value decomposition of \hat{M}"p7&8: the theoretical bounds should appear on Figure 2 and 4.p8: Replacing the Time Horizon n with the number of tasks T as on Figure 2 would be more informative.<BRK>*Summary*This paper theoretically studies the benefits of representation learning in linear bandit problems. The key assumption is the existence of a common linear feature extractor. Two different setting are studied. In the infinite action setting, the authors provide the $E^2TC$ algorithm that can achieve lower regret than the naive method when the number of tasks is large. *Assessment*Overall I m leaning towards acceptance. Representation learning in sequential decision making problems is an important problem that many readers of ICLR will care about, and it is valuable to offer some theory insights into this problem. Still I have some questions regarding the assumptions that the theoretical results are based on (see questions). I assume it has something to do with Lemma 3, which seems to rely on Assumption 2 ($\lambda_{\min}(\Sigma_t) \ge \Omega(1/d)$). Following the previous question, Assumption 2 looks rather strong; is there any good motivating example showing that Assumption 2 is likely to be true in practice? It would be better to give a concrete motivating example at the begining to give the readers a better idea of what $N, T, d, k$ look like order wise. There s a gap between upper and lower bound in the infinite action setting, but this is acceptable as a conference submission.<BRK>While I still hold my concern on the i.i.d.assumption of the context as it is less interesting both practically and theoretically, the author response and the revised paper clearly resolve my other questions and concerns. Specifically, the paper studies the setting where an unknown common linear feature extractor $B \in R^{d \times k}$ maps the original $d$ dimensional contexts $x$ to a $k$ dimensional representation. This paper studies the benefits of learning a low rank feature extractor in multi task linear bandits. In finite action setting, the proposed solution is a greedy algorithm while in infinite actions setting, the proposed solution is a explore the commit method. The required assumptions are presented and discussed clearly. 3) The analysis of regret upper bound and lower bound are good contributions. Cons:1) The paper introduces a very strong assumption (Assumption 2) that the context features are sampled from Gaussian  (a stochastic context setting), and is a serious limitation of this paper. What is the challenge to propose a solution for adversarial contexts, for example a linear UCB based solution? According to the description the algorithm is doing an explicit matrix factorization. 3) The authors argued that the problem of learning a low rank feature extractor has not been studied in the bandit setting before, which seems incorrect: [2] studies a very similar problem that tries to estimate a hidden projection matrix for linear bandits with low rank structure. One difference is that in [2] the low rank structure is about the features (thus can be directly estimated from the features), while in this paper the low rank structure is about the parameters $\Theta$. It seems to be linear regression + greedy strategy and I would suggest the authors to clarify it.
Reject. rating score: 4. rating score: 4. rating score: 4. rating score: 6. <BRK>Cons:  The motivation of this paper seems somewhat unclear. However, it is unclear to me why focusing on overall robustness is inferior. 2) If you think overall robustness is not the best evaluation criteria for adversarial robustness, what are the reasons and alternative criteria? The paper will be much stronger if the authors can improve the performance of existing robust models by leveraging the class wise properties discovered in Section 3. However, I still feel that the contribution of the current form of the paper is not strong enough to reach the bar of ICLR, so I remain my previous rating.<BRK>Specifically, they note a disparity in the class wise robustness of models for standard datasets. Additionally, the authors do not demonstrate that their findings can help to improve model robustness. Overall, I think in its current form, this paper lacks depth and novelty. For an example of class i, it is possible that the adv. * Many of the experimental choices are not sufficiently justified. From what I understand, 3a should be an upper bound on every element in 3b.<BRK>Finally, the authors propose a new adversarial attack that they evaluate against existing models. It is natural to expect that classes that are similar to each other will be more likely to be flipped on multiple examples. However this is not a fundamentally new attack. Overall, while the topic and initial exploration is interesting, the findings do not provide us with a fundamentally new understanding of robust models. ** Based on Appendix C, it is still unclear if the class wise disparity is a unique property of robust models.<BRK>As there are already several works [3,4,5] on augmenting extra data for improving adversarial training, the authors can use these models to validate the hypothesis above. Pros:(1) This paper is very clearly written and easy to follow. As there are already some works that begin to take care of vulnerable samples (a more fine grained level than vulnerable class) in adversarial training [1,2], it will be good to analyze if such customized strategies successfully reduce class wise confusions under adversarial attacks. (which makes this section less related to the core parts of this paper and easily confuse readers)The authors should carefully address these concerns during the rebuttal.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. rating score: 6. <BRK>All these modifications have been tested on 3 different datasets and 2 different tasks. One for each proposed method. My biggest concern with this paper lies in the complexity of the problem raised vs the lack of analysis of the proposed solutions. + The paper is self contained. sBN, scaling and masked loss "seem" to help, but it absolutely unclear to which extent. Remarks:  Eq.1, 2 and 3 are a bit hard to read.<BRK>If the authors chose a different architecture for their baselines, then the results are inconclusive. UPDATE:The authors have consistently improved their argumentation over the course of the review and addressed my concerns sufficiently. In the conclusion, the authors state that their method achieves better results with fewer number of communication rounds. I cannot find such an experiment in the paper.<BRK>This paper proposes a new federated learning framework called HeteroFL, which supports the training of different sizes of local models in heterogeneous clients. The authors organize the whole paper concisely and comprehensively, which makes the paper easy to read. The paper is well motivated. 2.The idea is novel enough.<BRK>For instance, $W$ denotes both a matrix/tensor and a set in the paper, which causes a problem in equations (1) (3). The proposed method follows similar motivation and approaches of split learning and federated split learning methods. That is, what are the benefits, and how do you assure that this approach enables to have these benefits? Following the rebuttal:I checked comments of other reviewers and response of authors.
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 6. <BRK>Also, for the quantity comparison, the model is only compared with the outdated vanilla VAE in CelebA and Imagenet64, more recent generative models should be included here. This paper focuses on the task of generating high quality data with generative models. Experiments were conducted to evaluate the performance of the proposed generative model. By using 3 auxiliary variables, the authors infer one of them by a discrete and determined variational distribution q(y|x) to simplify the training objective, where the downscale image y plays an important role in this model. For each image x or y,  are their pixels assumed to be i.i.d ? However, I want to know what is the performance of self supervised VAE if only using a standard Gaussian prior. 4.Section 3.3 is not presented well and the idea behind the sentences is hard to follow. 5.The experimental results cannot support the superiority of the proposed model in both of the quantity and quality comparisons.<BRK>Enforcing the posterior distributions to consider desired factors of variations in the input can be fulfilled by either making it more structured (i.e., quantization as in VQ VAE 2) or introducing additional constraints. $\bullet$ The idea of adding self supervised tasks to improve latent representation is very interesting. If yes, why does not the selfVAE sketches model apply in a similar way hierarchically? $\bullet$ *Performance of self supervised tasks:* What is the effect of self supervised tasks  performance on the quality of latent representations? The reason why previous methods  RE/KL values were omitted should be stated. For instance, some examples of FID scores on CIFAR 10 are 18.9 in MoML [1], 29.3 in WP GAN [2], 29.3 in spectrally normalized GAN [3], 26.4 in adversarial score matching [4], and so on. [1] https://arxiv.org/pdf/1806.11006.pdf[2] https://arxiv.org/pdf/1706.08500.pdf[3] https://arxiv.org/pdf/1802.05957.pdf[4] https://arxiv.org/pdf/2009.05475.pdfAs the results on CelebA and Imagenet 64 were not compared with previous literature, it is difficult to understand whether the contribution w.r.t.vanilla VAE is due to the self supervised task or merely the use of an additional stochastic variable ($u$) and networks. Minor issue: "Imagenette64" might cause confusion, I did not see this dataset name before. References for all datasets should be added. ###################################Reasons for score: Overall, I rate towards rejection. Even though the idea of bijective priors and doing this through self supervised tasks is a novel approach, my major concern is that it is beyond the state of the art in CIFAR 10, not compared to any other method on CelebA and ImageNet 64. Hopefully, the authors address my concerns above in the rebuttal period.<BRK>The work proposes the use of downscaling and edge detection as simpler representations of the input images to be reconstructed. ## Quality & ClarityThe paper is generally quite difficult to follow and the purpose, contributions and experiments are not presented clearly enough. There are a number of grammatical errors in the paper. ## OutcomeThe message of the paper generally was quite unclear and it could do with restructuring to assist readers.<BRK>bijective model to enrich data generation with flexible prior. The idea novel and reasonable. Here are some of my concerns. However, I  am afraid, in this way, the inference would be much difficult since the flow based bijective operation is hard to train already. 4.It seems the experiments are not conducted on High quality datasets. To me, the presented results can not obviously demonstrate the achievements of the model.
Reject. rating score: 5. rating score: 5. rating score: 6. rating score: 6. <BRK>Summary:This paper proposes a self distillation based graph augmentation mechanism to alleviate the drawbacks of existing MI based models w.r.t.their high dependency towards negative sampling. Strength:  This work has clearly discussed a drawback of existing unsupervised MI based models which is the leading approach in graph classification  They propose a mechanism to address this issue with satisfiable quantitative results on unsupervised setting and extended semi supervised setting with self training also supported quantitatively. In Section 4.3 "Performance with different amount of negative pairs", it is not clear the reasoning of the provided observation from Figure 3a. Why the results are not included? The reproduced results by the authors are different significantly from the published one in Table 1 of GCKN paper (~5%).<BRK>This paper proposed a distillation approach for unsupervised graph representation learning. The approach partially builds upon contrastive self supervised learning which contrasts pairs of augmented graphs. The approach is extended to the semi supervised setting. The authors performed evaluation in graph classification and regression tasks. My major concerns of this paper include:1. For example, in Table 1, comparing the mean and standard deviation of the proposed approach and CMC GRAPH, it seems that the difference is not statistically significant. 2.The paper is well written and easy to follow, with a clear organization. 3.The experiments were conducted on a rich collection of datasets.<BRK>This paper proposed a method for learning graph level representation in an unsupervised contrastive way. Instead of contrasting between graph level representation and patch representation like InfoGraph [1], they contrast graph level representation of a graph to its augmented variation using a teacher student framework. * The major concern about this paer is that the proposed method encourages the closeness of augmented views from the same graph instances but provide no guarantee that the transformation used (graph diffusion and sparsification with PPR + random remove edges in this paper) would be label preserving.<BRK>This paper applies the ideas from semi supervised classification task to improve the representation quality learned by graph neural network. Clarity:The presentation is not clear enough. In the last sentence of 3rd paragraph in introduction section, it s difficult to get the connection between negative samples mining and self distillation strategy. I guess that the graph feature from original graph will be fed to student network, and the augmented corrupted graph will be fed to teacher network. 2.The proposed method contains an encoder, projector, and predictor. Does it have a big influence on the performance? 4.The overall loss consists of supervised and unsupervised loss. The L^{sup} has conflict to the first term in Equation 7.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. rating score: 5. <BRK>However, its effect on model performance remains unknown in practice. The authors find that an operator with high affinity score and high diversity score leads to the best performance improvement. ##########################################################################Reasons for score: Overall, I like the idea of this paper about making the effects of augmentation operators tractable. The finding that higher scores are better is insightful. However, the computation of affinity and diversity scores may be very expensive. It will be good if the authors can compare the efficiency and/or share some comments in the rebuttal. The paper proposes a novel idea of quantifying the effect of data augmentation. Specifically, the idea introduces two metrics, affinity and diversity scores, to evaluate any given augmentation operator in its effect on model performance. It seems it takes significant time to compute the proposed affinity and diversity scores. Empirically, we can just run the model once to calculate the actual model improvement of the operator. ##########################################################################Questions during rebuttal: It will be good if the authors can add experiments or discussions related to efficiency in runtime.<BRK># SummaryThis paper analyzes data augmentation for image classification using two measures: Affinity and Diversity. The authors show that the performance of image classifiers depends on both of these measures through extensive experiments. # Strengths* The introduced measures consider both data and models, which are inseparable in modern deep learning. This requirement restricts the crucial application of the paired measures to find better augmentation configurations given a dataset and a model under limited computational cost. I think this is well known, and that s why we call data augmentation "data augmentation." This paper includes interesting and useful insights, but its novelty is limited.<BRK>This paper empirically investigates two crucial factors: affinity and diversity in useful data augmentation strategies. Through extensive experiments on existing image augmentation methods, it demonstrates that a good augmentation practice should bring high affinity and diversity for validation and training data. They are both model based, making the measures more adaptive to model biases. It also provides two simple metrics to measure them. My main concern is how to use them in practice to guide training. Post rebuttal updatesThank the authors for the efforts in answering the questions. The responses have addressed my concerns about the robust training and using training loss to measure diversity. Exploring the data augmentation for robust training will be interesting. Besides,  training loss is usually sensitive to some other hyper parameters such as optimizer and learning rate. So, investigating the robustness of this metric is also meaningful.<BRK>In the introduction, the authors mention this as a motivation for proposing the affinity and diversity metrics. However, although (some of) these augmentation strategies are included in the experiments, there is no specific discussion about them anywhere in the paper. Although generally clear, the methodology employed falls short at demonstrating the contributions stated in the introduction and portraying a complete picture of how affinity and diversity can be used to assess the value of data augmentation strategies. Second, we should simply think that it is expected that turning off a bad augmentation should improve the accuracy. Another one is that (so called) automatic data augmentation strategies, such as AutoAugment, are hugely computationally expensive. The presentation of the results, especially in the figures, can be improved, in my opinion, and hinders the clarity of the paper. This is also an interesting direction which could be worth exploring. In fact, the main result that the value of an augmentation strategy depends on both its affinity and diversity matches my (and the author s) intuitions and expectations.
Reject. rating score: 4. rating score: 6. rating score: 7. rating score: 7. <BRK>So the evidence of the effectiveness of UCB DrAC over the simpler DrAC is weak at best. Yet it has also become clear to me that the author s claims on why their method works are not yet supported by evidence. Since the theory is lacking and the approach is not well motivated, and since the theoretical claims haven t been rigorously supported, I feel as per ICLR guidelines the paper is not yet ready for acceptance. Initial Review: Summary In this paper, the authors introduce three approaches for automatically finding an augmentations for any RL task, and a novel regularization scheme to make such augmentations work effectively. Positive aspects: The paper’s language is clear and the authors provide a good overview of the problem of data augmentation for reinforcement learning. Furthermore, they nicely explain why data augmentation for RL isn’t as straightforward as augmenting data for supervised learning learning. In this paper, there are two main novel methods for doing data augmentation / insights in RL. Yet the authors have proposed a different regularization fix which judging the experiments does seem to work, as shown in Figure 2. This leads to an inner and outer for loop like setting, in the inner for loop, the agent does multiple episodes with a single environment, in the outer loop the agent gets new environments.<BRK>Summary: This paper proposes an automatic data augmentation approach for RL tasks. Then this paper evaluated the approach based on the Procgen benchmark and demonstrated that it outperforms existing methods. Reasons for score:On the one hand, I feel that the proposed approach is incremental (UCB for data selection with the actor critic algorithm as the RL algorithm plus additional regularization terms). However, on the other hand, based on the current experimentation results, the proposed method seems promising and can be useful for generalization in reinforcement learning. This would make the new approach seem incremental. 2.There is a lack of performance comparison between the automatic data augmentation method and non automatic approaches. 3.The data augmentation approach is only evaluated in the Procgen benchmark. It would be great if this paper includes more experiments to demonstrate the performance, especially since the proposed method is intended for any RL task.<BRK>This paper presents a method that utilizes data augmentation for image based reinforcement learning. The data augmentation is used to regularize the policy and function approximation in the proposed method. In addition, a method for automatically identifying effective ways of data augmentation is proposed. The experimental results show that the proposed method outperforms the baseline methods. I have some suggestions for improving the paper. I believe that the proposed method is now clearly presented and the claims are properly supported by experiments.<BRK>#######################################Summary:This paper tackles the problem of generalization in deep RL via data augmentation. It provides a framework for automatic data augmentation based on UCB, RL^2, or MAML. The paper is well written and the proposed algorithms are straightforward to understand. Surprisingly, when all ProcGen games are taken into account, some existing methods such as Rand FM are actually worse than PPO. UCB is shown to find the best augmentation asymptotically, and the DrAC is shown to be better than PPO and RAD. Cons:1.The experiments do not compare the proposed algorithms to DrQ, the algorithm proposed in Kostrikov et al.(2020).Since it also tackles generalization in deep RL through data augmentation, it seems that it should be included as a baseline. Can the authors explain why it was not included? 2.The proposed algorithms are only combined with PPO. It would be good to have some results for other actor critic algorithms, such as SAC, to verify if the SOTA behavior holds. The proposed approaches are novel in the data augmentation for generalization in deep RL subfield, although AutoAugment (cited in the paper) also uses RL for choosing data augmentations in the supervised learning case. #######################################Further comments and questions:1. 2.Is there intuition for why only UCB DrAC leads to statistically significant improvements over PPO, and not RL2 DrAC and Meta DrAC?
Reject. rating score: 5. rating score: 5. rating score: 5. rating score: 6. <BRK>This paper proposes a method for text style transfer where they dont need label information of the interested style. However the current presentation of the paper is hard to follow. As they need to provide two sentences which has to be chronological sentences, it is not possible to obtain always. How the authors are incorporating the same? They have not compared with3.<BRK>##########################################################################Reasons for score: This paper proposes a novel approach to the label free style transfer task where an input is corrupted via different strategies and fed into an auto encoder which is additionally conditioned on its prior adjacent context sentence via a "style encoder" which adds its mean pooled hidden state to the former before decoding. Both encoders are initialized to and leverage the strength of pre trained T5 model. The idea is novel enough where even just doing some more automated evals would be suffice for me. Also the authors compare against Lample 19 for the pos >pos and neg >neg setup for the Amazon data, why not show the results for the SYelp data as well? 3) There are two issues with your use of the Amazon dataset. 4) The paper hypothesizes that style is a "slow moving" feature consistent over large spans of text hence the use of only the prior adjacent sentence as context.<BRK>In this paper, the author proposed a transformer based encoder decoder framework for label free text style transfer. The experiment results show satisfying performance even comparing with state of the art supervised methods. About the assumption: The author claimed the method is label free. However, the "unsupervised" model is based on an assumption that two adjacent sentences should have the same style. This idea is also previously used in [1]. It could be more solid if the author conduct experiment on other commonly used style transfer datasets such as Yelp and Personality Captions [2].<BRK>Traditionally, modeling text style requires either paired sentences (supervised) or two pools of unpaired sentences (so called unsupervised). This paper exploits 1) language model pretraining and 2) free supervision signals in text to achieve modeling text styles without labeled data. For the 1st point, the authors (correctly) hypothesize that a large pre trained language model (e.g.T5) already “knows” about style information and one can isolate the style information using the right fine tun signal. In the experiments section, the authors test their model on transfer learning tasks. The experiments (Fig 2 &3) seem to suggest that at at given high content preservation score ( > 50), the proposed model is not as accurate as other supervised models. But with low content preservation, the model can steadily improve accuracy by modifier more words (Fig 2).
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 6. <BRK>This paper propose to use Laplace bridge as a building block to map the distribution of logits to the distribution of post softmax predictions. The idea of constructing a Dirichlet distribution to describe the output distribution for classification in Bayesian neural networks is not new. The idea of using the Laplace bridge in BNN is interesting and can potentially be useful. I like the demonstration in Figure 1, showing that Laplace bridge is a good approximation. Besides, another line of highly related works is on combining Laplace approximation and BNN, such as [5]. Since f_theta is an L layer network, with the parameter theta, the mean of the network’s output is not simply \mu_theta^T x. Therefore Eq.8 only holds when L 1. Another point that is unclear from the paper is the computation of the Hessian matrix in a large neural network. Given that a neural network typically has a large number of parameters, it would be important to provide details on related implementation in practice. The authors emphasize one of the advantages of the proposed method is that it is sampling free and therefore significantly speeds up computation. Although results on Table 2 make sense, the table itself is a bit misleading. Alternatively, it would be helpful to demonstrate the proposed method’s advantages in terms of obtaining calibrated uncertainty using metrics such as ECE or Brier Score. As I said, this could potentially be a very interesting paper if related works are handled and compared to thoroughly, especially highly relevant ideas proposed before [1,2,3]. Otherwise it is difficult to evaluate the actual novelty and advance this paper provides.<BRK>It follows the sampling free solutions within Bayesian deep learning (Wu et al., 2018; Haussmann et al., 2019, etc.). The difference is the proposed Laplace Bridge that approximates the  full distribution over the softmax outputs of a neural network. The Laplace Bridge tackles the problem of approximating the distribution over the softmax outputs of the ubiquitous Gaussian approximated BNNs without any additional training  procedure. This allows the Laplace Bridge to be used with pre trained networks and emphasizes its non invasive nature. Major comments:   Overall, I find the paper is easy to follow and the experimental evaluation shows promising results. But my major concern is about the novelty of this work, given the fact that the basic idea was originally proposed by MacKay (1998) in a different  setting which transforms a Dirichlet distribution into a Gaussian and the inverse of this approximation, called the Laplace Bridge, was already proposed in the literature (Hennig et al., 2012). I would recommend the authors to provide more details on the training of BNNs within the Laplace Bridge, including the hyperparameters used for the training stage. The size of some figures appears too small, for example Fig.4, which may hinder readability. At the moment, I recommend a weak reject as the main weakness is the novelty, but I could be open to increasing my score if my concerns are addressed.<BRK>Review Summary Overall this paper offers a simple idea   the laplacian bridge, revived from earlier work by MacKay (1998) and Henning et al (2012)   that produces useful yet affordable predictive posterior estimates. I thought the fundamental approach is sound and does seem to be an elegant way to apply some older ideas that do indeed seem to be overlooked. My chief concerns are that the presentation contains many distracting errors (e.g.as written Eq 8, the primary equation of their method, is fundamentally wrong but I think this is a typo) and many steps lack justification. Paper Summary The paper presents the idea of the "Laplacian Bridge", a deterministic mapping provided in Eqs. The Dirichlet to Normal direction is derived by performing a Laplace approximation to a Dirichlet written in the softmax basis. While this abstract construction is known, the present paper uses it specifically to approximate the posterior predictive of a multi class Bayesian neural network. Note that even after determining parameters m and S, in order to make predictions at input x we need to draw several samples of vector z, feed each through a softmax, and average the results. Drawing a single sample of vector z from a normal with covariance S usually has cost O(K^2). One new theoretical result is presented in proposition 1, showing that under some conditions, the variance of the k th entry of a probability vector constructed using the LB method increases with \Sigma_kk (the relevant variance of this entry under the Normal). The Laplace Bridge tends to have better results than diagonal sampling and ties with KFAC sampling w.r.t both metrics, while being around 400 times faster than both sampling based methods. Is there a justification for this "pseudo inverse"? Equation 8* This is an approximation of another integral. I think readers would benefit from seeing this other integral written out. I guess in MacKay s original derivation, the assumption here is a local linearization of the output of the network as a function of parameters (e.g.first order Taylor approximation), and this makes the predictive distribution a Gaussian. Would like to see discussion improved to explain this. Table 2 needs some clarity improvements:* Are these timings for performing predictions for a single image? in Sec.5.2, the authors state "the softmax applied to a Gaussian does not have an analytic form", but should this just be the well known logistic Normal distribution, which has a known pdf that is possible to evaluate analytically:https://en.wikipedia.org/wiki/Logit normal_distribution#Multivariate_generalizationPerhaps the issue is that the Logit normal produces a K dimensional probability vector by using K 1 dimensional means and covariances (to maintain an invertible mapping), while the present paper seems to use means/covariances of size K. Or perhaps the issue is that this logistic normal distribution does not have closed form expressions for its mean or other moments. Either way, the discussion should be more clear. Experimental Concerns ## E1: In Sec.5.1, should we expect LB to deliver improved classification over MC with many samples? To me, the convincing argument here is that LB is much faster than the MC sampling. I wish the experiments focused on this. However, it seems that Table 1 is trying to make an additional point, that the LB approximation of the posterior predictive will yield *better* OOD classifier performance than MC sampling. Perhaps in the supplement if needed.<BRK>The authors propose an approach called the Laplace Bridge to approximate predictive uncertainty in Bayesian neural networks. The approach is essentially based on first a change of variable, followed by a Laplace approximation. They provided a theoretical result for this approach, which essentially shows that for \alpha_k large enough, the variance of \pi_k given \alpha is increasing with the variance \Sigma_kk. The authors did a good job explaining the motivation and the paper is written in a clear manner. The experiments appear to demonstrate that this should work well in practice. There remains, however, several cons that I believe the authors need to address: First, the author should comment on how this is a *substantial* and *sufficiently novel* contribution to the field? The Laplace Bridge idea/derivations seem to come, for the most part, from Mckay and Hennig et al’s  (2012) etc prior work. The Laplace approximation idea is a common tool, and using the Dirichlet distribution for uncertainty quantification in neural networks for classification has been amply explored in other prior work (e.g.Sensoy 2018, Malinin etc). To play Devil’s advocate, it does seem like the authors are just applying to the BNN context something that we know works fast (Laplace Approximation) and comparing it to something that we know works slow (MC Sampling). Second, the authors should try to justify with more rigor/guarantees on how good the approximation is. I do think the computational speed up in the empirical evaluations are big. However, currently, it appears that the Laplace Bridge is simply a heuristic, with minimal quantification/guarantees on the approximation error etc. For example, in Figure 2 (Right), in the very simple case of approximating a beta distribution (transformed back to the standard basis) , one sees that near 0 and 1, the approximation appears to be doing very poorly. More rigor in the quantification of approximation error would be ideal.
Reject. rating score: 3. rating score: 4. rating score: 4. rating score: 5. <BRK>The learned representations are at an abstract level, resulting in desirable knowledge transfer capabilities between tasks. The learned action knowledge is represented using PDDL. Experiments have been conducted using blocks world and Minecraft domains. Results show that the agent was able to learn useful operators (actions) and that learned actions can be applied to different tasks. The object centric idea is highlighted in the paper, though the work is more about learning symbols for abstraction, which is not new. The issue is that many of the "learning abstraction" works have been demonstrated in much more complex domains. For instance, the work of Konidaris et al 2018 (cited in the paper) has enabled robots to learn action preconditions and effects in the real world. The developed approach is more like an integration of a few existing methods, and the connections among the pieces are rather weak (see Figure 1). For instance, once the actions are learned, it looks like the agent faces a planning problem, and the planner does not have a way to go back to improve its learned representation. There were a couple of examples presented, while there were no statistical results discussed in the paper. Figure 6 is on the Minecraft domain, where the baseline (such as no transfer) is very weak. The results are not convincing to support the claims on transferability and learning efficiency.<BRK>Originality and Significance:The authors’ novel contribution is to propose clustering objects based on their effect, allowing transfer between tasks. Their approach groups objects into object types; if two objects have the same outcomes in planning then they are considered to be the same object. This is certainly a very interesting idea however I have some concerns about how this approach would work in more complex domains and how well the approach would generalise to imperfect object individuation. This is an interesting way to group objects and could enable future research towards using objects in RL, for example by relaxing assumptions that the objects have already been individuated. Typos:In the introduction, PPDDL, is not defined. (2) The clustering must depend heavily on how the state is represented? Similarly, when learning the effect model? In this work the authors assume that the objects have already been individuated. Check the caption on Figure 4. Were there any fail cases when partitioning options based on their terminal state? Particularly in the Minecraft setting? Clarity:The authors could make their contributions more clear in the introduction. The authors say that they are pixels, but go on to say that their “state space representation assumes that individual objects have already been factored into their constituent low level attributes”. At the end of the “Partitioned Options” section, it would be good to clarify which approach will be used in this paper. Figure 1 is not very clear. It is also not clear why this is needed? Why can the classifier not learn for itself which objects are useful and which to ignore?<BRK>The paper proposes an approach to learn a Probabilistic PDDL representation for tasks and generalize to new tasks with very small number of additional samples. It does that by first learning a compact and lifted representation across different training tasks that get the gist of multiple different objects, then converts it into symbolic representation (in PDDL) for future planning. I think the problem itself is super interesting and important: how to combine neural based and traditional approach remains a key challenge for AI community. However, I found this paper is hard to follow without any detailed descriptions of the actual algorithms. The description is mainly high level, many symbols/terms are mentioned but not defined, and there is no clue how to implement the idea. There seems to be 5 steps (Sec.3.1 3.3 and Fig.1).But it is not clear at all how the entire system work. Here I only list a few:1. what are the features defined in Sec.4.1?2.Are the options o learned or pre defined? 1 computed? While the author defers “the exact implementation and domain details to the appendix”, I don’t find many details unfortunately, except for the learned/generated results. Given the difficulty in understanding the details, I feel that the paper is a bit premature for top tier conference. After reading the author s comments I still keep the score. After rebuttal/revision, the paper still has a lot of steps, many of them are human designed and are not well defined. For example, in the author response, they said "their effect distributions look similar, and so are merged into one class type", what is the criterion to merge them together? In the revised paper, what is the procedure "COMPUTEMASK" defined? Overall, this makes it hard to reproduce and it is not clear whether the proposed approaches can be applied to other problems than the specific tasks mentioned in the paper.<BRK>  No Baseline Comparisons: Paper proposed a way to generate object level representation that can be used across the tasks with same objects. However, there is no baseline comparison being done to figure out how sample efficient it is. Paper assumed that tasks are solvable from set of provided options, will the method work of the task is out of provided options space ?
Reject. rating score: 5. rating score: 5. rating score: 5. rating score: 6. rating score: 7. <BRK>The paper proposes GG GAN, a GAN based graph generative model for mimicking the structure distribution of realistic networks. And a bunch of add on theorems is provided to support the rationality of the proposed method. My major concerns are that the paper might over claimed their contributions and the experimental results show limited improvement over the baseline methods. * in terms of scalability, the authors claimed that "GG GAN is significantly faster than autoregressive models". Interestingly, the paper fails to compare with NetGAN, which achieves SoTA performance in a list of network properties in the real world datasets in my practice. Overall, I enjoyed reading this paper.<BRK>In general, this paper deals with an interesting and essential problem to generate geometric graphs under several standards. The idea of the paper is with novelty and some theorems can support the observations. 2) The authors claimed that the proposed method can model complex local and global dependencies among nodes and edges. I understand that such a procedure can handle node dependencies given the design of the generator part. Otherwise, it would be too weak Proposition 1 is. 6) Though the authors gave some discussion on the hand crafted features of nodes, I still think the features employed in GG GAN is ad hoc. I suggest the authors to show what will happen if we sample z separately for each node. This may help to understand the necessity of unique sampling, then further show the mechanism behind it.<BRK>These properties are desirable  if we want to generate efficiently new graphs with properties similar to the graphs in the training set. The paper is interesting and well written, designs important properties for the generator of graphs. Usage of GAN in graph generator has been explored in the previous approaches and showed good results for generating graphs with similar properties to a given one [1]. There are essentially 2 real world datasets with 9 vertices graphs and one artificial dataset with 20 vertices. Such repetitions may negatively affect performance of your model as well as baselines [3]. It would be more convincing to have a comparison on medium and big graphs. Table 1 is not convincing in showing that the proposed method is better than preious approaches.<BRK>The main contribution of this paper is dubbed as the geometric graph (GG) generative adversarial network (GAN), which is a Wasserstein GAN that addresses the challenges. The proposed method is inspiring and has sufficient theoretical support.<BRK>The paper investigates graph generation using adversarial technics. GG GAN generates points in an euclidian space that is then turned into a graph using a similarity function on the space. The authors show that their method successfully generate graphs within the same scope as the input dataset, and show that GG GAN generates much more new graphs that current state of the art approach. + The proposed method is new and is experimentaly efficient. This should be made very rigourous. It would be interesting to investigate the relationship of these approachs with the concatenation trick in GG GAN. What happens if we do not learn it and use random vectors instead?
Reject. rating score: 4. rating score: 5. rating score: 6. <BRK>### Summary In this paper, the authors propose a fine tuning scheme for pre trained language models, called Hidden Representation Extractor (HIRE). The authors apply the proposed approach on top of RoBERTa and evaluated on general benchmark GLUE. The experimental results show that the proposed method could give moderate improvements over RoBERTa baseline system. 1) The idea of HIRE model is very similar to utilizing ELMo in down stream tasks, where the hidden representations of each layer are weighted. The design of the components is not novel. Unlike Transformer based models, RNN models (such as Bi GRU) are not computationally efficient.<BRK>This paper presents a new mechanism, called HIRE, to extract more information from the intermediate layers of pre trained models, which will be further fused with the last layer of pre trained models. The paper is well written and organized. All the models are evaluated on the GLUE dataset, experiments on more challenging tasks like QA (e.g.SQuAD 1.1/2.0) should be added.<BRK>The paper proposes a method to improve the downstream performance of a pretrained Transformer on NLP tasks. To dynamically decide which intermediate layers to use depending on the input example, the model uses a mechanism conceptually similar to self attention, which yields a normalized importance score for each layer. The model is evaluated on the GLUE benchmark. It seems likely that this improvement could be achieved through much simpler means, e.g., additional self attention layers on top of the last pretrained layer. But all the tasks in your experiments are evaluated on high level natural language understanding tasks, which typically require representations at higher layers. This makes it more likely that your model does not improve much over the baseline, because the last layer will arguably already contain much of the information needed for the tasks.
Accept (Poster). rating score: 8. rating score: 7. rating score: 6. rating score: 3. <BRK>The introduction of quantum mechanics into the problem is through a trainable computational model of a beam splitter/phase shifter mechanism, aka a rotation in a high dimensional complex space, that s allowed to alter the photon s state before hitting the measurement device. The paper shows that using this overly simplified (and claimed to be physically feasible) quantum computer, which acts as the representation learning layer, improves classification accuracy over any other representation learning method that doesn t use quantum computing. The major take away is an accessible demonstration of how an elementary quantum computer might work for ML, and what may be possible with actual qubits. Comment:* The paper analyzes a single problem where no classical representation learning method can improve accuracy due to the fact that there is a single photon.<BRK>The current paper is an excellent step in this direction. (Though, I think the original goal of the paper is very worthy, and look forward to the final version of this work!) an equation for computing the predictions of the trained model. Given a photon that passed through a mask, a clear formula for computing the class probability with the trained unitary operator parameters. Finding a unitary transform to find bases corresponding to style and class is unfair to the classical method, which does not have access to this information. Hope this is helpful; I think with this additional work it could be quite a valuable contribution, as I think the ICLR community could be inspired to develop more methods that require complex valued numbers such as this one.<BRK>This paper focuses on the quantum computing based machine learning and proposes a toy model to illustrate the quantum information processing. Strength:+ The topic is interesting, which inspires the following researchers to focus on the combination of quantum computing and machine learning. With the proposed photon classifier, the semantic information of the input images can be well extracted. + The proposed method is analyzed in detail from multiple perspectives, including results on MNIST, confusion matrices and visualization. + The experiments are conducted on two simple datasets, MNIST and Fashion MNIST. Could the proposed method be applied on more complex data? If can, how to extend and apply it? Please provide such a discussion. Nanophotonic media for artificial neural inference.<BRK>The paper studies that  a ML system using quantum interference gives better classification accuracy than a vanilla ML system, under the  constraint that a classification decision has to be made after detection of the very first photon that passed through an image filter. The reader can gather that this work brings together the ML and QC worlds but it is not clear what the real motivation of this work is and primarily why is ‘single photon’ important. It might be good to know which audience reads the paper. Was there a reason to use the Fashion MNIST in conjunction with MNIST dataset?
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. <BRK>The authors present the split Poisson Gamma (SPG) distribution, an extension of the Poisson Gamma distribution, to model a discrete non stationary stochastic process. *  Title of paper has  causes . This is achieved through a combination of CNNs, GPs and MLE. *  How valid is the assumption that events are distributed independently in the mutation space?<BRK>Short summary: This paper introduces a split Poisson Gamma model to capture discrete time, integer valued stochastic processes at multiple scales. Pros: a useful and very sensible model for detecting cancer related mutation rates. clarity: the most parts of the paper is clearly written.<BRK>Summary: The paper extends Poisson Gamma models for non stationary sequences, in a manner that allows partitioning the counts according to a binomial model to account for multiple resolutions. This generalisation is motivated well with a biological application of practical relevance, and the proposed method is particularly strong in enabling linear computational scaling required for analysis of large genome data.
Accept (Spotlight). rating score: 7. rating score: 6. rating score: 6. rating score: 6. <BRK>########################################################################## Summary:The paper considers the fingerprinting of a DNN model via usage of specifically designed adversarial examples. The authors describe a proposed loss function and results of their experiments ########################################################################## Reasons for score: I vote for weak accept, because the model fingerprinting is an important topic in the modern DL, and authors propose an interesting idea on how one can generate such fingerprints via adversarial attacksThe authors propose new fingerprinting strategy for an already constructed DL model.<BRK>The idea itself is interesting enough, the this work presents a neat development toward solving this problem. An important issue with this problem is to distinguish a reference model from a stolen model. The experiments show that such an approach can indeed produce some fingerprint adversarial examples to distinguish between reference models and surrogate models to a certain degree. Having said this, the results are not perfect. The presentation has some issues that can be fixed by revision.<BRK>Summary:This paper introduces an interesting property of adversarial examples, which is called conferrability and can reflect the abilities whether an instance can exclusively transfer with a target label from a source model to its surrogates. A new method is proposed to generate conferrable adversarial examples. Conferrability is the core contribution of the paper. The existence of the conferrable adversarial examples is shown empirically in the paper. Ensemble adversarial attack CEM is shown effective in the same time. 3.The idea of conferrability is very interesting. 4.Impressive empirical results. Fingerprint in this paper is the first method that reaches an AUC of 1.0 in verifying surrogates, which is impressive for me. It may affect the practicality of the method.<BRK>This paper proposed a fingerprinting approach for identifying stolen models. To distinguish stolen models from reference models, the proposed approach generated conferrable adversarial examples, which can only be transferred to the stolen models, but not to the reference models. Pros:1.The idea of using adversarial examples to identify stolen models is interesting. The results outperform popular adversarial attacks, FGM, PGD, and CW attacks. Do attackers have access to the data? Many recent works show that model stealing attacks can surrogate datasets to extract the victim models. Can these attacks be detected by the proposed approach? Many definitions are missing in the paper.
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 8. <BRK> Summary The authors consider planning for Markov Decision Process. I do not understand. They provide a regret analysis of this algorithm named E3W and prove that EW3 converges at an exponential rate to the solution of the regularized objective function.<BRK>Section 3.2: the part of the trajectory discussed above (6) presumably corresponds to the selection part, not the simulation. (Presumably, i_n stands for the action taken in step n.)Regarding the experiments, they do show the superiority of proposed method on some benchmark tasks, such as CartPole, Acrobot and a couple of Atari games.<BRK>Finally, the paper provides some empirical gains on certain toy domains and some atari games. I cannot be a good judge for the theoretical contribution and I will focus more on the empirical side of the paper. ##########################################################################Please address and clarify the concerns above.<BRK>It uses the tools of convex conjugates and duality to derive the theoretical results and the algorithm/updates. Furthermore, the presented theory/connection coming from the duality is important   I do not think this connection of duality was presented in the MENTS paper.
Reject. rating score: 3. rating score: 4. rating score: 5. rating score: 5. <BRK>Clarify issues: It seems that the authors end up with a multi agent variation of TRPO in Eq 16. I encourage the authors to add more experimental proofs and make the presentation clearer. I m not convinced this is that novel.<BRK>Weak points:The writing requires much improvement in order to be publishable. The draft must be proof read for English style and grammar issues. But the paper format could be much improved such that it fits in 8 pages, so I haven t considered this a deal breaker. 2.The concept of the counter factual scene is not clear. Don t the authors use the marginal advantage?<BRK>The authors introduce marginal advantage functions and use them for the estimation of the counterfactual advantage function. The approach is interesting and the experimental results confirm that the method performs better than COMA. WeaknessThe paper is only experimental and gives no theoretical guarantees. In the results of the experiments, it seems that QMIX has excellent performance, sometimes better than the proposed method, but in the Experimental Results, there are no comments on this fact. Is it possible to perform an ablation study on the clipping parameter?<BRK>The main idea is to sample additional joint actions to variance reduce the advantage estimate for each of the agents at each time step. My understanding is that the paper uses the joint Q function similar to the COMA paper. On a related note, while using a critic that depends only on the Q(s,u) (ie.the central state and joint action) is common practice in this line of work, it is not generally appropriate.
Reject. rating score: 3. rating score: 5. rating score: 6. <BRK>This paper discusses an approach to perform importance sampling by reviewing performance over past batches and suggesting future batches. The paper seems to go beyond this and focuses on multi node training so this may be a way to refocus the paper in contrast to the existing work. It is not clear to me what the intuition of P(x) is. It would be better for the reader to make this as easy to understand as possible. On the experiments to demonstrate that this method is better: The replicate runs seem to almost have no variance. Typo: "Algorithm 2: Search based AuoSampling"<BRK>This work presents an interesting exploration of learning optimal data sampling probability. It is formulated with a population based training strategy. However, the empirical validation seems finished in rush and not sufficient. The chosen baselines are essentially standard sampling scheme or variants of the proposed method. Authors should compare with a few state of the art data sampling or data reweighting methods, such as Focal Loss proposed by He et al.In addition, Tables 2 and 3 should be clarified in the rebuttal. However, authors are encouraged to go deeper for the analysis, beyond the selected illustrative samples in Figure 3.<BRK>The authors have conducted sufficient experiments to verify the superior of their method, especially for the effectiveness and generalizability. Advantages:l	The exploitation step and exploration step in AutoSampling is interesting, it is straightforward that this method can work well as the sampling strategy is updated dynamically according to the current state of model. l	The proposed AutoSampling is simple and effective, one can implement it without much effort. The authors did not explain this. l	The transferability of the gained optimal sampling schedule is discussed in Section 4.4, a simple experiment is recommended.
Reject. rating score: 3. rating score: 4. rating score: 6. rating score: 7. <BRK>This paper proposes an adversarial defense method against black box attack by adding random noise on adversarial examples. The method is simple and empirical results verify that the proposed defense can be used to decrease the attack success rate of both optimization based and local search based attacks. My main concern of this paper is the simply use of randomness for adversarial defense, rather than directly improving the robustness of the target model itself (e.g.adversarial training). In addition, the proposed method is not useful to defense against white box attacks and transfer based attacks, since basically it does not change the predictive model.<BRK>The paper proposes a new defense against adversarial examples created through query based attacks. The defense is based on adding a small amount of random noise. The authors provide some theoretical arguments and experimental evaluation of their approach. Overall evaluationWhile the presented idea might be promising neither the theoretical nor the experimental evaluation are sufficient to validate this claim. The main shortcoming is the lack of a robust evaluation against an adaptive attack (i.e.an attacker aware of the defense). The majority of the analysis in the paper is restricted to evaluating  the defense against existing attacks, robustness against an attacker that does not take the defense into account is insufficient. I believe that the paper can be significantly improved if the authors incorporate the comments from the current round of reviewing.<BRK>#SummaryThis paper introduces a simple but effective method by adding a small Gaussian noise to the input, and shows it can neutralize query based black box attacks and achieve strong results on both clean accuracy and attack success rates w.r.t.several SOTA attack/defense methods. The proposed approach achieves good clean accuracy as well, which seems to be another plus compared to existing defenses that achieve strong defense ability but at the cost of clean accuracy. Could the authors show more study on this, like how is the query efficiency from adaptive attacks based on other attack methods? The experiments are thorough over various SOTA attacks and defenses, on both CIFAR and ImageNet datasets. I would vote for accepting the paper.<BRK>In this paper, the authors propose a novel method for defending againstadversarial attacks on deep neural networks in a black box setting. The idea issimple as it is effective: to simply add some small Gaussian noise to the inputprior to passing it through the model. The authors make some heuristic argumentsfor why this might be effective, including the difficulty of estimatinggradients (for gradient based attacks) and robustness against local search basedattacks that do not account for variability in the model output. It will likely be widely adopted given its ease    of implementation, in situations where protection against adversarial    attacks is critical. + The experimental evaluation was rigorous and supports the paper s main    claims. Areas for improvement/questions for the authors:    The theoretical analysis of the SND model, given its simplicity, is somewhat    lacking. Is this because    RS uses large variance noise, and is thus unlikely to maintain a sufficient    clean accuracy? Some clarification here would be welcome.
Accept (Spotlight). rating score: 8. rating score: 7. rating score: 7. rating score: 6. <BRK>The authors propose a generative model that is a combination (product) of a VAE and an EBM, where the goal of the EBM is to reduce the probability of out of manifold samples, which are typically generated by VAEs. This is, in my opinion, a very good work, which combines a novel and well motivated idea with clear writing and extensive experimental evidence.<BRK>The model is learned in two phase. The first phase learns the VAE model, while the second phase learns the EBM correction term by MLE. Overall, it is a good submission that proposes a principled method to combine VAE and EBM and demonstrates strong empirical results.<BRK>The approach generates high quality image samples by combining EBMs and VAE based models. The histogram of likelihoods of data points is a bit disappointing   it falls a similar trend of other EBM models, but it would nicer if it followed a Gaussian distribution What happens when more Langevin sampling steps are applied to the model?<BRK>Unlike other VAE+GAN/EBM liked model, it added a EBM after VAE. Overall method is easy to understand and follow.
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 5. <BRK>Summary: The authors propose variants of the SELU activation function that yield a stronger self normalization property. Minor: 1) English editing might be required. How are they handled in this work? Pros:a) The paper is clearly written and the line of thought can easily be followed. Cons:a) The work has limited relevance due to the fact that it is unclear whether the proposed property is indeed crucial for learning and that the empirical resultsare biased and far from state of the art. In order to demonstrate improvements, the suggested activation functions shoudl be compared in that set of experiments. The  presented experiments are done with architectures that are relatively far from the current SOTA on CIFAR and Imagenet [2], such that their relevance cannot be judged well.<BRK>The work builds on top of the mean field theory literature and provides a modified self normalization property (additional constraints compared to SELU). However, there is no experiment showing this effect and this seems to reinforce my concern that the proposed modification does not solve the gradient vanishing/exploding issue (also mentioned briefly in the para before conclusion). Therefore, I believe, it is important to show the trainability behaviour and the propagation of gradients. In retrospect, I just want to say that in the current form theory and heuristics are mixed together making it difficult to see where the benefit is coming from and I think if theory is tightened this could be a good paper. It seems the modifications could be done to other activation functions as well such as tanh etc. I recommend the authors to look at Gaussian Poincare inequality for connecting a function and its derivative under the Gaussian distribution. In the literature it is known that when the width is large, the preactivations will be close to a 0 mean Gaussian distribution due to the central limit theorem (Assumption 2 in this paper). This seems to be contradicting as well.<BRK># UpdateI thank the authors for extensive replies and updates to the paper. In this case these changes cancel out, and the conclusion does not appear justified. Unfortunately I still can t raise the score and advocate for it myself, since:1) Table 2 doesn t really show superiority of new nonlinearities, since the bolded (bottom) entry has both trainable $\lambda$, centralization and Mixup, while the baseline of dSELU only has mixup and trainable $\lambda$, no centralization. As presented, experiments do not support the introductory claim that “no additional hyper parameter is introduced". Without trainable $\lambda$ (only Mixup), they perform a bit worse than dSELU. With only centralization, BN is still better. Further, even after rebuttal, I still believe that making $\lambda$ trainable effectively cancels the preceding theoretical discussion, and makes this subset of results somewhat unrelated to the main idea of the paper. So at the moment I find that the proposed nonlinearities are promising in terms of both self normalization (Figure 4), and generalization (Table 1/2/6), but these results appear to be largely unrelated to each other, and neither of them in separation is strong enough to convince me to try s/lSELU over dSELU (given additional implementation complexity + the boolean hyper parameter of whether to use lSELU or sSELU) or over BN (given additional hyper parameter $\epsilon$). 4.Table 2: what $\epsilon$ was used? Original review below:# Outline The paper proposes two new nonlinearities designed to normalize the second moment of activations and the Frobenius norm of gradients, and therefore avoid exploding/vanishing activations/gradients. # ReviewOn one hand, I find the theoretical motivation and the idea of adding the new minimization constraint compelling, and empirical performance of nonlinearities promising (notably on CIFAR 100). Further, several decisions along the design process appear well motivated and backed by experiments (e.g Figure 2, 3, 4).<BRK>In this paper, the authors propose a new definition for the self normalization property of a network. Using this definition, the authors propose two new activation functions: sSELU and lSELU. The paper is also written reasonably clearly (see below for minor comments on how I think the writing could be improved). The fact that epsilon needs to be tuned seems to be a major disadvantage of the proposed activation functions. Would be good to add SELU in figures 1b, 1d and 3. The authors mention in definition 2 that the self normalization property is stronger when phi(q) is closer to 1/q. It is not obvious to me from the definition. Typo at the end of page 2: boarder  > border  Equation 13 and 15 need to be made clearer by adding "if q_l > 1", etc. Update after rebuttal: I thank the authors for the detailed response. However, some of my major concerns remain such as the insufficiency of the hyperparameter tuning for the baselines to do a fair comparison.
Reject. rating score: 4. rating score: 4. rating score: 4. rating score: 5. <BRK>Strength:* The idea of training an ensemble of specialized models in FL is interesting, although not novel. I would be more impressed if the authors could also evaluate some SOTA language models. Weakness:*  The technical contribution is limited and the novelty is not sufficient. However, the proposed method is worse than some prior works on CIFAR 10 even using ten time bandwidth (correct me if I interpret the results wrongly). *  There are many other works with similar technical consideration although their intention might be different. *  The writing is not clear given that the idea is actually simple.<BRK>The authors propose using an ensemble of experts, but where the mixing proportions depend on both the data and the client (providing the personalization in the method). Although the simple personalized bias does not generalize beyond label distribution, there are many many similar personalization proposals for federated learning which do, and it is not clear whether the proposed method is competitive with those. The method requires significantly higher communication cost to train, since multiple versions of the model parameters need to be communicated, as well as parameters for other models used for the mixing. Given access to $N_s$ and the discrete nature of $y$, this would allow the server to reconstruct the label distribution of each user s data, which is a huge reduction in the privacy achieved by federated learning.<BRK>  Summary  The paper proposes a method for federated learning of a mixture of experts model (FedMix). The approach allows training an ensemble of models each of which specializes to a subset of clients with similar data characteristics. Having said that, I also believe that the paper in the current form has many weaknesses, including:  a significant lack of clarity throughout section 2 (see comments and questions below),  in terms of methods, fairly ad hoc changes introduced into the evidence lower bound objective given in eq.5 (removal of the entropy term and addition of a different regularize, which is justified in a very handwavy way),  weak experimental results, which indicate that FedMix is, in fact, worse than the baselines both in terms of performance and the communication cost (unless I m misreading Table 1 and Figure 4). I would not recommend accepting the paper in the current form. Why use the graphical model formalism in the first place, if the final loss is being designed using some additional intuitive heuristics? Similarly, results presented on Figure 4 for CIFAR datasets demonstrate that the baselines are better. Section 4, paragraph 1: I believe the EMNIST dataset has 3400 users if the version from tensorflow federated is used.<BRK>The paper proposes a novel algorithm, which is a federated form on mixture of experts, called Federated Mixture of Experts (FedMix). In FedMix, an ensemble of specialized models is trained instead of a single global model. On the rotated MNIST experiments in 4.2 it performs better, however, this section is very short and the insights from the presented results are limited. It may well be that it also performs well in the rotated MNIST experiments. Anyways I am not convinced that the proposed method is superior to state of the art techniques in non iid settings (on Cifar 10 and  100 it is clearly not). The paper does not provide any new theoretical insights, it only reports empirical results.
Accept (Poster). rating score: 7. rating score: 6. rating score: 5. rating score: 3. <BRK>This paper sets out to show that multiple tasks can be encoded in a neural network that that does not have explicit modular construction for each tasks, which is in contrast with the work of [Bakker and Heskes, JMLR 2003], and [Jocabs, Jordan, Nowlan and Hinton, Neural Computation 1991]. I recommend *reject* based on the clarity and structure of the paper. The definition of g(c; x) in section 2.2 should be given from the onset and the related work discussion based around that.<BRK>This paper posits a very interesting question about provable multi task learning by neural nets. The idea is quite interesting to encode the objectives as task codes and then to write a smooth approximation to the predictor function as a weighted sum of indicators and the try training a net to learn this smoothening. But the problem with the paper is that the presentation of the details are extremely unclear and almost nothing about the proofs can be easily followed! Its far from obvious that the proof there will go through here again. I would strongly suggest resubmitting to a future venue a self contained paper with all the proofs. Can the authors point to this assumption anywhere in that paper? 1901.08584 is not a NNGP result!<BRK>Experiment results show that the networks are flexible enough to fit complex data generated in this way. Moreover, is the construction of the g function different from the cluster setting? This paper would benefit from explaining the different complexities added to the learning by different task coding schemes, and how do they make multiple tasks potentially conflict/distinct with each other. Overall, I think the monolithic task formulation is novel and the problems the authors would like to address are fundamentally important. The experiments look only partially supportive of the main claims. It is very likely for me to miss something important. The lacking of clarity is a big downside.<BRK>The main contributions of the authors are the following:  showing that "the two layer neural network can jointly learn the task coding scheme and the task specific functions without special engineering of the architecture"  "systematic theoretical investication of the extent of this ability" (ability   single network can successfully be trained to perform a wide variety of tasks)   "...primarily interested in the extent to which different tasks may interfere,..." (in a multitask setting)############################################################################# Reasons for recommendation / score: The paper is composed of a vast amount of very good research work. 2.The authors have carefully cherry picked the theorems and balanced the extent to which they explain them so that it reads with completeness on the whole. This is an effect of trying to squeeze in too much in too little space. The authors do direct the reader to the supplementary material many times. Parentheses helps understand the subtraction from unity. I would in this context, recommend some extra experiments and discussions (commented below also), to make the work more thorough. Eg.Is modular construction better than the monolithic ones? It is not suitable to be accepted as a conference contribution, by the sheer magnitude of work and the style it is presented in. 8.The authors need to address the few inconsistencies in the graphs they have shown in Fig.2. The research quality and quantity are exceeding requirements for acceptance!
Reject. rating score: 5. rating score: 5. rating score: 6. rating score: 6. <BRK>This paper shows a linear speedup in FedAvg w.r.t.number of devices, mainly theoretically, while most prior works ignore it. The paper is well written and motivated with good discussions of the algorithm and the related works.<BRK>The paper provided convergence analyses for federated averaging and a momentum based variant for convex and strongly convex problems, with a focus on the effect of the number of participating devices. 2.Another concern is this paper seems to be incremental, the analysis for federated averaging with client sampling should not be difficult given the existing theoretical frameworks for strongly convex/convex/nonconvex problems. This paper considered the effect of unbiased client sampling in the convergence analysis. The insight is that E can be O(T^{1/4}/N^{3/4}) when all devices are participating in every iteration, however, E should be O(1) if client sampling is used.<BRK>The authors convinced me that setting $E>1$ can reduce the number of communications. The contribution is mainly theoretical. This paper contributes better convergers rates than prior work, arguably.<BRK>The paper focuses on how FedAvg’s convergence scales with the number of participating devices. It improves previous analysis for FedAvg under more federated settings and shows that FedAvg has linear speedup for any number of participating devices.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. rating score: 5. <BRK>The further exploration of when to replace ReLU with an approximation seems somewhat expectable despite the novelty of the exact approach. Summary:The paper present a system for two party deep learning inference. To this end, the authors use a divide and conquer approach to gauge the impact of replacing activation functions of some layers by a version more amenable to secure computation. The improvement in efficiency is clear.<BRK>Summary:The main contribution of this paper is a new heuristic for identifying "less useful" activation channels. The authors then propose using simple approximations for activation functions for these channels without compromising network accuracy. Additionally, the authors propose a new hyper parameter search strategy (BTPBT) to efficiently search the hyper parameter space for the optimal approximation parameters. The (a) and (b) sub captions should indicate the network name  What is the source of the ~10% improvement in the runtime of the linear layers when compared with Delphi?<BRK>In the past, BNNs have shown remarkable speedups in computation without a major hit to accuracy (Sanyal et.al.2018), which is in fact a major point of this paper. i would encourage the authors to have more techniques in their experimental comparison section. * Clarity    I have found the paper very hard to read in general and some major gaps when considering baselines and background discussion. *  The figures (Fig 1, Fig 3, Fig 4) are very far from being self contained. I think it is okay to omit some details from the figures But there should be proper explanations in the captions. (2019).Are all layers created equal?.<BRK>It is able to support a secure, accurate and fast neural network inference service. In page 2, the 2nd line in Section 2.1, the sentence ``current state of the art cryptographic inference, Delphi  It should have a citation here. In the introduction, this paper discusses about cryptography but many important references are missing. InstaHide: instance hiding schemes for private distributed learning. TextHide: Tackling Data Privacy in Language Understanding Tasks.
Reject. rating score: 3. rating score: 4. rating score: 4. <BRK>Furthermore a new benchmark is being introduced. Also very good is the consideration that the existence of a behavior policy is a restriction that does not apply to every given dataset, as expressed in the terms "behavior policy(s)" and "coherent policy". Recommendation:In its current form, the experimental part of the paper is immature. The statements are not sufficiently substantiated. What is meant by "discrete offline RL algorithms“?<BRK>I have some questions to clarify my understanding of the paper: * I am not sure what is the propose of Appendix A? However, my main concern is that the proposed algorithm, especially with the behavior value estimation technique, has a big limitation for solving the offline RL problem (details come below).<BRK>In equation (7), the regularization for learning the scale parameter is not well motivated either. Pros:* This paper attempts to solve a significant problem (extrapolation error in offline RL). * The paper explains the intuition behind each proposed approach clearly. How to choose the value of ν and β (the given value in the paper are just randomly picked)?
Reject. rating score: 4. rating score: 4. rating score: 5. <BRK>The paper proposes the use of polynomial neural architectures (PNN) for anomaly detection in dynamical systems, and more precisely, for feature extraction. Quality, clarity, originality and significance:Pro: The paper is well written and approaches an important inverse problem, how to find anomalies in a dynamical system from some measured time series. Could the authors detail on this?<BRK>This paper investigates the problem of anomaly detection in nonlinear processes. The main idea is to employ polynomial neural architecture for feature extraction that describes the dynamical system. The experiment results in both simulations and a practical example showed the effectiveness of the proposed technique. Weaknesses:  Several related works are not mentioned or compared.<BRK>This paper is exploring anomaly detection problems where a time series does not contain statistical outliers. It shows the proposed polynomial neural network based approach, which uses the fitted weights as extracted features, outperforms both classical statistical features and an LSTM autoencoder based neural network. It is indeed interesting and of practical value to distinguish any anomaly condition resulting from an abnormal configuration of the dynamical system, especially when it is difficult to accomplish using classical methods.
Reject. rating score: 3. rating score: 5. rating score: 6. rating score: 7. <BRK>This paper propose a counterfactual approach to improve the performance in information extraction tasks and in particular on the rarer classes. While this is an important research problem, I think the paper has the following issues:  The overall  approach is best described as a form of a data augmentation based on the model predictions. Steps 1 to 3 is essentially finding out which part of the input had the most impact on the model prediction by comparing the impact of a token being masked at random, and then steps 4 and 5 use this info to improve the prediction. The causal framing in Figure 1 appears flawed. There is no good reason to assume that the NER tag "causes" the trigger representation and not the other way around. The paper is hard to follow. What is v_r in equation 3? Note that replacement with semantically equivalent words has been explored: http://sameersingh.org/files/papers/sears acl18.pdf  There are some vague statements about the novelty vs previous work by Tang et al, but no explicit statement made in the model description. While this is not necessarily the authors  fault (reproducibility can be difficult sometimes), combined with the uncommon choice of metrics and the lack of any comparison to previously reported results in the literature, means that it is impossible to understand where the presented method stands.<BRK>The novelty of the paper seems to be in application of the counterfactual analysis to address the long tailed IE issues, which might be interesting to the IE researchers. Overall, more theory about the counterfactual generation for IE task should be added, for this is what the novelty of the paper; also, for the rebalancing learning for slide effect and counterfactual, the theory appears to be not enough. Here are my major concerns for  the paper:Q1. Is it unimportant to mention or the SCM model definition is always the same no matter what sources of the data? Counterfactual Generation, as this forms the main contribution of this work, still no useful information is given in this section, but only a do calculus is given. How equation (5) (3) been used? More evaluation regarding the causal effect should be added.<BRK>This paper proposes a novel model integrating both causal inference and structure aware counterfactual training to enhance the long tail performances of information extraction. The strengths of the paper includes:1. In general, this paper is well written and easy to follow. The motivation and the structure are clear. 2.The ideas of both structured causal model and structure aware counterfactual training are interesting. It is interesting to see how different generation of counterfactual examples using dependency structure affect the final performance. If structure is considered, why not try to mask on some dependency relations? It will be interesting to see the difference between masking words and relations. 2.What is the effect of using (5) instead of (4) in terms of the experimental result? 3.It is also better to demonstrate some qualitative examples on which factors are most important for NER, RE and ED.<BRK>### SummaryModel performance suffers because of spurious relations present in the data, this is particularly true for long tailed scenarios. To overcome this challenge authors introduces counterfactual thinking to IE. To learn the main effect and ignore the spurious relations (side effects) the paper proposes structured causal model (SCM) with syntax structures using GNN on sentence dependency tree. Extensive experiments on multiple tasks with different datasets shows significant performance improvement. 5 measures the effects of the entity is not clear to me. I feel **4000** is too large for it to be considered "Few" for a class. 3.It s curious to find that GloVe based approaches outperformed BERT based approaches by a large margin in ATIS dataset in NER task (Table 1) and MAVEN dataset for ED task.
Accept (Poster). rating score: 7. rating score: 7. rating score: 5. rating score: 5. <BRK>##########################################################################Summary:This work studied how the connections in graph data affect  dyadic fairness  when applying GNN for representation learning on homogenous graphs. Might be helpful to highlight the formal definition of this and the corresponding insights. ##########################################################################Strength:  Fairness of graph representation learning is a relevant and emerging research topic  The analysis and the proposed method are technically sound and the experiments are executed well  Many interesting insights are obtained from the theoretical analysis##########################################################################Weakness:  The overall presentation can be further improved.<BRK>This paper discusses fairness problems in graph embedding for link prediction to mitigate problems such as graph segregation related to sensitive attributes. The notion of dyadic fairness refers to statistical constraints on link prediction between/across sensitive attribute groups, such as parity for positive predictions or false negatives. I recommend accepting this paper because it focuses on a problem where there is relatively little previous work, introduces a novel approach, and shows empirically that the approach is competitive. 2.In the theoretical analysis, immediately after Corollary 4.1, the paper states "Multiple layers of GNNs can be reasoned out similarly."<BRK>Clarity:I believe the presentation can be improved. Specifically, the problem setting can be better explained in the introduction, where terms like "dyadic fairness" or "homogeneous graph" are thrown without much details. did it matter at all? * Authors state that the goal is to have link predictions that are independent of the sensitive attributes. Not having a good explanation for this would undermine the work a lot. * The references in Section 2 seem rather arbitrary, for instance, in "fair machine learning" I do not see the work "learning fair representations" (Zemel et al.2013).I wonder why it was not referred or rather why are the listed references there preferred over other works?<BRK>This paper considers the problem of performing link prediction in a way that satisfies demographic parity through Graph Neural Networks. They evaluate this algorithm on several real world datasets. The experiments demonstrate that the proposed algorithm increases fairness as measured by demographic parity at the expense of accuracy. This paper is quite dense and difficult to read. From a technical perspective, the work appears to be novel and sound.
Reject. rating score: 3. rating score: 6. rating score: 6. rating score: 8. <BRK>The paper proposes to use a simple intermediate task   clustering   to improve the generalization ability of BERT in low resource text classification settings. The results show that the proposed method is effective in topical classification problems. Pros:   the idea is very simple and we can easily adapt the idea to different classification tasks. the results are promising, especially on topical classification problems. The BoW representations are known to be more effective for topical classification problems compared to BERT based sentence representations. So what the authors did maybe actually infuse/distill the BoW knowledge into the BERT representations.<BRK>This paper proposes a novel domain/task adaptation procedure for BERT style language models (LMs). Inspired by computer vision, the authors propose to specialize LMs to a particular domain and task with an intermediate clustering task. The authors go on showing that their approach works best when the cluster ids correlate well with the original labels. Concerns:  Some claims feel overly broad. I believe the claims should be limited to improving low resource/few shot *topic* classification tasks, not text classification in general, which is especially unclear in the title and abstract. Did the authors try using a number of clusters equal to the number of labels? What are the reasons for choosing that number?<BRK>QualityThe paper proposed using unsupervised clusters to help boost BERT performance in text classification tasks that lack labels. The method make good sense. Experiments well designed and showed clear advantage. I have no trouble following all details. OriginalityIt might be the first for BERT, but using unsupervised clustering to help classification seems an old topic in NLP. First, it limits to topical classification. Performance gain diminishes quickly as number of labels get over a few hundreds. Paper is well written, evaluation done thoroughly and showed good improvement. 2) Did you use training set for clustering, without considering their labels? are all test sets balanced?<BRK>The proposed inter training methods are an unsupervised method by first running clustering with BoW features for the target task and then fine tuning by training BERT over pseudo labels generated by clustering results. This inter training framework significantly improves prediction accuracies especially when the task is topical, i.e., the task to classify texts based on a high level distinction related to what the text is about, and the labeled data is scarce. This paper is well written. Experiments are comprehensive and analyses are well designed. I think it is better if the authors mention the computational cost of the inter training framework in detail.
Reject. rating score: 4. rating score: 5. rating score: 7. rating score: 8. <BRK>P6, Algorithm 1: The definition of the empirical transitions and the bonuses are not clear when N_h(s_h,a_h,_b_h)   0. Indeed the proofs are dangerously close to a sketch of proofs (see specific comments below) when it is not the case (see proof of Theorem 6). P23, Lemma 21: Because of the big O after “these terms […] separately” it seems that the constants in Lemma 21 are wrong. In particular, considering how you use it in the sequel it is not almost surely.<BRK>After a long discussion with other reviewers and ACs, we concluded that the paper would require another complete review process in view of newly added proofs, which were unfortunately missing in the first round. This is in particular true for bonus $\gamma$ discussed in p. 5.<BRK>The authors study reinforcement learning in two player (and more) Markov games, providing new algorithms and bounds. Overall, my impression is that the results are very valuable. > "We leave these problems as future work."? "a relaxation of Nash equilibrium"  > "a relaxation of the Nash equilibrium".<BRK>In particular, comparisonwith model free approaches would be welcome, as constants before the samplecomplexities may vary. Similarly, is there a foreseeable way in which $\Pi A_i$ could be transformed in a sum ? Review The paper is very well written and presents some exciting results.
Reject. rating score: 3. rating score: 5. rating score: 5. rating score: 5. <BRK>In this regards note that, even if the idea of using the features aware or the structure aware teleport function is interesting, the teleport convolutional layer defined in section 3.2 is not very novel in my opinion, since it seems very close to a multi scale approach where in the same layer several exponentiations of linear diffusion operator are considered. The main problem of this work is the empirical evaluation of the proposed method. In the introduction, the authors highlight the main issues related to message passing paradigms and deep GNN models.<BRK>A new architecture for graph neural networks, which the authors name as Teleport Graph Convolutional Networks (TGL), is proposed in this paper. The architecture enables nodes to aggregate information beyond their local neighborhoods. Authors motivate their work by reporting Pei et al., 2020 ignore the graph topology, but TGL can incorporate graph topology with a similar latent space approach. Overall, the paper presents some useful attempt to address problems in message passing operations, and some accuracy gains are shown in the graph and node classification datasets. The trick to aggregate based on similarity of features and structure leads to some gains compared to those only based on graph topology.<BRK>**Summary:**The paper proposes a method to increase the receptive field of GNNs, while avoiding oversmoothing. Computing the dot product between descriptors, gives a similarity measure of the local structure of each node. **Strong Points:**Clearly motivated and simple method. **Weak Points:**There are some concerns regarding the evaluation of the method. This should be compared to the approach of Geom GCN. Some statements regarding Geom GCN must be clarified: “ Geom GCN doesn’t consider theoriginal graph topology information when generating the additional set of nodes for aggregation” or “structural neighborhood in (Pei et al., 2020) is still built on node features without considering the graph topology”. The proposed method given in Eq.3 5 could be a good alternative to these methods, but more detailed explanations and comparisons should be given. **Conclusion**:This paper presents a good and clear idea to add additional connections in a graph, but it has some issues with the evaluation and some comparisons with prior work. In this form I am inclined towards giving a  *5: marginally below* rating.<BRK>This paper analyzed the key issues of the existing message passing graph convolutional networks. However, the motivations of the proposed structure aware and feature aware teleport functions are not very convincing, and Table 3 shows that the performance improvement of TeleGCN might largely be induced by model architecture rather than the proposed TeleGCL. Pros:[1] It analyzed the potential issues of message passing operations in conventional graph convolutional networks. [3] The experiments show that the proposed TeleGCN outperforms the existing graph convolutional networks. [2] Another concern is the scalability of the proposed graph convolutional networks. Besides, it might be more convincing to empirically compare the running time of the proposed method to the baselines.
Accept (Poster). rating score: 9. rating score: 7. rating score: 7. <BRK>## Overview The paper studies how the generalization of the neural network trained with SGD is affected by the scale of the random initialization. The paper also provides a hypothesis why does it happen   that the graidents of difference examples are orthogonal in the "bad" mode and proposes a measure called "alignment" to predict the generalization reghime of the network. The problem, tackled in paper is interesting and the paper itself is thought provoking. The central model studied is 2 layer fully connected neural network with {sin, ReLU} activation, where the 1st layer is initialized with variable (studies) scale and the 2nd   with Xavier init. Both layers are without biases. Besides "toy" 2 layer model, the similar results are get with more powerful architectures, like CNN, DenseNet and so on on the set of middle sized datasets like SVHN and CIFAR. The paper clearly states its place among related works and proposes a useful metric for diagnosing model training. This is hypothesized to be one of the problems with large scale initialization: the weights do not go far from the original (random) values. Why is this an important question? I strongly recommend the paper to be accepted.<BRK>###Summary:This paper investigates the role of scale in generalization of neural networks. ###Reasons for score: Overall, I find the paper to be a bit borderline. The observation regarding the scale impacting generalization is novel and interesting as I would have assumed that large initial scale would lead to bad optimization rather than a lack of generalization. However, all the experiments regarding the scale are carried out on a two layers MLP models and it is not clear to me if similar conclusion would be true for deeper architecture. ### Pros:  interesting observation regarding the impact of the initial scale on generalization  clearly show the effect in a two layers MLP with various activation and loss functions  propose an alignment measure which have some promising correlation with generalization ###Cons:   experiments investigating the impact of the initialization scales only for two layers MLPs  Alignment is not compared with other generalization metrics in section 5.<BRK>**Summary of paper:** A series of empirical observations are made about the influence of scale of init on generalization (in particular, that a continuum of generalization performance from random to very good can be generated by varying only the scale of init) , and these effects are explained in detail for different activation functions. I think it just needs a few more passes, with an eye to making sure things are accessible/understandable/flow. The combination of things is too much for me to recommend acceptance out of the box, but the things are relatively small and I think easy to address, and I d be happy to increase my score. Related work on inits should cite lottery ticket works (e.g.Frankle et al)   Geiger et al reference you describe what they do but not what to take away from it   extreme memorization should be bolded since it s a term you re defining (and make clear if you re proposing this term and if not, where it is from), but you then  define memorization the same way you define extreme memorization, making this term ("extreme") seem unnecessary. Conclusion discusses the results strangely, without mentioning the actual results (e.g."making it particularly interesting"   why/how is it interesting, what are the implications for people using sin?, "the loss function plays a crucial role" what role?
Reject. rating score: 4. rating score: 4. rating score: 4. rating score: 6. <BRK>This paper proposes an algorithm  for online logistic regression  based on analytical formulas that approximate the Bayesian predictive posterior. Two alternatives are proposed for the optimization: one based on Newton s method and the other based on a Taylor series approximation, which experimentally yields similar results. This strong dependence on the prior makes it of limited practical interest in real life online scenarios. Therefore, I think that the paper is not strong enough and recommend its rejection. "We demonstrate that it is sufficient to approximate the component of the posterior which will dominateat the horizon, matching it by a diagonal Gaussian approximation ,"How is this demonstrated? Eq 11: (d) should be with $\approx$ instead of $ $Since nonparametric Bayesian methods are mentioned in the abstract, it would be interesting to see a comparison against online nonparametric Bayesian methods. "* I agree that, for batch methods, the prior can be tuned to the data. 2019.*Therefore, unfortunately, my first two concerns (theoretical guarantees on the regret and strong dependence on the prior) remain so I retain my original decision.<BRK>PAPER SUMMARYThis paper proposes a new posterior approximation scheme for probabilistic logistic regression. The paper also appears to overclaim on the analytic tractability of its update as I have pointed out above. In that case, I am looking forward to receiving detailed clarifications from the authors. Given the current form of the manuscript, these arguments, however, are not very convincing to me as I elaborated in the followings:First, regarding (a), while it is true that VB s or EM s offline updates are more expensive than the update derived from Eq.(15), it seems to me they can still be made more efficient in online setting with very minor modifications. Second, the claim that the new approximation scheme performs better than existing methods is not well supported. Given that one of the key contribution claims here is the computation advantage over EM s and VB s, both theoretical complexity and empirical demonstration of averaged running time should be provided. Lastly, the conclusion surprisingly summarizes that with proper prior, the method "matches regret lower bound"   this seems like an overclaim as there is no theoretical analysis in the paper to back this up. It could have made its points using much less space. EXPERIMENTOn the experimental evaluation, my key concern (as mentioned above) is the lack of evaluation of real world dataset, and in addition, some of the more recent methods such as (Nguyen, 2017a; 2017b) were not included in the baseline. ; and secondly, why do we divide it by log(t) but not t?<BRK>The authors propose a low complexity approximation method with closed analytic forms for doing logistic regression in the sparse, online setting. This is an interesting approach. The authors should address the following questions/concerns:  	 	 		Assumptions: The diagonal Gaussian assumption appears to be quite strong. Approximation: The approximation is based on a Gaussian approximation to the sigmoidal. Are there any theoretical/quantitative guarantees on the approximation error? Experiments: since one of the main proposed advantage of this scheme is that it is computationally faster, it would be nice to have experiments/charts showing how much faster (in actual experiments) does this method run when compared to competitors like VB or a Gibbs sampler. Also, there is a Newton’s method step in the algorithm. Overall, I think this is a potentially useful proposal that is interesting, but I think a) more experiments needs to be done with competitors to illustrate not just regret, but runtime comparisons b) there needs to be more theoretical rigor as to how an approximation performs and what the approximation error/bounds/guarantees are.<BRK>##########################################################################Summary:The paper proposes an algorithm for learning the parameters of a logistic regression model in an online setting. The proposed algorithm is based on two approximations: the posterior at iteration t over the model parameters is assumed to be multivariate Gaussian distribution with a diagonal covariance matrix and the logistic/sigmoid function is approximated by the CDF of the normal distribution. The numerical results show the usefulness of the proposed algorithm. From my point of view, the introduction of the extra approximation layer due to the use of the logistic regression is detrimental to the easy understanding of the paper. I believe it would have been better to just introduce a section that describes the modifications to make in order to apply the proposed algorithm to the logistic regression problem. For me it is not clear how the proposed algorithm addresses this statement. It s welcoming that the proposed algorithm has very good results, however I m a bit surprised that the results are that good. However, the regret seems to remain steady as you increase the number of items seen. 2.There are some typos here and there in the article, however I believe you can easily detect them with the help of a spell checker.
Reject. rating score: 4. rating score: 5. rating score: 6. rating score: 6. <BRK>The paper at question tackles the well known problem of differentially private (DP) deep learning:  already for moderate privacy guarantees, the model performance suffers greatly. The paper proposes a particular SDE based  method for obtaining privacy for ResNets. In International Conference on Machine Learning (pp.2493 2502). Although providing an interesting approach by combining DP deep learning and SDEs, I think the paper has some major deficits. One of them is certain sloppiness with the presentation. The main results are regarding the DP privacy guarantees of the method (Thm.1 and Thm. 2).However these DP guarantees are not used anywhere in the experiments, and it remains a mystery to me what is actually DP protected. As far as I see, the experiments give an example where this given membership inference attack works better for DP SGD protected model than for this residual perturbed version. However the paper does not give any privacy guarantees for the residual perturbation method. I think that the paper would require a careful rewriting.<BRK>Two SDE models are provided to inject noises with abundant theoretical proof are provided. The problem itself will have great impacts on real world scenarios. 3.Experiments on the real world dataset provide some interesting insights about the advantages of residual perturbation. In general, there is a tradeoff between privacy and utility. This paper can increase both, and the authors owe this enhancement to the ensemble of noise injected ResNets. What’s more, if it is just because of the ensemble, what is the contribution of this paper? 2.There should be proof that each iteration of the whole model by strategy I and II can satisfy DP, while authors only prove the parameters can satisfy DP.<BRK>The paper focuses on the topic of differentially private deep learning. Specifically, based on the deep residual learning, they first see it as an ODE. The first strategy is directly followed the SDE while the second strategy is with an addition multiplicative noise of the additive noise. I tend to accept the paper since I think the paper is well motivated, also there are privacy guarantees and some theoretical results on defending privacy attack (Theorem 3). So I want to see more comments about this. 2) Moreover, the motivation of S1 is clear which is just followed by the SDE. However, the motivation of S1 is unclear, why the authors add an addition multiplicative noise to the additive noise? Is there any other previous work on it?<BRK>### SummaryThe paper presents a method for training ResNets with differential privacy. The authors prove differential privacy guarantees for two strategies of this type (one with additive and one with multiplicative noise). They also show some evidence that the noise can help generalization, by showing that the Rademacher complexity of a continuous linearized version of the model is lower when noise is added. ### Evaluation: TheoryThe theoretical results are a start, but have some limitations which seem significant to me:* Theorem 1 needs the output of any residual mapping to be bounded in expectation. * Theorem 2 only gives privacy guarantees for a single prediction. This is interesting but not as a strong as outputting the model. In general, I do not want to see work on privacy in ML adopt the strategy of running a single membership inference attack to verify privacy. This is not convincing: what if a slightly different attack does a lot better?
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. <BRK>The authors of this manuscript proposed a generative dynamics system for the modelling and generation of 3D conformations of molecules. Specifically, there are three components: (1) conditional graph continuous flow (CGCF) to transform random noise to distances,  (2)a closed form distribution p(R|d, G), and (3) an energy based tilting model (ETM) to capture long range interactions and correct the position matrix distribution. The proposed framework was compared with two deep learning methods for conformation generations   CVGAE & GraphDG, as well as the computational chemistry tool RDKit on GEOM QM9, GEOM Drugs, and ISO17 data sets. Comparisons in terms of COV and MAT scores show that the proposed method (particularly the one enhanced with ETM) can outperform baselines. The major novelty is the use of continuous flow to model the conditional distribution of the distances and an energy based model to correct the conditional distribution of positions.<BRK>This paper presents an approach to generate diverse small molecule conformations given its graph by combining a conditional flow based model with an energy based model. The models are trained separately. Can the authors report a statistic over the generated distribution (instead of over the test set)? This was confusing in the first read.<BRK>This paper combines flow based and energy based models to generate molecular conformations from a molecular graph. A continuous flow model maps a graph based molecular representation into a distribution over conformations. Additionally, an energy based model (EBM) is used to further help the model capture long range atomic interactions.
Reject. rating score: 3. rating score: 4. rating score: 4. rating score: 6. <BRK>It would also be interesting to have a plot showing the evolution of the adaptative regularization coefficient along training. **Clarity:**The paper is quite clear and well written.<BRK>Weili Nie and Ankit Patel. The author(s) also propose a heuristic to remove the introduction of a further hyperparameter.<BRK>The authors point out that while superficially similar to other gradient penalties, it has a very different motivation, structure, and probably works in a different way; I generally agree with their argument. The baselines compared against aren t state of the art.<BRK>This paper proposes a new regularizer to improve GAN training. Experiments on several GAN objectives, datasets and network architectures are provided to support the effectiveness of AdvAs. (2) The whole framework is theoretical motivated.
Reject. rating score: 5. rating score: 6. rating score: 7. <BRK>Summary:This paper proposes a sliced version of the Bures distance, which is a lower bound on the 2 Wasserstein distance. The purpose behind this is to identify instances that are have the highest contribution towards the discrepancy between two distributions. But compared to other sliced OT distances, this one operates on a the Bures lower bound, which yields a more tractable solution. E.g., it is not immediately clear why (7) corresponds to a sliced version of (4). Also, under this setting, how is this different from just embedding all samples as a pre processing step and then using the usual sliced Wasserstein? In this case, I would have expected to see a vis a vis comparison of the three proposed distances, and the original sliced Wasserstein ones, on synthetic datasets of increasing size, to get a sense of their asymptotic behavior* It might be just me, but I find the setup of the experiments in 3.1 very confusing, and have a hard time parsing the results. What is the relevance of the x axis used here? Are these results good or bad? * The covariate shift detection experiments suffer from a similar lack of explanation for the various experimental design choices (e.g., why/how were these scenarios chosen?).<BRK>This paper studies a family of integral probability metric (IPM) divergence on Hilbert spaces. This family can be characterized by the choice of the witness function, and specific witness function may give rise to the Bures distance, the MMD, Wasserstein, as well as many sliced variants. The power of the method is demonstrated on the covariate shift experiments. The results can boost further learning tasks, and thus are relevant to the machine learning community. However, the content of the paper is a general (more width and depth) on a general family of IPM on RKHS. Currently, the main results of the papers are included in the Appendix. The introduction should be rewritten with a clear exposition of the contributions. Can the authors clarify how "often" is this?<BRK>##########################################################################Summary: This work proposes the max sliced Bures (MSB) distance, a distance metric for comparing probability distributions. I found the mathematical analysis to be interesting and a potentially valuable contribution to the ML literature on probability distance. I did not check the math in detail, but the authors appears to know what they are talking about. The community could benefit from more such tools. What I was hoping to see was a compelling demonstration of the technique on common problem arising in the practice of machine learning. ##########################################################################Pros: * Interesting mathematics* Important problem##########################################################################Cons: * Some difficulty in interpreting experiments* More compelling applications (e.g.solving mode dropping are desired)* Comparison with other methods where possible seems weak (Figure 5)##########################################################################Questions during rebuttal period: Mode dropping is a very common problem. I reiterate that I have not checked the mathematical content of this paper in detail.
Reject. rating score: 3. rating score: 4. rating score: 4. rating score: 6. <BRK>To overcome this issue, they propose a defense method named Bit corruption Augmented Training (BAT) to enhance the robustness of the model by embedding corrupted video samples in the training process. **Strength:**  Explores an interesting and new problem space for video model robustness. No comparison with naive fault tolerance methods at the network and video file level. The proposed BAT method is trivial and the performance is not good. It seems to me that this paper is more on the side of fault tolerance than defenses for attacks. The benefit of applying these methods is that they are model agnostic and would not affect model performance under normal conditions. How is this different from data augmentation? Lastly, I do not think it is a good idea to categorize packet losses as bit level corruption since data loss is fundamentally different from data corruption.<BRK>Accordingly, this paper proposed a new framework, Bit corruption Augmented Training (BAT), which utilizes the knowledge about corruption by bit level data augmentation at the training stage. This is the first work that addresses the robustness against bit level corruption of videos. Cons 	The technical novelty of this paper is not significant. However, data augmentation method is the main technical contribution this paper proposes. Also, additional experiments on UCF101 by using corruption agnostic and corruption aware defenses would make the paper more convincing. I agree that the paper proposed a new problem setting, but I do not think that the technical novelty is significant, given the proposed approach of just applying the data augmentation simply at a bit level, rather than at a pixel level. Due to this concern, I want to keep my rating of "4.<BRK>This paper simulates network and file corruptions at multiple corruption levels, and explore corruption agnostic and corruption aware defenses. The presented Bit corruption Augmented Training enhances the robustness of the video machine learning models. Pros: The experiments are very extensive. Cons:1.The novelty is limited. Compared with [1], I wonder about the advantage of the proposed method. I think the baselines in the manuscript is too weak. I think the difference is not significant. Bit flip attack: Crushing neural network with progressive bit search.<BRK>The problem itself is not widely studied and experimental work like this one certainly opens some possibilities. The solution on the other hand is surprisingly simple and easy to implement. What is the importance of solving this type of problem in the general video application setting? One would hope a section of related work on it and discuss the further reliance of a data driven approach. 2.The "No defense" baseline at some corruption levels are much better in accuracy. In  all, the problem itself seems worth a pursuit if stated with more context. The concern is that the solution is fairly specialized on the known noise types and their general range.
Reject. rating score: 3. rating score: 4. rating score: 5. rating score: 6. <BRK>Unfortunately, I am not convinced that the proposed method is clearly improving upon previous methods in any settings considered in the paper, so I would recommend for rejection. This begs the essential question on the effectiveness of the proposed losses on top of FixMatch. The proposed methods are evaluated on standard SSL benchmarks. I have decided to keep my initial rating.<BRK>It would be great if the authors can talk about whether the semantics oriented similarity representation in [a] could be used (and how to use it) to help improve the performance of the proposed method in the setting concerned by the paper. Results of RankingMatch show some improvements over competing methods in some cases.<BRK>This applies to all variants of the proposed RankingMatch method.<BRK>********Notes  My main concern about this work is lack of contribution. Table 1, their performance is very similar to FixMatch(RA). Figure 1 is self explanatory, showing the general framework introduced in this paper.
Reject. rating score: 4. rating score: 5. rating score: 7. <BRK>This paper presents an interesting idea of using neural network based RL to solve a type of vehicle routing problems, where the vehicles are tasked with visiting spatial locations to deliver items, and are subject to load capacity and delivery time constraints. It extends the work by Kool et al.2019 to incorporate constraints in the optimization problem, such as payload capacity and visit deadlines. Moreover, the reviewer expects more extensive experiments to demonstrate the efficacy of the proposed method, as well as discussion on what enables the proposed method/network to work better). As such, the reviewer believes that this paper is not suitable for publication in its current form. Here are just a few examples. The authors should also explain what the solution looks like, e.g., it s a sequence of locations to be visited for each robot. It should actually be multi robot task and single task robots (based on Nunes et al.2017).$\quad$ h. In the sentence above Sec.1.1, what does multi scale features mean here?<BRK>Figure 1 shows that the outputs of the architecture are the action probabilities, but the reader still does not know what the actions are and has no clear picture of the problem that is being solved. 4) I would recommend to clearly state somewhere in the beginning of the paper what are the specific contributions of this work from methodological standpoint. This work does not offer methodological novelties, and the particular application is of limited significance as the experiments are conducted on a toy problem, not on the real task that is given as motivation. Probably the main limitation that precludes from evaluating the significance of contribution and seeing this work as general contribution to the list of solution for routing problem is the fact that is was evaluation on only single instance of such problem, with only single set of experiments parameters (20 robots / 200 tasks). How does it fare against other similar routing optimization problems? How does if fare against other methods or AM is the only method that is worth comparing to?<BRK>I recommen the paper to be accepted. Paper discusses the development of a method called Covariant Attention based model (CAM) which expands the work of Kool et al (2019) into multi robot tasks. The deficiency of the paper is the explanation of the experiments. Now it was only said that the area is one square kilometer and the task times vary, but more details of the simulations would give more insight ito the real usefullness of the method. km or 1x1 km?
Reject. rating score: 3. rating score: 4. rating score: 5. rating score: 6. <BRK>How is this taken into account in the evaluation of the communities? The overall approach is empirical, supported mainly by the experimental results. Various graph measures are considered in the evaluation. The paper is well structured and well written.<BRK>This paper tests performance of different node similarity measures when used in K means for clustering LFR graphs. It is easy to read paper and well organized. The average degree is much smaller whereas graphs are usually much larger than the setting here. A rich set of graph similarity measures is studied.<BRK>1.No good reasons to choose settings of evaluation, particularly kernel k means and LFR. The setting is kernel k means, and if the similarity measure is given as some kernel, it might be more clearly shown what kernel is good under what condition, under kernel k means. I think this type of investigation is missing in this paper. 3.So what is the reason why SCCT is the best and/or why highly ranked methods are so?<BRK>The paper is well written, mathematically sound and interesting, and definitely useful to the graph theory community. However, as acknowledged by the authors, the study is limited by the structure of the benchmark suites, which is restricted to networks that can be generated by LFR rules.
Reject. rating score: 6. rating score: 6. rating score: 6. rating score: 6. <BRK>Update: Following the authors  clarifications and additional experimental work, I m increasing my rating to 6. It builds upon RIO, a framework for predicting residuals of regression models and their uncertainties using GPs. Compared with other confidence metrics, RED aims for greater separability between correct and incorrect predictions. The method is straightforward to implement and performs well against the baselines considered on classification tasks for 125 UCI datasets. or simply the entropy of the softmax predictions. Unless there is a good justification for the limited set of baselines, I believe the paper s claims to generality are limited. Additionally, for the OOD detection results shown in Figure 3, why were AUROC and AUPRC not reported? While the scatterplots show separability of OOD data visually, these metrics (used elsewhere in the paper) would give a better indication of performance (and again, I think a greater range of baselines and tasks would be necessary to make any firm claims about OOD detection).<BRK>The authors show enhanced performance against other related methods and the ability of RED to detect OOD and adversarial data through the variance of the confidence score. It uses a wide range of datasets and several statistical tests, and RED obtains superior performance. 4) The idea of using the variance of the proposed confidence score to identify OOD and adversarial data is interesting and promising. The adaptation of these components is also straightforward: the output kernel now works on several dimensions (instead of the scalar dimension of regression) and the target is now the correctness of the original prediction. 2) The experimental validation focuses on several competitors which can be considered "of the same family" as the proposed approach. Namely, all of them calibrate the predictions of a pre trained neural network. I think it would be interesting to also compare to a different "family" of methods. 3) I do not fully understand the relevance of the experiment with the large deep learning architecture given by the VGG16 model. Since the proposed method works on the pre trained neural network, my understanding is that the complexity of the neural network itself is not relevant for the performance of the proposed approach. Also, in this experiment I miss several independent runs to assess the results variability. ####################################Additional questions/feedback:1) In the second paragraph of section 4.2., there seems to be a typo when reporting the margin. For instance, some of the intended OOD data could be similar to training data (specially because the latter is being normalized to mean 0 and std 1). 3) When it comes to real practice, a key decision is to set a threshold on the confidence score to decide what instances should be supervised by an expert. However, I still believe that the contribution is incremental, and I think the paper would gain in terms of novelty if it focused more on the detection of OOD data and adversarial attacks (which right now is more like a preliminary test).<BRK>In this paper, their goal is to improve calibration and accuracy by augmenting a classification model with a GP. They propose a model, RED, which instead tries to predict the residual between the predicted confidence score for the true class and 1 — the true class target confidence score using a GP. They show strong improvements over the methods they compare to for 125 UCI datasets and CIFAR 10 dataset. I find the approach interesting though the novelty is incremental over the RIO paper. My main concern is that I think some additional methods need to be compared with. For example [1] uses a bayesian last layer which is something that should be compared with. Using an ensemble of single layer NNs for the last layer or using MC dropout at test time (which is known to approximate Bayesian inference under certain conditions) would also be interesting. [1] “Scalable Bayesian Optimization Using Deep Neural Networks” by Snoek et al.[2] “Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning” by Gal et al.Edit: Based on the author response in terms of adding additional experiments, I m raising my score to a 6.<BRK>The authors propose a framework to calculate a confidence score for detecting misclassification errors by calibrating the NN classifier’s confidence scores and estimates uncertainty around the calibrated scores using Gaussian processes. This paper is also technically sound and to the best of my knowledge is novel and relevant to the community. It would be good to apply SVGP directly to some of these datasets and compare the results against NN+SVGP results. You use the term “calibrated” confidence score/prediction. I find the presentation of results very confusing. For example, in Table 1, AP Error is smallest for the RED method and in Table 3 AP error is the largest for the RED method. In both cases, it is mentioned that the RED method outperforms other methods. I do not see this number on the table. It would be good if the authors could mention in the paper what is RIO short for. You mentioned that you need to extend the kernel to multiple output kernel. Could you explain a bit more about that and how you build it?
Accept (Poster). rating score: 8. rating score: 7. rating score: 6. rating score: 5. <BRK>This paper is in my mind a novel and interesting submission and a clear accept. # Main IdeaThe main idea is to study how well extremely activating images help humans to predict CNN activations. It is also well taken that units may be highly activated by more than one semantic concept, or active in combination with other units (which may convey more information than selectively maximizing for the single neuron’s activation). While the authors points are well taken, they do sort of sweep aside one aspect of feature visualization that is not captured by natural images. Figure 10 in the supplementary also shows very interesting relationship between the response strength between the natural images and the synthetic images.<BRK>  Summary  This paper focuses on feature visualizations that generates maximally activating images for a given hidden node to understand inner workings of CNNs. They compare the informativeness of these images compared to natural images that also strongly activate the specified hidden node, and find that natural images help human better to answer which other test natural images are also maximally activating. 2.The experimental design is clear and reasonable. Are there some examples that natural images can not help the participant predict while synthetic images can, and vice versa? 2.The conclusion is not surprising given the task is designed to find other test natural images. Although I find the conclusion is not very surprising, I still enjoy reading this paper throughout its rigorous experimental setups like experts v.s.<BRK>A significant set of related literature is referred to. More specifically, a description on how the natural images used in the experiments are selected is not in place. If this manuscript is to be accepted, and to ensure that it is self contained, the description of this baseline should be in the body of the manuscript. This begs the question, what if you have experts that beyond being familiar with CNNs are also familiar with explanation methods? As admitted by the manuscript, one of its limitation is its limited focus to only considering the feature visualization methods from Olah et al, 2017.<BRK>This paper asks a simple question: do extreme activating synthetic images for a CNN unit help a human observer to predict that unit’s response to natural images, compared with maximally/minimally activating natural images. But it’s solid, and introduces a useful framework for evaluating feature visualizations. They find that the synthetic images provide useful information for prediction, but that the benefit is smaller than that provided by simply presenting people with other natural images that maximally or minimally activate a unit.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. <BRK>The paper presents a meta learning method for learning Hamiltonian dynamic systems from data. More specifically, the novelty is incorporating Hamiltonian Neural Networks (HNNs) within known meta learning methods (MAML and ANIL) in order to model new dynamical systems (with previously known structures but unknown parameters) from partially observed data. Overall, the paper is well written and the contributions are solid: leading to reasonable improvements over recent work on modeling Hamiltonian systems while offering better understanding of the underlying modeling problem. However, I have some concerns regarding the experimental set up as well as the discussion of related work (and the motivation, thereof), which are reflected in my score. Second, the authors chose two benchmarks which address modeling Hamiltonian systems (HNNs) "by design" i.e.vanilla HNNs trained from scratch (for a given task) and Pretrained HNNs (using the meta sets). Can you also clarify this?<BRK>The paper introduces a meta learning approach in Hamiltonian Neural Networks to find the structure of the Hamiltonian that can be adapted quickly to a new instance of a physical system. The contribution is novel and the paper is well written.<BRK>The paper is easy to follow and nice to read, and seems to have sufficient implementation details for reproducibility. * If the paper gave a hint of what real world problem settings could benefit from this specific combination, which does not seem to be part of the discussion. but those are not really well covered. Probably the biggest value of the paper is that it brings together the HNN community (often closer to natural sciences communities) to the meta learning community (often closer to data science communities), and this paper may be a gateway from people from the former one to learn more about meta learning, but I am not if this is sufficient to grant acceptance. > When observing 25 shot point dynamics and 5 shot trajectories, the number of given samples in the phase space is the same, and the same is true for observing 50 shot point dynamics and 10 shot trajectories.
Reject. rating score: 4. rating score: 6. rating score: 7. rating score: 7. <BRK>The authors propose to integrate a few data transformations into a generalized formulation. Experiments show some validations of the proposed framework on audio visual scenarios. + Video transformations in contrastive learning has not been carefully investigated before. + The raised problem of balancing (or enumerating) between distinctive vs invariant transformations is underexplored and worth studying. The experiment is done on a very specific scenario: audio visual task, from which I believe that the main contribution of this work is more of the improvement of a specific audio visual self sup method, rather than a generalized formulation of the transformations.<BRK>Code is provided. ### Final recommendationOverall, I believe the strengths outweigh the weaknesses and I recommend this paper to be accepted to ICLR, but I suggest the authors address the previously mentioned points. The GDT framework consists of two ideas, and they are not properly separated in the paper (or not totally unified in a single one). ### Additional comments and questions:  Is the reference to SimCLR incorrect?<BRK>I am still leaning towards acceptance since I feel the paper is an important milestone for self supervised learning from video and audio but I will wait for the answers of the authors to take a final informed decision. This would make the comparison in Table 2 a bit more stronger than using the retrieval or the few shot setup that was used by methods that were not leveraging multiple modalities for learning. The results are strong for self supervised learning from audio and video.<BRK>2.This paper focuses on video and audio learning. The authors may share some insights in the conclusion. I have the following comments:1. If so, what s the limitation of the selection process generalization to more self supervised signals?
Reject. rating score: 3. rating score: 5. rating score: 5. rating score: 6. <BRK>This paper adopted Stein s method to connect an explicit density estimator and an implicit sample generator to propose an objective function for deep generative learning.<BRK>This is achieved by connecting the training of IM and EM via Stein discrepancy (SD), which is called Stein bridging. However, this does not mean it defines a valid discrepancy measure.<BRK>In this paper, the task is to train an implicit and an explicit model simultaneously via GAN setting and a new regularizer called "stein bridge", which is constructed from the kernel Stein discrepancy between the implicit and explicit models. The idea of adding such regularization, with the notion of mutual regularization of two models, is interesting. The sample quality from the generative models are compared.<BRK>Pros:* The idea to bind an explicit and implicit generative model and study the effect on both models is a valid research topic. For training an explicit model, the mode collapse behavior may be due to the usage of the Stein discrepancy. * The paper presents comprehensive experiments, and the results are promising.
Reject. rating score: 5. rating score: 6. rating score: 7. rating score: 7. <BRK>What are the object(s) in "Putting (something) on a surface"? 2) The action graph is "unrolled", and a graph is instantiated for each time step. In the case of this paper, all the object identities and actions over discrete time steps are given directly to the graph model to do "scene graph interpolation". The task of generating the video is then as follows..3) The layout generating Function. and the previous positions of the objects. It s task is to predict positions of objects and their bounding boxes for the next frame. The action graphs are a succinct way of declaring an evolving scene with multiple objects. My main concern is for the utility of the methods outside the synthetic CATER dataset. And the contribution of the Action Graph to the "something something" dataset results is not clear. Most impressive are the compositional actions "eg. huddle and swap" in Fig6 which show ability to produce videos of unseen group actions (that are compositions of previously seen individual actions). They carry out visual quality assessments and ablation experiments. It is possible that others in the community can rally around and develop the action graph description. ConsWhat is the actual definition of the Action Graphs used? For CATER it is stated that the target positions are provided for some objects, and elsewhere that an angle can be included for rotate. Is it possible to have more than one action per object per time step? In the something something dataset, are all the actions in this dataset single actions for one object with an edge from the single node to itself?<BRK>This paper proposes a model for video generation which disentangles the object layout prediction, frame by frame, from the actual pixelwise frame generation. if not why? Action graphs model objects as nodes and actions as clocked edges. This way action graphs are "clocked" so to take into account the current progress of each action. A so called Action Graph (AG) is used as specification of the video to be generated, rather than a sentence. The GCN is fed with the previous layout and the current AG. Experiments on two datasets are provided human and quantitative evaluation show superior results wrt to the baselineStrengths  well motivated approach for video generation. This reflects both at training time and at inference time but it is more critical at training time. How would this work to obtain action annotations for a dataset such as Kinetics, AVA or EPIC KITCHENS? Given that GT layout are available why not adding some layout consistency loss? This could be done by optimizing the IoUs of objects [a]. Why not encoding the object pose in the layout?<BRK>Several metrics, including human evaluation, indicates that the method outperforms powerful baselines on two datasets: CATER and Something Something v2. Pro:  Generating video content is a difficult task and the idea of generating frames based on action graphs to more explicitly focus on the activity class is interesting and naturally integrated into the proposed architecture. The experiments regarding the generalization to novel compositions of actions are interesting and show promising results for generating videos beyond the training domain. This aspect is only briefly mentioned in the main paper. Moreover, I think the ability of the method would be more clearly demonstrated in classes that have more than 2 objects if the extraction of the AG would be possible in that case. In the same manner, as the compositional experiment, it would be interesting to test the model using the same first frame from training videos, but changing the action labels from the Action Graphs (on Smt Smt). Moreover, both the ablation study and the quantitative evaluation show good performance, so I recommend the acceptance. ########### UPDATE #########I thank the authors for their responses and for updating the paper. I think this work introduces some new and valuable ideas for generating videos conditioned by an action graph and I recommend the acceptance.<BRK>Overview:The paper proposes a hierarchical approach to video synthesis based on Action Graph. Action Graph is a graph representation to describe the dynamics of individual objects. Based on this, the authors proposes an action scheduling mechanism to track the progress of action and then generate the scene layout at each timestamp. Finally, the pixels are generated based on the predicted scene layout. Experiments show that such AG2Vid paradigm can generate images on CATER and Something Something dataset with a better quality compared to the baselines. ++ The experiments on generating multiple actions, single action, as well as novel actions indicate that the method is capable of disentangling and composing atomic action for individual object. However, it is occluded **by** the yellow one instead in the generated video. The results on Something Something indicate that flow warping method might not be a good way to preserve the structure of the object/hand.
Accept (Spotlight). rating score: 7. rating score: 7. rating score: 7. rating score: 6. <BRK>This work introduces a set of tasks that require a simple symbolic reasoning and a new model   Emergent Symbol Binding Network (ESBN) to solve them. The tasks are designed such that it tests the model’s extrapolation ability. They show that previous memory augmented neural networks fail on the tasks whereas their approach with an external memory that supports a specific variable binding achieves an excellent performance. Pros:  This is interesting work that addresses an important question in neuroscience and deep learning. It is unclear if the model can be useful for other more complex problems. Some ablation on this is useful.<BRK>This work proposes a neural network architecture comprising a two stream memory structure: one block is populated with visual representations, and the other is populated by hidden state vectors from a controller. Reasoning that indirection is a central component for solving problems in the abstract, the authors go on to show that, indeed, such a network can solve abstract reasoning problems out of distribution. For example, a simple random projection of the image, or an MLP would be interesting. But, we need evidence to demonstrate that this is the case. The work is well motivated, and well written, and there is ample background details to understand the models and experiments.<BRK>Summary:This paper addresses abstract rule learning in high dimensional data through constructing a recurrent neural network that exhibits a variable binding ability. The proposed method, ESBN, is a RNN augmented with two memories, one for keys and one for values. Tested on several abstract rule learning tasks on visual inputs, ESBN exhibits excellent generalization with limited training data. The solution, ESBN, is simple and effective. Empirical evaluations clearly show that ESBN woks well on tested tasks, while several well studied neural  networks (LSTM, NTM, Relational network, Transformers) fail. It would be nice to have these tested, or discussed in the context of abstract rules learning.<BRK>Summary:The authors present an architecture capable learning symbolic representations and rules over those symbols. Also presented is a set of  tasks involving manipulation of symbolic rules over a set of symbols where held symbol sets may be used to measure generalization performance on the task set. The  architecture described in this paper is named the emergent symbol binding network (ESBN) which is composed of a two column external memory for indirection and two information processing streams, one for representing embeddings of concrete variables and another that is recurrent and trained to operate over task relevant variables. It may have been useful to consider other the more complex tasks involving symbolic reasoning such as CLEVR or bAbI. Recommendation:While I believe that this is a very interesting problem domain I think that the solution provided would have been more compelling if the scope of the problem was more ambitious and also I believe that the baselines could have been stronger.
Accept (Spotlight). rating score: 8. rating score: 7. rating score: 7. <BRK>Summary: This paper tackles an interesting problem setting — fully test time adaptation with only target data. The proposed method is to minimize the test time entropy, and the loss is used to update the feature modulation layer only. I think they can use the target test set instead of the target training set during training? In this case, it should be a fair comparison with the offline adaptation. Run online/offline adaptation on the target training set, and then directly apply this model on the target test set without optimization might be interesting.<BRK>Strengths– The approach appears very simple to implement and seems to work well, particularly on adapting to corruptions– The paper is well written, clearly motivated, and very easy to follow. – A more descriptive caption for Figure 2 would be helpful. I’m not convinced of the usefulness of this method as a DA technique. Overall commentsInteresting paper on test time adaptation that proposes a simple entropy minimization based objective to update batch norm parameters, and works well on robustness benchmarks.<BRK>$Pros$  The paper is very well written: it is easy to understand the core idea and its applicability in the context of the broader literature. The idea is to adapt layer normalization parameters at test time, by learning affine transformations. This would also clarify one concern I have, which is <how good the source model should be for the method to be effective>. The method is reasonable and simple, and results are strong.
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. rating score: 6. <BRK>Summary: The paper does a thorough investigation of influence functions applied to neural networks. They conclude that influence estimates for smaller networks are quite accurate but are erroneous for larger networks. This should greatly help with the reproducibility of your results. Are there some properties of the weight decayed Hessian that make it more reliable? The fragility of influence on large networks has been folk knowledge in the community, and the authors do a good job of codifying this; however, I feel providing theoretical intuitions for the observed phenomena would strengthen the paper s findings. For such an empirical paper, this would be strongly encouraged and beneficial for the community. Did you ever run group influence estimation?<BRK>##########################################################################Summary:The paper provides an extensive experimental study on using influence functions in deep neural networks. The authors suggest that the estimation via influence functions can be quite fragile depending on various architectures of neural networks. To point out such information, approximation with inverse Hessian Vector product techniques might be incorrect, which leads to low quality influence estimates. 3.The experiments are well designed with multiple architectures of neural networks and detasets. They empirically found that the Taylor’s gap is strongly affected by common hyper parameters for deep networks.<BRK>In this work, the authors perform an empirical analysis of influence functions in deep learning. Influence functions allow one to estimate the effect of weighting a training point at test time (for instance, dropping a training point from the training set with a weight of $\frac{ 1}{n}$ under assumptions about the convexity of the loss function and the models Hessian $H_{\theta}$.The authors note that successful applications of influence functions are rare in the literature, despite their potential applications. In general, they find that each of these can cause issues with influence function calculation. Strengths: * The paper has excellent presentation.<BRK>The main idea of the paper given in Section 3 is that an approximation of the influence or impact of a training sample on the test set can be obtained using second order Taylor s series expansion at the optimal model parameter   a bilinear form where the matrix of the form is given by the hessian inverse and the vectors are gradients evaluated using training and test sample. Weaknesses:  The "retraining" phase to get the ground truth seems like an interesting idea, which in my understanding has not been looked at. The paper fails to clarify why such an approximation will provide any insights on the performance of neural networks. In fact, in it possible to count the number of linear regions, see (http://proceedings.mlr.press/v80/serra18b.html). Related to the previous point: It is unclear what the take away is from the experimental results in the paper.
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. rating score: 6. <BRK>Summary of the Paper:          This paper describes Bayesian context aggregation for neural processes. The proposed method also leads to a new way of training CLV models which is based on moment matching. The paper is well written and the proposed method is sound.<BRK>The paper builds upon previous lines of research on multi task learning problem, such as conditional latent variable models including the Neural Process. This makes it difficult for me to judge originality and significance, but it is well written and clear. This is also essentially what is done by Synthetic Likelihood (a Nature paper by SN Wood, 2010) which is I think more closely related to the proposed approach than GPs.<BRK>In this paper, the authors make two contributions to neural process like CLV models. Overall, in my opinion these modifications make the neural process model significantly cleaner from a Bayesian perspective and is quite nice. In the context of neural processes, I have very little criticism for the authors  methods.<BRK>The authors present the Bayesian Aggregation (BA) mechanism in the context of Neural Processes (NPs) for aggregating the context information into the latent variable z in the form of posterior updates to z. The background and method is presented very clearly. I am willing to increase my score should these results be included in the revised version of the paper.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. rating score: 6. <BRK>In particular, it proposes an open QA problem over both tabular and textual data, and present a new large scale dataset Open Table and Text Question Answering (OTT QA) to evaluate performance on this task. Two techniques are introduced to address the challenge of retrieving and aggregating evidence for OTT QA. Results show that the newly introduced techs bring improvements. I like the idea of open question answering with various types of evidence. The paper formulate an interesting problem of open QA problem over both tabular and textual data. 2.The creation of the dataset (OTT QA) is a great contribution to the community. The authors claim to release the data to public. Would the test set make blind so that make it a challenge like SQuAD?<BRK>This paper proposes a new setting of open domain question answering. The authors build up a new dataset which need to retrieve both text and the corresponding table to answer open domain questions. This setting is more close to a real world setting where structured information is also essential. Moreover, the authors propose a pipeline of fused retrieval and cross block reader to solve the problem. Although the idea is close to the entity linking or hyperlinks for multi hop QA, it is new under this open QA setting. Overall, I would like this paper accepted. Pros:1.Release a new task and dataset for answering open domain questions with text and table. 2.Set up very strong baselines, and propose fused retrieval which is important to achieve strong performance for this task. Cons:1.I would like to see more analysis on the dataset.<BRK>(This review is a collaboration between a junior and a senior reviewer as part of the training to the junior reviewer.Both of them read the paper in detail.) SummaryThis work extends the task of answering questions over tables and text to open domain. They construct a new dataset   OTT QA   on top of a closed domain multi hop question answering dataset, which requires reasoning over tables and text. Adding a retriever step poses a challenge for the system to retrieve relevant tables and text, given a question. I would request the authors to consider using the notation for dual encoder as used in [1]. Applying both strategies gives significant gains over other baselines. This makes the task artificial. HybridQA is built by first selecting a table and then related anchoring documents. The reviewer is left with distaste making them wonder what are the scientific takeaways from this work. Is it mainly the retrieval that is hardest or the reasoning (reading) once retrieved? An oracle baseline where the gold table is given but not the documents (and vice versa) should be presented to understand the impact of HybridQA annotation procedure on the naturality of this task. What will be the performance of the fusion retriever in the absence of hyperlinks?<BRK> Summary In this paper, the authors introduce the task of open domain QA using table and text. Unlike recent tasks on table and text retrieval, where the table associated with the text is known, in this task both tables and text need to be retrieved from a large collection. Overall this is a good interesting paper but it has some important questions that were not adequately answered. The dataset has been constructed by reusing the Hybrid QA dataset as well as crawling additional tables and passages from Wikipedia. The authors also present a method for for this task   It consists of a "fusion reader" which that aligns a passage and table segments ( Table row+ metadata  Table segment). This augmented query generator is based on GPT2 and has been fine tuned using the training data. Experiments have been presented using the HYBRIDER baseline from the HybridQA task as well as an iterative retriever reasoner baseline in place of the fused retriever. Experiments indicate that the use of fusion retrieval as well as cross block attention (using ETC) individually and jointly help improve performance over baselines.
Reject. rating score: 3. rating score: 3. rating score: 4. rating score: 7. <BRK>I also think understanding mode collapse with the duality gap was a good idea. Cons:  I am concerned by the repeated usage of "valid protein sequences" throughout the paper. I m not sure if the authors intended to use the word "functional". Homologous sequences could improve model performance. As someone working in biotechnology, I think there is great interest in the refinement of molecular properties to highly specific functions, and little interest in generating sequences generally from GO categories, which are much too broad.<BRK>In this manuscript, the authors present a conditional GAN for generating protein sequences given specified GO terms. 8.The primary use case for a model like this seems to be the ability to generate proteins with combinations of functions not found naturally. Also, there is no analysis of sequence complexity within these groups. Have the authors considered that use case? Strictly by random sampling? Increasing the size of the val and test splits is also a good idea. 4.Train/val/test splits: the val and test splits are very small. 3.Provide a more rigorous description of the model and experiments.<BRK>The paper applied conditional generative adversarial networks (cGANs) on the task of protein sequence design with respect to GO molecular functions. Overall the contribution was based on empirical numerical experiments.<BRK>As it stands, the paper simply proposes the measures and then evaluates various protein design methods using those measures. Overall, the experimental design seems to be quite rigorous. The results section also mentions, with respect to CVAE, that "close inspection of the sequences and of the predicted chemophysical properties (Figure 5) of the sequences indicates that the sequences are not well formed." For example, it is nice to see significant time spent on hyperparameter optimization for the competing methods.
Reject. rating score: 3. rating score: 5. rating score: 5. <BRK>Without experiments on real images, the analyses presented in this paper are unlikely to convince researchers in this area. The authors claimed that the new model is more data efficient.<BRK>**OVERALL**On the whole, I think that this paper is not ready for publication due to unclear writing, and the fact that it is missing a critical comparison to Prob NMN. I also take issue with the underlying approach, since I think the methods used to achieve data efficiency on CLEVR cannot scale to real world data. But testing this kind of model on CLEVR is not.<BRK>The paper presents results on CLEVR only, which goes back into my concern about the inflexibility of the probabilistic programs. However, the novelty of the paper seems limited to me, as it mainly combines together ideas that have been extensively explored in many prior works which are mentioned by the paper.
Accept (Oral). rating score: 8. rating score: 7. rating score: 7. <BRK>This is a very interesting idea for controlling a pretrained model for some sort desired criteria. The authors argue that existing approaches for this have taken a pointwise view for instance using REINFORCE to optimize for a particular reward. This can lead models to over optimize on the criteria and sacrifice diversity and other criteria. Some of these constraints are point wise but some are distributional. In addition to comparing with REINFORCE based methods,  the authors also compare with CTRL and PPLM in the appendix. Cons: I think the method section (especially the optimization part)  could be explained better for readers who are not familiar with EBM, and allow the paper to have more accessibility.<BRK>The problem is formalized as a constraint satisfaction problem, minimizing a divergence objective. Overall, the paper is well organized and easy to understand. Experiments were conducted over both pointwise constraints and distributional constraints, showing the effectiveness of the model over the compared baselines. Pros:  The problem under study is an important problem and can have extensive impact on many downstream language generation applications.<BRK>In this paper the authors have proposed a mechanism for controlled text generation both pointwise and distributional. or the generated corpus by GPT 2? The authors proposed a method Generation with Distributional Control (GDC), which is nothing but a constraint satisfaction problem over the probability distribution p representing the desired target Language Model. Overall I find the problem challenging and promising.
Reject. rating score: 4. rating score: 4. rating score: 7. rating score: 7. <BRK>Note that when the sample size increases, the sample correlation matrix converges in probability to the ensemble mean, and the whitening could be performed in a more accurate way. Weakness  The title and the sentiment of the paper may be misleading. When the sample size is small, whitening cannot be done very accurately since sample correlation is not accurately estimated. It may be important to keep the title accurate other than eye catching. But when the whitening step is performed without too much noise, generalization only depends on function class used and the number of samples, per classic generalization theories. It is scary at first glance, but the conclusion and experiments do not really support the claim “destroy”. The impression from there is the updates are dominated by the covariance matrices and if the covariance matrices are identity, then there is no information about the training data passed through the training process. Basic generalization theorem suggests that generalization is only related to function class’s complexity, but not the correlation among the coordinates of the data samples. It may be good that the authors compare their results with classic results, e.g., those based on uniform convergence, under some function hypothesis complexity measures (e.g., finite class, VC dimension or even Radamacher complexity). The main results claim that whitening is harmful, the simulation may have suggested otherwise.<BRK>This paper shows theoretical and empirical evidence that under some conditions, whitening the input data and second order methods may hurt the generalization performance. The paper is well written with good intuitions but overclaims its results. All in all, I do not think that the paper provides sufficient evidence that justifies its title and main message of the paper. What if you run a more standard second order method like KFAC? In Section 2.3, the statement "whitening hurts generalization" is true only for high dimensional datasets, where the input dimension > number of samples. Like I said before, there are a number of confounding factors and the story is not as simple. In Section 2.4, please also consider d > n case. This is hardly a claim justifying that "whitening hurts generalization", it is an optimization problem and is orthogonal to the paper. The statement "second order information destroys generalization" is therefore an overclaim. Moreover, this section focuses on the squared loss with a linear model. How is the learning rate selected?<BRK>This paper shows  that for a large class of models   models $f$ consisting of a fully connected layer followed by an arbitrary parameterized function, $f(X)   g_\theta(WX)$   data whitening removes all information that is relevant for generalization. **Overall, I recommend that the paper be accepted**. The theoretical results are interesting and potentially high impact, and the writing clarity was excellent throughout. My main reservation about the paper is that it s not clear to me which insights are being proposed as novel, and among those, which actually are novel. As mentioned in the paper, whitening is essentially putting the signal and noise in the data on equal footing. The paper seems to be really centered around the whitening, when it seems to be the specific combination of the two rather than whitening alone. ## Minor Comments (which did not influence my score but could improve clarity)   **Page 2**: *"Our result is not restricted to neural networks, and applies to any model in which the input is transformed by a dense matrix multiply with isotropic weight initialization"*  should read *dense matrix with isotropic weight initialization*?<BRK>The authors in particular focus on the impact of whitening  the data beforehand or using second order methods. Since whitening trivializes the Gram matrix, the authors argue that whitening destroys important information. The main message of the paper, contained in Fig.3, is easily reproduced with a few lines of code. The paper sheds an interesting light on the generalization properties of second order methods. Of course, the theorems also apply if we assume that the initial weights are zero (or close to zero), which is still a very interesting case. it would be worthwhile to better describe the initialization strategy for the linear weights. Second, I think that another important concept which is not mentioned in the article is that early stopping is similar to regularization of the parameters, which is why the reported ‘test error’ in the experiments is lower than the test error obtained by perfectly minimizing the train error. "On early stopping in gradient descent learning." In fig.4.b, does training epochs mean ‘number of epochs to reach the best test error’?
Reject. rating score: 4. rating score: 7. rating score: 7. rating score: 8. <BRK>The paper claims this new method provides a significant improvement over state of the art branching strategies, either based on expert designed rules or on imitation learning of strong branching. This alone raises serious doubt in my mind about the validity of the reported numbers. However, I remain concerned about the experimental setup in the paper, and therefore my final recommendation is still rejection. I suppose that $\phi_t (\theta_t,\sigma_t)$ ? From the RL training ? And as a result it aligns with your evaluation metric (nodes). Third, I found several arguments to be fallacious.<BRK>Additionally, the paper makes an interesting observation: It demonstrate the problem with mimicking an existing heuristic. This makes it difficult to compare the results of the two papers. I suggest adding experiments using those instances in the appendix. ### RecommendationThis paper introduces a new direction in the area of *learning to branch in MIP solvers*. The paper has potential for follow up work.<BRK>1.Ablations of novelty component inside search and learning architecture### Cons/Clarifications1. I don t feel confident that the evidence presented that strong branching decisions are bad, because of the non diverse and small sized data distribution   section 5.2 Table 1   I would feel more confident if the data were 300 randomly sampled instances from MIPLIB *if you don t get timeouts in your evaluation then it isn t large enough to be interesting application wise)1. the reward described may not work well when training on instances large enough that take lots of steps to solve1. the PD policy net is a graph neural network specialized for bipartite graphs with single scalar attributed edges, and its receptive field is 1 hop per layer, so 2 hops for the architecture used in the paper, which raise the question: how does the diameter (or average variable variable distance) of the data distribution compare to that? 1.I don t really know if the novelty score will scale well to large MIP instances, or if it is defined for infeasible MIPs. The paper is readable.<BRK>The approach is based on reinforcement learning. The paper presents an adequate overview of previous approaches to the problem. There is not a lot of detail about how these approaches work but the overview of the techniques given allows the reader to see how the proposed approach differs from this earlier work and motivates the technique. This is supported by later experimental results. It would be interesting to understand what it is about this problem that gives different results. There is some investigation of why this is and why the technique works. There is a discussion section in the appendices.
Reject. rating score: 4. rating score: 6. rating score: 6. rating score: 7. <BRK>To do this, they introduce additional transformers layers between the layers of a pre trained language model such as Roberta and term this model as "K Adapters", where the K stands for K different streams of knowledge. The proposed approach is simple and interesting and it scales to many different types of information as the different adapters can be trained in parallel with the weights of the pre trained LM being fixed. Performance gains on different classification tasks such as entity tying, question answering, and relation classification highlights the utility of the approach. In Table 1, dependency parser doesn t really fall under the same class of knowledge sources such as Wordnet or Wikidata. It just states that knowledge infusion using k adapter model outperforms Roberta models in different tasks. The paper doesn t report if the results are from single run or the mean of multiple runs. Currently, the paper pays just too much emphasis on raw numbers or performance improvements in various tasks. This raises an important question over the validity of the results in different downstream tasks.<BRK>##########################################################################Reasons for score: The authors propose a plug in based adapter approach to allow for task specific parameter settings without updating the original pre trained model which prevents the potential for catastrophic forgetting while also removing the need for separate models for separate tasks. The experiments are extensive and well done. ##########################################################################Pros:1) The number of experiments run ( 3 tasks on 6 datasets total ) are extensive and shows the K adaptor approach can benefit from the factual adaptor in particular in giving better performance over RoBERTa ( with or without multi task learning ). It is my understanding that when pre training the facAdapter on the relation classification task for instance in Section 3.3, for a given example in T REx rc,  two entities and context are passed into RoBERTA whose weights remain fixed while those of the KIA units of the facAdapter are updated and the final hidden representations of RoBERTA and the facAdapter are concatenated to form an input representation of the entities given their context and this used for the actual task. Clarifying this process for 3.3 and 3.4 would be beneficial for clarity purposes and its not discussed in the supplemental materials either.<BRK>The paper proposes a new approach to inject knowledge into pre trained language representation models (PLMs). Instead of tuning the original PLM parameters, the paper plugs in new adapters for knowledge injection to avoid catastrophic forgetting. Pros:* Injecting knowledge into PLMs is an advanced topic. * The paper is well written and can be easily understood. Some more explanations are expected.<BRK>#### SummaryThis submission proposes a general method (K Adapter) for injecting knowledge (either factual or linguistic) into pre trained language models. The key architectural property of the approach is that K Adapters are isolated from one another, allowing the use of multiple adapters without interference. These K Adapter modules take hidden layer _inputs_ from the main pre trained model (eg, BERT), and are pre trained on their knowledge outputs before a fine tuning phase where they feed into a joint downstream task specific model along with the pre trained model outputs. The proposed approach yields strong quantitative performance against solid and relevant baselines, and the LAMA experiments give some support to the hypothesis that it is doing so by capturing knowledge as intended. "inject different types of knowledge independently"   is it correct to say then, that, by design, there can be no _beneficial_ interactions or synergies among different types of knowledge? If not, it would have been interesting to have an experiment of this sort in this work.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. rating score: 6. <BRK>Whether this denoiser can be applied to other noisy scenarios, such as a real color noisy image or MRI. This paper is well written and good organized.<BRK>An observed image with noise is input to VAE, and after the expression $z$ in the latent space, the noise removed image is finally output. The paper itself is interesting, and the proposed method itself is good as one of the image processing methods, but there is a lack in the explanation part.<BRK>2) Table 1 shows 13 datasets, but it is hard to use them to compare with other denoiser results in other literature.<BRK>(3) VAE framework seems only to work for small and constrained images. The experimental results show that this method can outperform existing unsupervised denoising methods. How can the proposed method deal with it?
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. rating score: 6. <BRK>This paper tackles online continual neural network learning (following Lopez Paz & Ranzato, 2017) with a combination of techniques: (1) a controller (or base parameter modulator, or hypernetwork) is introduced which produces task specific scale and shift parameters, which modulate the feature maps of a base model (Perez et al., 2017); (2) as training data set samples are only provided once, the authors maintain experience replay buffers using soft label targets (by now standard techniques in online learning); (3) a bilevel optimization scheme where controller parameters are updated in an outer loop and base parameters adapted in an inner loop is employed. I think that these merits outweigh the lack of novelty. The presentation of the method (which spans roughly two pages and a half) is lengthy and not very clear. Why is $h_l$ obtained from $\tilde{h}_{l 1}$?<BRK>**Summary of paper**This paper introduces a continual learning method called Contextual Transformation Networks (CTNs). CTNs consist of a base network and a controller, which outputs task specific feature modulators. Both these have independent memories used to reduce forgetting. These two networks are trained together (formulated as a bi level optimisation problem). The strongest part of this paper for me is the experiments section. I think it would be useful for the authors to think how they can simplify it further for a future version of the paper.<BRK>However, as I do no longer have access to the file submitted by the authors for NeurIPS 2020, I encourage the authors to correct me by detailing modifications to the manuscript made for ICLR 2021, in which case I will be open to changing my score provided sufficient reason. The authors introduce Contextual Transformation Networks (CTNs), a replay based method for continual learning based on a dual memory design and a controller that modulates the output of a shared based network to task specific features. Please describe this in more details. CTNs are a novel (albeit simple) architecture that might inspire future work.<BRK>This paper proposes CTN (Contextual Trasnformer Networks) for online continual learning. In particular, the authors introduce a dual memory framework that contains an episodic memory for base networks and semantic memory for task controllers. The overall framework is optimized with bi level optimization. In addition, the base network also uses a KL divergence loss to prevent catastrophic forgetting. ####### Strengths######+ The paper is addressing an important problem, i.e., continual learning. #######Weakness######  The novelty is a bit limited.
Reject. rating score: 5. rating score: 5. rating score: 6. <BRK>I could not find any analysis of the trade off between the accuracy and the values of parameters r and p. As a result, it is not clear what the runtime dependence on those parameters is. The algorithm itself proceeds by applying polynomial approximation to the twiddle coefficients in FFT, which makes it possible to reduce the running time. Overall: the paper has interesting (and potentially very useful) ideas.<BRK>The resulting algorithms run in time O(N + M log M) where M is the size of the required frequency range, and N is the input. In fact, the main idea in the paper uses Cooley and Tukey s decomposition of the expression for Fourier transform. This is done by pruning Cooley Tukey s FFT. It is not as good as O(N + M log M), but it is EXACT, and it doesn t require the M frequencies to be in a single consecutive range. This setting is different from the one in this paper, but it is definitely relevant.<BRK>My main objection to this paper is one of scope. Overall this is an interesting paper. While I did not check the math fully for correctness, the development appears correct. A discussion and an experimental study of the performance of the method compared to the Goertzel algorithm or the direct implementation would demonstrate the benefits of the algorithm.
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 6. <BRK>The presentation of this paper lacks clarity and a good structure. The information in the appendix does not provide sufficient details. The paper does not successfully justify the merits of the proposed method, with many hidden parts that are hard to follow.<BRK>2.The main contribution of this paper is the loss function derivative in Theorem 1, which mainly uses classical calculus. The comparisons to existing baselines are missing. 2.The author mentioned that model free methods such as PSRO, has the issue of low sample efficiency and high variance issue for policy gradient methods, however, both of which has not been addressed by this work, and this proposed method is not compared to model free method either.<BRK>This can be enough to show that the presented method is efficient but it is not enough to claim that the compared methods are not. The main goal of this paper is to address the problem of multi resource spatial coverage. However, I found the paper clearly written, and the subject nicely presented with examples. Anyway I ve been convinced by R4 and R1 that a few baseline models are missing.<BRK>This paper shows that spatial coverage objectives with multiple resources are combinatorially hard to approximate with neural networks and proposes a spatial discretization based approximation framework to solve this problem. The paper is very hard to follow due to all the notations the authors introduced and the details set up in the examples.
Reject. rating score: 4. rating score: 6. rating score: 6. rating score: 7. <BRK>If video segmentation is indeed not the end goal of your approach, when it shouldn t be used as the main evaluation metric. My main issue is with the positioning of the paper. The authors claim that their goal is learning disentangled, multi object representations, but all the evaluations are on the task of unsupervised video segmentation on toy datasets.<BRK>The main concern about this paper is the novelty. First, unsupervised video decomposition, like Sqair and R NEM all use the temporal information, and the iterative inference method has been used in previous work like IODINE. The authors should better illustrate their novelty and contributions of this paper. Highlight them with some red bounding boxes is helpful. "Unsupervised object segmentation by redrawing."<BRK>This paper presents a new model for unsupervised video decomposition based on the multi object scene representation of IODINE. The most important contribution, if I understand it correctly, is the use of 2D LSTMs in the iterative amortized inference for temporal modeling.<BRK>The paper presents a model for the unsupervised decomposition of videos into objects. It builds onprevious models operating on individual images such as IODINE and GENESIS, and extends them to thevideo domain by conducting iterative inference also across the time dimension, leading to acomputation graph resembling a 2D grid. The proposed method closes an important gap in the landscape of unsupervised object based    models: It is the first such method to decompose colored videos using pixel wise segmentation    masks. The method is well motivated and clearly presented. It is well executed and adds some interesting ideas to the toolset of unsupervisedobject models.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. rating score: 4. <BRK>What is the goal of the paper? Investigating stability of fine tuning BERT. What has been done before? Both works focus on pre training and thus orthogonal to this work. Investigating fine tuning failures on datasets from the popular GLUE benchmark and show that the observed fine tuning instability can be decomposed into two separate aspects: (1) optimization difficulties, characterized by vanishing gradients, and (2) differences in generalization, characterized by a large variance of development set accuracy for runs with almost equivalent training loss. Presented a simple but strong baseline that makes fine tuning BERT based models significantly more stable than the previously proposed approaches. What are the key techniques/experiments used to investigate this task? To investigate catastrophic forgetting   comparing language modeling perplexity for failed and successful fine tuning runs of BERT. To investigate the effect of small size of the fine tuning datasets   compare fine tuning using  downsampled data sets for 3 epochs (standard) vs. more epochs. Loss surface visualizations of failed and successful runs when fine tuning BERTVisualizing development accuracy vs. training loss at the end of the training for all BERT models fine tuned for the paperFine tuning performance of (a) BERT, (b) RoBERTa, (c) ALBERT for different learning rates α with and without bias correction (BC)	What are the main results? No.Catastrophic forgetting occurs for both failed and successful models in the top layers of the network,  except for a much smaller increase in perplexity in case of successful models. However, this is not the case for the failed fine tuning runs. This suggests that the observed fine tuning failure is rather an optimization problem causing catastrophic forgetting in the top layers of the pre trained model. The role of training dataset size per se is orthogonal to fine tuning stability. StrengthsThe approach is well motivated and well placed in the literature. Paper claims look correct technically and are experimentally rigorous. Paper is easy and clear to read. Findings apply not only to the widely used BERT model but also to more recent pre trained models such as RoBERTa and ALBERT. These findings should benefit others as fine tuning BERT based models is a very common practice now. Different sets of GLUE datasets were used for different experiments without any explanation for the selection.<BRK>The paper explores why fine tuning is an unstable process, and proposes a strategy to stabilize it. The experiments use BERT, RoBERTa, and ALBERT, fine tuned on three popular datasets from the GLUE benchmark. Based on the analysis of failed fine tuning runs, the authors conclude that while catastrophic forgetting and small size of the datasets used for finetuning (both of which are common explanations for fine tuning instability)   indeed correlate with fine tuning instability, they do not directly cause it. In a set of experiments it is shown that instead, fine tuning instability is caused by: (1) optimization difficulties early in training, characterized by vanishing gradients, and (2) differences in generalization, characterized by a large variance of development set accuracy for runs with similar training performance. Pros:  The experimental approach is insightful and seems solid  The paper is exceptionally well written and illustrated  A contribution of practical importance for a large communityCons:  The focus is on a particular type of problem: transformer based masked language models that are fine tuned on small datasets  I noted that the proposed fine tuning guidelines are only evaluated using BERT, whereas the failure analyses apply also to RoBERTa and AlBERT. I m not sure that I like this sentence though   "there is no clear motivation for why preserving the  original masked language modeling performance after fine tuning is important". This obviously depends on the task.<BRK>################################ Summary:This paper considers the stability of fine tuning BERT LARGE models, with considerations for RoBERTa and ALBERT. The underlying argument is simple and slightly advances a conversation about the underlying workings of BERT based models while leaving substantial room for future exploration. ################################ Strengths:  Broad interest. BERT based models have become prevalent in NLP due to their strong empirical performance. However, variation in fine tuning hinders the consistency of the demonstrated gains. As a reader this is appreciated insofar as claims are stated unambiguously and then can be validated by the work that follows rather than intuited. The guidelines of using a "small learning rate with bias correction" and "increase the number of iterations" are good, but can they be characterized in more detail? While the existing datasets are sufficient for illustrating the arguments made, additional datasets would further support generalizable insights by providing additional points of evidence with respect to dataset size, and variance. This may support the point above regarding a characterization of large vs. small. If I were to apply these insights to a NLI dataset in another domain, e.g.MedNLI, could I expect these to hold? While the aspects of pretraining and continual pretraining are explicitly deferred in the related works section, are there any insights you can provide about their impact on these findings for fine tuning? ################################ After response:Thank you for the clarifications. The response and changes address several of my concerns.<BRK>### OverviewThe paper focuses on the instability phenomenon happening in the fine tuning of BERT like models in downstream tasks. The reasons of such instability were assumed to be catastrophic forgetting and the small size of datasets on which being fine tuned in previous literature. The authors conduct experiments on several sub tasks of GLUE in an attempt to show the aforementioned two assumptions cannot explain the instability of fine tuning. Instead they claim that the real reasons are gradient vanishing and the lack of generalization and subsequently propose a set of training hyperparameters to improve the stability. ### ProsThe analysis of the impact of dataset size is designed clear and concise, which shows it is the number of iterations that really matters rather than the size of datasets. This conclusion is valuable for the audience. The suggestions of training hyperparameters provided at the end of the paper is somewhat useful for future researchers. A very simple counter example: assume a fine tuned model A has 50% accuracy on a binary classification task while model B s predictions are all opposite to model A s predictions, which also makes it a 50% accuracy model. While the std of performance is 0, which by the definition of the authors it is the most stable case. Since the definition is very important and used through the whole analysis, the fact that it is defined too rough makes the following conclusions in the paper not convincible enough. Besides, the proposed improvement method is only using slightly different training hyperparameters, which is possible to be covered by a simple grid search of hyperparameters and therefore cannot be seen as a big contribution.
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. <BRK>This paper proposes a new algorithm for black box optimization (BlendSearch) that combines global search methods together with local search methods. Extensive experiments on different applications (XGBoost, LightGBM, DeepTables, fine tuning NLP) which show promising results. Theoretical and/or experimental justifications are needed for some of the key statements in the paper. Furthermore, it is not very clear to me how or why the fundamental claims made about the algorithm are true. Maybe this needs a theoretical proof or maybe it is somehow obvious by construction, but either way the paper should explain this clearly. If no parallelism was used, does ASHA even make sense (e.g.without any parallelism there is no need for the ‘asynchronous’ aspect)?. The paper could be made stronger by showing how the performance of BlendSearch improves as more workers are added, and how it compares to schemes like Hyperband and AISA with the same number of workers.<BRK>Summary:This paper proposes BlendSearch, which combines global and local optimisation for the problem of hyperparameter optimisation when search cost is heterogenous. ConsThere is generally no theoretical discussion in this paper. Pros (in addition to the summary provided) 	The paper addresses an important problem and proposes a sensible strategy that builds on two successful ingradients. While TurBO does not consider the cost heterogeneity and do not use local optimization instances, I think that their selection method is more principled and could be food for thoughts for the authors.<BRK>The proposed BlendedSearch (BS) presents an intuitive next step in the combination of global and local search schemes for hyper parameter optimization (HPO). Another unknown is the interplay between the global and local search   it is not clear whether the proposed scheme really leverages both global and local searches. This needs better clarification. For points to be valid, the $\Delta_i$ for the local searches need to be large, but the choice of these $\Delta_i$s are not discussed in this paper.
Reject. rating score: 3. rating score: 5. rating score: 7. rating score: 7. <BRK>The authors propose a deep RL solution for the communication problem of user scheduling and resource allocation. I’ll add that my score is not influenced by my concern that this paper may not be a good fit for ICLR (I leave that choice to the AC). There were other issues with the paper. However, the specifics of the problem, specifically in the context of RL was not. Novelty of the algorithm is low in the sense that it is a combination of prior, existing ideas. The use of the dueling architecture also seems unusual when the authors also propose a much simpler solution.<BRK>8.There is a large literature on wireless scheduling with latency guarantees from the networking community, e.g., Sigcomm, INFOCOM, Sigmetrics. Representative results there should also be discussed and compared with. post rebuttal: My concern regarding the experiments remains. The paper considered a complex scheduling scenario, which is a hard problem by conventional optimization methods. I will keep my score unchanged. 2.The paper adopted state of the art techniques and works fine. The presentation of the paper should be improved. This can cause confusion for readers reading the main text. From this paper, the illustration of Distributional RL lacks clarity. 4.The experiments are not comprehensive for validating that this algorithm works well in a wide range of scenarios. 3.The authors should state clearly as to why the complete state history is enough to reduce POMDP for the no CSI case.<BRK>Basically, it seems that the proposed method is interesting and meaningful. The scheduling problem in this paper is based on the analogy to a server having a water pitcher, and the deep reinforcement learning approach for the scheduling problem has been designed. However, the scheduling problem in wireless networks is a very famous issue.<BRK>This paper addresses the long standing problem of scheduling and resource allocation in wireless networks using modern Deep Reinforcement Learning techniques. The methodology is well justified and thoroughly motivated. It would be nice to have these details listed in a sub section somewhere in Section 3. Regarding the evaluation, "synthetic" traffic patterns are used. Will the inference times for the deep network lead to any significant overheads when measured at the time scale of wireless communications? Overall, the evaluation setup seems preliminary to me and needs more work to provide assurance of real world usability.
Reject. rating score: 3. rating score: 5. rating score: 5. <BRK>This work studies the generation technique for multi category MTPP using adversarial autoencoders for sparse and incomplete datasets. Weakness: The major concern is the contribution of the work is very limited. Why change the timestamps to days and scale it to a probability value?<BRK>Summary:The authors propose a method for multi category marked temporal point processes (MTPPs) generation with sparse, incomplete, and small training dataset. Besides, the method to convert t_ij to a_i and examples are not provided. The paper is clear in general.<BRK>The paper is concentrated at dealing with the data missing problem of MTPP and applies an AAE for the “incomplete multi categorical MTPPs”. The authors seem to misunderstand the difference between empirical distribution and probabilistic distribution. Here the authors see the arrival time of the events as a random variable, and $t_{ij}$’s are independent samples of the random variable, which is unrelated to point processes.
Reject. rating score: 4. rating score: 4. rating score: 5. <BRK>Conclusion:Again, I believe that this work is addressing a very important question with an interesting idea, but it may require a little bit more work to make the case. I appreciate the authors thinking about this problem, and hope the authors are encouraged to continue their work. The idea of using variational free energy with model based RL seems novel to me, and has not been widely explored. The experimental sections also do not mention how MCTS and MPC baselines differ. I do not find the answer from the paper. The paper uses different indexing styles which make the method more confusing than it should have been. Experiments  As metioned briefly before, more baselines or ablation will be critical to judge the importance of the proposed model? What about compare against other sliency approaches such as prediction error for memory accumulation? The experimental results do not provide enough information to understand what tasks can be solved and what cannot be solved in Animal AI environment.<BRK>There are lots and lots of references to work by Friston et al., but I am not sure I see the connection with active inference as being that strong or even necessary. P4: “The habitual network acts as a model free component of the system, learning to map inferred states directly to actions”. Could one think of applying the same STM principle that is already applied to states, to actions as well? Perhaps an environment with longer horizons would be a more adequate testbed? I very much liked that the authors showed the additional results in Appendix C, I think they are extremely important for the paper. However, I disagree with the claims made in the text, as it appears that they are not substantiated by the figures they reference.<BRK>In this paper, the authors describe a variable timescale prediction model for planning in the context of a deep active inference agent. They show that this agent outperforms a baseline in a scavenging task in a 3D first person environment. They show example rollouts of the baseline and variable timescale models. Until reading this paper I wasn t familiar with deep active inference agents, which apparently enable the extension of free energy methods to more complex settings. It seems like an intriguing alternative to deep RL. It s not clear to me whether it has the scaling potential that has been demonstrated for deep RL. This will be reflected in my confidence score. However, (2) is not substantiated well by the paper s analysis section. The only evidence for this is in the form of two pairs of example rollouts for the time locked and variable time models. Are these cherry picked examples, or are they actually reflective of general trends? But, as far as I can tell, there s no evidence in the main paper for this. Maybe it would be sufficient to simply randomly drop out timesteps from the trajectory to reach the STM MCTS performance level. If the authors can provide stronger evidence on these points, I d be very happy to increase my rating.
Reject. rating score: 4. rating score: 6. rating score: 6. rating score: 6. <BRK>This paper provides an interesting research direction for the cross domain of federating learning and backdoor attacks. This direction has very limited work until the recent 2 years. The author(s) have created many splendid terms to describe the modules used in this work, however, their implementation uses both clustering and median, which is very engineering and may not reliable with a different clustering algorithm or data set is severely unbalanced (just like the non iid data sets among clients). This kind of uncertainty due to the ad hoc nature of the pipeline causes me to wonder: how bad this framework can be if any of the carefully cherry picked modules fails its purpose? Please compare it with a few Trojan attack methods in recent years. I believe no matter what kind of backdoor and Trojan attack, can be easily applied to FL by applying them individually on each client without too much trouble. The holomorphic encryption is a pretty standard concept in FL, I don t understand why the author(s) have listed this as the major contribution for the work.<BRK>In the paper, the authors proposed a novel privacy preserving defense approach BAFFLE for federated learning which could simultaneously impede backdoor and inference attacks. To impede backdoor attacks, the Model Filtering layer (i.e., by dynamic clustering) and Poison Elimination layer (i.e., by noising and clipping) were presented respectively for the malicious updates and the weak manipulations of the model. To thwart inference attacks, private BAFFLE was built to evaluate the BAFFLE algorithm under encryption using secure computation techniques. The paper is clear, logical, and easy to follow. 2.The topic of simultaneously defending against the backdoor and the inference attacks is significant. The topic is significant but the contributions to the proposed approach are limited. What is the cause of this phenomenon？3. In FL, clients locally train model updates using private data and provide these to a central aggregator. If some models were directly discarded in the central aggregator, the corresponding private data are not utilized for model training which is not an ideal approach, especially, the private data is irreplaceable. After reading the response, I still think that the work is promising and would like to keep my recommendation.<BRK>This paper suggests a new solution to protect FL models from backdoor attacks. This paper s main idea to defend against a backdoor attack is to use clustering and adaptive clipping and noising. In the clustering phase, the aggregator uses a clustering technique to identifies the weight matrices that have been manipulated by the adversary. In the clipping and noising phase, the aggregator tries to mitigate the effect of manipulated weight matrices that could not be identified in the filtering phase. Strengths: This paper uses an existing clustering algorithm (the HDBSCAN clustering algorithm (Campello et al., 2013)) that works best in the FL problem in identifying manipulated weight matrices. Using this clustering algorithm combined with adaptive clipping and noising, the proposed method can mitigate the backdoor attack. The extensive numerical examples show that the proposed method outperforms other defense methods most of the time. I ask the authors to clarify/explain the $\bf{\underline{novelty}}$ of their algorithms during the discussion period.<BRK>The paper proposes a backdoor resilient federated learning method to defend the backdoor attack of poisoning the models. The clustering is based on the assumption that the poisonous and benign models can be classified into two parts. How to choose the parameter \lambda such that adding the noise N(0, sigma) do not flooding the model G_t? What are the overall operation complexity? As in experiments, there are differential privacy based method? Would the authors provide the reasoning to compare different privacy methods?
Reject. rating score: 3. rating score: 4. rating score: 5. rating score: 7. <BRK>This problem is equivalent to the parameter estimation for logistic regression in the first of the paper and quite close to it in the second part when we purposely change the encoder via transfer learning. No surprise, that the reconstruction in this setting works well. So for the benefit of the quality of the paper, I suggest dropping all theoretical results as they are not new. For the setting with the fine tuning of the models, we can see from experiments that after learning emerges a disagreement between the parameters estimates via the proposed procedure and the initial values of parameters. In particular, how can we measure the distance between two models even if they are one layer logistic regression models, and can we do something if there is one layer in a setting closer to the white box problem.<BRK>Summary: This paper is an interesting study of algebraic model extraction attacks on modern NLP models based on BERT. This result by itself is not sufficient for acceptance to ICLR. The attacks in this paper work perfectly in settings where BERT is frozen and a single classification layer is fine tuned. This is a new attack setup (especially in the BERT fine tuning setup), algebraic attacks have only been attempted on very shallow neural networks with ReLU activations. These two layers are needed to separate the MLM representation from the logits. for MNLI is close to 33%. While I like the overall idea of leveraging the BERT pretrained checkpoint to do algebraic attacks, the authors  results show that this by itself is not sufficient to make an effective attack.<BRK>Summary:This paper proposes a range of algebraic model extraction attacks (different from the prevalent learning based approaches) for transformer models trained for NLP tasks in a grey box setting i.e., an existing, public, usually pretrained encoder, with a private classification layer. The pretraining finetuning experiments on different tasks also show the smallest number of dimensions needed for high fidelity extraction, and also that the model extraction attacks effectiveness decreases with fine tuning the larger models base layers which is an insight that is very useful for a lot of interpretability/probing work. Reason for score:I think this paper is very well formulated both theoretically and empirically with promising results that will be useful not just for grey box adversarial attacks, but also for works interesting in the effects of pretraining finetuning (which at this point encompasses nearly all NLP tasks). It would be helpful to have a discussion and examples of those. 3.Is there a comparison between the algebraic approach and a learning based approach for the same tasks? (I think the paper is novel and useful enough in itself, but it would be helpful to see a side by side comparison).<BRK>The paper proposes an algebraic attack for extracting the parametersof a semi private language model that consists of a pre trainedencoder and a privately trained classification layer. Experiments on two public datasets and two versions of the BERT modelshow the effectiveness of the method, and demonstrate thatthe number of queries needed is relatively small,the probes can be drawn from the distribution of legitimate input,and that fine tuning the encoder makes the attack less effective as the trueembeddings deviate from those computed from the publicly knownencoder. One question is whether the proposed approach could be put to somepositive use, such as learning about a model s potential weakness inthe input space?
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. rating score: 6. <BRK>This paper presents a variant of Transformer where low dimension matrix multiplications and single head attention are used. The paper is well written and easy to follow. Although the proposed architecture has fewer MACs, it would be interesting to know the real decoding time.<BRK>Before fully recommending this paper for acceptance, I’d like to see more discussions on how the proposed changes affect latency, a latency benchmark against other relevant Transformer variants, especially with parallelism, and some concrete statements regarding latency in the abstract and the conclusion. The only reference I could find is in the conclusion: “we expect a dedicated CUDA kernel for DeLighT units to be much more efficient, both in terms of speed as well as memory during forward and backward passes.” This implies that the current implementation might not be efficient speed wise.<BRK>I also find it rather controversial that the depth in the paper counts all linear layers, and not just the number of nonlinearities between the input and the output. It is important to build more efficient and compact models, but I find the paper’s analysis of models computational demands rather incomplete. I think it is important for the paper to justify the use of the DeLighT layer. DeLightT layers seem similar to the DeFINE layer. It is hard to make a call in the case of this paper.<BRK>The results of the paper look encouraging at first glance but I have a couple of major concerns with this paper as it is right now: 1) The paper s motivation is that parameter rich, wide and shallow models are problematic to train due their requirement of large training data or strong regularization. Furthermore, deeper models will have other issues such as storing many more activations which can result in memory bottlenecks.
Reject. rating score: 4. rating score: 5. rating score: 6. rating score: 6. <BRK>This paper studies the convergence rate of double Q learning under the tabular setting. The technical novelty of this paper seems limited   possibly a direct combination of [Wainwright 2019a] and [Xiong et al 2020]. Without numerical results or additional theory, such a gap makes one ponder whether the rates in this paper are tight. Thus, the technical novelty of this paper is limited. A more interesting setting is the asynchronous setting, where one updates each state action at each iteration. 5.I appreciate the efforts of the authors in comparing with the related work details. It would be nice to also compare with papers on standard Q learning and other methods in the tabular settings. 6.In the abstract, why is the run time complexity given by the "big Omega" notation, which means that the time complexity is larger than the quantity provided in terms of the order.<BRK>This paper refines the existing finite sample bound of double Q learning. This paper considers the rescaled linear schedule of the learning rate and claims that the sample complexity bounds are improved in the sense the dependence on all main parameters (epsilon, 1 gamma, L, D) have been improved. The nested SA representation of double Q learning is interesting and the proving techniques seem new. Significance: I am not sure whether the significance level of this submission meets the standard of ICLR or not. Is the comparison with Xiong et.al (2020) really fair? 2.Does the theory in this paper lead to any new insight for design and tuning of double Q learning?<BRK>This paper provides a sharper analysis for the finite time convergence rate of the double Q learning algorithm. The authors provides bounds for the synchronous and asynchronous settings and uses a more refined learning rate of $a/(b+t)$. It is shown that with such step size rule, a sharper convergence rate than (Xiong et al., 2020) can be obtained. Moreover, though the double Q learning algorithm is different from the standard Q learning, it also seems that the sharper analysis done in this paper has a worse dependence on $1 \gamma$ compared to (Qu & Wierman, 2020). Relation to Prior WorksAs claimed by the authors, one of the major innovations in this work is to deploy a rescaled step size of the form $a/(b+ct)$.<BRK>This paper provides a new theoretical analysis of double Q learning in the tabular case. The analysis improves over previous result of Xiong et al.which assumes polynomial learning rate. This paper considers rescaled linear learning rate and the sample complexity has better dependency on 1/eps. The improvement comes from a better characterization of the error dynamics. My main concern is whether the results are interesting enough to the ICLR community. Certainly, understanding the theoretical guarantee double Q learning is an important topic, and this paper provides a nice improvement over the previous analysis. However, I am not sure if the improvement is significant enough compared to the previous result. ***Post Rebuttal***I appreciate the authors s improved analysis.
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 6. <BRK>The authors propose a low bit floating point quantization method to reduce energy and time consumption during training. An efficient training algorithm needs to be supported by detailed experimental results on various types of DNN models while any computational overhead should be reasonably addressed.<BRK>Algorithm 1 is too busy to be useful. Dynamic quantization and MLS tensor arithmetic are used to enhance the effectiveness of MLS. The results seem incremental.<BRK>This manuscript describes a new low bit training framework as well as a new low bit format and shows promising accuracy precision trade offs and better energy efficiency. The proposed method achieves no accuracy drop with 3 bit training on CIFAR dataset and 1% accuracy drop with 6 bit training on ImageNet dataset. Although the results are comparable to state of art works like "Hybrid 8 bit Floating Point", this paper has several drawbacks. However, it is also very important to show a logic justification. 3.It is not clear to me that how MLS format avoids 32 bit FP multiplication.<BRK>This paper investigated the low bit training problem and proposed a novel method, which can reduce the element wise bit width to simplify floating point computations to nearly fixed point. The major contribution can be summarized as follows: a multi level scaling (MLS) tensor format, a dynamic quantization and the low bit tensor convolution arithmetic. it is not clear how or why the proposed model should be more efficiency to reduce the element wise bit width compared with other methods? Is it just an observation/interpretation of the results?
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. <BRK>Minor comments  The authors propose an original pipeline, yet the dataset and the code to reproduce the results are not provided, which hinders reproducibility and the potential impact of this work. The automation of EEG pipelines, like this paper does, is extremely important.<BRK>I believe the paper has been clarified, results are more carefully evaluated and claims are sound. This gives the impression that the bVAE+SCAN approach is substantially superior to the hand engineered baseline. I believe that this work consitutes a well selected application that addresses a relevant research question with important clinical implications. Methods 	Some aspects of the methodological description of the analysis are missing. Justification of recommendation 	I believe the research question addresses a very important problem in trying to identify sparse and interpretable clinical markers from EEG data.<BRK>The paper is well written but lacks a description of related work in the field and also a detailed analysis of the results to support the claims. Novelty:  The use of VAE and beta VAE for EEG data is not novel and this line of literature should be better discussed in the paper.
Reject. rating score: 5. rating score: 5. rating score: 6. rating score: 6. <BRK>The paper addresses multi task learning for multimodal emotion recognition on two existing datasets (IEMOCAP and SEMAINE). Strengths:*The issues addressed in this paper are very relevant. Weaknesses:*This work is motivated by the analysis of video conferencing videos which is indeed a crucial and topical issue. However, this motivation is a little bit heavy handed as the processed data are very different from video conferencing videos (face to face human interactions for IEMOCAP and human agent/Woz interactions for SEMAINE database). *Contrarily to what is claimed in the abstract, the relevance of the auxiliary task is not investigated in the paper. The primary tasks (4 classes emotion classification using the same 4 emotions, and dimensions prediction) are very close to these auxiliary tasks. *The method used to provide a multimodal representation of the data for the inputs seems interesting (as I understand it: extracting multimodal features and generating an augmented text containing multimodal narratives using MONAH, a previous system proposed by the authors) but it s difficult to understand what this method brings compared to the state of the art of learning multimodal representations. Besides, it will be interesting to discuss shortly the performance of MONAH on the two datasets of human human interactions (maybe showing some outputs). Thus the contribution is rather experimental than methodological.<BRK>This paper tackles conversational analysis problem and more specifically the Primary Multi Task Learning. The three hypotheses the paper tries to address are interesting and important. In this section, I am not quite sure if using future labels would cause information leakage to the primary task. Hypothesis H2: When the primary branch is given maximum learning capacity, it would not be outperformed by models with primary branch having less than the maximum learning capacity. For this, where is the experimental result for using them as features instead of using as targets? Overall, the paper adopts an experiments driven approach to test the three hypotheses, but the main issue is that this approach adopts a specific neural network method.<BRK>This paper addresses challenges faced in the multi task learning (MTL) models used in analyzing multimodal conversational data. The authors explore how the preprocessed data used for feature engineering can be re used as auxiliary tasks in the model. The paper is trying to tackle an important problem faced by multi task learning (MTL) and the way different aspects of the problem are explained in paper is valuable. The paper is well written and easy to follow. Although the paper is trying to tackle an important challenge, the novelty or contribution of the paper is limited. The useful ideas concluded by the paper has been previously identified in the community, for example, NLP community has been using auxiliary tasks like NER to improve primary task’s performance. Also, hierarchy in which to structure primary and auxiliary tasks in a model is also somewhat discussed previously. Another shortcoming of the paper is that the proposed solutions are evaluated on a specific domain and it is not clear if these findings are general enough to be applied to other domains.<BRK>The authors propose and test three hypotheses for primary MTL. To explore how to use the preprocessed data as auxiliary tasks in primary MTL, the authors present a nicely executed study and test three hypotheses. Here are some of my questions and concerns for the paper:1) The contribution of this paper seems to be limited since the idea of using visual features, audio features, and context as auxiliary information is similar to lots of emotional classification models such as ICON, CMN. 2) More related works about multi task learning and multimodal emotion detection tasks should be included. 3) More in depth experimental analysis should be carried out.
Reject. rating score: 2. rating score: 4. rating score: 5. rating score: 5. <BRK>It draws a conclusion about continuing improved RL sample efficiency in the past few years. In all, the material presented in this paper does not fill a complete paper, and the evaluation protocol and conclusions are not valid. This conclusion is rather thin to fill a complete paper. Also, authors only report results for score 400 and 2000, which is also inadequate.<BRK>##################################Summary: This paper conducts a meta analysis of the trend in sample efficiency in deep RL. ##################################Overall: I am not sure that this work in its current form is the right fit for ICLR. Since S and N vary between papers, it is difficult to measure progress in this field. Therefore, I suggest that it be moved to the main paper.<BRK>The paper is trying to make extensive and systematic investigation in deep RL papers to measure the recent progress in the broad literatures. Answering how DRL has progressed on data efficiency is an essential addition to measuring how much it has progressed; Minor:  For Figure 1 (a) some agent was labelled at a wrong published year, e.g.FRODO was published in 2020 instead of 2018. In fact, as also be mentioned in the paper, van Hasselt et al.2019 and Kielak 2020 noted that if you tune  the hyperparms for data efficiency, you may draw a very different conclusion. It might be worth expanding these sections and put those into the main paper instead of the Appendix.<BRK>The paper also shows that there has been exponential progress in the sample efficiency on both Atari and DMControl with nice log linear plots. This is an interesting analysis, on the lines of OpenAI s papers on Scaling Laws, but done for Deep RL. Cons:The DMControl results could be presented better.. I believe this is an issue with SLACv2 as well. is not clear to me.
Accept (Poster). rating score: 8. rating score: 8. rating score: 7. rating score: 6. rating score: 5. <BRK>The choice of mixing function appears to be dependent on the problem   for instance, it could be an universal mixer such as a neural  network or it could be a simple summation. The paper is written well. Experimental results appear convincing. Personally, i feel that the paper can have a good impact. Does this mean that you are overfitting in terms of creating newer edges that dont exist?<BRK>* The empirical results clearly illustrate the benefits achieved due to action representation. * The paper is clearly written and well organized. From Fig 6 & 7, it is unclear what are the benefits of using hyperedges of higher order. * It would be informative to conduct experiments on problems with higher dimensional action spaces such as Hunters & Rabbits. It d be worth adding a small section on how to scale this method for higher dimensional action spaces (bullet 2 in author response).<BRK>Prior to DQN, many RL (with function approximation) papers treated the action as an input. Now, I m not saying that not handling continuous action spaces is necessary (your results on discretized continuous action tasks are impressive), just that you should be more up front with this fact. This provides a strong inductive bias for reinforcement learning problems with a small number of action dimensions, each  taking several values. Not until the experiments is it revealed that the method (in its current state) is only applicable to tasks with finite action spaces.<BRK>This work considers the idea of adding a representation for action space. Their approach is based on hypergraph representation and shows its merits in the experimental results. But in general, I find the technical contributions (borderline) incremental.<BRK>This paper incorporates a concept called hypergraph network into reinforcement learning. This seems natural for scenarios like continuous action control with multi dimension action space. From experimental results this proposed action hypergraph networks outperform several existing baselines. The idea of hypergraph may be useful for broad range of applications. It s unclear how significant the proposed method is better.
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 6. <BRK>2) Label smoothing alone does not provide stronger adversarial robustness, this is not a surprising result as pointed out by many existing work. As entropy maximization is similar as label smoothing, it is also in the expectation that they have similar performance without providing stronger adversarial robustness. In addition, this work only tested the model on the PGD attacks, the same type of attack (although with smaller l infinity norm bound) is used during training. It is very necessary to test the model against different types of attacks, especially decision boundary based attacks, to support this conclusion as this is the main contribution of this work. In all, I vote for a rejection for this work. ******** After Rebuttal ************I carefully read the authors  response and unfortunately they do not address my concerns. Based on my research background in adversarial robustness and uncertainty estimates, I would keep my original rating unchanged as this work has very limited contribution to these two areas.<BRK>The authors combine adversarial training with two methods that increase the entropy of the output distribution of neural networks (label smoothing and entropy maximization). While the authors provide a detailed experimental evaluation of their defense method, this part of the paper is still my main concern. In particular, I see the following issues:* It is not clear if the authors choose a sufficiently large steps size for the PGD attacks. This is a concern particularly because Table 1 shows that the model accuracies still decrease substantially when going from 10 to 40 PGD steps. * Again on the note of step sizes, why did the authors choose max(1 / 510, eps / k) in the attacks with more iterations? * It would be good to see attacks with the Carlini Wagner (margin) loss function. Considering the well known difficulties with evaluating defenses against adversarial attacks, I currently cannot recommend accepting the paper. Could scaling the softmax temperature also work for increasing the entropy of the softmax distribution in a way that leads to increased robustness? Beginning of Section 6: "deeper into the how"  Equation 12: what is X + delta?<BRK>Summary:This paper tries to improve the model robustness by modifying the loss function with the EntM or LS term. Also, they give a further analysis to identify how uncertainty promotion works. And the experiments also demonstrate the effectiveness. Weakness: The novelty is limited. Also, it seems that the label smoothing is the only contribution proposed by this work, but it is pretty naive. The analysis part is difficult to follow. Comments: There are many works that claim the distillation training can improve the robustness of the model, which also adopt the soft label in loss function. For uncertainty analysis, the explanation is not straightforward. Second, why the L2 norm of the Jacobian matrix is its largest singular value? I think the performance drop with adversarial training is still high, although the results show the accuracy is better than TRADE. I suggest the authors to provide some experiments that adjust the hyper parameters to identify the trade off between the clean accuracy and the robustness of the model. This work only considers untarget attack. Please try more algorithms if possible.<BRK>* Theoretical insights as to why Entropy Maximization would help improve adversarial robustness, complementary to adversarial training is provided in Section 6## Weak points  * The method is studied on small datasets (CIFAR, MNIST, SVHN) using small models (ResNet18). However, the numbers were obtained using the CIFAR10 dataset and a ResNet18 model. [Comment: I am not 100% up to date with the related literature, so I ll be looking to other reviewers if they are aware of existing work combining uncertainty regularization and adversarial training.] * Ablation experiments in Figure 3 shows substrates for the complementary actions of Entropy Maximization and Adversarial training. How do the normalized margins and adversarial distances of normal training compare in this plot? Table 4 already shows that the normalized margin (0.19) is smaller than the three methods, but I miss the numbers for adversarial distances during normal training. # Minor feedbackThese points are minor feedback and not part of the assessment. It is not clear to me if its direction is parallel or orthogonal to the decision boundary.
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 8. <BRK>#### Goal  This work presents an experimental investigation that shows the impact of training selection bias in GNNs (bias with respect to the test data). It also proposes a decorrelation approach to eliminate the spurious correlation in the node representations that come from this training bias. I like the experimental investigation (since I think the problem is very relevant). I am skeptical about the method and the results. It uses a lot of results from linear models into a proposed nonlinear model. Assumption 1 gives us a statistical model not a causal model. The linear models presented later are not linear on the observed variables. Nice demonstration of the issues with biased training data. Generally, bias assumptions are made about the data, not the output of a representation learning procedure. It says that there are some topologies that cannot be represented exactly. How do we know that the decorrelation of H is not restricted to the training data?<BRK>This paper presents a novel method to remove the selection bias of graph data, which is neglected by previous methods. Specifically, the authors suspect that all variables observed by GNNs can be decomposed into two parts, stable variables and unstable variables. Experiments on three datasets confirm its effectiveness. Pros:+ The studied problem is general and also practical for real world applications. Cons:+ The novelty of this work is limited. Although the authors claim it is the first work to solve agnostic label selection bias problem, I in person believe this work can be regarded as a special case of DWR [1]. Therefore, on the basis of DWR, this paper presents not much theoretical contribution to this problem. For example, it is not clear to understand the connection between the example presented in Section 2.1 and the proposed method. Besides, how do you efficiently compute the inversion of matrices?<BRK>For simpler models such as Label Propagation previous work has shown that different variants perform better depending on whether we label high or low degree nodes (see e.g.[3]).It would be interesting to discuss whether this also affects GNNs and whether the proposed approach can help mitigate such bias. If the authors show stronger empirical evidence (see questions) I will consider increasing the score. * Evaluating the effect of small sample selection bias on massive graphs from the Open Graph Benchmark (https://ogb.stanford.edu/) would be insightful. Moreover, it is not clear whether the type of selection bias studied in the paper is actually relevant in practice. * The causal view analysis of the proposed regularizers is insightful. Since the performance improvement is still marginal and based on the other reviews I have decided to keep the same score. Weak points:* There are no results in the paper which show how the proposed method performs for a standard (non biased) labeling scenario. "Revisiting semi supervised learning with graph embeddings." * It is not clear whether the highlighted label selection bias is actually present in practice. In most real world graphs however, we tend to observe homophily (opposite of heterophily), i.e.neighboring nodes tend to have the same labels. * The performance improvement in most cases is marginal and does not seem to effectively mitigate the highlighted issue. "Generalizing graph neural networks beyond homophily." Are there any trade offs? How well do the proposed methods perform in the transductive setting?<BRK>The DVD regularizer is designed based on the causal view of variable decorrelation terms. Furthermore, the paper theoretically proves that how to combine variable decorrelation terms with GNNs would be a more flexible framework for most GNNs and how to extend the theory to the multi classification scenario. The paper conducts extensive experiments on four benchmark datasets with two kinds of selection bias, well showing the effectiveness of the proposed model. The agnostic label selection bias problem in GNNs proposed by this paper is very important but seldom studied. 2.The technique of the proposed method is sound. This is a general framework for enhancing most existing GNNs under label selection bias setting. I think these ideas are instructive. 3.The experiment part is comprehensive and convincing. These two kinds of selection bias usually happen in real world scenarios.
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 5. rating score: 6. <BRK>The authors present a very interesting idea of training a large network and a small network simultaneously with an interesting new loss function. The authors show that this can lead to a much smaller network with good accuracy (compared to the original network); thus this may be a good technique for sparsification. Can you motivate why we should focus on the second order term during training? (That paper also has a checklist of things to be careful of when doing pruning research.) Also, a claim in the introduction is that training is faster this way since pruning and finetuning don’t need to be iterated. **Writeup**The write up could do with some more attention e.g.use \citep instead of \citet in most places. The mask M should be a tensor not a matrix. Would that give similar results?<BRK>This paper introduces a training policy for jointly learning parameters of both supernets (or big teacher models) and subnets (or small student models). : How about the transfer (generalization) ability of the proposed adjoined networks? For jointly training teacher models and student models, an adjoint loss consisted of cross entropy loss and KL div is defined. (1) No state of the art model compression method is compared for verifying the effectiveness of the proposed method. The corresponding discussion and comparison are missing in this work. Particularly, one shot NAS based on knowledge distillation has been studied [r5], which supernets and subnets are jointly trained. Meanwhile, [r5] also shows the searched small student models can achieve comparable or better performance than big teacher models. (4) For fully verifying the effectiveness of the proposed method, the authors would better report the results using more CNN models, rather than those on various benchmarks. In particular, Imagewoof shares similar philosophy with ImageNet.<BRK>The authors propose a method for training two networks jointly. This resembles the teacher student approach where the teacher (large) network is trained first and used as an instructor for training the student network (smaller). The proposed paper implements the training of the two networks in a joint procedure and proposes a new kind of loss function "adjoint loss" that consists of two terms: (1) the prediction loss of the teacher network, and (2) the Kullback Leibler divergence between the predictions of the student and the teacher. The results should be clarified. This comparison is not relevant, as there are over 4500 citations to the original work.<BRK>The parameters are shared between the two, and the loss  aside from the standard cross entropy of the larger network  also incorporates the KL divergence between the outputs of the two architectures. This is so the trained small network will be able to simulate the larger one with a fraction of the parameters, which makes for less memory and faster inference at deploy time. The improvement on the accuracy of the large network when trained adjoined is also a nice byproduct. However, I have the following concerns:  From a practical standpoint, this approach requires to train the large network alongside the small one. I believe it s important to understand how the small adjoined network compares to the teacher student network as a function of changing the desired size.<BRK>The proposed technique deals with the main issues of current compression approaches. The author says that the small network selects a fraction of the convolution filters of the large one as its filters. How to implement the convolution in small network needs to be further illustrated? However, the M is fixed before training and is not learnt. In table 9, with M zeros outing parameters incrementally, the results do not follow the same trendy. 3)	The proposed “Adjoint loss” is similar with the loss of existing knowledge distillation architectures. The author needs to illustrate the difference between them.
Reject. rating score: 3. rating score: 4. rating score: 4. rating score: 4. <BRK>This paper proposes a line search for optimizing deep neural networks. Please also cite the recently proposed methods based on the Polyak step size, Berrada, et al "Training Neural Networks for and by Interpolation" and Loizou et al "Stochastic polyak step size for SGD: An adaptive learning rate for fast convergence" that have been used to train deep neural networks. The idea of building a model of the loss function by using additional points (from the past) is well known in the deterministic optimization literature in the form of line search with quadratic/cubic interpolation.<BRK>Update: I thank the authors for the detailled response. Due to the number of required changes and the feedback of other reviewers, I believe the paper needs a major revision before publication and still recommend rejection. The submission introduces a heuristic to select the step size for training deep learning models. Reducing the dependence on hyperparameters and improving the performance of optimization methods with out of the box settings is an important problem and relevant to the ICLR community. The main weakness of the manuscript is a lack of motivation for the details of the proposed heuristics and insufficient experimental evaluation. The experimental evidence in section 3.1 is promising but is not broad enough to be informative. There is evidence the proposed method can work.<BRK>The method is simple and easy to understand. New batches are sampled, and the loss values along the search line are fitted with a low order polynomial. A major weakness of the paper is the empirical evaluation. One would have to evaluate on an independent test set. For Figure 6 right: This comparison is meaningless unless the stopping criteria for all methods are clearly stated.<BRK>Summary:This work proposes ELF, a newl method to do line search. The idea shows promise but the current state of the paper should be improved before warranting acceptance, for the reasons listed above. To my knowledge, SLS is the best performing line search method in deep learning. Weaknesses:  I find the contribution of this paper a bit weak.
Accept (Spotlight). rating score: 8. rating score: 8. rating score: 6. <BRK>In addition, the authors provide some results for the full batch case. The paper is well written and the logic of it is convincing. I like the introduction and Figure 1 (this nicely illustrates the relevance of this paper).<BRK>The analysis shows that there exists a beta2 < 1 that leads to convergence for realizable problems, and to convergence to a bounded region of interest for non realizable problems, without requiring a bounded gradient assumption. One of its strongest points is how well the analysis and the relevance of the results is motived. Overall, this is a nice, well written and relevant paper that clears the bar for publication in its current version.<BRK>More specifically, it investigates the relation between the hyper parameters and the convergence of the algorithm. Cons:Apart from the strong points, I still have some concerns about the clarity of the paper. 3.The experiments supporting the theoretical results are comprehensible. These results provide basic guidelines for tuning hyper parameters of the algorithms in practice.
Reject. rating score: 3. rating score: 4. rating score: 4. rating score: 5. <BRK>This paper attempts to provide a convergence analysis for nonconvex continual learning with episodic memories, and try to theoretically show the degradation of backward transfer caused by  overfitting to memorized samples. It further proposes an algorithm for learning rate scheduling in  nonconvex continual learning based on these results. The reason of the score of the paper is that the theoretical proof is wrong in my understanding and cannot support the main contribution claimed in this paper,  the main problems are as below. So the  significance of this paper is further limited. If the authors can clarify all above main concerns, I m willing to make another round of review. "Gradient episodic memory for continual learning."<BRK>In this paper, the authors provide theoretical justifications for memory based continual learning (CL) methods and provide a scaling learning rate method NCCL to improve the practical performance. The results look quite exciting (there is quite scant theoretical paper for CL), however, after looking into the details of the paper, I was confused by many places and would say the authors need to further improve their manuscript in order to qualify for the ICLR standard. 1.The theoretical analysis is not very impressive. Based on the flaws that I have previously pointed out, it is impossible for me to validate if my concerns were actually adequately addressed without seeing the updated version.<BRK>**Summary of paper**This paper analyses the convergence of episodic memory based continual learning methods by looking at it as a nonconvex optimisation problem. **Update to review**Thanks to the authors for responding. They then introduce a method that scales the learning rates of the their update method, with the goal of tightening the bound obtained in the convergence analysis. Finally, experiments are shown on different benchmarks, and the proposed method is compared to some competing baselines. The paper attempts to analyse the convergence of continual learning methods theoretically (especially Section 3.1). This has not been attempted enough in the literature, partly because this is a very difficult problem.<BRK>This paper takes an interesting nonconvex optimization perspective on the continual learning problem. More specifically, the authors pose continual learning with episodic memory as a smooth nonconvex finite sum problem. Overall, the strength of this paper is its theoretical analysis and I find the idea of connecting continual learning with the associated nonconvex optimization problem compelling. I am not an expert in nonconvex optimization, but my understanding is that the analysis itself is not that unique for the field. Rather, what is novel is the interesting application of the ideas to the continual learning problem. I find the theoretical aspect of this paper strong, but still lean towards rejection in its current form as I am very skeptical that the idea is at all validated by the experiments. The other reviewers have mentioned some very valid concerns about the submitted draft as well.
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 5. <BRK>This paper discussed the task of generating scientific paper summaries along two axes: contribution (ie.novelty) and context/background. Overall, I think the evaluation is not adequate for a paper at a top conference. The point is two disentangle these two, since often different readers would be interested in only one of these. They would share the context quite often.<BRK>This work presents a dataset based on S2ORC with additional annotations on the abstracts in terms of contribution and context. Based on this dataset, this paper also adopts two baseline models from prior work with a training strategy (also defined by prior work) to demonstrate the task of summarizing scientific literature from two aspects. Based on my understanding it could either be presenting a newly annotated dataset or demonstrate this task using some baseline models. However, how do we know these 20 papers are the most relevant to a specific work? Besides, if the major contribution of this work is about the dataset, then manually annotating 400 abstracts really did not sound like enough contribution.<BRK>Strengths:I generally think decomposing scientific article summaries into two pieces, contextual descriptions vs. contributions, would be helpful. The paper uses a reasonable set of automated metrics on a silver data source, and I found those experiments to be relatively well done although ultimately the results are somewhat inconclusive, in that there were not strong differences between different techniques. Unfortunately I think the human evaluation in this paper leaves too many questions unanswered. Additionally, the truthfulness of the generation seems like a potential concern that is not discussed. The evaluation does not directly address this question.<BRK>Thanks to the authors for the hard work on this paper. Here is a list of some concerns and questions related to this section:* 86.3% accuracy is not a revealing metric because we don t know how unbalanced the test set is. In Section 5.3 you report that "context summaries include article contribution information." This may be related to the kinds of errors made by the original classifier. How representative are they of the different scientific fields in Table 4?
Reject. rating score: 3. rating score: 4. rating score: 4. rating score: 5. <BRK>I see lots of misconceptions, not only in this paper. This is black box optimization. In other words: The contribution of the paper in itself is valuable, provided that the baseline method is. THE PROPOSED METHODSection 2 provides a motivation of the method of [Zhang et al., 2020]. The proposed method is based on line search. The search itself replace the learning rate parameter, which is then used with with an exponentially fading record technique to adapt the sampling radius. The most relevant comparison experiments are missing. The most important experiments are missing! The contribution of the paper is to remove tuning parameters from Zhang s method. Does the new mechanism work close to optimal or not? It may still be considered superior if it comes close, removes two tuning parameters, and the adaptation mechanism is robust. However, it does not allow me to reproduce the experiments since it does not include the competitor methods. Critical information is missing in the paper, like the initial step size.<BRK>** Summary **This paper considers the problem of adapting the learning rate and smoothing parameter in the Directional Gaussian Smoothing (DGS) algorithm. The authors claim DGS is particularly sensitive to these parameters and thus attribute the strong experimental results to these changes. That should be the focus here, since the contribution of this paper is solely the adaptive mechanism. That may make the use of backtracking line search more prominent across other methods, as if it is just useful for DGS then it may have limited impact. ** Strengths **1) The topic of learning hyperparameters on the fly is well motivated and an important direction to improve many existing methods. 2) The experiments are interesting, with a wide range of tasks considered. It would be interesting to see if the proposed method can improve other algorithms too. 3) It would be useful to get a comparison vs. other hyperparameter optimization methods, since that is the sole contribution of the work.<BRK>In this paper, the authors apply a line search of the step size parameter of DGS (Zhang et al., 2020)) to reduce tunning. A heuristic update rule of the smooth parameter in DGS (Zhang et al., 2020))  is also used. Overall, I think it is an incremental work of DGS (Zhang et al., 2020)). The contribution is too marginal. Pros1.The paper is well written and well organized. Does AdaDGS sensitive to these hyperparameters? 2.In the experiments on synthetic problems, the initialization point and optimal point are not clear. Actually, the optimization performance depending on the distance between the initialization point and the optimal point. It is challenging for problems with a large distance.<BRK>Their proposed solution trade offs some additional function evaluations per parameter update to perform a line search for the optimal learning rate. 2) The experimental results are comprehensive and the proposed approach has (sometimes substantially) better performance than the alternatives. Line search for tuning the learning rate is applicable to a wide variety of optimization algorithms. The update rule of Equation (4) could be applicable to any algorithm that employs Gaussian smoothing. 2)  The main effort of the authors is to avoid having to use learning rate and smoothing update schedules as they introduce many hyper parameters. However, the author s tuning approach also introduces many hyper parameters as well like $L_{\max}$, $L_{\min}$, $\gamma$ and $S$. 3) In the experimental analysis, the authors show that DGS with their tuning approach outperforms the baselines. Given that plain DGS (with some default adaptation schedule) is not part of the baselines, it is not clear if the performance difference should be attributed to DGS or the tuning mechanism.
Reject. rating score: 6. rating score: 6. rating score: 6. rating score: 6. <BRK>This paper proposed a k shortest path constrained reinforcement learning method for solving sparse reward MDPs. Careful numerical studies are provided to evaluate the effect of the k shortest constraint in a tabular RL settings  Cons:It is unclear how this method and its theoretical results can be generalized to other settings where the rewards are less sparse than single goal MDP settings, but still very sparse. The experiments for testing the proposed method are all based on navigation tasks, which give us an impression that the proposed method is only applicable to a specific problem. after the rebuttal I appreciated the authors  effort in addressing my comments and questions. I maintain my score of weak acceptance for this paper.<BRK>**Summary**This paper proposes a new constraint for constrained MDP, based on k shortest path, which helps improve sample efficiency for (model free) RL algorithms in sparse reward MDP, while theoretically proving that the constraint retains the same optimal policy in the original MDP. Experiments were conducted in several maze navigation environments (2D grid world MiniGrid, to first person 3D maze environments in DeepMind Lab), showing promising results compared to several baselines which use intrinsic curiosity. Please clarify for me and in the paper. Overall I think that it is a well written paper with thorough theoretical and empirical results. **After rebuttal responses**:I have read the authors’ response to my concerns, as well as the other reviews. I maintain my current evaluation with a weak acceptance of the paper.<BRK>Overall, the paper is well written and clearly conveys the main idea and the main results of the work. The theoretical results are immediately following the ideas. Some important discussions are highlighted to introduce the algorithm,. However, I wasn t fully convinced by the paper about relevance. Using the shortest path constraint to solve shortest path problems seems not fair to be placed among a set of learning algorithms. Some strong justifications are needed for the work to be relevant. Pros: 1.The paper considers a practical problem in reinforcement learning: sample efficiency in sparse reward tasks.<BRK>The paper proposes a novel k shortest path constraint that prevents over exploration by exploit the combinatorial structure (i.e.shortest path) of sparse reward tasks. Overall, the paper is well written, and the empirical results are clear. To be more specific, could the author(s) provide more discussion compared to HER (Hindsight Experience Replay) and hierarchical reinforcement learning?
Reject. rating score: 5. rating score: 5. rating score: 6. rating score: 6. <BRK>This paper builds on the template of TRPO and proposes an algorithm that searches for deterministic policy. I feel overall this paper may not be quite well motivated. Where does the noise be injected? In (9), the theoretical lower bound to be optimized involves C_1 and C_2 that has a very complicated form. Again, this may correspond the motivation of the proposed algorithm.<BRK>This paper proposes a new deterministic policy gradient method (TDPO). Overall, the studied idea is interesting. Here are some of my main concerns regarding to this idea and the quality of the paper. Why it could be a showcase of the use of a deterministic policy gradient method. It is also questionable on why the TDPO does not perform well in comparisons to the baseline on Gym suite environments.<BRK>The paper proposes a deterministic policy gradient method using the Wasserstein distance to quantify the difference of deterministic policies. Theoretical justification for the main results. I have the following questions and comments:Q1. C3.From the way the method is presented, it seems that it is not simple to implement the method? Although experiments indeed show the clear advantage of the proposed method over existing ones, more environments or more setting in the same environment should be presented to better evaluate its performance.<BRK>This paper introduces a policy gradient method based on deterministic policies and deterministic gradient estimates. By assuming such a deterministic setting, the authors show that the proposed technique can estimate gradients on long horizon tasks without the need to inject noise into the system for exploration. These seem to be key assumptions to the method, but (in my opinion) they were not well motivated or discussed. Overall, this is a well written paper with sound mathematical arguments.
Reject. rating score: 3. rating score: 4. rating score: 5. rating score: 5. <BRK>Summary: This paper talks about online continual learning in scenarios where there might be domain shift during test time. Though I find the problem to be important, I believe that the solution proposed in this paper is straightforward (which is fine) and imposes a new set of constraints (knowing a priori the domain id during training) making the problem quite impractical for scenarios where continual learning might be useful. The section was a bit unclear to follow. Could you please comment on the training time? 5.References: I would suggest the authors to correct their citations a bit.<BRK>This paper studies the domain adaptation problem when the source data comes from multiple domains continuously and the test domain for adaptation is unknown. Even for an online paper, showing the performance for the batched version seems to be necessary. The paper introduces two discrepancy measure based on the Jensen Shannon divergence and the one dimensional Wasserstein distance. In the experiment, the data set for continual learning is constructed using domain shift data such that it mimics the online learning setting. The results are competitive in comparison with a limited set of baselines. The paper focused on an interesting and important topic. Basically, after learning the adversarial domain predictors, how the representation learning looks like.<BRK>Hence, I will adjust my review after reading the authors  response as well as other reviewers  comments accordingly. This work proposes CIER, a continual learning method that adjusts to domain shift during test time. The authors claim that existing methods correct distribution shift in P(X, Y), which makes the stronger assumption that P(Y | X) is the same across domains. My concerns are as follows:1. I am skeptical of the central claim of this work, which is that continual learning does not address domain shift. I am not an expert in this area, but to my knowledge, all reinforcement learning work that train on one environment and adapts to another environment must continual learn in a different environment (e.g.https://arxiv.org/abs/1803.11347, https://arxiv.org/abs/1905.04819, https://arxiv.org/abs/1910.08210). I suggests that the authors make their terminology consistent.<BRK>This paper investigates continual learning under domain shift and proposes a conditional invariant experience replay (CIER) method accordingly. In particular, CIER uses adversarial training to correct the domain shift. Pros.1.The problem setting of continual learning with domain shift is well motivated. The technical details are easy to follow. Cons.1.Although the problem setting is new, my main concern is the limited novelty of the proposed CIER method.
Reject. rating score: 5. rating score: 6. rating score: 7. rating score: 7. <BRK>### Paper SummaryThis paper allows agents to set the initial conditions (level) for procedurally generated episodes during exploration to past observed values, and proposes to have agents form an intrinsic curriculum by resampling past levels based on a heuristic measure of expected learning progress. The authors verify that their prioritization strategy usually improves performance in several Progen Benchmark and MiniGrid environments, usually by a small but statistically significant amount, but sometimes by a large amount. The idea is simple, and the algorithm/experiments seem straightforward to reimplement. The experiments are about what one would expect and seem to be well executed. ### Pros  This a simple idea that can improve performance in Procedurally Generated Environments given that the agent is allowed to set the initial conditions / pick the level. The paper is well written/presented, easy to understand, and the empirical evaluation seems well done. The results do not seem difficult to replicate. If this is only useful with a simulator, then the small gains in sample efficiency aren’t actually that relevant, though this approach does seem to improve final performance in 4 of the 19 environments tested. My main question for the authors is to ask for a counterargument to ($\dagger$) above. It would be good if this can be shown to work in multi goal setting, as it is quite similar to ProcGen setting... you draw some distinctions, but I do think your approach would be applicable there.<BRK>While training an RL agent across many tasks (levels), we can either sample a new task uniformly from the training task distribution or sample a new task with different weights. The paper claims that sampling based on the average magnitude of generalized advantage estimate (GAE) yields faster learning in most Procgen environments and a few MiniGrid environments. But the benefit of using prioritized level replay is also not very consistent across different environments used in the paper. ##########################################################################**Strengths**:The method of the paper is simple and can be incorporated into many existing RL algorithms. The paper only presents results in the easy mode of procgen. In Figure 4, it is hard to connect the top row to the bottom row as the top row uses the environment steps for the x axis, the bottom row uses the number of PPO updates for the y axis. I would suggest plot the bottom row figures in terms of the environment steps as well and use the same x range.<BRK>This paper concerns about the use of experience replay in a way that past experience is sampled based on (implicit) levels so as for the agent to better adapt to the current task at hand. The authors defined a replay distribution (where experience is sampled) based on two scores relevant to learning potential and staleness. So I would like to see (in future or revised version) some experiments that measure how well staleness measure correlate with such score. One more comment about staleness. The overall impression of the paper is that it presents a simple yet effective solution to prioritizing experience in the presence of level ness in a given task. I suspect that Eq.1 also works for a singleton environment, which the authors excluded from consideration. Point: The conjecture about curriculum learning. Would different algorithms other than (PPO + GAE) make the results different from the current form? Further, it is conceivable that the optimal \beta and \rho are not fixed quantities but can be dependent to a given pair of policy and trajectory. I updated my score to 7. Given that this replay scheme works fairly well (intuitively, empirically), easy to understand and implement, fairly sufficient amount of empirical experimentation, I would like to see the paper accepted (and adopted and improved by others).<BRK>The present work proposes to sample the training environments such that the learning progress of the agent is optimized. This is achieved by proposing an algorithm for level prioritization during training. The performance of the approach is demonstrated on the Procgen Benchmark and two MiniGrid benchmarks and the authors argue that their approach induces an implicit curriculum in sparse reward settings. I also liked that the authors compared with a big variety of different scoring metrics. **SUMMARY**I found that paper very interesting. The heuristic score also works well in practice. That being said, I believe this line of work to be really interesting and to have a lot of potential for improved sample efficiency when training RL agents in algorithmically generated simulation environments. My intuition is that levels in which agents were historically very slow to learn are maybe not as useful (or at least not useful at the moment). **EVALUATIONS**The work is compared with several scoring function baselines using PPO. Wouldn t it make sense to use more recent agents to see the added benefit of the proposed approach.
Reject. rating score: 4. rating score: 5. rating score: 6. rating score: 7. <BRK>BACKTRACK procedure may not find a better score, so bottleneck is not passed, is it consistent with "bottleneck passed"? Pros: This is a very dense paper with multiple key ideas, namely (1) using QA model to construct knowledge base; (2) escaping local optima by backtracking; and (3) modular policy chaining. Empirical results demonstrate the effectiveness of the proposed methods. This is related to the ``what is policy" question. There are other things about the framework that need to be clarified as well. Is the training algorithm online or offline? (2) Many essential technical details are not clear. (But I agree that Figure 2 is useful to illustrate the interesting idea.) In this submission, the agents also rely on the learned knowledge base. That being said, I request the authors to rewrite all the claims like mentioned above. [Technical clarity]The most important clarity problem is about the modular policy chaining method: it is not clear how the method is integrated with the entire framework.<BRK>This paper studies reinforcement learning setting where the agent s decision is augmented with external knowledge representation. Termed Q*BERT, this proposed method uses question answering to build a knowledge graph of the world. Results show the agent was able to pass the bottleneck for a popular game where most other algorithms failed. Pros:The proposed method seems well motivated and reasonable to improve agent s performance. Cons:1.The novelty in terms of methodology seems a bit low. The idea of Q*BERT training is not new. It is possible that using BERT s representation alone, the agent s performance will be much better and training will be more efficient already. In a fair experimental setup, there is no way an agent can foresee the world. Maybe I am misunderstanding here, and I hope the authors can help clarify.<BRK>focus on text based adventure games  create agent that can build knowledge graph by answering question  introduce novel exploration strategy  IM reward: expand size of knowledge graphBecause the authors present a number of interesting and well tested strategies for a well justified task, the paper is above the acceptance threshold. If the clarity could be improved (specifically by making the contribution in the general case more explicit) and if the experiments could be made more thorough (+ a stronger improvement of prior work) it would be a strong paper. Clarity: The authors did a reasonable job of familiarizing readers with the challenges of text based games. However, the description of the research contribution and its potential impacts could have been more focused. Originality: While the individual components are not extremely novel, taken together they create an interesting and original system design. More experiments to better understand how bottlenecks are addressed by the model (e.g., more of figure 4b) would be enlightening<BRK>The paper presents two new algorithms: Q*BERT and MC!Q*BERT, as well as a QA dataset to help training a component of these agents that builds a knowledge graph of the current game state based on the textual descriptions received by from the game. In particular, the new approach to integrate exploration strategies to overcome "bottlenecks" in the search space is interesting and, to the best of my knowledge, novel. Basically, location and inventory are not the only state of the game, but there are many other state variables in many of these games. Thus, I think this part of the paper needs some work (authors mention "relatively linear plots", but "relative linear" does not mean "completely linear"). page 8: about the bottleneck identification rates reported: how were ground truths established?
Reject. rating score: 4. rating score: 4. rating score: 4. rating score: 8. <BRK>This paper considers algorithms that attempt to learn learning rates for gradient descent by gradient descent. Analysis is provided for a few specific quadratic losses showing that the gradient with respect to the learning rate may explode or vanish, and taking the logarithm is suggested to mitigate this. Further results suggest that implementing the gradient of the log comes with interesting numerical difficulties as *intermediate results* might explode or vanish even if the final answer does not. Next, linear regression problems are analyzed in both the over determined and under determined settings. It shown that in the under determined setting the optimal learning rate when tuned on the training set is very far from the optimal learning rate when tuned on the validation set. Experiments are presented validating these theoretical findings, as well as comparisons to manual tuning on MNIST. I felt that the claims in the abstract were a bit overblown here. I would not say that there has been a characterization of when to use validation vs train set, or that the proposed logarithmic method necessarily avoids vanishing/exploding metagradients. Theorems 5 and 6 appear to be making statements about the minimizers of the meta objectives. This setting seems a bit limited since it is almost possible to write in closed form what the sgd iterates will do.<BRK>In Section 3, c_{min} is assumed to be positive, but what does it mean? There are many typos and colloquial statements are presented. Theorems 1 and 2, seem central to motivate the work. Moreover there are 21 "it s" throughout the paper. In Theorem 1:"For tuning the step size of gradient descent on a quadratic objective, if the meta objective is theloss of the last iteration, then the meta gradient can explode/vanish." is too strong and was not proved. In Theorem 2:"For a simple least squares problem in d dimensions, if the number of samples n is a constant fraction of d (e.g., d/2), and the samples have large noise, then the train by train approach performs much worse than train by validation"Comment: what is much worse? "On the other hand, when number of samples n is large, train by train can get close to error dσ2/n, which is optimal." The constants in Theorem 5 and 6 are unused and could be omitted for the sake of concision. But from section 4 onward, I see that the regular cost is used for the meta objective. Is it that use of a logarithm helps remove vanishing gradient problem? The imprecise nature of the Theorems added more to the confusion. Pros:   There are not many theoretical works on learned optimizers, thus this can be interesting to provide new insights. Cons:   It seems to be hard to generalize the proposed analysis to more intricate (and practical) problems, such as training MLPs as optimizers. The results of Theorem 3 were partially discussed in Metz et al.(2019) (Sec.2.3).The authors could acknowledge this fact in the text.<BRK>The first is the use of the log objective rather than the raw objective for the inner loop optimization step, and the second is the differences between train by train and train by validation. Overall, however, I feel that this work relies much too heavily on its supplemental material, as the proofs themselves are not well spelled out within the text itself, and at 68 pages total this is perhaps too extensive for this venue. The authors give a reasonably good overview of recent approaches to to learning to learn, or meta learning for optimizers. Notationally, the work is also very dense. Otherwise it might be helpful to be more explicit about the indices x_i  > y_i when introducing these models, although this is perhaps a very nit picky and aesthetic consideration. Theorem 3 is itself interesting, however it seems to follow quite directly from Section 2.3 of Metz et al.Although the authors do provide more detail, this is restricted to the quadratic inner loop setting, whereas the description of Metz doesn t go so far due to the more general problem setting (and changing Hessians). But it s not clear how much practical value it has. I may have misunderstood, but if this is not the case why not? Similarly, how does this compare empirically to the solution proposed by Metz et al? And lastly, the authors did not describe in detail how they dealt with the intermediate gradients which would have been most useful. Finally, the remaining theorems are interesting, but mostly seem to confirm the results of Metz at al, and are restricted to the quadratic setting.<BRK>## Overview Meta gradient descent is an approach to step size adaptation in which the step size is adapted by considering how it influences the loss function over time. 2019.**AdaGain (Meta descent for learning stability)**: Jacobsen, Andrew, et al."Meta descent for online, continual prediction." This paper provides guarantees for this class of algorithms when applied to a quadradic loss function. It is then shown that this can be remedied simply considering the logarithm of this meta objective, but that this too will have issues with numerical stability if approached with back propagation. Finally, results related to the generalization ability of these methods are presented. **Overall, I recommend the paper for acceptance. ** Despite focusing on a simple quadratic loss setting, the results are quite non trivial and I believe will be of interest to many in the community. The writing was clear throughout, and I found the proofs that I worked through (Appendix A) to be instructive and of high quality. My main reservation about this paper is the length of the Appendix. However, I did work through Appendix A, and the material was well explained and generally quite excellent, so I m willing to believe that the rest of the appendix follows suit. **Page 6**: *"Experiments show that in many settings (especially with large t and large $\eta_0$) the implementation does not converge. Is there a reason why figures 5 7 don t include any measures of spread? **Page 2**: *"Another challenge is about the generalization performance of the learned optimizer"* This might read more clearly by rephrasing as "The generalization performance of the learned optimizer is another challenge"  **Page 13**: *"where the second inequality holds"* I think this is supposed to read equality rather than inequality.
Reject. rating score: 5. rating score: 6. rating score: 7. <BRK>This paper is to train a generative neural networks that can output adversarial examples. Details:+ the idea of generating adversarial examples by a trained GAN is interesting. It is to train the difference of G_original and G_attack and I think in the training aspects, this is almost equal to the proposed idea. 2).attack a GAN to generate adversarial examples (Song s): min_z  \|z   x\|, s.t., f(G(z,y)) \neq f(G(z ),y). However, the there is no training time additionally needed . The attack transferbility has not been tested. Since there is adversarial samples involved, the obtained GAN is expected to be related to the victim model. Additional questions, mainly for the experiments  result 1. But where the adversarial examples come from? 2.How many examples and time are needed to train the AT GAN?<BRK>Once trained and transferred, AT GAN could generate adversarial examples directly for any input noise, denoted as non constrained adversarial examples. The paper is clearly written and some experiments are conducted. However, I have some concerns as below:1. The novelty could be further summarized by highlighting the difference with most related works including but not limited to the aforementioned ones. The current manuscript makes the work seem like a straightforward combination of many existing approaches.<BRK>This paper proposed the adversarial transfer on generative adversarial net (AT GAN) to train an adversarial generative model that can directly produce adversarial examples. In the other way, AT GAN could generate the adversarial examples directly for any input noise. The goal of this work is obvious with experimental justification. Mathematical description and experimental illustration are desirable to show the merit of this method.
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 5. <BRK>The experiments are conducted on a synthetic dataset (colored MNIST), with various interventions to control the bias (background color, number of lines drawn on the digit, green pixels added with different widths and locations). #Pros:  Due to the increased popularity of bias mitigation methods recently, there is a need to benchmark them carefully and fairly. The proposed experimental framework is very interesting, by using a colored MNIST dataset with various controllable interventions: 1) background color; 2) number of lines drawn on the digit; 3) green pixels added with different width and locations. This paper seems to merely present the empirical results, i.e., under different settings which method works better, without further insights on why certain methods work under certain conditions. This might be a stretch but as a benchmark paper, I would expect to see comparisons of more methods and more datasets. Method wise, I don t see a clear argument on how the three methods presented in this paper are chosen, is it one method each from the three representation learning categories? I m not sure what s the particular reason causing this, could the authors do a deeper analysis on what are the factors? However, it would be better if the following can be better addressed:  As a benchmark paper the experimental setting is relatively simple/artificial, more realistic datasets/settings would be more useful;  Thanks for adding the stability study. It would be more helpful if the main results can be presented with a better control over the stability. As the other reviewers have mentioned, it is still unclear how this simulated setting connects to real world fairness applications.<BRK>Using this benchmark, it compares several recently developed and prominent methods for fair representation learning and shows their relative strengths and weaknesses under different data generation assumptions and for different metrics. The type of careful, systematic comparison provided by this paper is potentially an important contribution. However, I recommend rejection for this paper for one main reason: I believe the synthetic dataset is inadequate for use as a realistic benchmark. It is too abstract and unlike examples where people are concerned about fairness, and the protected attribute background color is something which can be encoded far too simply. As a result, I believe that the relative performance of methods evaluated on this benchmark dataset may be not be indicative of their relative performance on a more realistic dataset with more complex sensitive attributes like race and gender. It is not obvious how to improve this flaw, since more realistic datasets may also be less general and hence less useful for benchmarking purposes. In this way, the paper could propose a systematic comparison of methods for a particular synthetic task, provided that task is realistic enough to be related to some potential real world applications. I have no specific suggestion for how to modify the synthetic data generation process, but the features, especially the sensitive attribute(s), need to be rich enough to be more like a real fairness application.<BRK>The paper claims to contribute the following:  (1) Show that models exploit any correlation between eligibility and the sensitive attribute found in training data even if the test data does not have such correlation; This leads to unfair predictions. 1.I am afraid that the impact of the paper won t be good with only one out of the four reviewers understanding a paper meant to present an entry point benchmarking dataset. However, as a future user of the benchmarking dataset, I see that there still remains the question of whether the metrics measured against the proposed benchmarking dataset with simple pseudo sensitive attributes can translate well to the model performance measured against some real world dataset with real sensitive attributes. (4) Provide a deep learning codebase composed of six debiasing models and a baseline. 3.Add something like what is proposed in #2 to help the readers understand how to choose the best model and make tradeoffs for a given scenario using the presented dataset with the proposed methods. (5) Provide a dataset with different controllable sets of features and correlation among them. Nevertheless, I believe the authors  core work is in the right direction. Sensitive attribute values are limited to binary values. In contrast, the real world sensitive attributes are multi label. See 2.(1) and 3 above. Make it clear that these points are here to help, and not necessarily part of your decision assessment. Just as FYI, it was difficult to read the labels of the third graph of Figure 2 when printed on A4 paper.<BRK>The proposed simulated dataset pertubs MNIST in various ways to create data distributions that could impact the difficulty of satisfying various fairness criteria. And why is g_1 2 considered to be a “biased” setup? For example, have one paragraph discussing different methods for enforcing fairness on deep learning models, and have a different paragraph discussing other survey papers for evaluating various fairness criteria and algorithms. The experiments provided seem thorough, with many different dataset simulation parameters. ############# Weaknesses ##############  The dataset features seem a bit contrived, and it’s not entirely clear how the different simulated features correspond to real data scenarios. They modify how many of the 6 20 line digits are odd, and how many are even, such that the number of lines on the digit can correlate with whether the digit is even or odd. Of course, I recognize that it’s impossible to capture every possible real data distribution in a simulation like this, but it would be helpful to have some explanation of why they use horizontal lines specifically. A similar explanation would be helpful for the use of the green column. They only use a binary sensitive attribute, encoded in the simulation as various shades of red/blue. The related work has limited discussion of other papers that evaluate multiple fairness criteria and algorithms. The paper would benefit from deeper discussion of how or why the three evaluated approaches differ in performance.
Reject. rating score: 2. rating score: 4. rating score: 4. rating score: 6. <BRK>It is a bad sign that none of this body of previous work was discussed in the paper, which I would argue was the more relevant literature upon which the paper had to be positioned. The paper evaluates the proposed technique using two standard search planners (MCTS and BFS). What the authors refer to as Trust But Verify, it s just an ad hoc instance of the well known principle of *optimism in the face of uncertainty*, which underlies classic bandit and RL algorithms such as UCB1[1], UCT[2], Thompson Sampling [3, 4]. However, this work is still too immature for publication.<BRK>While the presented method is interesting with high performance, I found many editorial errors in the writing. There are so many errors like this and the paper needs serious rewriting. Also, having a conclusion or discussion can help the structure of the paper.<BRK>I am not quite sure about the comparisons the authors are making. The paper says, "The proposed action is the first edge on the shortest path to the best node in the subgraph searched so far." It seems like it is mainly used as a comparison for the disagreement measure. What if the agent behaved greedily with respect to the disagreement measure all the time.<BRK>I think a plot similar to figure 7, but for RANDOM and combination of RANDOM and QR would improve the paper. The work is very well written in general, especially sections of problem definition and related work. 3) Have the authors considered a QR that changes with number of steps?
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. rating score: 6. <BRK>This paper proposes a method for fine tuning to address the issue of representation collapse. The proposed method is called Robust Representations through Regularized Finetuning (and an extension called Robust Representations through Regularized and Reparameterized Finetuning)  the main idea, as I understand, is to minimize the amount of change in representations of the model at each training step during the fine tuning. In order to show that the representational collapse problem exist when using standard fine tuning techniques, and that their method, indeed, resolves this problem, they design a series of probing experiments where the apply fine tuning on a set of datasets/tasks in a sequential order using the best checkpoint from the prior iteration. I think the paper can be written in a way more clear way with a bit bigger audience in mind.<BRK>SummaryThe paper proposes a method for finetuning pre trained models that ensures the generalization ability of the representation is maintained. The method has been evaluated on a large range of NLP tasks using various transformers as the base model. The proposed novelty compared to the closest existing approach is clearly highlighted and validated by the experiments. The need for a new term “representational collapse” is not really justified in the paper. It would be good if the authors could explain this in more detail in the paper.<BRK>The paper also introduces a new analysis by defining a notion of representational collapse and provides a new methodology for measuring it during fine tuning, which is interesting. This paper  is well written and strongly motivated with solid experimental results. It may motivate other works of robust representation learning, and it is well suited for ICLR. + A novel fine tuning method which does not require extra backward computations and empirically works as well as or better than SMART+ SOTA evaluation results on both NLU and NLG datasetsWeakness:  The overall design of R4F is simple, as leveraging the Spectral Normalization to make the function 1 Lipschitz is not new,  Some notions and symbols are missing, such as x~ in equation 2.<BRK>#### Summary  This paper presents a simple but effective method rooted in trust region theory for fine tuning pre trained models without  representational collapse . The introduction of simple but effective & efficient methods for fine tuning pre trained models. I understand that the proposed methods are desirable in the case of XNLI where zero shot cross lingual transfer explicitly requires fine tuned representations to be still general enough to be properly transferred to other languages. It s good to see experiments on XNLI and summarization tasks in addition to one on GLUE.
Reject. rating score: 3. rating score: 4. rating score: 6. rating score: 6. <BRK>The idea of computing losses across iterations to save on the total number of iterations that must be performed is a good one given the high computation costs of GAN training. Weaknesses:  I found this paper to be poorly written and hard to understand. The game theory language used here is not standard GAN terminology and thus made it difficult for me to follow. Not all GAN loss functions are zero sum (in fact the best performing models e.g.Big GAN do not use a zero sum loss), but as I see that is required for this approach, or at least is the only thing  that is considered. This seems prima facie unrelated to the proposed method, and if it really is causally related, that would be valuable but this needs to be investigated with deeper experimental analysis for it to be claimed. The experiments are weak. Models that have achieved state of the art results in the last couple years like Big GAN should be included.<BRK>This paper proposes to use the well known Double Oracle methods for solving large scale games for computing the equilibrium in GANs. Pros:The idea of using double oracle algorithm for GAN is novel though surprising that no one has tried it earlier. Not sure why this is not done. In fact, the authors have this line about Hsieh et al "The sampling approach may be inefficient to compute mixed NE as the mixed NE may only have a few strategies with positive probabilities in the infinite strategy space"   do the authors have any evidence (theory or experiment) to support this? Also, wondering why WGAN is not considered   WGAN also is a game and actually better than some of the GANs tested. Clearly the NE is not being computed exactly because of the many approximations (e.g., approximate best response). It is very surprising that only 10 pure strategies are enough in the mixed strategy support when the pure strategy space is infinite   there are results on small support for approximate NE (please cite those also). I am not sure though if it is so small, the lack of rigor here is unconvincing. There is no new technique in the way double oracle is used. Please state these clearly.<BRK>This paper proposes a  new training framework for GAN, inspired by the double oracle (DO) algorithm in game theory. The authors design many mechanisms to make it possible to employ DO in GAN training. The motivation is clear, and the experimental results support the claim. In the paper, several experiments are conducted in the laboratory and real world environment. However, some of the more common GAN scenarios at this stage (2020) have not been proven to be suitable for DO framework, such as high resolution image synthesis, e.g., CelebA HQ and LSUN scene generation [1] and conditional generation [2]. However, its FID still seems to be declining.<BRK>This idea is novel, although the most interesting problems that must be solved in order to apply DO have already been tackled in previous work (PSRO   Lanctot 2017, Pruning   Cheng & Wellman 2007). This paper applies Double Oracle (DO) / PSRO to training a GAN, a 2 player zero sum game. DO cannot be applied directly "out of the box". The authors do not propose any significant modifications to the previous approaches. I really only view the last one as a key contribution. Overall, the value of the paper lies in applying DO to GANs. I have been eager to see this tried and I view it as a necessary piece of research. These aren t criticisms against the paper. For example, not all DC GANs are created equal. I would also like to see a discussion of training time for DO versus vanilla training. As I said, there is not a lot of originality on the algorithmic side. Quality:The quality of the paper is at a high enough level for ICLR.
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 7. <BRK>The paper s starting point is the question whether the episodic training is beneficial, or not, for FSL / Prototypical Networks. Towards answering this question, this paper points out that Prototypical Networks (PN) are related to Neighborhood Component Analysis (NCA), and NCA can be considered as an episodic training free alternative of PN. The paper, with more water tight arguments only, could otherwise be a valuable contribution but it requires quite significant & fundamental revisions throughout the paper, therefore, is not ready for publication in its current form. The paper also approaches this problem from an interesting point of view, by focusing on sample utilization in the episodic training of PN. The fact that the very construction of these two models, despite the similarities pointed out, blurs the strength of the overall NCA vs PN based discussion on the value of episodic training. To this end, Fig.3 is indeed interesting, but again the results are not very clear. Overall, I think the paper makes a valuable step in an interesting direction but the paper fails to make a strong enough case. Overall, I  improve my rating by a single level to 4, but find that the paper is not stronger than this in its current form.<BRK>I think many questions can be explored to strengthen this paper, for example:Are classes embedded tighter together? This paper proposes an interesting method that improves upon Prototypical Networks, and performs on par with other baseline methods. Pros: The proposed method is a straight forward improvement to Prototypical networks. Regarding the proposed method, NCA is certainly an improvement over ProtoNets, but performs worse than existing methods in most experiments. This proposed method should also be easy to implement, making integration with other FSL methods based on ProtoNets feasible. Even so, I think presenting only favorable comparisons in the performance tables is counter productive as it fails to capture the research context of this work. Arguably, these additional architectures are more expressive "deep" alternatives to NCA, and hence achieves better performance than the proposed method. 3.The motivation of the paper feels unclear: on one hand the authors claim that they aim at understanding the (un)usefulness of episodic learning, yet on the other hand this paper doesn’t present any results beyond the final performance number to aid with this understanding. Why would some examples be more likely than others in the episodic scheme? This is not true in general.<BRK>This paper investigates the usefulness of episodic learning in prototypical learning which is a popular practice in few shot learning. The sections 3.1, 3.2 and 3.3 are not the contributions of the paper. Only section 3.4 can be considered as something new from experimental point of view and not methodologically new. Therefore, I do not see the technical contributions of the paper other than the claimed novel experimental settings which is also marginal. 3.I am curious if you have done a comparison with baseline NCA, i.e.equation (3). I have not found the comparison in A.1 which only contains some discussions but no direct comparison. However, I would like to follow the discussions on the paper and understand the contributions well.<BRK>When controlling for batch size, the paper claims to show that NCA (combined with a nearest centroid inference strategy) performs better than Prototypical Networks, as evidenced by experiments on CIFAR FS and mini ImageNet. Finally, NCA is evaluated alongside comparable competing approaches on mini ImageNet, CIFAR FS, and tiered ImageNet, and is claimed to yield results comparable or superior to the state of the art. #### Strengths and weaknesses* **+** The value of episodic training is increasingly being questioned, and the submission approaches the topic from a new and interesting perspective. * ** ** The Matching Networks / NCA connection makes more sense in my opinion than the Prototypical Networks / NCA connection. To be clear, I don’t think the missed opportunity would be a reason to reject the paper, but I think that showing empirically that the leave one out strategy applies beyond Prototypical Networks would make me lean more strongly towards acceptance. Finally, I have some issues with how results are reported in Tables 1 and 2.
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 8. <BRK>## Post rebuttal commentsI am impressed at the amount of time the authors have spent trying to clarify the different concerns. However, there are some concerns on my end that I hope you can help me alleviate that are keeping me from giving the paper a positive review. To me, this is an unsurprising and obvious optimization. I hope the gist of my comment is clear here: it seems like the comparison is not really a fair comparison. What is the unit for training time in Table 1?<BRK>The main message seems to be that LARS can help large batch adversarial training? What are the insights from the authors’ reimplementation of Xie’s method on CIFAR? post rebuttal  I do not think my concerns are addressed by the discussion. However, I also think this is a well written paper in general and I will not be upset if it is accepted.<BRK>This work introduces a framework, called DAT, to scale out adversarial training to distributed settings. The paper shows that sparse gradients and large batch training scheme also apply to adversarial training and provide some theoretical analysis to show the convergence rate of the composite of these schemes. Therefore, the main contribution is on applying these techniques in the context of adversarial training. Is it because there is no performance gain when training Fast AT across multiple servers, or is it because Fast AT does not support multi node training?<BRK>Adversarial training is a principled approach towards robust neural networks against adversarial attacks, but it is extremely computing intensive. + I like the idea to use gradient quantization/compression. Additional comments and questions:1. Please comment on what s the typical speedup of distributed training with n times of resources. Why?5.Which deep learning framework is used to support gradient quantization?
Reject. rating score: 3. rating score: 4. rating score: 6. rating score: 7. <BRK>This paper explores 8 bit floating point formats for the inference of deep neural networks. The paper is relatively clear written, and experiments seem sound, however, I have some major concerns on the objective and novelty of this paper. Can the authors provide an application case where only quantizing data is beneficial? 3).The main contribution claimed in the paper are to use exponent bias to cover tensors with different range of distribution.<BRK>FFP8 is more flexible than other 8 bit floating point formats with fixed exponent biases. The authors claim in section 5 that the extra hardware support required for FFP8 would be minimal. Alternatively, the authors can describe a different and an efficient implementation of FP 8. Do you expect the programmer to hand code this? Or will there be compiler support? These details are not answered by the paper.<BRK>The experiments in the paper demonstrate that the proposed format achieves a very low accuracy loss of < 0.3% compared to the regular float32 format for several popular image classification models. Strengths   The concept of flexible floating point format makes sense and can potentially result in significant space savings for large models. Figure 6 seems to be only showing the high level components. Overall, the paper’s ideas are promising but my score reflects the fact that the authors presented end to end experiments demonstrating the performance/storage gains.<BRK>There is previous work on using an 8 bit floating point FP(8), usually (1,4,3) or (1,5,2) where 1 bit is used for sign, 5 or 4 bits are used for the exponent and 3 or 2 bits are used for the fraction. I advocate for the acceptance of the paper. The authors observe that both the maximum magnitude and the value distribution are quite dissimilar between weights and activations in most DNNs.
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 5. <BRK>This paper proposes to extend the techniques of Baader et al.[2020], demonstrating that interval analysis provable ReLU networks are universal approximators, to a larger class of activation functions, which they call squashable functions. * Technically, the paper appears to be correct. Cons:* The proposed method mostly follows the same proof technique ad Baader et al.[2020] and thus is not particularly novel. * The authors claim that their method uses the most commonly used activation functions, yet ReLU is by far the most relevant activation function and is already included in the original theorem. * The number of ReLUs they use for an indicator function (they might need to use intractably many indicator functions) is asymptotically identical to Baader et al [2020]. Final Review:In summary, while technically the paper does not appear to have flaws, its contributions are incremental, and its similarity to prior work is such that it is hard to recommend acceptance. I am thus giving this paper a rejection.<BRK>The paper shows an "augmented" universal approximation (UA) result for neural networks that the authors call Abstract UA (AUA for short) and the motivation comes from understanding expressivity and certifiability of NN. The major issue with the paper is the lack of novelty. The most related paper in terms of techniques and ideas (Baader et al.) The reviewer feels that given the previous work on ReLUs (Baader et al.), the proof for the more general activation units can be reverse engineered. Overall, conditioned on the immediate prior work,  the result itself simply extends AUA from ReLU activations to more general units, and is not surprising. However these works do not consider certifiability which may be an opportunity for your techniques. Other comments:Theorem 3.3:  Do the authors consider this one of the main contributions of the paper? The sentence starting with "but..." is the extension presented in Baader et al.and that is the contribution, right?<BRK>This work studies the task of universally approximating continuous functions by (certain classes of) neural networks. This proof is constructive and applies to $N$ using ReLU, sigmoid, tanh or ELU activation functions. (The result actually includes an even larger class of activation functions, that the authors call _squashable_.) The authors of this paper provide a result applicable to a broader class of networks. They also improve the size of neural networks constructed in Baader et al.(as discussed in the last paragraph of Section 6), but at many points in the paper this result feels to be incremental. Many paragraphs are named, and then they have definitions with the same name.<BRK>This paper studies the universal approximation of robust networks called the abstract universal approximation. While the traditional universal approximation aims to approximate the single output corresponding to each input value, abstract universal approximation studies the output interval generated by the input interval (or box) and the interval value propagation. The main contribution of the paper is to extend the result of Baader et al., 2020 to networks using general squashable activation functions. I think that the main weakness of this paper is its novelty. This idea and using a squashable (or sigmoid) activation function to approximate the indicator function have been widely used in the universal approximation literature. Hence, I think that the result of this paper (Theorem 4.2) can be viewed as a simple extension of the result by Baader et al.2020.The authors additionally claim that their construction and analysis are simpler than those by Baader et al., 2020.
Reject. rating score: 5. rating score: 5. rating score: 6. rating score: 6. <BRK>The paper presents a pixel wise embedding strategy for panoptic segmentation, which aims to learn a pixel representation that encodes both semantic and instance information. Concerns:  The focus of this work is a bit unclear. It seems trying to tackle two related problems, one is the learning an object instance specific visual context representation and the other is the panoptic segmentation. In particular, how well the learned representation is able to cope with an object out of its common context? The evaluation of the panoptic embedding is a bit lacking. First, as the method is fully supervised, all different types of object centric context do exist in the ground truth label maps. Second, the CE metric is hard to interpret as it is a KL divergence measure. Moreover, the common practice in panoptic segmentation literature is to conduct evaluation on both COCO and CityScapes, and report detailed metrics on PQ, SQ, RQ. Here the COCO benchmark and some metrics are missing. Unfortunately,  I still think the results on the object representation is not convincing due to lack of comparisons with other embedding methods, and more needs to be done to study the generalizability of this method for complex non street scenes. I retain my original decision for these reasons.<BRK>The idea of assembling over segments sorting, segments merging, dynamic partitioning, and seed selection is interesting, which can be applied to many downstream tasks, like panoptic segmentation and instance relationship modeling. Cons1 This work emphasizes that the proposed approach can encode and discover object centric context. Besides, it further designs experiments to compare the context errors between UPSnet and the proposed one. However, I am not quite sure what is the use of object centric context? Is it meaningful for some applications? Besides, the work does not achieve better performance than previous solutions. 3 How about the generalization ability of this work? For example, can PSS be trained on Cityscapes and applied to coco stuff based on a few shot setting (i.e.only a few training samples are available)?<BRK>##########################################################################Pros:  The overall idea is very interesting, instead of using separate models (or branches) to learn instance segmentation and semantic segmentation, the proposed method directly learns a unified embedding that encodes both instance and semantic information. ##########################################################################Cons:  It is still not clear to me how does the learned panoptic embedding able to encode object centric context. Throughout the paper I don t see any specific design to optimize to learn context and the authors also do not provide theoretical explanation. If this is the case, I don t think it is suitable to name it "contextual image parsing" and put "discovering object centric context" in the motivation (or the goal), since I think it is not well studied. If the proposed method indeed learns object centric context, I think it is more reasonable to apply the method to tasks where object centric context is important, e.g.relation detection.<BRK>**Pros*** Competitive results on benchmarks. The PQ results are good, with relatively few additional "tricks" (assuming they re not simply left out of experimental section). This includes swapping in/out some proposed improvements to the underlying SegSort training, plus different components of the method used to construct panoptic segmentations from the oversegmentation. * Makes additional interesting observations about the behavior of the model/properties of the embeddings, in looking at the "context." So the main difference from existing panoptic segmentation methods is the use of an intermediate segmentation. The fact that it seems to improve panoptic segmentation results is more concrete, but it is less clear *why* this method would yield this improvement. * Description of hybrid scale exemplars is unclear, with very few details.
Reject. rating score: 2. rating score: 4. rating score: 4. rating score: 5. <BRK>Since the authors remained unconvinced that the PD is sensible to positive scalings of a model s parameters, and hence comparing the PDs of two sets of models with different activations (one activation per set) is not sensible, here is a more detailed explanation of this fact. The problem of understanding how model design choices can have negative impacts on experimental reproducibility is interesting and timely, but I believe the paper does not provide a strong enough case for their approach and contributions. "PD, as we defined in Section 2, is aimed explicitly at measuring differences between predictions of a set of models that are supposed to be identical in all their components"Indeed, and my point is that comparing the PD of two sets of models that are not identical is also problematic **even if all models within each set are identical**, except for the PD in its Hamming form.<BRK>Thanks for the efforts of the authors. However, I still think that the experiments are not convincing enough for ICLR. For SmeLU, the parameter \beta is very important. In Figure 4, different optimizers could produce different results. It is better to test with SGD, Adagrad, Adam, and AMSGrad. The datasets used in the paper is very small.<BRK>The paper claims that smooth activations are more reproducible than ReLU. I am looking forward to the responses from the authors on this point. It’s a fresh perspective and focuses on the main problem at hand. If so then there would be numerical issues in the way models are trained.<BRK>They show that smooth activations can help remedy this issue, by tuning the activation to become more relu like, which leads to a better tradeoff between prediction differences (i.e.consistency) and model accuracy. * This paper shows how weight normalization also influences the loss surface, but was not explored empirically. The paper can be more convincing if more datasets are explored, preferably not on a private dataset for which no one can validate their results. I think adding additional experiments taht scan different weight norms for a fixed beta would only strengthen their claims.
Reject. rating score: 6. rating score: 7. rating score: 7. <BRK>This paper proposes a posterior approximation for BNN that models correlations between the layers weights. In order to make inference tractable, the paper proposes the use of global inducing points as well as noisy pseudo observations of the activations of intermediate layers which are treated as variational parameters. The paper also describes how such procedure applies to convolutional neural networks and how it can be applied for DGPs as well. As pointed out by [1], one of the main interests on posterior approximations that allow correlations between the weights is for capturing the uncertainty of the compositional structure. Doubly stochastic variational inference for deep Gaussianprocesses.<BRK>Instead of factorizing the inducing points The global inducing input $Z_0$ is propagated through the network to ensure posterior dependencies across layers. The authors also extend this idea to deep Gaussian processes so that the latent functions across layers are correlated. Cons:The description of the method itself is not very clear. 1 is easy to follow, how does it relates to the training process of BNN? The paper didn t say much about these important details, and by just staring at Eq.(16) I really couldn t figure them out. Comparing to methods the paper compares with such as (Salimbeni and Deisenroth, 2017), Section 3 of this paper is not clearly written. In Sec.4.1, 100 inducing points per layer was used on a dataset with only 40 points. What if the number of inducing points is smaller? I thank the authors for their detailed reply. Very good work.<BRK>**Summary**: The paper proposes a posterior estimation for Bayesian neural networks (BNNs) and deep Gaussian processes (DGPs). The difference from the previous approaches is to use global inducing points which help to take into account correlations across layers. And as the methods that factorise across the layers use the assumptions of Gaussian units, the error is higher for shallow NNs. So maybe it is possible to keep in mind the “heaviness” for shallow NNs induces due to the correlations between the units and to improve the results.
Accept (Spotlight). rating score: 7. rating score: 7. rating score: 6. rating score: 6. <BRK>Overall, I vote for accepting this paper. ### Strong points  The theoretical result is sound and significant. This is quite a success of applying random matrix theory to study machine learning. What can be said about the unbalanced case?<BRK>The theoretical analysis highlight the intrinsic  relation between task statistics/relatedness and the classification performances. How the presented results transfer to the multi class classification setting? My major concern is about the clarity of the paper notations.<BRK>ICLR seems to mainly about representation learning while the problem this paper does not rightly concern processing the input data. The main contribution of the paper is a theoretical analysis for the setting where the training data and the test data are all Gaussian random vectors.<BRK>This paper provides a theoretical analysis of the inner workings of multi task learning methods, based on a random matrix analysis applied to Gaussian mixture data model. The main contribution of the paper is to introduce the random matrix theory to study the performance of MTL LS SVM theoretically, which is novel and facilitates the understanding of MTL. After rebuttal:The authors  response addressed some of my concerns and I d like to adjust my rating to marginally above.
Reject. rating score: 5. rating score: 5. rating score: 7. <BRK>The paper mainly addresses shortcomings of a previously mentioned simple concept, bias amplification, brought up in Zhao et al 2017. In this regards, I am not sure about extensiveness of novelty and contribution of this paper along with its technical rigor. One suggestion would be to add some theoretical analysis maybe in Validating the metric session. 2.Although Zhao et al s paper is a famous paper in NLP domain, not much attention has not been given in the pure algorithmic fairness and using it as a measure along with other well known measures, such as statistical parity or EO. 3.The discussion on error bars and their need sounds like an intuitive concept which authors spent a section on it. Mostly vision datasets are explored, but authors could have done some studies on famous fairness benchmark datasets as well. This can introduce bias amplification concept to the fairness community and make it more comparable to other well known fairness measures and more acceptable to the community. 5.There are some claims that I do not find accurate in the paper as follows:5.1. 5.2."A trait of bias amplification is that it is not at odds with accuracy, unlike many other metrics ..."  > where is the proof for this? need strong evidence for this claim. Overall, this paper addresses shortcomings in a previous work based on a simple bias amplification metric.<BRK>The paper builds on the "bias amplification" aspect of fairness in machine learning literature i.e.the tendency of models to make predictions that are biased in a way that they amplify societal correlations. Overall I find the metric as the only major contribution of the paper, and below I will explain why. It would be more effective if the work also included a study such as Zhao et al demonstrating how to mitigate the bias as measured by the BiasAmp measure. The discussion around the usage of error bars because of the Rashomon effect seems incomplete and almost trivial. I would be curious if it were robustly tested e.g.another experiment such as Fig 4 where the authors control the amount of the bias by tuning at the source of the bias. Overall, I am not very convinced that the paper should be accepted unless fellow reviewers think strongly otherwise. However, I think the paper has the potential to be a more complete and important contribution with a more comprehensive study around the technical contributions and clearer discussion about the normative contributions.<BRK>In particular, the paper offers useful insights concerning the meaning of bias amplification across varying contexts or use cases and prescribes the use of confidence intervals for better validation of various fairness metrics. In particular, the authors clearly state the benefits of their method as described in Sec 3.4. 3.Experiments and analysis:This is the biggest strength of the paper. A thorough investigation makes this paper compelling. The authors also discuss the limitations of the proposed metric. The running example (fig 1 ) considered in the paper is interesting, especially given that such stereotypes are not considered often. The recommendation for confidence interval is justifiable, but lacks a proper grounding. While it is ok in terms of notation, it raises the question of how causal claims can be justified by merely thresholding  as opposed to interventions . In this context, more elaboration of the metric (Sec 3.3) would be useful.
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 5. rating score: 6. <BRK>This paper extends the results for actor critic with stochastic policies of [Zhang, ICML 2018] to deterministic policies and offers the proof of convergence under some specific assumptions. The authors consider both the on policy setting and the off policy setting and offers some convincing derivation. This work might provide a promising way to address the problem of inefficiency of exploration in MARL.<BRK>This paper establishes the asymptotic convergence of on  and  off  policy DPG in the multi agent setting under some assumptions. I suggest the author to consider some RL settings to make the experiment results stronger. (4) The current muti agent setting in this paper is not that practical, as too many variables are requied to be globally observable.<BRK>Clarity: The paper is well written. If my understanding is correct, in the off policy setting, we are still interested in the maximising the reward with respect to target policy, and the restriction is that the samples are from the behaviour policy. But for the off policy case, other results seem to be correct. 2) Weakness: The experiments are on a toy domain. Novelty:The deterministic policy gradient result is new. The off policy case seems to have some issue (see above).<BRK>This paper proposes a solution to learning deterministic policy in the multi agent RL setting, where local rewards are private to local agents. Both on policy learning and off policy learning are considered in the paper. (2) the decentralized algorithm itself, although similar to prior work in Zhang et al (2018), provide needed guarantee to the algorithm for convergence.<BRK>This paper offers a comprehensive theoretical treatment of deterministic policy gradients in a multi agent setting, working out several key results:* existence and explicit formulas for the multi agent deterministic policy gradient in off and on policy settings;* convergence of stochastic policy gradients to deterministic ones as policy variance converges to zero; * convergence of multi agent deterministic actor critic algorithms. The paper is incremental in a way that the deterministic results seem to be extensions of known stochastic results along the lines of well understood techniques.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. rating score: 6. <BRK>The authors propose a novel 3D neural mesh model of objects that is generative. I would vote for acceptance of the paper. The neural mesh model representation is novel and clearly leads to superior robustness. Their experiments are exhaustive and convincing.<BRK>This paper tackles the task of pose prediction and takes a render and compare approach. Updates after author response: I think the revisions and the responses did address all the concerns I had, in particular towards assuring that the method and baselines leverage the same information for inference. Additionally, the experiments where one can  search  for the optimal subtype instead of assuming known subtype at inference also showed encouraging results. Overall, I think the paper writing and presentation is much improved, and I would argue for acceptance as the paper presents a simple and intuitive idea which is shown to work (rather surprisingly!) **Concerns**I have several concerns/questions regarding the empirical setup and results, and feel that these have not been detailed sufficiently in the text. The text in  training setup  states  we .. learn a NMM for each subtype separately . It is also not described how this is known for a new image. Does simple gradient descent with a fixed starting point work?<BRK>This paper describes a neural mesh renderer that operates on a feature level for 3D object pose estimation. The 3D CAD model of the object is converted to a mesh, which is converted to feature space   one feature per 3D mesh vertex. The paper is reasonably well written, but could do with a spell check. Contrastive loss and learning in feature space is not novel, but their application to a mesh model for render and compare type object pose estimation seems to be new.<BRK>\  One major limitation of the proposed method is to rely on a fixed template model. What if we provide explicit segmentation mask for each baseline as in NeMo? \  The paper explains how to compute z_i only in the caption of Fig.2.I would recommend explaining it in the main text. Post Rebuttal:Thanks for the revision and detailed rebuttal. I think the clarity is largely improved now. As the authors described, this property makes difference in terms of robustness to partial occlusions.
Reject. rating score: 4. rating score: 4. rating score: 5. <BRK>Overall, I think the approach that this paper proposes, namely using a MCTS/AlphaZero type approach to learn heuristics for graph based combinatorial optimization problems, has good potential to improve on pure RL methods. I think the main contribution of the paper is in thinking to apply MCTS/AlphaZero to these graph based combinatorial optimization problems. Moreover, even with a stronger experimental methodology, right now it is not clear to me if the gains are significant. Based on this assessment I would recommend rejection. Combinatorial optimization with graph convolutional networks and guided tree search. (2019).Learning heuristics over large graphs via deep reinforcement learning.<BRK>This paper applies AlphaGo Zero to solve combinatorial optimization problems on graphs, replacing the CNN with a graph neural network. However, I do not think that the paper makes a sufficient contribution to warrant publication at ICLR. The techniques used are mostly an off the shelf application of AlphaGo Zero, with the modifications (swapping a GNN in instead of the CNN and normalizing the rewards) being fairly direct. Investigations of off the shelf methods can of course be valuable, but I don t think that enough insight was gained from the experimental results in this case. What about it leads to more effective generalization, even though the in distribution performance is roughly equal?<BRK>This paper proposes an AlphaGo Zero style algorithm for training policies for solving combinatorial optimization problems. Different graph neural networks (GNNs) are considered as learning models to compare their performances. I suggest including it in the main paper. This information is in Appendix D. It is important to know that the comparison with S2V DQN is fair. c) Lots of experimental results are in the Appendix as well. I understand there is a page limit but including and discussing them in the main paper would make the paper more convincing.
Accept (Poster). rating score: 7. rating score: 7. rating score: 7. rating score: 6. <BRK>In this paper, the authors focus on the problem of lossy video compression. Pros:1.The proposed problem of video compression has direct societal applications. 2.The application of generative models, especially flow based models, to video compression is a novel and relatively underexplored topic in the community. 4.New dataset released will be useful for future work. Cons:1.There ideally should be more qualitative evaluation. 2.The new dataset is fairly small by the standards of video datasets. In summary, the paper explores an interesting and novel application of flow based models to video compression. While I think the paper could be strengthened by more qualitative examples and a larger dataset, I think this could be a good contribution to the conference.<BRK>The paper also introduce a dataset for neural video compression that collected from youtube.com. Cons:   I think the introduction of scale parameter is the most important point of this paper. Authors says it acts as a gating mechanism. Figure 2 shows the case of an image, but no comparison with traditional SSF has been made. For example, showing some kind of residual noise amount of conventional SSF (Agustsson et al., 2020) and show a reduce effect by scale parameter will make the claim of the paper credible. There needs to be a more specific and clear explanation of how the SP is processed. Figure 4 shows the effect of SP is that the image quality is better than SSF at high bitrates, but the image quality is worse at low bitrates. I would like to see a discussion on the reason for this.<BRK>#### SummaryIn this paper, the authors provide a new interpretation of existing video compression models. The introduced latent variables could be either used for providing more expressive power for 1) motion estimation&compensation modeling and 2) residual noise modeling, which are two key components of traditional video codecs. Although I am not entirely familiar with the learned video compression field, the interpretation looks quite interesting. It would be helpful for other researchers in the field. * New moderately high resolution dataset is provided for training learned video compression models. To make the work stronger, I have a few suggestions as follows. * Study on the effect of using a pre trained optical flow model. However, it might be challenging to learn motion estimation parameters end to end with other parameters. However, in this work, only the frame t and t 1 are considered for compression.<BRK>+ It is good to see that the paper includes comprehensive reviews regarding neural network based compression schemes and autoregressive models. The contribution has been depicted in aspects of 1) a new framework, 2) a new model, and 3) a new dataset. However, beside to 3), it is hard to see the other two aspects have significant novelty both in a neural video coding architecture (Agustsson et al.2020) and in temporal autoregressive models, etc. The evaluation should be conducted in YUV 4:2:0 domain for fair and reasonable comparisons.
Reject. rating score: 4. rating score: 4. rating score: 6. rating score: 6. <BRK> Summary This paper presents a system design method to train GNNs on large graphs in a distributed manner. Due to the irregular edge connectivity and the limited GPU memory, intelligent graph partitioning is necessary to support full batch computation. Then with the objective of minimizing the edge cut and improving load balance, the authors use the existing METIS partitioning algorithm to obtain node assignments. For Cluster GCN, it seems that the overhead is the same as the proposed BDS GCN, since both use METIS. The overall paper is easy to follow. + Strong experimental results (see also cons below for experiments)+ Distributed GPU training is an important topic Cons   Limited novelty: the main algorithmic steps, partitioning and sampling, seems straight forward. I would expect that reducing p from 1 to 0 would reduce the memory by multiple folds (since the number of boundary nodes is an order of magnitude larger than the number of inner nodes). According to the claim of the paper that dropping neighbors incurs information loss, the BDS GCN accuracy should achieve at most the accuracy of GraphSAGE. Why the accuracies are higher?<BRK>This paper developed a simple method for the distributed training of GCNs. To address this problem, this paper proposed BDS GCN, a method that adopts unbiased boundary sampling strategy to enable efficient and scalable distributed GCN training while maintaining the full graph accuracy. The experimental results show good performance on large graphs. 1.The writing is good and the idea is clearly presented. 2.The idea is straightforward. It just communicates a subset of neighboring nodes to reduce the communication cost. 3.In table 1, why is the number of boundary nodes larger than that of inner nodes? It seems that this method is identical to DropEdge. Otherwise, it is diffcult to see the novelty of this method.<BRK>Towards this goal, this paper proposes distributed GCN training, BDS GCN. For each partition,  BDS GCN samples a portion of boundary nodes (that are shared across partitions) and broacasts the features of the sampled boundary nodes over all partitions. In contrast to previous sampling based methods, this paper can potentially avoid information loss by only sampling the boudery nodes while awalys keeping the inner nodes and their connections. Overall, this paper is good written, the idea is valuable, and the exerimental results generally support the claims the authors have proposed. Below are some concerns for the current version:1. It seems in Table 2 that BS GCN can still obtain promising results when p is small. The reviewer wonders what will happen if p 0, when no boundery node is sampled. 2.The authors claim that DropEdge is not practical in distributed graph learning, which seems problematic. It is expected to explore this kind of baseline, and compare it with boundery node samling method. 6.In figure 3, it seems increasing the number of partitions does not necessarily reduce the time cost, why?<BRK>This paper addresses the efficiency issue raised by GNN training on large graphs. The proposed solution falls in the category of data parallelism, which aims to partition graph into smaller parts while reduce the communication cost caused by extensive number of boundary nodes. The proposed idea is interesting and practical, and the experimental results have demonstrated the superiority of the proposed approach. This paper successfully identifies the issues in the data parallelism based GNN training algorithms – each graph partition share too many nodes with other partitions, called boundary nodes, which significantly affect memory and communication cost. 2.The proposed solution is simple yet neat, which is to sample the boundary nodes to reduce memory and communication cost. The graph partition idea is interesting, but more details on how to apply METIS is expected. But in the experiment section, only a small subset of the mentioned methods are treated as baselines. Also, for the data partition based baselines, only throughput is compared. How about the accuracy comparison? For the sampling based methods, more methods are expected to be compared to the proposed approach.
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. <BRK>The paper introduces Supe RL that intermingles off policy reinforcement learning with periodic beam search operations. The method makes a greedy selection between the rl solution that it had and the best produced by the beam search using Polyak update to update the incumbent rl solution if the one suggested by beam search is better. Overall, the authors present an interesting idea. The paper could be clearer with more copy editing and technical rigor. I have read the ERL paper in the past and from memory know this to be incorrect. This is crucial as an ES is a finite difference approximation of the gradient at heart and would be rather redundant with a gradient based learner. However, these kinds of updates with a target network is a fairly standard tool in most modern policy gradient algorithms i.e., Soft Actor Critic (SAC).<BRK>This paper introduces another combination of an Evolutionary Strategy (ES) with RL, which basically consists of running an RL agent which every GE episodes alternates to run an evolutionary algorithm iteration based on the current policy as the parent of the population. If none of the individuals generated are better than the parent, the RL continues as it was before the genetic operations, otherwise the RL agent parameters are soft updated towards the value of the best individual. The contribution is interesting and fair, although the authors give considerable attention to the navigation problems used for validation,  which environments are also presented in this paper in the sections of the method and the results. Why not focusing on the more conventional/standard tasks (approached in the appendices) for evaluating the learning methods in the main paper, and leaving the proposed navigation tasks for the appendices, for a reader it would be more intuitive when analysing results of deeply well known studied problems.<BRK>Aiming at exploiting the benefits of population based policy optimization and policy gradient, this paper proposes a novel framework that combines these two techniques. The proposed framework is designed to be capable of combining evolutionary policy search approaches with ANY deep reinforcement learning algorithms. For one cases the authors obviously exploiting the structure of the combined reinforcement learning algorithm (existence of the target network and update the target network only), which is not possible in general. The above mentioned two instantiations are evaluated only on a single task for each. It is definitely not sufficient to evaluate the generality of the framework. The only existing approach is ERL, where its actor critic part is replaced so as to have the same RL approach as the proposed framework. However, since ERL is not designed to be combined with other approaches than policy gradient, it is easy to imagine (and also mentioned in the introduction) that the performance will drop severely.
Accept (Poster). rating score: 8. rating score: 7. rating score: 6. rating score: 6. <BRK>The paper aims at justifying the success of few shot learning methods that work based on finding a shared representation among a number of tasks.<BRK>The paper lacks discussion with some prior work  [2] where the authors obtained results for task averaged excess risk. The result in this work is not for new task but since the authors make strong assumptions on input data distribution and task model the result seems like a natural extension of the results in [1]. Provable meta learning of linear representations.<BRK>This paper presents some new theoretical insights into a two layer (linear or non linear) network based meta learning framework for dimension reduction and few shot linear regression. In the considered problem setting, the hidden layer for feature extraction is assumed to be shared across the training and test tasks, and the output layer is optimized in a task specific way with quadratic loss. The same concern can be raised for the underlying true model of data generalization in Equation (4) with linear feature map.<BRK>#####################################################################Thanks for the  response from authors! The paper is easy to follow and clearly discusses the meaning of assumptions. #######################################################################Pros:  Understanding when and why few shot learning is useful is an important and interesting problem. By introducing some new assumptions on data and tasks which is different from previous the iid assumption on the tasks, the paper shows that one can use all source data.
Reject. rating score: 5. rating score: 5. rating score: 6. rating score: 7. <BRK>This paper proposes a distillation method for BERT. The work is based on two fold main ideas. The authors should stress this point clearly and early in the paper (in the title, abstract or introduction). The motivation and the proposed method are somewhat problematic. However, my concerns about the motivation of the work still exist, so I am still slightly leaning to reject this paper.<BRK>This paper proposes a parameter efficient KD which consists of two main parts: Shuffled Parameter Sharing (SPS) and Pretraining with Teacher’s Predictions (PTP). The paper is well written and easy to follow. When applying SPS, the number of layers in the student model is double than the normal case, even the parameters are the same as the counterpart, I guess the FLOPs will increase or be doubled than the original one. I think for a small student model, the number of parameters should not be the only metric but also consider the FLOPs. Why this paper doesn’t discuss this?<BRK>the paper does admittedly not claim to provide fast inference times as a goal; nevertheless I have a hard time imagining a BERT model running on an edge device with a limited amount of resources in a reasonable time, so I think that inference time is a critical metric which I feel this paper does not consider, or measure  PTP sounds to me only weakly novel, since typically the student will be trained to predict the full softmax output of the teacher, whereas in PTP, the student must predict whether the highest value of the softmax is high or low. I feel that little insight or motivation is given as to why this auxiliary task was used, or is better than predicting the full softmax distribution. However, I have two main concerns:  the approaches used in the paper feel to me only weakly motivated. Little insight is given into why the approaches were chosen, and why they should work. Importantly, none of the experiments mention inference time, which I feel is a key metric to report for distillation? did you try a regression task to predict the confidence?<BRK>This paper proposed a framework for knowledge distillation with smaller number of parameters.The authors proposed a new parameter sharing method that allows a greater model complexity for the student model. The author combined these two methods to improve the performance of the student model on existing tasks, which has surpassed the existing knowledge distillation baseline. At the same time, the teacher model s generalization of knowledge is given to students through initialization, and then fine tuned. The experimental part of this article is also quite sufficient.
Reject. rating score: 3. rating score: 3. rating score: 5. rating score: 6. rating score: 6. <BRK>It is theoretically shown that the similarity pairs have lower noise rates compared to the original categorization. Then, a similarity transition matrix (that is pretrained) is applied to the prediction. Section 3.1 and 3.2 were quite hard to follow due to some notational inconsistencies, lacking definitions, and not being self contained (relies on the knowledge of Hsu et al.2018).The relevance and implications of the theories are not properly discussed. This renders the similarity noise rate to be (arbitrarily) low (depending on the number of classes and samples per classes). 2. from algorithm 1 it seems the method requires two independent trainings, shouldn’t that at least double the computational complexity? The latter could be dominated by the dissimilar pairs and unless formally analyzed or at least directly discussed it’s hard to draw any conclusion on how the bound on the similarity prediction empirical risk translates to a bound on the original classification risk which is the objective of interest. In fact, this can be a weakness of the proposed method that should be studied further and more thoroughly with designated experiments. Such a noise is possible in the real world applications due to semantic ambiguity or human error (as demonstrated in Clothing1M). 2.Is the same set of hyperparameters used for all the baselines as well as the variants of the proposed approach? In particular, which variant of the method or baselines are the hyperparameters optimized on? 3. the improvements for asymmetric noise, and on MNIST and CIFAR seem marginal. Furthermore, there are concerns regarding the motivation, relevance of the theories, and the significance of the results. During the rebuttal phase, the authors actively discussed various points raised by the reviewers and the AC. That is except my 2nd point of the major theory concerns, regarding the time complexity and convergence time which is at least partially addressed. The convergence time would also be addressed if the number of epochs for the proposed method is the same as the baselines. Given the outstanding majority of the concerns my final feedback is as follows:The paper provides an original idea for learning with label noise which is positive, to rate the demonstration of the relevance of the idea, I can either consider the paper from an empirical study lens or a theoretical one. From the latter perspective, the concerns above effectively affect the whole theoretical arguments of the paper. The main claim of the paper, even in the latest revision, is based on the noise rate of similarity labels being lower than the noise rate of the corresponding class labels and that this is what can bring improvement in the final performance. Furthermore, the discussion still does not make a clear formal connection between the error bound on the noisy similarity learning and the noisy classification for the general case. When it comes to the empirical view, the experiments are inconclusive and not thorough enough for an empirical paper due to 1) the drastic change in the learning setup (which is implemented inhouse including the base transition matrix methods) in tandem with the fact that hyperparameter optimization is not done per method (e.g., the hyperparameters are taken from the papers for baselines while they are optimized for the proposed method s training). On top of these, the final version of the pdf is still lacking on clarity several instances of which were listed in the original review.<BRK>This paper proposes a new algorithm on learning noisy datasets by transforming class labels into pairwise similarity labels. It also gives some theoretical analysis on the fact that the induced similarity noise transition matrix works better than the class noise transition matrix. The paper empirically demonstrates that the proposed method works well on several synthetic datasets and a large scale real world dataset. Strengths:  I believe the idea to use pairwise similarity as supervision is novel and interesting, and it is easy to implement. Th.2 shows that when the number of classes is large (>8), the noise rate of similarity labels is less than class labels. However, as far as I understand, the supervision effect of the pairwise label differs a lot between positive and negative labels. In fact negative pairwise supervision is not very meaningful as there are a lot of gradient directions that can minimize the loss. The baselines on CIFAR seem too low compared with the SOTAs, e.g.[1], and the improvement of the proposed method is limited. And the final result is not comparable as well. For example, under the setting of 0.5 sym noise of CIFAR 10, the best result of the proposed method is 81.15, while [1] has 84.78. 2019.Post Rebuttal ModificationRegarding A1: I agree with R2 that the theory has major concerns and the authors were not able to fix it during rebuttal. I think we need to be clear that whether the method can work empirically and whether the provided theory can explain it are two problems. Now it seems to me that it is clear that the theory is wrong, and the problem is that the authors did not take into account the difference of the class wise labels and pairwise labels. Now that the theory is wrong I have to be critical about the experiments. Since the performance is much worse than STOA, it is no longer clear whether the proposed algorithm works or it s just because the baselines are too bad. I adjusted my rating from 5 to 1. Regarding the authors  2rd and 3rd responsesFirst, please allow me to clarify that my wording "the theory is wrong" means the theoretical justification on why the proposed algorithm can benefit from the transformation and achieve better performances is wrong, as the authors wrote “This theoretically justifies why the proposed method works well” in their submission. The major flaw/concern has been raised by R1(Q1) and myself(Q1), and the authors’ responses on these two questions are not convincing. I don’t see any potential way to fix this major concern in the current theoretical justification sketch, so I think this submission needs a major revision. I have temporarily increased my rating from 1 to 3 as it has been questioned by the authors, especially the author who “have served as a reviewer 100+ times and as an area chair 10+ times for top conferences like NeurIPS/ICML/ICLR”. What’s more, I would also like to request apologies from the authors. As the author asked, “what are you angry for?”, I’m not angry at all. I simply adjusted my post rebuttal rating with my expertise after reading the authors’ responses and other reviewers’ comments.<BRK>In this work the authors propose a method to learn from noisy labels. The propose method converts the noisy labels to similarity labels which are more robust to noise and helps in reducing the noise ratio in the training data. Pros:The proposed idea to convert the class labels to similarity labels is very interesting and intuitive. It has some good properties which leads to a better performance. The authors provide a theoretical analysis of the proposed method to estimate similarity noise transition matrix which makes it more grounded. The authors have provided sufficient experimental results on multiple datasets to demonstrate effectiveness of the proposed learning technique. Cons:For asymmetric noise, the results are shown only for a noise rate of 0.3. Also, how does the proposed method compares with existing approaches for asymmetric noisy learning? The asymmetric noisy learning in Li et. al.2019 (and many others) can achieve around 93% accuracy on CIFAR 10 which is 10% higher then the proposed method. The presented ablation study is not very meaningful. The authors acknowledged that it is not a theory paper and therefore, the biggest concern is empirical evaluation. The shown performance is not comparable with existing high performing methods and therefore it is hard to judge without any direct comparison. The authors stated that their method can be applied on top of any existing method, which was not shown in this submission and therefore it will not be meaningful to judge just based on this statement.<BRK>This paper proposes a new perspective on dealing with label noise, called Class2Simi, by transforming the training examples with noisy labels into pairs of examples with noisy similarity labels and then learning a deep model with the noisy similarity labels. Experimental results on real datasets show that Class2Simi achieves better classification accuracy than its baselines that directly deals with the noisy class labels. The idea to deal with label noise by transforming noisy class labels into noisy similarity labels seems to be novel. The proposed Class2Simi provides a framework to improve different existing learning methods. In addition, the paper is well written with good organization. Although in most cases the proposed Class2Simi can improve the accuracy compared with baselines, the improvement is not significant in many cases like those on MNIST and CIFAR10. It is better to provide deep analysis about the principle of the proposed method and the experimental results, and give insight for readers about when the proposed method will achieve significant improvement and what is the underlying reason. After rebuttal:I thank the authors for clarification. I would like to keep with my score.<BRK>This paper presented a working framework for learning a robust classifier with noisy labels. It proves that if the number of the classes is more than 8 then the noise rate in the similarity matrix is less than that in the noise rate in labels. It also provides the generalization bound for the proposed techniques. The paper has a strong experimental evaluation of the proposed method against recent models on robust learning with noisy labels. My concern is the technical novelty of the proposed model, as learning from the noise transition matrix (Xia et al., 2019; Patrini et al., 2017) and learning from the similarity matrix (Hsu et al., 2019) both are well known. It will be good if the authors also comment on the running time of the proposed method as it is learning the classifier first from the noisy labels. Why?In Table 2, we have seen that model does not make a significant change in the news20 data set. Why so?We have seen that difference in performance is higher with a higher noise rate in the labels. The authors have stated in Theorem 1 that the noise rate for the noisy similarity labels is lower than that of the noisy class labels. But they did not provide any quantitative analysis of that. It will be good to see what is the reduction in the rate with respect to the number of classes and also the noise rate in labels. Though the paper has combined existing ideas to learn a robust classifier, the proposed classifier is outperforming when the noise rate is higher. Hence it can be useful for the ML communities. Along with this, the paper has also given a generalization bound. I would like to be with my score.
Reject. rating score: 4. rating score: 4. rating score: 6. rating score: 7. <BRK>This paper proposes a method which can simultaneously perform clustering and represent learning with local and global structure preservation. The experimental results show its effectiveness. (2) In the initialization of the algorithm, first use t SNE to transform the latent space Z into two dimensions, and then run K Means to get the label of each data point. (3) In this method, the author uses K Means for initialization. Has the author analyzed the effect of different label initialization methods on the results? In the adopted data sets, three are all about MNIST, and there is little difference between MNIST test and MNIST full. The data sets used by the author are repetitive, and it is difficult to reflect the experimental performance of the method. Overall, I think this paper is not ready yet.<BRK>Average?What about the baselines? This apply to all the tables. The authors provide arguments to several aspects of their contribution. From this point of view, it appears to me to be two completely different things. 2/ The second section reviews the most important and related works in the field of deep clustering. A.7 It should be say more clearly that the rank of j relatively to i is in terms of distance. As a summary, the paper is well written but includes several claims that are not justified. The separation of the clustering centers depends on their initialization. Indeed some geometric aspects are preserved by the projection, but are relevant for clustering? Besides, the benefits over N2D do not appear clear to me. It seams that the method depends on its initialization. I wonder how (I)DEC would perform with the same initialization. Although, Fig 2 and its caption could be more informative and self contained. However, the experimental setting is not clear and weights a lot in my final opinion.<BRK>The authors evaluate the proposed framework on five datasets and the experimental results show that the proposed framework brings certain improvements over the baseline approaches. [Pros]+ The paper is well organized and easy to follow. Moreover, the relationship between geometric structure and the clustering performance is also recommended to be analyzed to show the necessity of preserving the local data structure. It is not clear whether the data structure will be preserved for ConvAEs which is also commonly used in real world applications. In Fig.4, ‘AE+K mean’ should be ‘AE K means’. Markov lipschitz deep learning. 3.How do the hyperparameters $k$ and $scale$ affect the performance?<BRK>The idea of including the geometric structure is well founded and their approach appears to account for this well. I would not say they are not independent in this case. This is more of a question about the authors choice, rather that a criticism of the work. The above paper N2D (which you reference) mentions that the cluster quality lessens with 2 dimensions as opposed to higher. Further, like much of these works, the method is only tested on smaller datasets. [1] Guo, Xifeng, et al."Adaptive self paced deep clustering with data augmentation."
Reject. rating score: 4. rating score: 4. rating score: 4. rating score: 7. <BRK>Therefore, studying this notion is not well motivated to begin with. This notion is too stringent   as the authors confirm in the paper   and cannot be satisfied unless in some special cases.<BRK>For networks with constrained layer structure, such as convolutional networks, this paper shows that aligned networks in general cannot achieve zero training error with the squared loss.<BRK>However the main use case for this Def 3 in the paper is that these conditions make the analysis of convergence speed of gradient descent simpler.<BRK>The paper presents an extension of the idea of alignment in linear neural networks, that can help in providing convergence analysis of such networks.
Reject. rating score: 4. rating score: 6. rating score: 6. rating score: 7. <BRK>Previous studies report negative result. I think it s an intriguing question, and it would be beneficial to know how categories and viewpoints are intertwined in their recognition in CNNs. In the experiments, the authors divide category viewpoint combinations into a training and a test split without overlap. They then observe how prediction accuracy for the test split (i.e., unseen combinations) changes as the number of combinations in the training split (i.e., seen combinations) increases while its cardinality is kept constant. From the standpoint of the above question, it would have been more interesting if recognition of category and viewpoint were not separated but coupled with each other. They say "Thus, it is unclear that generalization to unseen viewpoints shown in our results is completely explained by the similarity between the seen and unseen set,..."I agree with this comment. In other words, a major issue with the current manuscript is that we cannot derive a firm conclusion from the experimental results.<BRK>Ultimately I think this submission is above threshold. Strength: This submission provides a novel perspective in understanding the relationship between jointly learned tasks. Strength: Novel experiments. But I think the paper s value mainly has to do with the experimental design. As the number of _seen_ combinations increases, there s less of _unseen_ examples to extrapolate. But it also increases the scope of predictions you have to make on seen examples. Another observation is that a _shared branch_ architecture can be computationally the same as a _separate branch_ architecture if you insert zero weights at the correct channels (and had more channels to make up for the sparsity). My current rating of the paper is "above threshold". As the number of seen combinations increases, the extrapolation problem becomes an interpolation problem.<BRK>One interesting aspect of their experimental setup is to withhold a set of category/viewpoint pairs for the test set. Essentially for each category the test viewpoint is not seen in the training set. Furthermore, this paper studies specialization, selectivity and invariance of neurons to category/viewpoint. This paper has an extensive number of experiments on various setups measuring different criterias. I would be very interested in just comparing the category accuracy. It is valuable to at least have one version that only category accuracy is reported for shared/separate. Question: Can you please clarify whether the images in the test set are unseen instances of the categories as well as unseen viewpoint?<BRK>This is done by setting up training testing data in a specific pattern where some category + viewpoint combinations are held out and never seen in training data. I have updated my rating from 6 to 7. PROS:  The authors tackle an interesting and relevant problem of generalization of CNNs for joint viewpoint and category estimation. The experiments are well designed to validate the authors  hypotheses. CONS:  The authors correctly identify a few variations of the network architecture that could be used for the joint viewpoint and category estimation task and study how this affects generalization. The features learned by the stem will be viewpoint invariant because the category estimation task requires viewpoint invariance. REASON FOR RATING:I like the idea and analysis present in the paper for generalization to unseen category viewpoint combinations.
Reject. rating score: 4. rating score: 5. rating score: 5. <BRK>This paper proposed a method to preprocess the dataset, so a machine learning classifier learned on the pre processed data would be counterfactually fair. Strong points:+ The studied fairness problem is very important, and the causality base fairness is a very challenging question+ The proposed method is very intuitive and easy to followPoints for Improvements:  On the experiments part, I was wondering why the paper didn t compare to the original Counterfactual fairness paper s algorithms by Kusner et al.2017.They have proposed three levels of algorithms to study the counterfactual fairness. Would this appear to be unfair to other baselines? The paper assumes a causal model as in Fig.1.Does this model always hold in practice? If it is not, what should we do?<BRK>The paper is well written, and the related work is coherent with the work done. However, I think a few new paper are missing, for example Counterfactual Fairness: Unidentification, Bound and Algorithm from Wu et al 2019 that bounded the reachable counterfactual fairness. It would have been interesting to see how the results related to these bounds. On the real data, I would like to see a discussion on the meaning of CF metric and FLAP method given that the condition 1, 2,3 are not verified. Finally the review of reviewer1 made me realize that CF metric and FLAP are based on the same function.<BRK>The authors propose ortogonaliza tion and marginal distribution mapping so as to achieve counterfactual fairness. More discussion on the MAE would be appreciated. I would encourage the authors to run more experiments with more real world datasets (possibly ones that are publicly available) so that the readers can get a more comprehensive comparison of the methods.
Reject. rating score: 5. rating score: 5. rating score: 6. rating score: 6. <BRK>This paper proposes to use power law dynamics to approximate the state dependent gradient noise in SGD, and analyses its escaping efficiency compared with previous dynamics. 2.Still with strong assumptions on covariance structure, the analytical results based on power dynamics are interesting. For example, it indicates that so called kappa distribution highly depends on the fluctuations to the curvature over the training data. However, the first term also includes the Hessian and might also affect generalization bound. The authors said that generalization error will decrease w.r.t.kappa’s increase and infinite kappa results in Langevin dynamics. Then the question is what are the difference between the power law dynamics and Langevin dynamics in term of generalization? My view on the ambiguous analysis is that the authors attempt to answer extremely challenging questions but left with many questionable concerns. 3.The experiments might not be sufficient. About comparing the escaping efficiency, the result only shows the success rate, and the evidence about the polynomial and exponential difference should be provided. Also, practical networks and datasets should also be considered to provide more strong evidence.<BRK>This paper proposes power law dynamic of SGD which considers state dependent noise. The proof of theorem 2 is not provided in the appendix. It does not make sense to me if w* is fixed when taking x >\infty, as the quadratic approximation should be used in the neighborhood of w*. 2.The escaping efficiency of the power law dynamic is only analyzed in low dimension case. I think  [Li et al., 2017] also proposed state dependent noise in Theorem 1.<BRK>It is particularly interesting that the authors show that the second order effect of the SGD noise in the Hessian induces a power law distribution over the iterates. Some empirical support is provided for the theory. This should be stated more explicitly. It is sometimes unclear which computations are rigorous equalities and which are not   for example, in Lemma 6 about escaping times, exact equality is used. *********EDIT: Changed my score from 5 to 6 after the author response/revision.<BRK>The authors derive this new dynamic (which they call Power law dynamic) using basic principles and the assumption that the noise variance depends on the state. They prove also that the expected time to escape a barrier is polynomial in the parameters, as well as a generalization error bound. The assumptions made are somewhat strong and may not hold in some cases, see below. Even though there are crucial assumptions that are made, it can be considered as a first step towards a more rigorous and general argument. Also, it seems that the distribution is defined only for positive $w$. At the bottom of page 3, it is said "in this case, .... is satisfied", while I think it should be "not satisfied".
Reject. rating score: 5. rating score: 5. rating score: 5. rating score: 5. rating score: 7. <BRK>I do think that the paper can be developed into a very nice contribution, if more substantive findings about epoch wise double descent can be obtained, and/or if the value of the newly introduced optimization variance is evaluated more thoroughly (e.g., through simple theory, or through more rigorous experiments). Strong points are that the paperi) is an early work studying epoch wise double descent, and that ii) the newly introduced optimization variance is an interesting concept and might very well be useful for finding good early stopping points. Weak points are that i) the findings about epoch wise double descent are not conclusive, and that ii) optimization variance is not sufficiently evaluated to judge its usefulness.<BRK>* qualityThe idea is interesting, but the paper lacks theoretical insights. And it was difficult to find in the paper how OV is related to generalization. * clarityThe paper needs to make it more clear how OV is related to generalization   is it always monotonically decreasing/increasing? * originalityThe idea seems new, but more theoretical insight is needed. * significanceIf the authors include more theoretical justification, the paper s results would be more significant. The current version is too empirical and not very convincing.<BRK>This paper proposes the metric of estimating the variance of gradients during optimization of deep networks and empirically found that this metric correlates with test errors, which may indicate a good point for performing early stopping during training. Granted, it might be difficult to actually prove it. So why is this OV so different from the gradient norms as to constitute a novel metric? At least from experiments, the changes in denominator do not matter that much. The dataset is kind of simple in the empirical analysis. It would be better if Imagenet size level ones or regression tasks are also performed.<BRK>To alleviate my concerns I would love to see some theoretical justification for *why* is this an important quantity and when does it arise naturally. The paper also introduces a quantity they name optimization variance (OV) and that correlates with the test error (while being only a function of the train set) and can be useful for early stopping. al.carries over to epoch double descent, by itself, this experiment is not too surprising.<BRK>Having a stopping rule without the validation set is intriguing, especially for datasets with a low number of samples. The authors propose a rule that doesn t require the validation dataset, i.e.it is solely based on training data. It introduces the notion of optimization variance which is different from the variance of gradients. It would be interesting to learn the impact at different levels of the percentage of the samples in validation. I also think the work can be impactful on small datasets. While they experiment with large scale datasets, experiments with even smaller datasets and different validation set proportions would be of great interest.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. rating score: 5. <BRK>The paper is a nice read. It builds on a line of research on multi modal video understanding that utilises transformers where these works: 1) fix one of the transformer models (e.g.BERT) and 2) utilise tokens and thus do not train the approach in an end to end fashion. Second, the experimental results (tables and commentary on tables) are not designed for easy consumption.<BRK>This paper studies modeling and training choices when designing a single model based on ConvNets and transformers for audio visual representation learning. As strategies for negative sampling in audio and videos are different, it proposes to sample negatives that are similar in the ConvNets  embeddings. Contributions:+ A sound, extensive set of ablations of the choices made along the way of modeling and training. + Good performance (overall best reported but for UCF101). Some explanations come after the first introduction of the term.<BRK>Since both video processing and Transformer based model are memory intensive, a parameter reducing scheme is proposed, which facililates training the model end to end. have not yet been used in this setting, and the ability to process such long videos seems doable due to the contributions of this paper. Empirical results on both audio and video understanding tasks demonstrate that the proposed method does indeed learn useful representations, and that multimodal training provides the expected boost to results. Obviously, comparing fixed vs. end to end training of vision/language models using the proposed method would be very interesting to see, but is out of the scope of this work. [1] Alwassel, Humam, et al."Self supervised learning by cross modal audio video clustering."<BRK>Experiments are performed on several audio and video benchmarks. In addition, improving negative sampling for audio visual learning is also not a new idea. For example, [1] uses an audio visual transformer for audio event classification, and [2] proposes a new joint audio visual transformer module with both self attention and cross modal attention. (4) With an additional multimodal transformer model, the proposed method fails to greatly improve performance. However, the proposed model has a large additional multimodal transformer after slowfast visual net and ResNet 50 audio net. The proposed model indeed has some merits (e.g., parameter sharing and negative sampling). However, to me, the technical novelty of the paper is incremental. The authors claim that the proposed model is more effective in handling long videos.
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 7. <BRK>This work proposes a novel pruning method, called all alive pruning (AAP), which is a general technique to remove dead connections from pruned neural networks. AAP equipped with existing pruning methods consistently improves the accuracy of original methods on three benchmark datasets. The motivation is very clear, and AAP is expected to improve existing pruning methods by removing dead connections especially with high compression ratios. 2.The authors perform various experiments on three benchmark datasets changing experimental settings such as classifiers, base pruning methods, and compression ratios. 3.The paper is written well. There is no theoretical study of AAP. Algorithm 2 removes dead connections in a greedy manner by making the scores of dead weights as zero, even though they can be alive by revived connections at future iterations. 2.The experiments are not practical. The proposed approach works well only with high compression ratios which degrade the performance of original models. 3.The novelty is limited.<BRK>This is shown to improve the accuracy of pruned networks at a given sparsity ratio, especially for very high levels of sparsity. The method proposed in not completely justified by the submission. Strengths  **Significance:** Nearly all neural network pruning approaches should consider this kind of improvement. As observed in the related work, some previous literature does explicitly ensure there are no dead neurons, but this is not universal. Some of the earlier investigation that the authors report, on more direct methods for finding dead connections, may need to be given a more complete treatment in the paper itself. **Possible drawbacks** It seems possible that an activation or gradient may be zero in one iteration simply due to a filter not being active on examples in a *that minibatch*. This also possibly isn t measured well by accuracy on small scale experiments such as MNIST and Tiny ImageNet: with a larger model and larger datasets I d guess that probability is greater that a dead connection will be spuriously identified somewhere in the model.<BRK>The paper proposes to remove dead neurons and their connected parameters through a very simple check while reviving pruned (salient) parameters up to the prespecified sparsity level, such that the sparse network obtained could perform better. The main (and perhaps the single major) contribution of this work is in its demonstration that such a simple method is indeed effective for different pruning methods on various network architectures and datasets. Moreover, except for visualization of remaining parameters, the idea is mainly demonstrated only for the performance, and it lacks in depth analysis, ablations, and insights including for instance, why existing methods produce dead neurons, what’s the cost of AAP (or N value) in practice and theory, etc.<BRK>Summary:This paper talks about a novel network pruning method, called all alive pruning (AAP), which seeks to effectively remove dead connections in a network. The proposed approach aims at enhancing the saliency based pruning, and technically the approach searches for the dead neurons by inspecting their gradient flows. Reason for score:Overall, I recommend accepting this manuscript. Although the proposed solution (AAP) is simple, the experimental results on several different saliency based pruning scenarios consistently demonstrate its effectiveness and versatility. Authors repeatedly mention that one of the positive byproducts of AAP is that it is more compatible with modern memory architecture. Additional descriptions would be appreciated.
Reject. rating score: 6. rating score: 6. rating score: 6. <BRK>This framework allows leveraging of unlabelled output data to train the denoiser, which consequently allows the base predictor to be of low complexity that can potentially generalize with relatively fewer labelled data. +ves :  The paper is very well written and easy to follow. The motivation and the contributions are very clear, and the experimental section is also well detailed and organized. The authors argue that this framework allows reduced complexity of the base predictor, backed theoretically for a 2 layer ReLU network. The authors have provided a detailed proof of their argument in the supplementary material, although I have not completely verified its correctness. The authors compare their method with other methods for leveraging unlabelled data such as pre training and back translation.<BRK>The authors propose a more data efficient way to train generative models with constraints on the output; specifically they evaluate on image generation and pseudocode to code (SPoC) tasks. The recommendation is a “weak accept” though, because the experimental evidence for the technique is not convincing enough to me. I would have expected significant gains on a well understood task, clearly attributable to the technique. They argue that this should theoretically simplify the task of the predictor, and show improvements on several tasks.<BRK>This paper proposes a framework for problems where the output has some validity constraints, for e.g.the output must be a valid python program that must compile. The idea proposed in the paper is simple and intuitive, and the authors show that this approach leads to an improvement of 3 5% on the SPOC pseudo code to code data set. The authors also provide some theoretical justification why such a composition is the right thing to do. I wonder how this would compare to the proposed method?
Reject. rating score: 4. rating score: 5. rating score: 6. rating score: 6. <BRK>This paper explores a way of learning how to automatically construct a concatenated set of embeddings for structured prediction tasks in NLP. This paper has some nice empirical results and the simplicity of its approach is attractive. MOTIVATION/COMPARISONSThe authors motivate their technique by drawing parallels to neural architecture search. Computationally this would be cheaper than what the authors did. Intellectually, I think these approaches are related, and they should be discussed and compared to. Because the embeddings aren t themselves fine tuned as part of the ensemble, it really feels more like a fine tuned ensemble of existing models rather than true NAS. The paper should specify that it s these, and not arbitrary graphs that are being produced here.<BRK>This paper introduced an interesting application of reinforcement learning in the selection of concatenation of contextual/non contextual word embeddings. More experiments of the comparison with ensemble models should be conducted to prove the necessity of ACE. The author(s) conducted many experiments that compared many other models (including SOTA models, and ablation study). Instead of using reinforcement learning to learn the concatenation of different embeddings, why not use the ensemble model to aggregate the results from different contextual embedding based models?<BRK>This paper describes an approach to choosing a subset of several options for (optionally contextualized) word embeddings to use in NLP tasks. Ideas are drawn from neural architecture search (NAS) and RL. I don t think the mask is being concatenated; I think it s being multiplied elementwise with the embeddings. I m not sure if I m thoroughly convinced of the empirical superiority of ACE. The primary baselines are All (using all embeddings always) and Random (random search over subsets of embeddings). Relatedly, I am concerned that the All baseline is not strong enough.<BRK>Summary: This paper proposes to automate the concatenation of word embeddings (obtained using different strategies) to produce powerful word representations for a given downstream task. Since ACE already pretrains the task model for each of the embeddings independently to begin with, why not adopt a "boosting" style approach instead of the naive "ALL" baseline. ##########################################################################Positives:  The idea of using NAS to construct concatenated embeddings is interesting and the formulation is clearly developed in the paper.
Reject. rating score: 5. rating score: 5. rating score: 5. rating score: 6. <BRK>In this paper, the authors proposed a novel reparameterization framework of the last network layer that takes semantic hierarchy into account. The strengths and weaknesses are very obvious in this paper. + The proposed method seems novel and interesting. The proposed method depends on a pre defined semantic hierarchical graph rather than a learned one, which potentially limits the technical value of this work. I think this parameter should be dataset dependent due to different numbers of categories and the densities of class distributions. Finally, forcing a fixed radius does not sound as reasonable as allowing a learnable radius with soft regularization. However, I feel there is still some improvement space for the experiment part of this section, and I encourage the authors to incorporate the changes, including ImageNet experiment and following stronger baselines to make the results more solid and convincing.<BRK>Figure 2 right depicts Riemannian gradient and "projected gradient", but the paper does not formally compare them. It is not clear why Euclidean distance is not sufficient for learning with such a hierarchical regularization. Is there a discussion on which one may be more efficient (or compute time) during a training iteration? Moreover, the sentence is confusing, "the parameter of the classifiers that identify dog’s breed should also be similar". I think this paper is at the borderline. If not, are there any related work adopting this method? As far as I know, SGD is sensitive to the initial learning rate. What is the optimization method used for learning other layers? Even though the authors provide C.2, C.3 and plain files on the prepared hierarchies in the datasets, it is disappointing that the paper does not present the hierarchical structure in a nice way. Visualization is interesting to look at. But it should be better analyzed. The paper uses two networks ResNet and DenseNet, then what is "plain networks"?<BRK>The idea of introducing class hierarchy as a regularization into deep networks seems to be novel. The following comments could be relevant:1. The reviewer finds Section 2 is not easy to follow:  Authors may consider to give more specific definitions to terms such as, classifier, separators, etc. For example, in (2), Wp and Wpi are called classifiers. In Definition 1, authors may like to give some early examples about P and L. Otherwise, it is not easy to interpret the matrix H.  Authors may consider to use a different notation for Delta in (8), as Delta may remind an operator on H in (9). 2.In (9), do we require or observe deltas in the same subtree roughly the same direction? 3.In Section 3, it is claimed no hyperparameters are added.<BRK>It is naturally motivated to combine the hierarchical structure in the label space as a prior knowledge to supervise the training of neural networks. The overall idea is simple and easy to understand. I believe this direction is of sufficient significance to the ML community. This paper has several aspects that I found most interesting:(1) The formulation is interesting and is novel from my perspective. Then, the authors are able to formulate this in a matrix multiplication, which is basically a linear matrix factorization that over parameterizes the classifiers. I want to note that it is a suggestion for the paper rather than a weakness. The radius decay for the hierarchical spheres is also novel to me, because labels in finer grained level should be modeled with less capacity. It will make this paper more interesting to have more experiments that analyzes the difference in feature distributions between normally trained neural networks and the hierarchically trained neural networks. (2) Some important ablation studies to justify some heuristic designs are very important and necessary. The method uses additional prior knowledge on the label space, but only yields very limited performance gain. What is the underlying reason?
Reject. rating score: 4. rating score: 4. rating score: 5. <BRK>And, how is the proposed method overcoming that limitation? ————————————————————————————————————————————————————————————————————————————————Strengths:S1) The paper is very well written and easy to understand. S3) The proposed approach is able to generate real time saliency maps, and, therefore, is computationally cheap. ————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————Update after rebuttal: I thank the authors for their responses to all my questions. They satisfactorily answer some of my concerns. W2) Another key concern is the evaluation of the proposed approach. Hence, I cannot recommend the paper for acceptance. It is not clear to me how we can evaluate that from qualitative examples. Especially, when compared to other methods, is there a reason to believe that these artifacts might be more common in some methods than others? Given that it is computationally equally cheaper to the proposed approach, comparison with Real Time seems to be the most important one. However, it is important to disassociate the contribution of this difference from the rest of the approach.<BRK>Summary: This paper proposed a method for generating saliency maps for image classifiers that are stochastic (instead of deterministic). Stochastic saliency map is interesting and novel to my knowledge. The paper is generally easy to understand. Concerns:  Current empirical experiments compare to several saliency generation methods in the pixel perturbation benchmark. A positive point is the improved inference time. This is shown in Figure 5b but not discussed in the text, only briefly mentioned in the conclusion. I also think that improved inference time is at the cost of longer training time (the authors can correct me on this).<BRK>Overview:This paper proposes a new interpretability method for image classification networks. Quantitative evaluation on the perturbation benchmark as well as qualitative result show the effectiveness of the proposed method over baselines. + From results on the perturbation benchmark, the proposed method achieves better or comparable performance compared with baseline methods. Although the proposed method is quite efficient at the inference stage, it requires extra training steps and extra encoder with parameters. It is not clear whether the proposed method can be generalized to other kinds of data rather than images, such as text data, video data, vision language tasks etc.
Reject. rating score: 2. rating score: 5. rating score: 6. rating score: 6. <BRK>***Summary and general comments:***This paper presents a method to parametrize a set of constraints via a linear space that may change. This method was already studied in much more depth in [1], where this idea is explored through the lens of vector bundles and retractions on them, with a convergence result appearing in the follow up work [2]. Why is that the case? 2) "In contrast to this related work our method reparameterizes the update step during gradient descent rather than the parameter matrix itself"This is not really different as explained in [1]. I do not understand what is the motivation behind using the low rank update besides the fact that it allows for an (amortized) low cost of the inversion. It is also nice to see the improvement that this idea gives over RNVP. At the same time, when it comes to the experiments, I believe that it would have been of interest to compare this approach with other known ways to parametrize invertible linear layers, such as those that use QR, SVD or Choleski factorizations.<BRK>This paper introduces an algorithm for training neural networks in a way that parameters preserve a given property. Instead of directly optimizing the parameters of the network, the optimization is carried out on the parameters B of the auxiliary transformation R.  The method is (only) exemplified with the particular case where one needs to optimize a network with the property of having invertible layers (which is an important use case for example for normalizing flows, and invertible networks). The parameters are updated periodically, after a series of perturbations which helps to stabilize the optimization. My main concern with the paper is that the experimental evidence is quite limited so it is hard to judge the real contribution of the method. The title mentions a general idea, but in practice only the case of invertible matrices is analyzed and discussed. Section 2.2. is rather disconnected from Section 1.1. There s no motivation why this is there.<BRK>It is not clear to me how harshly this should be penalized. Unfortunately, it is hard for me to judge if this is the case here, as I know of the previous articles reviewer 2 refer to, but I have not studied them carefully. Occasionally, the rank 1 updates are merged with the network parameters. ### Strengths**[+]** Preserving properties like invertibility is important and has been studied by much previous work. The authors present a novel approach based on rank 1 updates, which, to the best of my knowledge, is completely novel. **[+]** The paper demonstrates how rank 1 updates can be used in deep learning, which I believe will inspire further research into this interesting direction. Furthermore, I ll re evaluate my conviction after reading the comments by the other reviewers. ### Questions The following question was already answered by the authors before the submission of this review.<BRK>It particularly focuses on the case of invertible layers and demonstrates improvements over classical architectures for density estimation with normalizing flows. It is empirically shown that parameter perturbations allow for sign changes in the determinant. I think the approach is original and the fact that it could be applied for other properties makes the development and the proof of work very interesting. The experiments are insightful and help the reader to get a better feeling of what is happening at training time. Most of the paper discusses how perturbations can be applied for learning invertible matrices. However, it is not clear which method is preferable in which situation. What is even more embarrassing is that no comparison at all is performed against this work.
Reject. rating score: 4. rating score: 5. rating score: 6. rating score: 6. <BRK>Authors research the problem of robust metric learning in this work. They propose a min max formulation to learn the adversarial example and robust representations, simultaneously. My concerns are as follows. The reason for current choice is that having perturbation on positive example achieves best performance as shown in appendix. At least robust triplet loss in [2] can be included. [1] A. Sinha, et al.Certifying Some Distributional Robustness with Principled Adversarial Training. [3] A. Zhai, et al.Classification is a Strong Baseline for Deep Metric Learning.<BRK>edit after rebuttal:My opinion about the paper has not changed. The paper proposes a robust deep metric learning approach to adversarial attacks. Unlike previous Deep Metric Learning (DML) approaches, the approach focuses on robust optimization based training that uses a saddle point formulation. Is the proposed approach robust to other kinds of adversarial attacks? For instance, if (x_j, x_i) are dissimilar and x_j is in the epsilon ball centered at x_i, then rho(x_i, x_j) should be equal to x_j. How does the proposed approach have an impact on the norm of the learned representations? Can the authors perform an analysis on the difference of representations between classic DML and the proposed approach?<BRK>The authors propose a novel robust training approach for deep metric learning (DML), accounting for the dependencies of metric losses within mini batches. Unless I am misunderstanding something, this feels out of sync   either it is a key insight, or inconclusive? While this is certainly sufficient to establish that the method works and that it provides some level of robustness to adversarial attacks, it feels really limiting to only assess a single attack type, of various options that are available   as it would have been potentially valuable to establish the degree of provided robustness under these different cases. Apart from the general metrics shown in the tables, there isn’t much additional analysis that would aim to reveal whether there were any patterns in these datasets on where the method worked vs didn’t. If not, why? Or are there issues with rare classes? It would be good to include key discussion points in the main body of the paper.<BRK>A robust training framework is proposed. Positive points:  The topic of rendering deep metric learning robust to adversarial attacks has received little attention in the past, and the results presented in the paper seem indeed novel. Concerns:  The derivation of the proposed robust training framework for DML is a bit unclear. It would be great to be able to compare the proposed strategy with other results. (cited by the paper)?. Reasons for score:Overall, I lean towards accepting the paper, as it seems to propose the first results around robust deep metric learning. 3: the bold value for CUB200 2011 with contrastive loss does not seem to reflect the best performance. Metric learning for adversarial robustness, 2019.
Accept (Poster). rating score: 7. rating score: 6. rating score: 5. rating score: 3. <BRK>This is done by training a goal conditioned policy together with a universal value function. This solution is used as a demonstration that the policy can use for self imitation via an advantage weighted behavioural cloning objective. This approach tackles an important problem of effectively learning policies for long horizon tasks taking advantage of compositional structure of sub problems. It nicely combines several ideas from prior work such as self imitation and universal value functions to present a method that is conceptual simple but performs well empirically on complex tasks. 2.SIR seems quite related to the two level architecture in standard hierarchical RL approaches — the planner for task reduction is the top level and the low level being the policy. There is a few key difference though: SIR uses this structure primarily for learning and over time the knowledge in this bi level structure is distilled into the low level policy. 3.Unlike traditional sub goal selection methods which recursively decompose the problem into sub problems, SIR does a single reduction step to decompose the task into two sub tasks. Is it possible to extend the current approach to a recursive decomposition for harder tasks? There is a clear motivation, contributions and a thorough overview of the related work in this area. The discussions are well structured and together with the appendix a lot of detail is provided on the experiments and methods. This somewhat reduces the strength of the proposed results. As an additional baseline, it would be good to see the performance achieved by SIR when search is not structured and allowed to explore all dimensions of the state space. 6.The paper presents initial results on a vision based task where a VAE representation is used as state. As mentioned above, this can have a significant impact on the learning performance (while CEM should do better compared to random search it is not clear if this can mitigate the issue by itself). While this is briefly discussed in the paper it is not clear how this can be mitigated easily. A more detailed discussion would be useful. Overall, the approach is quite nice and the initial results are encouraging. I would suggest a weak accept.<BRK># Summary This paper proposes a new method that combines task reduction and self imitation learning for goal based reinforcement learning problems. The idea is to decompose a hard task into two subtasks (subgoals) such that the solution to one of them is already known. The experimental result shows that the proposed method outperforms the baseline SAC + HER and SAC + SIL as well as hierarchical architectures such as HIRO and DSC. # NoveltyThe proposed idea of decomposing a task into two easy tasks is novel and interesting. It would be worth citing and discussing a relevant prior work [1], which also proposes such a decomposition for goal based RL. Specifically, it is interesting that the proposed method outperforms hierarchical RL methods without being explicitly hierarchical. * At the same time, the proposed method seems very specific to a subset of goal based RL problems, where searching the goal space is computationally tractable. Either showing much better results on Figure 8 or showing results on complex visual domains would strengthen the claim. * It would be more convincing and interesting to show that the proposed method can do deeper planning by applying task reduction recursively. # Clarity* The paper is easy to follow, and the figures are well presented. This seems quite specific to “goal reaching” 1 or 0 reward structures. Do you have an idea how to generalize this to more general reward structures? Otherwise, they are not fair comparisons. * Just to check if they are apples to apples comparisons, do you use HER across all methods (yours and baselines)? It would be good to mention that this paper considers goal based RL problems early in the paper (in abstract or introduction).<BRK>The submission proposes an intuitive curriculum learning method which focuses on sparse reward tasks in RL and uses universal value function approximators. It has 3 explicit steps: 1. identifying a state to decompose the one task into two 2. solve these new tasks 3. solve the complete task by imitating the trajectories from both subtasks. On the positive side, the paper is overall clearly written and easy to follow for most parts and performs commensurate or better to baselines on a set of simulated manipulation and locomotion domains. On the negative side, the method often only performs commensurate or close to the baselines while introducing significant added complexity and additional hyperparameters. The minimum requirement for a fairer comparison would be to include a version of SIR without this constraint. More generally, aspects regarding the specifics of the space in which we search for intermediate states and the baselines remain unclear (e.g.in terms of the search space since according to the appendix the space for states and goals is not the same and e.g.for stacking other constraints exist). The final problem regarding the evaluation is that while presenting essentially a curriculum learning method, the paper does not compare against other work in curriculum learning as baseline (e.g.[1,2]).Other questions remain such as the surprising statement that off policy SAC underperforms on policy PPO on the navigation task. Statements that are counter to intuition and existing comparisons between SAC and PPO should be supported with experimental results. Overall, the introduced method follows a valuable direction for curriculum learning in RL but the submission demonstrates significant weaknesses regarding fair evaluation. (Disclaimer: I have reviewed a previously submitted version of this work and a big share of critical points remains the same between both reviews including domain knowledge unavailable to baselines and comparison to other curriculum learning methods.)<BRK>#######################################################################Summary:In this paper the authors propose a method for solving compositional tasks in the RL setting. #######################################################################Reasons for score:I am currently voting for a rejection based on what seem to be two key omissions from the paper:1. A measure of how expensive this offline component of the algorithm isThe experimental comparisons could also have been stronger. I think the paper is reasonable well written. 2.The 2 step implementation of some sort of "policy reduction" followed by an imitation learning step would seem to be a good in principle idea that merits further exploration#######################################################################Cons:1. In Sec 3 the authors talk explicitly about a multi task RL learning setting, and indeed a central part of the method is a search step over interim states $s_\beta$ , but I do not see explicitly how this set is constructed. This is of course a critical consideration for a number of reasons:(1)  If this set of tasks is large, then you are likely to find a good $s_\beta$, but the search space increases (as does the memory footprint)(2) If this set is small (and perhaps curated), then the subsequent result is weak (if the agent need only search over a small handful of interim tasks which already include moving the elongated box say, then of course the subsequent learning is rapid). The comparisons to SAC for example are valid in that they provide a lower bound, but there is additional information available to SIR. 3.The authors mention that the method is extensible even though "... tasks reduction only performs 1 step planning... SIR still retains the capability of learning an arbitrarily complex policy by alternating between imitation and reduction: as more tasks are solved, these learned tasks can recursive further serve as new reductions..."   this is a nice idea, but I saw no evidence of this implementation in the paper. #######################################################################Questions during rebuttal period:Please address the concerns above. Also, you have some comparison with hierarchical policy algorithms in 9.a/b   is it possible to extend these to the other domains? since your reduction phase is 1 step and greedy, in which situations might it not work so well          etc. A little more justification for you particular experimental comparisons can be helpful.
Reject. rating score: 5. rating score: 5. rating score: 7. <BRK>The autoencoder and prior encoder networks are iteratively trained with the sliced Wasserstein distance (SWD). While the paper cites some works that also aims at addressing the drawback of SWD, it still misses some important related works like [a, b, c]. It is also not clear why to choose Eq.(6) for the nonlinear transformation. Unfortunately, this paper does study this at all.<BRK>The pipeline is clear and easy to understand. The representation learning with VAEs is a widely studied topic. * In the experiments, the authors claim the generations are better, while the quantitative results, such as fid, are not provided. Update after the discussionsI appreciate the efforts that the authors make in their responses, some of which address my concerns and improve the quality of the paper. I have raised my rating.<BRK>Probably worth including these for the main results in section 5 for the two results presented. You would have to invert the prior network with gradient descent to do this ... but it might work. Is there any evidence of structure in the latent space after training on CELEB A? The plots on spiral might make this point, but it is not clear. While I recognize that evaluating generative models is hard, the observations do not clearly support the author s hypothesis that the EP component provides an advantage. # Recommendation I recommend a rejection of the paper. The hypotheses (that richer priors and geodesic interpolation generate better images on realistic images) are not clearly supported by the experimental results provided.
Reject. rating score: 3. rating score: 4. rating score: 5. rating score: 5. <BRK>The paper aims to improve compositional generalization of grounded language learning methods. 2.The entropy regularization is also explained poorly. I do not think the paper clearly explains what these “nodes” are, and how this is related to the possibility that “a representation can be fed to multiple networks”. This distinction alone in principle might explain the difference in the results. Unfortunately, this concludes my review: I was not able to understand enough in order to make more substantial comments.<BRK>It proposes to use interactions between agent and the environment to define output components, and entropy regularization to reduce redundant dependency on input. It shows significant improvements in most of gSCAN tasks. The paper also has an ablation study that investigates the effectiveness of entropy regularization and other factors. This paper proposes entropy regularization and shows some good results compared with Seq2seq and GECA are from Ruis et al.(2020).Semantic is from Kuo et al.(2020).WeaknessesThe paper is very hard to read. If not, the paper should clearly cite relevant papers. The paper claims to be "the first work to enable accurate compositional generalization in grounded instruction learning problem, serving for analyzing and understanding the mechanism". It is not clear this is true given Ruis et al.(2020).Semantic is from Kuo et al.(2020).The paper fails to make a connection to the two papers. I would be open to revise my decision if the authors make clear of their methods and contributions.<BRK>The paper proposes a new regularization method that constrains the mapping between the inputs and output spaces for achieving compositional generalization in simple grounded environments like gSCAN. The problem is interesting and important and the paper is corroborated by good experiments with 25% accuracy increase and also generalization to longer commands. Some Typos  What are the components in output  > in the output  other changes with ablation study  > with an ablation study  to understand command and the environment  > the command and  redundant dependency on input  > on the input  Grounded SCAN (gSCAN) dataset  > the Grounded SCAN dataset  but agent needs  > but the agent need or but agents need   of agent and the environment  > of the agent  to change position  > to change its position  on addressing grounded compositional generalization problem  > addressing the problem  Input contains command  > the input   Output contains  > the output  Information of color  > of the color  design entropy regularization layer  > a/the layer  finds correct object  > find the correct object In addition, the idea presented feels somewhat too specific to the particular gSCAN task. For the entropy regularization idea, while it may allow for compositional generalization, it may reduce the model ability to capture trends in the training data, and so it may produce too "extreme" representations that can’t account for correlations within the data, and therefore I suspect it may not work well for more complex problems beyond gSCAN. It will be good to move the general text from the related work section to the introduction section and instead add a bit more detailed description about prior approaches for the problem and how they differ from the new method. The description of the task is not clear enough. However, this causes errors for compositional generalization in test. A model that will learns that there is no correlation at all between pairs of properties will not work in the real world. The description of entropy regularization isn’t completely cleared to me.<BRK>The paper proposes to use "entropy regularization" as a way to enforce that spurious correlations between input tokens and output actions are not learned. The paper achieves impressive performance on the gSCAN dataset across all but one task, and describes intuitions on why the remaining task failed. ########Suggestions to clarify the presentation of the paper and the approach:1. The related work should contrast the proposed approach or evaluation setup with the cited works. My main concern about the paper is its framing of the problem and use of vague terms, especially in the introduction and abstract. E.g., how does the proposed approach differ from the approaches used on SCAN? However, there are other dimensions of compositional generalization which the paper does not cover. EntReg here just seems to add some noise to an input x, which is not necessarily a distribution. This paper should clarify the dimensions along which it is evaluating compositional generalization, and contrast that with other forms of compositional generalization. Later on, I am also confused on what "a change of direction between steps" means, and why there is a direction, action, and manner. While it performs well on this benchmark, evaluation on other grounded instruction following tasks, such as some of the examples above, or even on non instruction tasks such as image question answering, would make the results more convincing. ########Major questions for the authors about the paper setup :1. 1.The evaluation is only performed on a single synthetic dataset. Its description could be more concise (e.g., by removing Algorithm 1). What is the intuition of the EntReg component actually solving the problem of learning spurious correlations?
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. rating score: 4. <BRK>The DECSTR system s intrinsic motivations may be applicable to other application domains, depending on how objects and relations are enumerated. This potential is not explored beyond the toy environment presented. The learning methods (especially inductive biases) are hand crafted based on human level knowledge about semantic predicates, but only two ("above" and "close") are demonstrated. Would similar careful design of inductive biases be necessary and possible for n ary predicates that do not demonstrate these as easily (e.g., "topmost")? Areas for Improvement:5 "a learning architecture that discovers and masters all reachable configurations from a set of relational primitives" this is literally true but only demonstrated on  a  single set of relational primitives, so it feels like overclaiming. "Caregiver" in section 5 is an unintroduced role. Ending the paper with "etc."<BRK>This work proposed DECSTR, a procedure for encouraging intrinsic motivation via an intermediate semantic state space representation. This is particularly problematic since this baseline is a key motivator for the existence of the proposed semantic goal representation. However, the approach presented in the behavior (in particular the form of the semantic representation that is claimed as one of the primary contributions of the work) is very specific to the single problem used for demonstrations in the paper, limiting the potential impact of the work. First and I think the most significant issue with the submission is that many critical experimental details are included only in the lengthy appendix. Here are what I think the main contributions of the work could be:1. In addition, it seems that many if not all of the tools used in the learning process are not novel. 3.*State of the art performance on language driven block manipulation tasks. The paper currently seems to claim that the combination of progress in these three areas is a novel contribution; I am sympathetic to this idea (as I do not believe that every paper needs to be "state of the art" in one single thing), though it is sufficiently unclear at the moment what the takeaway message of the paper is that I cannot recommend it be published in its current state. In particular, the authors need to work on honing the message of the paper. It is also not unlikely that one or two more experiments will need to be added to support the focused narrative. The paper/Introduction would benefit from a summary of contributions: even after reading, it may not be clear to a reader which contributions are from this paper versus other work.<BRK>I raised my evaluation to a weak acceptance for the paper. The architecture is based on Deep Sets (Zaher et al., 2017), which allows the pairs of the objects to be encoded with a shared network. Once trained to be able to behave with respect to these semantic relationship goals, the second phase is language grounding. **Pros**:  The paper is well motivated, citing literature from several fields. The sum is greater than its parts: many components in DECSTR are based on existing works (e.g.Deep Sets, C VAE, using LP for intrinsically motivated goals, etc. And being able to have the agent explicitly maps from the natural language text to the semantic goal space also helps us debug/understand what the agent is thinking at inference time**Cons**:  Part of the thesis is that decoupling of sensorimotor learning from language acquisition is advantageous to an end to end language to sensorimotor learning. This would provide a ‘coupled’ version that is different from any of the baselines studied in the paper because it still uses the semantic configuration as the intermediate goal representation while having joint training of the language representation and the sensorimotor. 3.Section 3.2: the main text and appendix C.2 was not very clear about the second inductive bias for the symmetry of the behavior required to achieve $above(o_i, o_j)$ and $above(o_j, o_i)$. **After rebuttal responses**: I have read the authors’ updated draft and response to my concerns, as well as the other reviews.<BRK>This paper introduces DECSTR, which is an agent having a high level representation of spatial relations between objects. DECSTR is a learning architecture that discovers and masters all reachable configurations from a set of relational spatial primitives. They demonstrated the characteristics in a proof of concept setup. The motivation and target of this paper are ambitious and important. The proposed method, i.e., DECSTR, is comprised of many components. Therefore, the main contribution is also not clear. In evaluation, Figure 1 shows ablation studies alone, i.e., comparison with the variants of DECSTR. Therefore, the contribution of the paper is hard to grasp. Currently, the paper somehow seems to be a demonstration of DECSTR. In this sense, if the authors state research questions, challenges, and contributions of this paper more clearly, that will make this paper more impactful.
Reject. rating score: 2. rating score: 3. rating score: 4. rating score: 5. <BRK>This paper proposes to mitigate double descent by artificially augmenting the dataset with concatenated inputs, and presents some empirical results for linear regression and neural networks. In fact, augmenting the dataset with duplicates or artificially constructed data is equivalent to incorporating certain prior structure or imposing some form of regularization, which in turn should have an impact on the double descent curve. On the theoretical side, the paper does not provide any rigorous theoretical analysis; on the methodological side, the data augmentation strategy is defined in a restrictive manner and seems to be of little practical value. In fact, the notion of sample size usually comes with the i.i.d.assumption, i.e., the samples are drawn independently from a common distribution. In this sense, augmenting the dataset with concatenated samples does not directly increase the sample size. 3) The paper aims to mitigate the double descent curve, which, however, is not necessarily harmful. If double descent helps to generalize well, why should we mitigate it?<BRK>It proposes the augmentation of the dataset via concatenating the covariate x and interpolating the label y, which increases the data size from n to n^2. The paper shows that the phenomenon of double descent can be mitigated via augmenting the input. The idea of investigating double descent from manipulating samples is novel and interesting. However, the paper is quite poorly written. The authors are suggested to provide a concrete introduction and experimental details for it. Furthermore, the paper does not provide enough reasoning how simply concatenating the x and averaging y can mitigate the double descent phenomenon.<BRK>**Summary**: In this article, the authors proposed a data augmentation procedure by concatenating the input data to produce an augmented dataset of size $O(n^2)$ from an original dataset of size $O(n)$, so as to mitigate the double descent curve. **Strong points**: The idea of (artificial) data augmentation looks interesting. Both the theoretical and empirical contributions of this work are somewhat limited. However, there is visually no theoretical contribution and the empirical contribution is also somewhat limited. In general, this paper does not meet the standards to be published at ICLR. Also, I am not sure that the theoretical understanding of the right plot of Figure 1 easily follows from existing results since, the concatenated data are no longer standard Gaussian, and I think they are even not linear transformation or simple Kronecker product of the original Gaussian data. * Figure 2 top right plot "the double descent curve is completely removed": it would of interest to check whether there is a double descent type peak around $O(n^2)$, to help better understand the proposed construction.<BRK>Summary:The paper empirically studies the Double Descent phenomenon by using a cool construction that squares the dataset size by concatenation of every pair of inputs and linear interpolation of the labels. The main empirical finding is that this construction mitigates double descent. Nevertheless, the empirical findings are not strong enough to warrant publication in my opinion. I believe that as the authors note, the concatenated inputs provide some sort of regularization (my intuition that something close to label smoothing/mixmatch is happening) and we already know that regularization mitigates double descent. Pros: The concatenated input construction is an interesting and original experiment and using it to mitigate double descent is somewhat surprising. Argument for my assessment: In my opinion the paper with a better story (and further experimental/theoretical evidence that support it) could be publishable but it falls short at its current state.
Reject. rating score: 3. rating score: 3. rating score: 4. rating score: 4. <BRK>3) It is not even clear whether it is meaningful to call the presented system as "multi agent", since in additionto a centralized shared reward, there is also a shared world model. 4) the authors are right to say that there is little research on model based MARL, and cite one exception:Krupnik et al.However, it is not justified why this closely related work is not included in the baselines,or at least compared in discussion more thoroughly. 2) The paper uses very loaded but undefined vocabulary like "imagination", "language" and "communication". While in general I think it can be sometimes useful to use concepts and terms from human cognitive sciencesto describe AI systems, in this particular case I found it very far fetched to speak of "imagination" and "language",even "communication".<BRK>The paper talks about developing a model based method for cooperative multi agent reinforcement learning. The authors present their motivation for using language as a medium in model based RL stemming from early literature in psychology and linguistics. Still, I have some qualms related to the experimental setup that arguably makes the contribution of the proposed imagination framework inconclusive. The choice of baselines doesn t seem to be appropriate for the task. I would like the authors to reference if the baselines were modified in a way to accommodate this. This is crucial since it will determine whether the performance gain is due to the abstract planning or the communication.<BRK>Summary: This paper proposes to combine model based and multi agent reinforcement learning. The authors follow the typical recurrent neural world models setting to generate imagined rollouts for decision time planning. + The ablation study on the roles of world models and communication channels is interesting. ########################################################################## cons:   Although the paper claims as a combination of model based and multi agent RL, my major concern is that the proposed model still deals with these two problems separately. I d like to see the performance of other baseline algorithms that use explicit communication channels, which is not compared and seems to work well as the paper reported.<BRK>Unfortunately, in its current state, this manuscript is not ready for to be shared with the wider community at ICLR. I will leave here a few suggestions for improvement and ideas on how to strengthen your argument. The manuscript is well written and easy to follow, and the authors properly place their contributions in the context of existing ideas. I understand the need of didactic environments, but in a purely methods paper, the reader is left to wonder if this method scales to more complex environments, if it can work with more than two agents, and if it can handle non cooperative settings. This is especially acute here, given that Fig.6 suggests MACI only helps in 1 out of 2 environments, as the performance gains in Invisible Spread are obviously attributable to partial observability in the baselines. The tasks presented are purely cooperative, and the communication system is differentiable. This is similar to what is presented in Fig.6 in the ablation study, but would add including a shared world model to produce an "ideal" agent. How does this perform? This performance ceiling would guide the reader in understanding how much of the gap is recovered by MACI.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. rating score: 5. <BRK>This paper presents an interesting technique to generate multimodal trajectory GAN and a carefully designed latent intent space. The paper is overall clear and well written. However, there is one point regarding the hallucinative learning probably can benefit from more elaboration: the time step "t" is only introduced in the Hallucinative Learning paragraph. How is the time step being used in the network? If I understand correctly, the main hallucination idea is to extract as many intentions in the latent space as possible, from the training data, and then the hallucination is implemented as randomly switching between different learned intents to generate augmented data? This point needs to be carefully clarified. Regarding the idea of using "hallucination" to generate more training data, many recent works have used the idea of hallucination for data augmentation, or even generating training data from scratch. For example, https://arxiv.org/pdf/2010.08098.pdf and https://arxiv.org/pdf/2007.14479.pdf generate training data using hallucination based on geometric feasibility, instead of latent intent, https://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_Few Shot_Learning_via_Saliency Guided_Hallucination_of_Samples_CVPR_2019_paper.pdf uses saliency to guide the generation of hallucination, https://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Adversarial_Feature_Hallucination_Networks_for_Few Shot_Learning_CVPR_2020_paper.pdf also used a very similar adversarial approach to generate feature hallucination.<BRK>Summary:The paper designed a framework for motion forecasting (trajectory prediction), with emphasis on multimodal distribution modeling and generalization. Specifically, they use latent code to model agent s intents. This latent code combined with historical trajectories and map were used to generate future trajectories, which were further judged by a discriminator. Besides, they added latent code classification and hallucinative data augmentation for performance boosting. The interplay of latent code classification and hallucinative is interesting. 2.The proposed method seems to be interesting, especially the adding of latent code z to generate trajectories and then classify them. Cons:1.The proposed methods seems to be combination of existing components, which limits its theoretical contributions. 2.The underlying reasons for the success of different components (classification of latent intent and hallucinative latent intent) are hard to explain. It would be interesting to see how this method compare with "Mercat, Jean, et al."Multi head attention for multi modal joint vehicle motion forecasting." IEEE, 2020." I notice the authors discussed about this, but I think this interplay needs more discussion. 5.For equation (2), it is better to display it as multi lines for easy understanding.<BRK>Its main contribution is incorporating generative augmentation losses for improving the quality of a trajectory predictor. This is achieved by allowing trajetcory predictors to model intent as an unobserved latent variable in the model and using this to generate trajectories corresponding to different intentions. The work also proposes to use a descriminative loss encouraging diversity of the intents and an additional "hallucination" loss that allows for modelling mixed intents. In summary, I believe that the paper has now surpassed the acceptance threshold and am happy to recommend its publication. Some other points remain still open such as the limited focus on Trajectron in evaluations. In human experiments, it is also shown that the trajectories predicted by the new approach are considered more realistic by humans in comparison to the baseline. Human studies seem to be a very interesting idea for studying trajectory prediction. Maybe simply write "discrete latent variable"? It is not possible to judge the usefulness of the code without it being available during the review process. Because the proposed method s performance is still somewhat close to Trajectron++ s, it would be interesting to see several runs of the same experiments also reporting the standard deviation of the obtained metrics. At least for the comparison with Trajectron++. **SUMMARY**In summary, I think the authors propose an interesting idea and I believe using humans to judge the quality of trajectories is a cool evaluation methodology. And, in the comparison with this baseline, it is not clear to what extent the work will constantly outperform it.<BRK>The paper is very hard to read. For example, the contributions are confusing and not clearly defined. In the first paragraph of the Introduction, a data augmentation scheme is presented. But then on Pg.2, the authors present two notions of intents as their contributions. From my understanding, the authors use $\hat z \sim P(z)$ to generate new data  (I m looking at  Eqn 4). And this eqn 4 is termed as the "classified intent". There are several things to unpack here: First, these contributions are not well defined. What is a "classified intent" and "hallucinative intent". These are not standard terms in the trajectory prediction literature. So these terms need to be defined and explained. I would like to see a mathematical definition and references to relevant citations in the traffic psychology literature. Because eqns 4/5 are not derived with supporting derivations and justifications, the main concern here is that I don t find the motivation or relevance of these equations convincing. Instead, use that space to include the motivations, definitions, justifications, and derivations for eqns 4/5 as explained above. 2.The questionable nature of the proposed equations (4, 5) directly relates to my next point, that is, the lack of any useful improvement over SOTA. For fair evaluation, it is necessary to also present comparisons using ADE. In summary, the paper suffers from lack of a clear justification of the proposed contributions, unfair evaluations, and questionable significance of the results
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 5. <BRK>### Pro’s / Con’s / JustificationOverall the paper is well written and easy to follow. Note that I don’t consider the “objectness scores” to modulate the NS CL reasoning process very novel, since it is essentially a straight forward heuristic to cope with a limitation of MONet/Slot Attention in that sometimes the object centric representations may containing background information or are “empty”. * I noticed in Appendix B that on PartNet Chairs the second training phase (where only the reasoning part is trained) is skipped. What is the reason for this? What happens if this is also done for the Shop VRB Simple dataset? However, since this task is learned in a supervised fashion and the dataset contains questions of the form “what is the name of the white object?” (parsed by a pre trained semantic parser using a custom DSL), this provides a substantial degree of supervision to the representation learning part. I appreciate the extensive revision and response of the authors. This would almost certainly make the contribution more significant. * The main finding, which is that providing some degree of supervision to purely unsupervised object centric representation learners improves their performance, is not very surprising. ### Detailed comments* Regarding the objectness score an ablation is missing. It can be seen how when training on the visual reasoning task using only 25% of the provided data (i.e.22.5K as opposed to 90K) actually reduces segmentation performance, i.e.from 83.51 (image only) to 81.01. This is surprising, and perhaps somewhat concerning, since I would have expected any reasonable amount of supervision to be helpful and certainly not degrade performance. For these reasons I remain in favor of a rejection.<BRK>This paper proposed an interesting idea that uses language to learn the concept and aid downstream tasks such as segmentation and referential expression interpretation. The authors combine the unsupervised segmentation method (MONet and Slot Attention) with neural symbolic concept learning (NS CL). By joint training these two objectives, the authors show improvements in the object segmentation and several downstream tasks. 1) What is the language objective for the PartNet Chairs dataset? The dataset contains templated captions instead of questions, but the paper didn t mention any of the associate target or loss. I can not find that information even in the supplementary materials. 5) If the pretrained semantic parser can provide very high accuracies, for a fair comparison, it will be good the authors can show the performance of MONet and Slot Attention with additional supervision. The authors should discuss the difference between this work.<BRK>3.A pre trained semantic parser: a pre trained module to parse the input (for ex.a question) into semantically meaningful program which can be easily executed. The paper mentions that this is a "principled" framework for object centric learning. The authors evaluate how inclusion of the language can improve the performance of MONET and SLOT attention. Experiments: The authors evaluate the proposed work on two visual reasoning datasets for image segmentation evaluation: Shop VRB Simple, and PartNet, as well as a subset of PartNet called PartNet Chairs. 2.It s interesting to note that the gain in performance for Slot attention is more as compared to MONET. Since the contribution of the paper is to actually evaluate different methods for object centric learning (MONET/SLOT Attention) and combining with the framework of neuro symbolic learning. After Rebuttal: I have read the rebuttal, as well as reviews by other reviewers. I very much agree with the authors that the problem is very interesting, but as of now more work needs to be done in terms of "downstream applications".<BRK>Here we have synthetic images with no background (relatively easy to segment) and synthetic (templated) language (easy to parse). The authors have collected language descriptions for the PartNet Chairs dataset. Adding LORL on top of Slot Attention leads to notable improvement in object segmentation performance on two datasets. It does lose to NS CL slightly, which has access to pre trained object detectors. Specifically, they could have used CLEVR for MONet, as MONet is not applicable to the ShopVRB Simple data. It is in unclear what the language task on the PartNet Chairs actually is, it is only stated that the authors collected descriptive sentences. Some of the remaining issues:The positive impact of the objectness score on performance was not demonstrated. The training objective for PartNet Chairs should be discussed in the main paper, not in the appendix. I hope to see an improved version of the paper (with more exciting technical contributions) in a future venue!
Reject. rating score: 4. rating score: 4. rating score: 4. rating score: 5. <BRK>However, the paper does not provide any comparisons to the state of the art concerning computational gains. The idea of jointly optimizing the sensing and the decoder is interesting, although not really that novel. This is a well studied area that the paper fails to discuss.<BRK>However, the novelty of the proposed method is very limited. Finally, since the selective sensing pattern is learned from data, it s more fair to compare it with the learned compressed sensing counterpart, as exploited in the journal version of the ReconNet [3] used in this paper.<BRK>Overall, this is an interesting approach that I think deserves to be eventually published. However, the paper needs significant work and comparison with the state of the art in the literature.<BRK>* The function o(.) Thus, considerations of the "sensing complexity" are moot in those cases, and the approach provided in this paper is only relevant in cases where custom sampling schemes can be designed (e.g., when the referred imaging sensors are used).
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 5. <BRK>Are the conclusions of the analysis the same for other popular optimizers like Adam. The idea is interesting but the empirical validation of the idea should be improved and some claims should be proved. Overall, the structure of the paper should be improved. They should motivate this decision more because these models are not so popular. It is well known that the SGD is sensible to its hyper parameter and in particular the learning rate.<BRK>Without convincing theoretical support, such a claim can only be established through extensive and rigorous experimentation, and I find the experiment description in this paper is short on delivering strong evidence. Is the performance sensitive to the distribution? The authors provide some motivations based on the error similarity plots, but no theoretical backing. What are confidence intervals on the results?<BRK>Lastly, the performance gains in Table 3 seem limited, given that only one run was performed for each dataset. The writing is satisfactory and the paper develops the ideas sufficiently well to help any reader who is a beginner in this area.<BRK>The proposed model is further extended and analyzed for the fixed cosine similarity maximization setting. Pros:The motivation of this paper is comprehensive. There are some experiments should be done: 1) Compare this method with relevant methods such as NormFace and ArcFace to proof the effectiveness of this approach. 2) Compared with exact performance in face relevant datasets and compared with other SOTA methods.
Reject. rating score: 4. rating score: 4. rating score: 4. rating score: 5. <BRK>Given an input X, the proposed method decomposes X as X   BZ + E where BZ is a low rank approximation of X and E is the residual term. Experiments using MNIST and CIFAR10 show that the proposed method accelerates the speed to reduce the training loss. The analysis in Section 2 is based on a shallow network model. Also, I feel the experiments are not convincing enough. The main motivation of this paper is that "the ultrahigh dimensional features can be decomposed into two parts". However, the dimensions of MNIST and CIFAR10 are not quite ultrahigh (28^2 784 and 32^2 1024). Experiments with more high dimensional data such as ImageNet would be necessary to convince the research concept.<BRK>The paper describes a training scheme based on decomposing input features into two parts which have different training dynamics: a low rank "factor feature" computed using PCA on the raw features, and a high rank "residual". Experiments show that the proposed algorithm can speed up wall time to  a certain accuracy on MNIST and CIFAR10 classification, across several neural network architectures and optimizers. Pros:  Simple and straightforward proposal, easy to understand, and seems to lead to improved accuracy/reduced loss early in training. Experiments cover several datasets and architectures spanning very simple to very deep, which is nice to see. It s not clear why these results would necessarily generalize to very deep and highly nonlinear networks such as AlexNet. Perhaps this is the motivation for only processing "factor features" with an extremely shallow (albeit still nonlinear) network? The experiments are not very convincing. This issue is illustrated in the training curves in Fig 3 (MLP on MNIST), where the validation accuracy for the proposed SGD+FN appears to be plateauing faster than the baseline SGD curves. At least for MNIST I d expect decent performance to be obtainable from the factor features alone. Overall I feel that the paper is not ready for publication at this time since the experimental validation is incomplete and does not fully explore the benefits and potential downsides of the proposed method.<BRK>**Strong points**The paper provides a very detailed theoretical analysis of motivation. **Weak points**Analysis in section 2 is based on linear regression, but the proposed method is based on deep models. The proposed method is more similar to feature extraction instead of a training method. Many models in the chart are not fully converged. It is important to compare convergence speed but also the final accuracy. I think they are not converged, because the training and testing curve is perfectly smoothing without any fluctuations. Comparison in chart 3 needs improvement. Only comparing them with the same learning rate may not adequate to prove the significance of the proposed method.<BRK>The paper makes an observation that datasets used for training many deep neural nets exhibit a strong factor structure, i.e.have a small number of dominant principal components explaining most of the variance. 5) Is the "time consumption"  including the time to do PCA? The paper proposes to separate the dominant factors and the residuals,  train the original DNN on residuals with a much faster SGD learning rate,  and then recombine with a shallow small NN learned on the dominant factors trained using its own (slower) learning rate. Another criticism   is that there is no discussion of how to do large scale PCA / factor analysis for high dimensional image data arising in say modern DNN image classification pipelines, and its computational cost,  as simple numpy.linalg.svd won t work. Overall in my opinion the paper needs to consider the context of related works, and has a few other correctable issues, but I would certainly encourage the authors to continue to improve it. Additional details: 1)  Prior work   that should be cited / contrasted with your approach:   (a) Since a substantial part of the paper analyzes linear models,  it s important to mention that factor structure has been long exploited in various ML / stats works. Recent work by Alex Smola et al,  "Deep factors for forecasting" has looked at the deep NN instantiation of this idea. In particular there are some low rank preconditioners for accelerating convergence of linear systems:  Nicholas Higham, et. 4) Sec.3.1.How do you conduct  standard principal component analysis  for ultrahigh dimensional features.
Reject. rating score: 4. rating score: 5. rating score: 7. rating score: 8. <BRK>Also, this paper proposes a new augmentation called DeepAugment. **Pros**\+ A new benchmark could be useful for many researchers in this field. First of all, what does "robustness" mean in this paper? However, I cannot find any detail in this paper. "Benchmarking neural network robustness to common corruptions and perturbations." Furthermore, this paper aims to solve the robustness problem (where the ``robustness  is not defined in this paper). I wonder how the ImageNet R benchmark can evaluate the robustness of the trained models. Also, I wonder how the "renditions" are chosen. **[DeepAugment details are missed in the main paper]**In my opinion, this paper has two contributions (1) a new benchmark, and (2) a new augmentation method to solve (1). However, the augmentation method (DeepAugment) details are not able to understand without reading the appendix. Why do we need to apply layer wise distortions instead of input level distortions? Are the distortions independently chosen from the benchmark distortions? I still have many questions. If the authors directly tune their method on the ImageNet R, it is not fair and not convincing benchmark to evaluate the robustness. However, here OOD (distribution shift) is ill defined, and the robustness test is heavily dependent on the test dataset. Hence, I think this paper needs more justification for the new dataset (e.g., why the chosen shifts?why 200 classes for ImageNet R? why different three datasets? This paper is not clearly presented. After reading the paper, I am still confusing about how to understand the experimental results. I think R2 has a similar opinion on me in this criterion. It is not mentioned in my previous reviews, so I lower the weights for this part to the final decision, but there are already some datasets benchmarking the dataset distribution shifts, e.g., PACS [9], NICO [10]. It may not be true that this kind of distribution shift is only measurable by the proposed datasets. But, as my first words, I noticed that I did not mention these datasets in my previous reviews, and these datasets will not affect my review a lot. However, I will respect all decisions made by AC.<BRK>This paper provides a empirical study on the robustness of image classification models to distributions shifts. The authors construct three benchmark datasets that control for effects like artistic renditions of common classes, view point changes, and geographic shifts (among others). The authors additionally propose a novel augmentation scheme, that uses deep image processing networks together with random perturbations of their weights to synthesize distorted image samples. Summary  I think this work is interesting and is in principle asking the right questions. However, the analysis and conclusions currently do not providing robust and generalizable insights that advance the field. Weaknesses  The conclusions that result from the empirical findings are unfortunately not very crisp. Some hypotheses are supported by some datasets, others are not. is still very much "it depends on what you are testing on". Table 4 provides a simplified summary of various hypotheses and how they are supported by different datasets. The core issue seems to lie in the construction of the datasets:1) We know that deep networks have a texture bias, so there is no reasonable expectation for transfer to ImageNet R. There wouldn t be any expectations to improve this performance for any change, but enlargement of the dataset towards more abstract depictions of the objects. I acknowledge that collecting a new dataset is a non trivial effort and can be useful. I acknowledge that the paper proposes an additional augmentation technique that seems to improve results in certain cases. If not: collect more data.<BRK>This paper contributes three new datasets to evaluating seven robustness hypotheses. Strengths:1.The introduced three databases would be valuable to probe the generalization of classifiers in the real world. 2.The deep augmentation method seems neat. It is a unified method to produce a variety of perturbations (despite in a less controllable way). And the performance gap on the proposed databases is noticeably reduced by DeepAugment. The authors may clearly state how they collect human labels for these datasets. In practice, collecting 1 out of 200 possible labels in ImageNet R is not trivial. What is the intended solution for solving the StreetView StoreFronts dataset? Is it the structure of the store or just text in the image? 2.As shown in Fig.3, DeepAugment seems to distort the input images. Is there a way to systematically control the distortion levels? [R1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively, https://openreview.net/forum?id rJehNT4YPr<BRK>To study the model robustness in a controlled setting, the author introduces three new robustness benchmarks: ImageNet R, StreetView StoreFronts and DeepFashion Remixed. The author evaluates seven popular hypotheses on model robustness in the community on the three new datasets and has found counter example for most of them. And future work should be tested on multiple datasets to prove robustness. Moreover, the author also proposes a new data augmentation method using perturbed image to image deep learning model to generate visually diverse augmentations. Significance: This paper is a solid work on the robustness problem. The analysis is insightful and supported by the experimental results. The authors also provides three new carefully designed datasets for future work evaluation. While the study of using deep neural network to generate training image is not new, DeepAugmentation is still an innovative and practical way for data augmentation purpose. Question: On DeepFashion Remixed datasets, it seems large zoom has better result than medium zoom. Is there a good explanation for that, considering the original image has no zoom in? Clarity: The author did a great job on explaining the idea, objective and approach.
Reject. rating score: 5. rating score: 6. rating score: 7. <BRK>This paper proves that $\Theta(N^{2/3})$ parameters are sufficient for memorizing arbitrary N input label pairs under the mild $\Delta$ separation condition. Overall, it is an interesting theoretical paper and obtains an improved rate over previous works. There are some concerns given as follows:1. The $\Delta$ separated set seems to be an important condition. The paper claims that $\log \Delta$ is not a big number. I am wondering, when the data points are iid from some distribution such as a multivariate normal distribution, what is $\Delta$ in terms of sample size? In this case, $\Delta$ will depends on both the sample size and the input dimension. 2.The theoretical developments in this paper are for fully connected feedforward networks. There seems to have a gap. 3.The paper considers the network where the output dimension is 1. It is not clear to me in the Definition 3, how to use a network with 1 d output to memorize data with C classes. 4.What is the connection among memorization, training/testing accuracy, and generalization? In the experiment part, the authors sometimes try to show there are some connection but sometimes try to show there are no relationship. Are there any new techniques beyond those from previous papers?<BRK>Summary:  This paper makes the following four contributions. Firstly, it is shown (Theorem 1) that \Theta(N^{2/3}) parameters are sufficient for neural networks  with sigmoidal activation functions   to memorize N input label pairs, under an admittedly mild “\Delta separated” assumption on the input points (Definition 1). This is an improvement over existing results which show that \Theta(N) parameters suffice, albeit typically for arbitrary N input label pairs. As discussed in the paper, this result implies that depth is crucial for memorization with sub linear parameters. Of course, the setup in the present paper considers the sigmoidal activation to be fixed (e.g., ReLU) and this is a non trivial difference. This implies that the network width does not necessarily have to increase with N for memorization with sub linear number of parameters. Thirdly, the authors study the question of identifying the maximum number of input label pairs a given network can memorize and provide general criteria (Theorem 3) for the same. But still, it is not clear just how big of a difference this is. The result in this paper shows that memorization of \Delta separated points can be done with the number of pairs super linear in the number of parameters. Therefore the set of N points in $\mathbb{R}^{d_X}$ can be first mapped to distinct points on a line, and then be  shattered/memorized by the aforementioned one neuron neural network. The problem has been motivated nicely in the introduction. Cons: No proof sketch is provided within the main text for any of the theorems. Studying finite sample expressivity of a network in an infinite precision setting also seems a bit strange (See "post discussion" below). This implication was not clear to me, some additional explanation will be helpful. 6 which discusses transforming the d_x dimensional inputs to “distinct” scalar values. Post discussion: Following the discussion phase, the significance of these results seems to be a bit unclear to me.<BRK>  Summary  The paper studies the memorization capacity of deep networks as a function of the number of parameters. Many prior works have shown that to memorize $N$ examples $O(N)$ parameters are sufficient and that to memorize any set of $N$ examples $\Omega(N)$ parameters are necessary. This work shows that under very mild and commonly satisfied conditions, $O(N^{\frac{2}{3}})$ parameters and layers are sufficient for memorizing $N$ examples, a significant improvement over prior results. Main weaknesses:* The proof method is not discussed in the main body. I recommend acceptance in light of the drastic reduction in the bound and its implications, as well as the novel perspective on the role of depth. I will be more than happy to raise my score once the authors update the paper with a clearer proof sketch and discussion of key proof methods in the body of the paper. Update following rebuttal and discussion  The AC has raised an important point that the paper does not discuss its reliance on infinite precision. While using infinite precision is not necessarily wrong, it does make the paper s result less relevant in practice, narrowing its contributions to being mostly about theoretical aspects. More importantly, by hiding this technical detail deep within the proofs, the authors missed the opportunity to discuss the difference between the number of bits used by the parameters and the number of edges (operations) necessary for memorization. It seems to me that the number of bits is linear with the number of examples, even as you can reduce the number of edges, which does have practical implications about the utilization of the memory bought by depth. Moreover, if the authors had discussed this topic, it would ve been accepted more easily.
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 6. <BRK>Summary: The purpose of this paper is to analyze the reasons why complex/hyper complex neural networks yield performance improvements (especially pertaining to generalization). Inspired by this, the authors also propose the idea of vector map convolutions which captures the aforementioned properties but at the same time, are not subjected to the dimensionality constraints. I have to first acknowledge that I have not very familiar with much of the background literature on complex and quarternion networks. Detailed Comments/Questions:  I would prefer a clearer and more comprehensive way of introducing the background work and how it leads to the intuition of vector map convolutions. Post rebuttal:I would like to thank the authors for their rebuttal and addressing some of my concerns. However, after reading the updated manuscript as well as the other reviews, I decide to maintain my current ranting.<BRK>The authors derive the functional formula for the vector map by generalizing the quaternion algebra proposed in a previous paper in the literature. For the satellite data case, the authors show that their proposal achieves a slightly lower Jaccard Score with fewer parameters, but it’s not clear at all what is the Jaccard Score or what its scale is. In the case of CIFAR 10 and CIFAR 100 the architecture does seem to give some improvements in parameter efficiency. If this issue is addressed, the recommendation can be reviewed. While the networks are shown to be more parameter efficient, what about the FLOPS of the resulting networks?<BRK>The idea is worth of interest but the results obtained during the experiments (from other previously already published papers) are not convincing and more efforts have to be provided in the theoretical side. If this is mainly the fact of the Hamilton product, the authors have to give some words on the quaternion space obtained from the real valued feature map.<BRK>The paper also conducts an experiment on recoloration. I am concerned that the paper does not discuss the properties of the operation. Such numbers do not form an algebra and they are not commutative. Therefore I encourage to extend this section to give more details on this experiment. While I do not believe that this work is a clear cut solution for such applications, it is a step in the right direction. Therefore, I increase the score by one point, as this work is just very slightly above the acceptance threshold right now.
Reject. rating score: 3. rating score: 4. rating score: 4. rating score: 5. <BRK>This paper studies a straightforward generalization of v optimality from linear regression to (kernel) ridge regression. A simple experiment is conducted comparing the proposed method with random sampling on MNIST. I vote for rejection. This is a simple derivation of the v optimality of ridge regression (or Bayesian linear regression). The novelty is somewhat limited. The title “single shot active learning” seems a little inappropriate.<BRK>This authors analyzed the V optimality criterion of the experimental design for the ridge regression setting, proposed a greedy algorithm to optimize the criterion, and connected with the infinite neural tangent kernel. Also the evaluation task looks overly simple and uses a trivial baseline; I would expect at least a comparison with another active learning algorithm, for example, using the coreset approach. I don t recommend the paper to be accepted in its current form for the following reasons:1. The paper s relevance of deep active learning is unconvincing to me; probably the results are more suitable for a different conference.<BRK>The results are also unconvincing, and the one figure in the main body (Fig 2) only shows comparison with a weak (random selection) baseline. Some other concerns include:1. 2.Unconvincing contributions description, “sometimes able to mitigate the double descent phenomena”, “sometimes able to find better design than random selection”. Overall, even though active learning is a highly relevant problem domain, in my opinion, the paper falls short in establishing itself as a strong competitor in the domain for reasons described previously. I would encourage the authors to resubmit with stronger justifications of the contribution and more convincing results.<BRK>The paper focuses on an important problem of active learning, and is written clearly. Although the authors claimed that the proposed method can mitigate the double descent phenomena, this claim is not so particularly attractive currently because the classical OED also mitigates it in the illustration of Figure 1. This would be important past analysis closely related to the proposed method, and should have been mentioned. However, no practical discussion on how to set t is provided. Comparison with other state of the art AL or classical OED would be indispensable.
Accept (Spotlight). rating score: 9. rating score: 7. rating score: 7. rating score: 6. <BRK>PlasticineLabThe paper presents a new soft body manipulation benchmark for RL and differentiable planning. The presented simulation suite is very interesting and the contribution is solid. Strength:  new simulation benchmark with features that are not yet well explored  differentiable physics to open up possibilities for planning methods  tasks are difficult enough to be challenging for a while  baseline results are providedWeaknesses:  only the computation times would be good to addPresentation:The paper is clearly written and easy to follow.<BRK>####  SummaryIn this work, the authors present PlasticineLab, a new framework for soft body manipulation tasks for Reinforcement Learning and planning algorithms. The PlasticineLab framework proposes 10 novel tasks involving manipulation of the soft plasticine material. Thus effectively showcasing the complexity of the proposed tasks and the inability of state of the art RL models to model the proposed tasks. 3.Another major effort prelavent in the paper is that the authors have chosen to use a differentiable physics engine using the DiffTaichi system thereby making the gradients available for planning and control algorithms. 5.An important facet of a benchmark is to propose tasks that are sufficiently complex for the current state of the art procedures. Sim to real reinforcement learning for deformable object manipulation.<BRK>The paper introduces a new open source simulation benchmark for soft robotics. The simulation environment builds on top of DiffTaichi, an existing differentiable simulator which enables end to end differentiability. The paper proposes 10 different tasks, each with 5 variations and evaluates both RL based policy learning methods and gradient based optimization methods on those tasks. Overall the paper is well written and the contribution is well argued.<BRK>This paper presents PlasticineLab, a differentiable physics environment geared towards softbody manipulation. ## Strengths**S1** The central problem tackled here is quite interesting (and challenging)! **S2** The paper is extremely well written and easy to follow. While this builds heavily on DiffTaichi and ChainQueen, it is commendable that this paper came across as self contained. An interesting point made here was that TDW and SAPIEN do not provide assets for soft body simulation. were this to be relaxed?
Reject. rating score: 4. rating score: 5. rating score: 5. <BRK>The considered task is reaching with a robotic planar arm; the considered context is varied varying the robot degrees of freedom. The goal of the paper is to find correlations across neural activity patterns across networks trained to solve the same task in different contexts. To achieve their goals, authors propose an heuristic network pruning algorithm to reduce the network size while keeping performance in training and evaluation. To correlate different networks, authors propose a technique to project a source network onto a target network. #### ClarityThe paper is well written and easy to read. #### Significance The significance of this work is relatively low. The results could be more conclusive with further analysis and experiments. * **Results and conclusions**.<BRK>Finally, neuron activations are used to assess the correlations between learned policy networks for manipulators with a varying number of degrees of freedom. A projection mapping between different policy networks is implemented and analysed, as a type of transfer learning between different robot morphologies. There are some important flaws that need to be addressed regarding the clarity of the methodology and contributions, as well as the significance of the experimental evaluations. My impression is that although the work tackles an important problem with a good idea, this is still an incomplete work, as the presented experimental evaluation is insufficient to draw significant conclusions. There seems to be a missing link between the neuron activation estimations for pruning and correlation analysis for transfer mapping. Because currently, it is difficult to see any significant differences between the plots. This would also strengthen the paper significantly. Another metric which would be necessary to evaluate the transfer procedure, is to evaluate the mapped network on a test set of the reaching task. "Weight agnostic neural networks." Could you maybe elaborate on these more? “We define a distance metric between neurons that is based on the neuron activation history in scope of every episode in order to account for the dynamics in motion trajectory learning.” It is a bit unclear how the activation history is evaluated.<BRK>#### SummaryThe authors present a method for analysing neuron activity in neural networks trained via RL on a multi joint planar reaching task, as well as correlating neurons between different models trained on tasks with potentially a different number of joints. #### Pros  The authors perform a sufficiently thorough evaluation, with a large number of models compared and reasonable ablations, baselines and metrics. The proposed heuristic pruning approach seems to perform well in this case, as evident by all model sizes converging to the same size in Fig.3.The approach of first pruning networks to maximise information content in the activations before correlating different models makes a lot of sense. The scope of a planar reacher may also be too limited to draw more general conclusions for other control tasks. Effectively only the target model is evaluated within distribution, after which the inputs observed there are then remapped to the source model.
Reject. rating score: 3. rating score: 3. rating score: 4. rating score: 4. <BRK>The paper succeeds in developing diversity metrics that correlate better with ensemble accuracy than the original diversity metrics. Additionally, the appendix has the algorithms and other substantive content that is central to the paper, which is not supposed to be the case. Here are additional comments. 1.Bagging does not necessarily (or typically) aim to train weak models to form a strong ensemble.<BRK>The idea of focal model (which seems to be crucial) is never explained. Furthermore, it s unclear why this paper focuses on deep learning models. What is about these measures that make them correlate with accuracy? Figure 1: I don t think (c) is showing much of "a sharper trend in terms of the relationship between ensemble diversity and ensemble accuracy" as claimed by the authors. What are the negative samples? The explanations in this paragraph are not useful. It s comparable to standard diversity measures on CIFAR 10, and worse than standard diversity measures on Cora.<BRK>Summary:The manuscript studies the problem of ensemble selection (pruning) with the ensemble consists of deep neural network models. The authors compare different diversity metrics, which they named collectively as Q metric, visualize the accuracies of different ensembles on CIFAR 10 dataset where the ensembles are stratified by their sizes. ”              Can authors verify this? Finally, the authors did not show that the ensembles selected by their approach do, on average, have higher negative correlation among the ensemble members b)	On page 5 “we argue that comparing ensembles of the same team size in terms of their diversity scores can better capture the intrinsic relationship between ensemble diversity and ensemble accuracy”Can authors give a more formal definition to “the intrinsic relationship between ensemble diversity and ensemble accuracy” and at same time give some explanation as to why comparing the diversity scores of the ensembles of the same size can better capture such relationship?<BRK>The paper is well written, and extensive experimental results are presented. Also, the contributions made by the paper do not seem significant. HQ diversity metrics proposed in this study, as the authors also mention it, are an extension of the Q diversity metrics (first paragraph of section 2.1). In the proposed extension, HQ diversity metrics are a normalized (scaled) version of the Q diversity metrics in which the model accuracy rank is also considered. Also, I am wondering how costly would be validating the accuracy of the models.
Accept (Spotlight). rating score: 9. rating score: 9. rating score: 6. rating score: 6. <BRK>Future research for improving and testing the algorithm is clearly detailed.<BRK>I think they should denote the union of all the spaces that variables are living in, but instead they are defined as finite sets of specific variables.<BRK>**Post rebuttal comments.<BRK>Are all x, y, z the positions?
Reject. rating score: 5. rating score: 6. rating score: 7. <BRK>The paper propose a novel method to address the lack of diversity in mixed samples created by the saliency based Mixup strategies such as Puzzle Mix. The paper presents an interesting extension to the existing work. It would be very beneficial if the paper could show it somehow. 2.The way that the proposed method generates the mixed modeling target for the mixed input reminds me of this paper: nonlinear mixup: out of manifold data augmentation for text classification (AAAI2020). In the nonlinear Mixup method, the mixed label for a mixed input in Mixup is also computed based on the input pair, although the method is evaluated using text classification tasks. 3.Some parts in the proposed method deserve further discussion and justification. This suggests that it would useful to experiment on other network architectures such as ResNet 18 or ResNet 50, which are used in the original Mixup and the PuzzleMix papers. I think it would be useful to include some citations such as the manifold intrusion issue raised in the AdaMixup paper (AAAI2019) or the noise image issue as discussed in the PuzzleMix paper (ICML2020).<BRK>However, in doing so they replace the random nature of Cutmix with a deterministic approach potentially reducing sample diversity. The first contribution of the paper is a saliency guide stochastic augmentation method which combines the best of both worlds. The second contribution is in the generation of more meaningful labels for the newly created image by taking into account the saliency of the regions used from both images rather than blindly using the mixing ratio. The contributions of the paper are somewhat incremental but are reasonable. The validity of using saliency in determining the label of the new sample is clear. The experimental results are mixed. Most experiments demonstrate minor improvements over previous methods. On the other hand the top 5 performance of CutMix is better than the proposed method in Table 2. With such small differences and no standard deviations on accuracy reported it is not clear whether the improvements are really significant. In the data scarcity experiments, I find the statement “ Note that the performance of CutMix deteriorates as the number of data per class decreases due to their randomness occurringlabel mismatching.” misleading. This is true of every method in that table not just CutMix, and the detoriation amounts are very similar. Clarity: Overall I found the paper well written and easy to read. The authors have provided standard errors which improves the confidence that the improvements in the experiments are significant.<BRK>The authors propose a novel sailency guided data augmentation method that alleviates some of the drawbacks arising with recent Mixup based augmentation approaches. Specifically, the authors propose sailency thresholding for region selection (instead of maximum sailent region), stochastic sampling of sailent patches, and sailency based label mixing. The paper is pleasant to read and all decissions are properly motivated. The claim of robustness of data corruption of the model seems like an over statement. Even though the authors show that Sailency Grafting performs well under data corruption, one may attribute the robustness feature to the AugMix method that the grafting acts upon. The results of table 5. just show that grafting sailent corrupted image patches improves over just training on corrupted patches, which is something to expect given the previously reported improvements. Early in the paper the authors claim a difference wrt. previous work that is the uniform thresholding of the salient region rather than selecting the maximum, to mitigate selection bias. Also the authors briefly mention the approach to select the thresholding as the mean of the normalized sailency map. I m curious to know if any other method of threshold selection (or patch sampling) has been explored.
Accept (Spotlight). rating score: 9. rating score: 7. rating score: 7. <BRK>This paper advances the current digital contact tracing significantly and is a great contribution to the field.<BRK>In the manuscript entitled "Predicting infectiousness from proactive contact tracing" the authors present a sophisticated algorithmic approach to control of app based quarantine advisories with regard to covid 19.<BRK>Reasons for score: I think this work is well motivated and of great potential use to policymakers in what will be a long fight against COVID. The reason I ask this is that contact tracing measures are only as useful as the containment protocol that they are paired with.
Accept (Poster). rating score: 8. rating score: 7. rating score: 6. rating score: 5. <BRK>This paper presents a novel technique  (layer adaptive magnitude based pruning, or LAMP) for pruning neural network weights (pruning can be beneficial in terms of overfitting prevention as well as other practical considerations). The method is motivated theoretically as minimizing the distortion in the input/output mapping implemented by the weights of the layer. Pros:The experimental results are strong,  with LAMP consistently winning vs. competing techniques on 4 benchmarks problems. The method is elegant, requiring no hyperparameter tuning and minimal computation. Cons:My only objection is that all of the experiments seem to be done on image datasets. It seems possible that deep learning networks applied to non image data might not do as well under LAMP as they do for images. Under diverse datasets  in the abstract seems like an exaggeration.<BRK>LAMP is motivated with a distortion analysis: LAMP is shown to be equivalent to minimizing an upper bound on the supremum of the change in model predictions of unit vectors. Within the scope of the empirical evaluation in the paper, LAMP is demonstrated to outperform uniform and global magnitude pruning, the two most common approaches in the literature. Empirical evaluation: the training and re training regimes used by the paper are very non standard, raising questions about the generality of the technique and the comparison to prior work. Specifically, if the authors reported the results a comparison of using LAMP with the same networks and training/re training schedule as any of [1,2,3,4], or any other specific setting that claims to be state of the art, I would raise my score. It would be good to have some more details on the networks, especially since many are being used in non standard settings (e.g., VGG and ResNet 18 on CIFAR). Specifically: how are these networks adapted to these datasets, and what are the base accuracies for each networks on each dataset? It would be worthwhile to include full methodological details for each of these experiments, including the training and re training (where applicable) schemes, the specific point in training at which the importance scores are calculated, and the specific importance score used by each line on the plot.<BRK># After Rebuttal: Score Lowered from 7 to 6## Concerns AddressedI appreciate the effort the reviewers put into revising the paper to include the settings I suggested. It is not immediate. I implore the authors to replace the experiments in Figure 2 with well tuned versions of these networks that achieve SOTA accuracies. **## Overall: Score Lowered from 7 to 6I am less confident in the method s significance in well tuned settings, and I can no longer unequivocally trust the empirical evaluation in the paper. The section on the LAMP score is completely uninformative. (3) The authors need to verify that their statements about prior papers are correct. I would prefer to see a model like ResNet 20 or ResNet 56 on CIFAR 10, which is much less overparameterized for the specific task. In general, the results look very impressive. In addition, other smaller (but important) changes I would like to see include:(4) The authors should ideally include results on all of ImageNet, since subsets of ImageNet tend to show very different results from the full task. Importantly, it is difficult to tell what the unpruned accuracy looks like for these models. # QuestionsWhy is "minimizing the l2 distortion for the worst case input signal" a reasonable design choice to make? Han et al say that "the pruning threshold is chosen as a quality parameter multiplied by the standard deviation of a layer s weights."<BRK>Summary  The authors propose LAMP, a layerwise adaptive magnitude based pruning method. Pros  somewhat novel pruning method, based on new weight score  extensive experiments on image and language datasetsCons  In Equation (2), the authors point out that LAMP score is align with the order of weight squares. Why is it necessary to prune the network based on LAMP? The comparisons are not sufficient. The authors should compare other "pruning retraining" methods, like network slimming [1], soft filter pruning [2], etc. Lacking of experiments on large scale datasets and large models, for example, on ImageNet.
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 6. <BRK>The paper introduces a method to replace qkv attention by a simpler, efficient building block. 4) The potential efficiency gains are never put to practice, that is, the authors don t show any application of the model to very large input sequences. The results show good performance on a couple of standard image and language modeling tasks while occasionally exhibiting favorable training speed. Why were the models not trained till convergence in on WikiText 103?<BRK>Thus, it is an exaggeration to say that the Transformers evaluated in the paper are attention free. It is not clear how to generalize them to more practical cases with num_heads<hidden_dim and SoftMax non linearity. While the motivation of the authors is to replace MHA with more cost efficient operation, it is not clear whether the proposed method is the better alternative.<BRK>The introduction does not acknowledge recent efforts towards efficient transformers and what is the unique contributions of this work. This reduces complexity to linear complexity in the non autoregressive case and log linear complexity in the autoregressive case. Could the authors elaborate a bit on why that happens?<BRK>The proposed alternative is targeting the non linear soft max operator (in the MHA) and suggest to replace it with the "relu" operator.
Reject. rating score: 3. rating score: 4. rating score: 4. rating score: 6. <BRK>Summary: this paper generalizes existing decision trees to some neural style model. The most critical argument is that the model generalizes decision tree while maintaining interpretability. Since this is a new model, interpretability should at least be justified with the visualizations that can be judged as interpretable (let alone an objective measurement or human experiments). 2.The current proposition 1 does not seem useful. The factorization only makes intuitive sense when each $T_i$ is restricted / interpretable. Hence, visualizing the whole tree is necessary to claim interpretability, especially for a new architecture. 4.The theoretical statement is not clear and rigorous. Working notes of the AAAI 94 workshop on case based reasoning.<BRK>For example, all left children can be constrained to be leaf nodes. It is clear from context that DTNs have a fixed number of nodes per layer, but this should be made clearer (as this is quite different from standard DTs and the decision transformer shown in Figure 1). The width and depth of DTNs is not clearly stated in the paper. The theoretical analysis for interpretability does not apply to models "if a nonlinear activation function or a bias term exists between transition matrices". Neither of these interactions seems possible with a DTN. Additional experiments on interpretability would support the authors  claims that their model is interpretable.<BRK>The authors propose Decision Transformer Networks (DTNs): a model that generalizes decision trees to deep network style decision graphs. The authors propose special scoring functions to explain the decisions made by  each layer as well as the model. The architecture is not well explained. Most of the formal definitions and descriptions in section 3 are focused on decision nodes with only two branches, left and right. One of the claimed contributions in the paper is the theoretical analysis of interpretability of DTNs (theorem 1). Next, how does one interpret the score for a layer and for a decision. The question of how to train these models were completely omitted.<BRK>Summary:The authors propose a new model that consists in transforming decision trees by seeing such models as a sequence of "layers" made of all nodes at the same tree depth. The most interesting feature of the proposed approach is the generalisation / unified view of several decision tree algorithms that may appear as completely different and but comes down to a mere choice of a type of decision function (kind of layers) in the proposed approach (similarly to what typically happens when building a neural network). On the other hand, this work is focused on mimicking the deep learning framework while neglecting a bit the tree based learning framework (comments (b),(c)). (b) To which extent your method relates with the tree based learning framework? I totally agree that for the sake of interpretability you suggest not to consider the model as a single transition matrix but mathematically it can be rewritten as such. Therefore, how does it relates to kernel based formulation of decision trees models?
Reject. rating score: 5. rating score: 5. rating score: 6. rating score: 7. <BRK>This paper approaches long horizon planning by learning a sparse graphical representation. Overall, I believe the paper is interesting and proposes some novel ideas that have benefit, it requires more thorough analysis, and thus I am leaving my score unchanged. A clustering algorithm is then used to represent this latent space through only a small, efficient set of latent landmarks. It would also be interesting (though not fully necessary) to see comparison to Savinov 2018a (SPTM), which uses a learned distance predictor rather than the Q function as in SoRB and L3P. 2) It is not clear how this method would generalize to new environments, e.g., Section 5.5 in SoRB. Previous topics:1) The author’s add ablations on the hard vs. soft min during the graph search, the additional results are informative, but not conclusive. Given that the overall performance is similar, the authors need to demonstrate the soft min’s benefits for each experiment and over more training seeds. I believe these are still important benefits, though it would be useful to discuss how generalization may be achieved.<BRK>##### Pros:  The results seem strong. The method is straightforward and nice, and it seems to work more efficiently than previous methods. Is there a reason for this choice? Would other choices be better or worse? There is very little detail about how this all works. The specific components of the latent landmark learning and the planning are mostly fleshed out (albeit with some missing details still) but the rest of the setup is mostly not described. These need to be cited and described. Any sort of information on these? It would be very difficult, if not impossible, to reproduce this work from this paper alone. Regarding generalization, I fully agree that it can be difficult to show. It seems that the language has been greatly toned down in the updated version. However, without entirely re reviewing the paper, I am unable to fully recommend acceptance. 11.The “planning algorithm” seems trivial. This should be defined. 3.How is the autoencoder for the latent space learned within the overall system?<BRK>2.The clustering methods to find latent landmarks are novel in this setting. The novelty of the paper is limited. Planning on the graph or learning a latent distance embedding for planning are all existing ideas. 2.I am confused about why the authors  approach is better than MSS or SORB. It s not obvious that a distance based clustering will perform significantly better than sampled landmarks (like farthest point sampling). Moreover, the paper is not clear about the contributions of each component in the improvements. The author shall provide more ablation studies and explanations. 3.Although the paper presents the overall idea well, there is still a lot of room for improvement in writing. ~~~Here are some questions:1. Will it be worse? Why?2.Can a sample based approach work in non navigation environments? If so, why do we need the expensive RL algorithm?<BRK>This paper proposes an approach for automatically learning state abstraction on a RL problem, which can then be used for temporally extended planning using a search algorithm. The main contribution is introducing the concept of latent *landmarks*, a clustering of low dimensional state embeddings. International Conference on Machine Learning. With landmarks in hand, the paper proposes a soft value iteration method to compute shortest path distances to the problem s goal. In general, I found the paper interesting and the key ideas intuitive and sensible. The paper is reasonably well written, but there are some important points that are unclear (see below). The experimental section compares with very recent algorithms for planning over learned value functions (SORB and MSS), and the results on five continuous control task show substantial improvement over these methods. In terms of clarification, I have a few questions for the authors:  With regards to the embedding used and $\Psi$:    The embedding operates over goals. Are these the goals of the problem? A common approach is to use Djikstra on the graph representation. In general, I m having quite a hard time figuring out what this is doing. But, overall, I m positive towards this work and I think it is a nice contribution, particularly since I m not aware of other work creating explicit low dimensional landmarks to be used for search.
Reject. rating score: 3. rating score: 3. rating score: 4. rating score: 4. <BRK>(2): I have some doubts about the correctness of the method (or the implicit assumptions made). Cons:I have several concerns about the paper, concretely regarding (1) the clarity of presentation, (2) the correctness/generality of the proposed method, and (3) the conclusions drawn from the experimental results. These questions should be clearly answered early in the paper.<BRK>Also, it seems like there is an implicit assumption that all objects need to start in the same place. Recommendation:RejectThe method as presented seems flawed, and the experiments are toy and hard to make sense of. It’s not clear until the experiments section of the paper that the goal is to produce diverse trajectories.<BRK>Conventional learning methods tend to be quite sensitive to them. * The key part of the method, learning representations by encoding actions as opposed to observations, makes a lot of sense in this context. * For the most part, the paper is well organized, well written, and clear.<BRK>The setting is relatively clean/simple, comparing to most real world scenarios, in the aspect of system dynamics, appearance, and etc. The paper is well motivated. In my opinion, it is necessary to conduct an experiment to demonstrate the generalization of the proposed method.
Reject. rating score: 5. rating score: 5. rating score: 5. rating score: 5. rating score: 7. <BRK>[Self Supervision] The framework proposed in the paper can be seen as an instance of a general framework for self supervision proposed in SS GCN (When Does Self Supervision Help Graph Convolutional Networks?, In ICML 20). It is well known that the performance of GNNs is highly sensitive to the quality of the input graph structure. [Quality] Regarding experiments, the dataset domains (such as citation networks) considered in the paper are those in which the graph structure is known.<BRK>Cons:  1.Some model designs are not entirely clear. The authors may want to detail how to cope with this problem in the training process. Since the main goal of the paper is to learn GNN and graph structure simultaneously, the learned graph structure is important and should be analyzed empirically.<BRK>Overall, I think that this paper strength is the proposed self supervised loss and the experimental evaluation. It is rather weak on the methodology, its presentation, and related  discussion. There are several questions I need to hear your response to. First, both of the nodes have to be not directly connected. This should also include the validation nodes used for the outer objective in LDS. It can happen that, even if there is a pair of nodes where both nodes are not directly connected to a labelled node in one sampled graph, one of these nodes might be connected in a different sample.<BRK>The proposed solution is expected to infer unobserved graph structure as well as the parameters of the classification model. The model compares favorably with other states of art models in several benchmark graph data sets. The solution proposed seems to be incremental under this setting as the problem is a special case of few shot learning where metric learning based methods including GNN and denoise autoencoder all have been studied before. Further discussion of related works is necessary. 3.How does the proposed model compare with regular GNN/GCN models if edges are not entirely missing? The scope of the paper will be limited if it doesn’t work well when graph data is noisy but not entirely missing.<BRK>The paper proposes a way to use self supervision with denoising autoencoders to improve learning of the graph structure for GNNs. There is a substantial experimental comparison with relevant prior work and the conclusions seems to be substantiated. It would strengthen the manuscript if these works were discussed in relation to this work. However, consider how new they all are it is not surprising that they were not mentioned.
Accept (Spotlight). rating score: 7. rating score: 7. rating score: 7. rating score: 7. <BRK>Summary: To enable robust policy learning with image observations, the paper proposes a simple data augmentation technique that can be used with existing model free reinforcement learning algorithms. The reasons are as follows. (i) It’s a simple technique which can be used with any RL algorithm to improve the performance of the algorithm (ii) Good and detailed evaluation  (iii) additional ablation studies and robustness analysis presentQuestions: Will using different random image transformations in sequence help?<BRK>The primary claim of the paper is that image augmentation improves the performance. Paper claims that the proposed method can work with any model free RL algorithm.<BRK>This paper tackle the effectiveness of data augmentation in reinforcement learning. Authors have introduced a regularization technique, based on image shifts and Q function augmentation,(DrQ) that significantly improves the performance of model free RL algorithms trained directly from images.<BRK>##########################################################################Taken both pros and cons in to consideration, I vote for an acceptance because of the novelty of the proposed idea and large scale comparisons to previous model free, model based and contrastive approaches. This paper tackles a valuable problem of improving RL by data augmentation. This approach is easy to use and can be combined with any model free RL algorithm.
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 5. <BRK>Summary:The paper claims that the vulnerability of DNN w.r.t adversarial samples comes from the overfitting issue when applying softmax cross entropy loss. They propose I SCE to mitigate the overfitting issue and show good performance in several adversarial attacks benchmarks. The author claims that avoiding overfitting can help improve the robustness under adaptive attacks. Specifically, it shares a similar motivation and objective function to label smoothing and cosface. I hope the authors can elaborate on the difference between your work and label smoothing.<BRK>Paper proposes a modification to the widely adopted "Softmax Cross Entropy" (SCE) loss function that they refer to as I SCE, with I standing for "Inference", that is designed for making the loss function more robust to adversarial examples. Perhaps authors can explain? The main idea of the paper is to stretch the logit for the "true" class.<BRK>The authors propose a loss function that is robust to the adversarial samples and claims the training with this loss function makes the model achieve better generalization ability. Although the authors claim the adversarial training has a noticeable sacrifice of accuracy on clean examples. Thus I concluded it is still below the acceptance threshold.<BRK>The authors present a new inference SCE loss in order achieve a higher robustness to adversarial attacks. The works seems convincing, even though I would have liked to see more extensive experiments on more complex dataset than CIFAR10 and MNIST.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. rating score: 5. <BRK>The authors address transfer learning scenarios. In particular, the authors resort to training to a diverse set of experts and "cheap" performance proxies to select, for a given task, the relevant expert. Positive:  On pair performance with other approaches,  but faster and less parameters  The authors provide test statistics (i.e., not only single runs)  The work is well written and well structured)  Comprehensive supplemental materiaNegative:  The authors argue that their approach is 500 1000 times faster (main contribution), but this does not become clear in the main paper (also not in the supplemetal material?)<BRK>**Reasons for score:**The general idea of this paper (i.e.replacing generic representation with one from target dependent expert model) is very intuitive, and the experimental validations are very solid. Overall, I think it s a good paper and may inspire future work on more efficient and effective transfer learning. The proposed idea is intuitive, and empirically very effective. 3.The paper is well written and easy to follow. 5.Section 6.1 mentioned that ImageNet21k use 50 experts and JFT use 240 experts, but in supplementary JFT seems to have 244 experts.<BRK>Quality: The method is a heuristic one, but generally simple and reasonable. Overall, the paper is sound. Clarity: The paper is well written and easy to follow. I have two questions:1. Or (because there are four blocks) does the number of experts equal the combination of adapters, $n^4$? Originality: The paper is a novel method for transfer learning, though using multi expert system/adapters in network are not new.<BRK>3. for the target task of interest, select the best expert based on the nearest neighbor performance 4. fine tune the selected expert on the target taskThe authors tested their method on two transfer setting: 1) from ImageNet to VTAB 2) from JFT to VTAB. Empirical results show that their method outperform the baseline. The paper is clearly written and easy to understand. 2.Exploiting the label hierarchy to train multiple experts and select the best one makes sense. When doing multi source transfer, selecting the best performing expert for the target task seems like a straightforward baseline. 2.The method does show empirical improvements, but perhaps not strong enough. Is that the same as doing ensemble?
Accept (Poster). rating score: 8. rating score: 7. rating score: 6. rating score: 6. rating score: 6. <BRK>Overall, the paper is very easy to follow and the figures really help understanding. after rebuttal I would like to keep my origin score due to the pros listed above.<BRK>I appreciate the idea at the center of this paper   adding simple hierarchical structure to a multi output neural network, with the aim of increased interpretability   but I feel the work as it is presented is nascent and the manuscript itself is flawed.<BRK>This paper proposes a neural backed decision tree that aims to improve both the accuracy and the interpretability of deep learning models. The authors provide clear illustration of the procedure and promising experimental results.<BRK>ReproducibilityThe paper describes all the algorithms in full detail and provides enough information for an expert reader to reproduce its results. + Page 3, the last paragraph forgot a period after the parentheses.<BRK>I find the claims unconvincing and the results unpersuasive. Perhaps it s possible to understand all the details by re reading the text several times, but the paper definitely lacks clarity.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. rating score: 5. <BRK>Eta_aux and eta_prim are properly discussed and the authors convincingly show that these parameters are implicitly set by other methods as well. The choice of the subspace for g_aux seems very critical and the provided experimental results and discussion are somewhat lacking. PCGrad most closely resembles this work. Early stopping after 10 epochs seems quite short and might explain some of the large variance in the results. Minor remarks:k is introduced without much explanation, which was a bit confusing on first reading.<BRK>[Strength] How to adjust auxiliary tasks in a beneficial way is always a challenging problem in multi task learning. The subspace of the primary task gradient is composed of all training samples in the primary task, based on the definition of $\mathcal{S}$. I have noticed that the authors have constrained the search space into 4 sets of weighting, but this does not justify this problem.<BRK>The work studies the auxiliary task selection in deep learning to resolve the burden of selecting relevant tasks for pre training or the multitask learning. By decomposing the auxiliary updates, one can reweight separately the beneficial and harmful directions so that the net contribution to the update of the primary task is always positive. The most salient result is the 99% data efficiency to achieve improvable performance in the medical imaging transfer task. The decomposition allows a reweighting on the updates to optimize the primary task as much as possible while keeping the auxiliary tasks providing improvable directions.<BRK>Even though this is an interesting setting and the technical solutions presented in the paper look reasonable, the idea seems to be pretty incremental as it stacks multiple existing techniques without many innovations. The proposed methodology utilizes  automatic differentiation procedures and randomized singular value decomposition for efficient scalability. 2.The proposed framework allows the model to treat each auxiliary update independently by its impact on the task of interest, which seems to be interesting.
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. rating score: 5. <BRK>The paper describes a bit flipping white box attack on deployed neural network classifiers: given a model with quantized parameters, find a perturbation of the parameters bits such that the model with misclassify one specific example, while maintaining high accuracy on other examples. The attack is formulated as a binary programmig problem where the parameter bits are the optimization variables and the objective function is an additive tradeoff between an effectiveness term (misclassification loss on the selected example) and a stealthness loss (classification loss on a batch of training examples), a constraint on the number of bit flips is also included. The proposed attack is compared to other weight attacks in the literature, and it achieves comparable or better attack success rate (a measure of effectiveness) and post attack accuracy (a measure of stealthness). There are also experiments on different values of hyperparameters and on more robust models (obtained either by a defense technique or by making the model bigger). Overall I find this a valid contribution.<BRK>This paper proposes an ADMM based optimization method to conduct adversarial weight attack, and achieves superior or at least comparable performance compared with previous heuristic methods. Pros:1.Adversarial weight attack is an interesting research direction with important practical importance and deserve more studies. And it empirically outperforms or at least is comparable with previous state of the art methods on undefended models, and consistently outperforms previous methods on defended models. Cons:I think this paper as an necessary step towards stronger adversarial weight attacks, which could be used as an evaluation method to benchmark future defense methods. Some comments:1. Table 1 and 2 may not be the best way to present the results. Considering there are three evaluation dimensions (PA ACC, ASR and Nflip), I suggest the authors to add some pareto frontier figures.<BRK>The paper proposes an optimization based algorithm for bit flipping a limited numberof bits in a quantized / binarized deep learning model, so that the prediction on atarget input example is flipped while the prediction on the other examples is asuntouched as possible. **Weak points:**  The main shortcoming of this paper is the limitedness of the technical contributions. This is problematic  since there are quite a number of hyper parameters. It would be nice to have a back of envelop estimation of the complexity (running time,  number of flops, etc.) The experiments are very detailed and well presented.<BRK>The paper proposes a bit flip attack where model parameters weights are altered such that a certain sample is misclassified to a target class. While the utilized optimization strategy and the combination of techniques seems interesting, a major concern is the motivation behind the proposed method and why it stands out against prior works. The major difference seems to be the number of flipped bits. However, the paper in its current form does not state "why" the number of flipped bits seems to matter. Therefore, it is not really clear why this work is preferred over prior methods, i.e., does reducing the number of flipped bits matter in the attack? In addition to motivating the number of flipped bits, the authors need to also clarify why the current "single image" attack is preferred over other works where all images from a certain class are mapped to the attack target class.
Accept (Poster). rating score: 9. rating score: 7. rating score: 6. rating score: 5. <BRK>This is done by iteratively adding trees that fit the GNN gradient updates, allowing the GNN to *backpropagate* into the GBDT. Basic idea:* GBDTs work well with *heterogeneous* tabular data. * BGNNs work well on *graphs* where the nodes contain *heterogeneous* tabular data. * BGNNs is optimized end to end and seems to obtain great SOTA results!<BRK>**Summary**The paper proposes a GNN model by incorporating gradient boosting. In the proposed BGNN, the input feature on the graph is learned by the gradient boosting model. The processed feature then becomes a new feature for a GNN model following the gradient boosting. The paper proposed a simple model combining Boosting and GNN methods, which can effectively learn the heterogeneous features of graph structured data. 2.The performance of BGNN, including the training speed and regression error, is good as compared to the GNNs for datasets with tabular features. 3.What is the performance of the proposed model on other node property prediction tasks such as Open Graph Benchmark? 6.Will the GBDT apply to link prediction tasks?<BRK>This paper aims to learn from graphs with tabular node features. This paper naturally extends GBDT to deal with graph structured data and train it together with GNN in end to end fashion. This paper is clearly written and easy to follow. I enjoyed reading this paper. The idea is clear and well motivated. The essence of GBDT is to approximate the gradient of the undifferentiable part of the model by selecting a weak learner h from H (eq.2).This proposed training method seems valid and effective on semi supervised regression. Post Rebuttal Thanks for the additional experiments and the updates. The new results are informative.<BRK>Review: This paper proposes a fusion of GBDT and graph neural network that works on graphs with heterogeneous tabular features. The proposed method is a new ensemble tree method which alternates between functional gradient step in GBDT (which train on the current latent features) and SGD training of graph neural network (to generate the latent features which are fed into the subsequent trees). +Positives:  The proposed end to end training combining GBDT and GNN is easy to implement and clearly described. improving GBDT to work on graph structured data is a novel idea. The contribution of the paper is mainly empirical and offers little intuition on why the proposed method improves upon GNN and GBDT.
Accept (Poster). rating score: 7. rating score: 6. rating score: 4. <BRK>At the beginning of section 3, the term “NRI” is used, but is not defined earlier in the text. In addition, GTS appears to be more computationally efficient compared to LDS, a recently proposed meta learning graph based approach. A time series forecasting model is proposed to automatically learn a graph structure among multiple time series and forecast them simultaneously using a GNN. 2.The graph structure and the parameters of the GNN are learned simultaneously in a joint end to end framework. 3.The graph structure is parameterized by neural networks rather than being treated as a (hyper)parameter, thus significantly reducing the training cost compared with the recently proposed bilevel optimization approach LDS. 4.A structural prior based regularization is incorporated in GTS. In case a “ground truth” graph is provided upfront, this may serve as a healthy variation of such a graph for the purpose of more accurate forecast. 5.Extensive experiments are conducted in which the proposed GTS is compared to a number of baselines, including a recently proposed graph structure learning approach, and deep or non deep learning based (as well as graph or non graph based) forecasting models. 7.Generally, the paper is well written, while the notation is clear and easy to follow. (Comparison with NRI), the authors state that the “structural prior” $A^{a}$ offers a stronger preference on the existence/absence of each edge than a uniform distribution over all edges. This seems a bit unclear, thus I would encourage the authors to elaborate a bit more on this difference between GTS and NRI w.r.t.the structural prior. I am wondering whether the correlation between the series (mentioned briefly in Appendix A) is used for the graph construction or another distance/similarity metric is considered? 4.The authors construct the PMU dataset by extracting only one month of data. Is this perhaps due to data unavailability? If that is not the case, I would ask the authors to clarify the reasoning behind the decision to extract the data for February 2017? 6.There are several minor textual errors throughout the paper that can be easily addressed. In the next to last paragraph on page 2, consider replacing “it is better scaled” with “it scales better”.<BRK>The paper considers learning both graph structures and NNs for time series data, similar to the idea of LDS (Franceschi et al., 2019). Observing the computation and scalability issues with LDS, authors propose a unilevel optimization form wrt. the mean performance over the graph distribution. This is done via NNs, with input being the observed sequence, to output a real matrix whose elements are then treated as weights for the Gumbel trick. NN structures, training procedure, etc. Overall, the paper is well presented, easy to understand, with a simple and somewhat effective modification over LDS. I generally like simple ideas with sufficient insights and explanations (though there is not much in this work), but I m not sure if the empirical improvement is sufficient. I recommend a weak acceptance for now and may change my score after reading other reviews. I only have one question: the proposed idea is not restricted to time series case. It would be a big benefit if the proposed idea also helps in a more general case than the present scope.<BRK>The dimensions are considered as nodes in a graph, and the problem is mapped to learning a discrete graph structure that can help with downstream forecasting task. The paper shows that a graph neural network (GNN) can be leveraged even though an explicit structure is unknown, to improve forecasting performance. This is achieved while learning the graph structure and forecasting architectures in an end to end fashion. The proposed approach is computationally efficient compared to a bilevel optimization approach where a discrete graph structure is learnt in a meta learning framework. The proposed approach improves forecasting performance in comparison to several strong baseline methods on three real world datasets. In general, the paper is well written and easy to follow. Attempts have been made in the past for learning such a discrete graph structure from data. The authors mention LDS [2] and NRI [3] as closest to their work. The authors claim that "The most essential distinction is the number of structures": one structure is learned in the proposed approach while many structures are learned in NRI. From what I could follow, this single structure is achieved by using the entire multivariate time series data to obtain a feature vector for each dimension (series) via a neural network instead of using window wise data. In this sense, this appears to be a simplification of NRI, rather than being something novel and different. The proposed setup and the approach are different and novel compared to NRI as the "Amortized inference is not desired nor relevant": I am not sure how this makes the proposed approach non trivial given NRI? Furthermore, in contrast to LDS, the key contribution of the proposed approach is to get rid of the bilevel optimization. But then, that also seems to rely mainly on the Gumbel reparameterization trick which has been used in NRI for forecasting albeit for a slightly different setting. Another very closely related approach to the proposed one is that in [1], which the authors seem to be unaware of. I have some concerns regarding the empirical evaluation:1. Despite the fact that the only difference between DCRNN and the proposed method seems to be the graph structure learning part, it is still not obvious qualitatively as to why the observations of Fig.2 can be attributed to the graph learning part, e.g.why is "GTS curve better captures the sharp dip toward the end of the series" attributable to the graph learning part qualitatively or as per domain knowledge? I think an empirical analysis on a synthetic dataset to support such claims related to ablation could be useful. As such, the effect or usefulness of regularization is not clear. 3.The analysis on regularization and learned structures is done using a kNN graph as apriori knowledge for the PMU dataset. Rather than relying on another data driven graph structure (kNN graph) as ground truth, I wonder if it would be useful to do such analysis on the public datasets (METR LA and PEMS BAY) for which the ground truth structures are actually known. Other minor points:1. al, KDD2020. Kipf et.al, ICML, 2018.
Reject. rating score: 3. rating score: 3. rating score: 3. rating score: 3. rating score: 4. <BRK>The paper presents an example application of person ReID using the VideoFlow platform. The VideoFlow platform software is certainly a great development tool for video analysis tasks. The major concern is that if it is appropriate for ICLR to publish this tutorial which may be regarded as an endorsement to this software.<BRK>In this framework, learned models are treated as an atomic node and executed on other DL libraries. The authors need to emphasize this forward/backward function is different from DL models  forward/backward. Although this work seems helpful for system integration and deployment, I did not see a strong connection between it and the topic of this conference. The graph mentioned in this paper, as well as terms like forward/backward, has nothing to do with the graph in machine learning concept.<BRK>VideoFlow is introduced with providing a flexible, efficient, extensible, and secure visual analysis framework for both academia and industry. However, through the whole paper, the key contributions of the VideoFlow should be only counted as engineering efforts rather than any novelty in the scientific or research perspective. Therefore, ICLR would be not an appropriate venue for the submitted paper to be published.<BRK>The paper introduces VideoFlow which is a framework that aims to improve the development process of streaming pipelines. I believe this work in full fledged form may help the productivity while building visual analysis applications. Sadly, there are many shortcomings of the paper. This looks more like a technical report than a research paper. Up to this point, the paper seems to be an amalgamation of various libraries and frameworks with a GUI wrapper.<BRK>The paper describes the design and implementation of this framework. VideoFlow seems like a useful tool, but its novelty and contributions to the state of the art have not been clearly articulated in the paper. Flexibility, efficiency, extensibility, and security have been identified to be the key design goals for VideoFlow s architecture. Weak points:  The paper reads more like a system demo paper. Its contribution as a research paper is not clear.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. <BRK>The inference is that starting at white noise x_0, it defines a conditional EBMs given x_0, runs Langaving dynamics to sample from P(x|x_0) defined by the conditional EBMs, and then use the sample as the evidence of another conditional EBMs. In general, I believe that this is an exciting paper and an important step towards training better EBMs.<BRK>The paper proposed a novel method to train EBMs based on diffusion recovery likelihood. 3.The analysis of the normal approximation and how it leads to choose step sizes in the Langevin dynamics is neat.<BRK>Denoising diffusion probabilistic models. In particular the comparison with [1] and [2] is necessary as the main claim of the paper is to show improvement using recovery likelihood. * Eq 9 should be an approximate sign as it is a Taylor expansion. * The authors proposition is well grounded in theory, and comes with rigorous and strong mathematical derivation.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. rating score: 6. <BRK>This paper introduces a new neural network layer architecture (spatial dependency network   SDN) that can be used in place or in conjunction with traditional convolutional layers. SDNs are evaluated with VAEs on density modeling and learning of disentangled representation and show better performance than purely convolutional baseline architectures. What can SDN do that attention can t (in principal or in practice)? How much overhead does SDN in the SDN VAE actually introduce in practice   regarding model size/VRAM and training time? Overall I think this is a good paper. I also believe the paper would benefit from a discussion comparing SDNs to traditional attention and when SDNs might be a better choice than attention. ######Update after revision: I have looked over the revised paper and believe the authors have addressed most issues that were raised by the reviewers, especially by describing in more depth the relation of their approach with autoregressive models and self attention and mentioning the runtime differences of their model compared to a normal CNN.<BRK>1.Summary.This work is in line with the latest attempts[1,2] to improve the VAE quality by employing more powerful decoding architectures. The authors propose a new block that handles (non local) spatial dependence of pixels at the expense of increased computation time   O(scale). The presented experiments demonstrate that usage of the suggested layer is beneficial for the tasks of density estimation and image generation. Therefore, I tend to vote for acceptance. However, major issues of this approach are the increased number of parameters and computational time. 1.Is it sufficient that the sweep from Algorithm 1 is GRU like, or, more generally, gated? [1] https://arxiv.org/abs/2007.03898[2] https://openreview.net/forum?id RLRXCV6DbEJ#############After reading the rebuttal I confirm the initial rating.<BRK>**Summary**: This paper proposes a network architecture, spatial dependency network (SDN), that attempts to more explicitly model spatial dependencies, as compared with convolutional networks. Admittedly, the particular architecture itself is novel, and it is likely a useful improvement. However, note that this is in the conditional mappings and *not* the flows. The model achieves state of the art performance, as compared with non autoregressive models. Given the similarity with previous autoregressive modeling approaches, I found it surprising that the authors chose to parameterize the conditional mappings, rather than the distributions, with SDNs. The authors also demonstrate improved disentanglement on a single level VAE. If SDNs are a swap in replacement for CNNs that are truly better at capturing spatial dependencies, then this should be apparent across multiple settings, not just latent variable models (VAEs). While this might be attributed to an increased number of parameters, the authors also conduct an ablation study to demonstrate that SDNs outperform much larger CNN architectures. I do not expect every experimental result in a paper to be surprising, but it’s unclear what we learn from the results in this paper (other than the fact that SDNs work in practice). There is nothing intrinsic to SDNs that allows them to calculate explicit density estimates. This paper would benefit from exploring these other settings (other generative models and discriminative models). **Weak Points**: While I agree with the approach, I felt as though it was poorly motivated. More broadly, it may help researchers to consider spatial dependencies more explicitly when constructing network architectures.<BRK>Their method performs much better than other VAE methods, and almost as well as SOTA autoregressive models. The authors clearly discuss the advantages of SDN over CNN, but the experiments focus on generative modeling VAEs, but not any of the other tasks where CNNs are used & more expressive architectures might be helpful. Since SDN introduces some sequential dependencies, it trades off computation during sampling time vs during likelihood evaluation (autoregressive models are slow at the former but fast at the latter; the proposed method is somewhere in the middle but the same speed for both). On a similar note, the authors allude to the extra computational overhead incurred by adding SDN to VAEs, but I don t think they explicitly state what that is? This would also help frame the contributions of their work. Nit: the description of SDN in Algorithm 1 is a bit confusing   it doesn t seem to convey the sequential nature of SDN? From reading Algorithm 1 only, it sounds like SDN could be implemented via masked convolutions + gating, but this seems to disagree with the rest of the paper? Also, the output variable I_+ doesn t seem to be used?
Reject. rating score: 4. rating score: 6. rating score: 7. <BRK>The motivation for this paper is quite hard to understand. A VQ VAE is directly applied to convert an image from one colour space to another one. In this case, the latent space of VQ VAE should be collapsed into this simple equation easily. The analysis of this paper does not teach us any additional knowledge. The motivation of finding a better embedding space of colour is admirable, unfortunately, the analysis and methodology does not support the motivation.<BRK>This paper proposes to study an interesting problem of how color informaiton is structured in the variational autoencoders (VAEs). Several instances of VAEs are trained in an unsupervised manner to perform color space conversion. Several interesting conclusions are drawn from the experiments that help interpret the encoding process of autoencoders. To address this, it may show some applications based on the proposed task/conclusions. I only have some minor issues. 1.It could be better to include results of state of the art methods on, e.g., object classification and scene segmentation. This could further show the potential application of proposed method. Figure 1 is not referred to in the main text. Besides, it could be better to prodive more details in the caption.<BRK>This framework able to encompass additional constraints is relevant to understand why the considered representations could have emerged in the brain. General opinion and recommendation I think the metodology and findings are really interesting to understand why the brain may have developed the opponent representations that have better performance in the presented experiments. The use of an autoencoding tool to enforce the minimization of the loss suggests that comparison between the color representations is fair. However, this message (pointing out the advantages of opponent representations wrt more trivial non opponent representations) is not clearly stated. This would be necessary for a fair comparison, isnt it? Presentation is confusing at many points (see specific list below), but this can be fixed. * Correlation   1 between L and M seems like too much. Major Points The goal of the paper (in my view, a fair comparison of different color spaces in a bottleneck context using an appropriate optimization tool) is not clearly stated. For instance, in the abstract and intro it is said "We propose a novel unsupervised task —colour conversion— to explicitly examine the colour representation learnt by deep networks (referred to as ColourConvNets)." 2012.Nonlinearities and adaptation of color vision from sequential principal curves analysis. At this point the reader may think that the proposed autoencoder will learn a specific color representation well suited for certain goal(s). In fact, spatial and chromatic parts of visual information are mixed in the vectors of the inner representation of the considered autoencoders.
Reject. rating score: 5. rating score: 6. rating score: 6. <BRK>This paper proposes cut and paste neural rendering that allows to insert objects into a target scene in a plausible manner, i.e., in terms of shading plausibility. At the core of the approach is a deep image prior that allows to match the shading and albedo fields based on shading and albedo consistency losses. The results obtained by this approach look plausible. There is one statement in the paper I disagree with: “We cannot quantitatively evaluate our reshading method, because we do not know ground truth”. In summary, I like the submission and I think the proposed approach is novel, but I would have hoped for an actual evaluation against GT data.<BRK>SummaryThis paper introduces a reshading method for cut and paste image composition. It uses a modified deep image prior as the rendering networking, and trains with a novel shading consistency loss. The results are plausible. Pros:  an improved DIP that produces consistent image decomposition inferences (albedo, shading, gloss). Therefore, in the inference phase, the shading factor for the cut out might be ambiguous. My concerns are mostly addressed.<BRK>**Paper Summary**The paper proposed a carefully designed neural rendering pipeline to realistically insert one image fragment into another image via deep image prior and the consistency in the albedo, shading, and gloss in the rendered image. This idea effectively helps the network to learn the shading of the target image and to avoid directly copying the inserted objects. 2.The shading consistency loss and the designed experiments to pre train the image decomposition network are also carefully designed and thoughtful. 2.Some notation in this paper is not clear. 4.It s not clear how does the proposed method generalize to high order lighting effect since the lighting model the paper used is Spherical Harmonic.
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 6. <BRK>The authors provide an algorithm for adversarial training that generates adversarial examples on a trusted public dataset and iteratively sends them to the clients, so that they can perform learning on the adversarial examples as well. The method is tested empirically on a wide range of datasets and compared to adversarial training using the local clients  data. In general, I find the idea of generating adversarial examples based on both the model bias and variance (instead of the bias only) quite interesting. I completely agree with these points and therefore I find the problem of robust federated learning an important one. 2.While I do think that considering bias and variance in the context of adversarial training is an interesting problem, the paper does not provide any motivation for such analysis. In this sense, I think more analysis should be provided about when each of the algorithms should be preferred and in general how should the results be interpreted.<BRK>This paper proposes FedBVA for robust federated learning. The idea seems interesting, but I have a few doubts about its validity and the correctness of the experimental results. Concerns:   Secure aggregation:  The proposed scheme seems to require access to individual models, implying that it cannot be used together with secure aggregation. Note that client data is not anymore private if the server has access to individual local models. For instance, see the first row of Table 1. Unless the model trained with standard FedAvg is inherently robust against adversarial examples for some reason, which I doubt, I cannot understand these results. Writing: It was tough to read the paper, especially the bias variance trade off part. [Domingos 2000] (not [Pedro 2000]) helped me understand this part, but I believe that the authors can improve the readability of this part.<BRK>The authors propose a robust federated learning algorithm, where they assume that all samples are iid, and $n_s$ clean samples are available at the server side. While overall the paper is interesting, there are several shortcomings in the execution as discussed below that the authors can address to improve the paper. Existence of such decomposition is not obvious at all. **C2.** In bias variance decomposition, the weights of different components is fixed. Can you please comment on how this framework is privacy preserving? **C4.** The authors assume that the data is IID, and also some shared and non adversarial data is available at the central server. Can you please explain how such shared dataset is created? I don t see any reason why a single adversary cannot completely destroy the model performance for all devices if they can do whatever they want with their updates. It would be good to see how the different methods compare in terms of the tradeoff between robustness and performance (and repeat that for different notions of robustness).<BRK>Assuming that a shared public dataset exists, a novel method called FedBVA (Bias Variance attacks) is introduced: it consists in crafting new adversarial inputs on the server by minimising a custom loss function at each aggregation round, and sharing these new inputs to all clients. 2/ Acceptance decisionOwing to its well conducted experimental section and the novelty of the problem tackled, I would tend to accept this paper, even if it has some weaknesses in the algorithm section. I think this is the first time the problem of training an adversarially robust model in the Fl setting is investigated. However, I have some doubts on the justification of this approach, for the following reasons:  The authors slightly change the definition of the bias and variance, and in the cross entropy case they are not equivalent due to the asymmetry of the cross entropy loss in its both arguments. Further, none of the related works cited by the authors explicit the existence of this bias variance decomposition in the case of a cross entropy loss, which makes it difficult to check if the decomposition holds in this case. It is difficult to see them and it would be profitable in order to better understand the contributions of both loss terms. In some FL settings, this is an unacceptable breach of privacy, and secure aggregation is used to ensure that the server only sees the mean update. Is it the model used for FL training?
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. <BRK>I find this difficult to read and would appreciate a summary of the assumptions required directly at each step. My recommendation is to accept the paper with a 7. The paper states “This result complements [1], proved that Polyak Heavy Ball algorithm on the Hamiltonian is asymptotically worst case optimal.”  It’s unclear to me how this is shown in their paper.<BRK>In particular, first order methods are derived and studied that are average case optimal for certain optimization problems. Also for finding the root of non symmetric affine operators average case optimal operators are derived if either the relevant matrix is normal or the eigenvalues are supported in a disk. Some experiments with the derived methods are conducted but the focus lies clearly on the theoretical results. For the analysis of first order methods a well known and elegant connection to residual polynomials is used. The analysis is quite technical and rather densely written. As a non expert in this area I had some difficulties in following the analysis and I had to read some of the related work to understand the contribution of this submission.<BRK>So what’s the benefit of introducing complex instead of real. Although the authors pointed out the difference between this paper and the previous work Pedregosa & Scieur (2020) in Section 2.4, the contribution of this paper is still not very informative to me. They said that Pedregosa & Scieur (2020) considered the symmetric matrix $A$, while this work extends to normal (diagonalizable) matrix $A$, i.e., $AA^T A^TA$ (Assumption 2). It seems that the analysis only needs the spectral information of the matrix.
Reject. rating score: 3. rating score: 5. rating score: 5. rating score: 5. <BRK>The parallels with the CEM RL paper are once again obvious and misquoted. **Pros:**  The experimental part seems to have received a lot of work  The setup and hyperparameter description is very complete, coupled with open sourced code, potentially allowing full experiment reproduction**Cons:**  The first sentence of the Conclusions claims the pairing of CEM and TD3 integrating policy gradient and population based search as a novelty and contribution, while it was introduced in the (cited!)<BRK>This a nicely written paper. The authors propose an algorithm that combines population based search with policy gradient approach to obtain optimal policies in reinforcement learning.<BRK>This paper proposes a novel combination of an evolutionary direct policy search and an actor critic approach. The current evaluation lacks the evaluation of the generality of this approach.<BRK>The paper proposes a new method combining evolutionary methods and RL. PGPS maintains a population of policies, which interact with the environment to collect data filling the replay buffer. The data in replay buffer is then used to train TD3.
Reject. rating score: 2. rating score: 4. rating score: 5. rating score: 7. <BRK>## SummaryThis paper presents a graph attention architecture that captures long range interactions. The novelties in the architectures are (1) vector based parameterization of edge type in modeling message, (2) slight modification of graph attention (Section 3.2), and (3) GRU based node update function. However, it is unclear if modeling such long range interaction is useful in real tasks. The paper fails to demonstrate convincing results on the real tasks of entity classification in knowledge graphs. 2.Good performance on synthetic tasks. The novelty of architecture is limited as detailed below. One domain long range interaction could be useful is molecule classification, where you can treat molecular graphs as multi relational graphs and those graphs tend to have large graph diameters. 3.Details of the real knowledge graph datasets (AIFB and AM) are not provided in the main texts.<BRK>The three approaches are potentially meaningful for ameliorating various issues with long range reasoning, such as overfitting or vanishing gradients, and I think the methodology from this paper could be useful to GNN practitioners. However, the paper s current presentation and motivation does not feel suitable for a venue like ICLR, in my opinion. While the GR GAT model achieves some strong outcomes on synthetic benchmarks, the strength of these results is, in my opinion, insufficient to carry the weight of the paper, especially for a venue like ICLR. Post rebuttal update:I thank the authors for carefully addressing my comments, as well as other reviewers . However, the lack of stronger real world experimentation (on datasets such as OGB) unfortunately renders the contribution insufficient   the synthetic benchmarks being insufficient on their own to pull the weight of the paper.<BRK>#####Summary#####This paper proposes a new GNN model (GR GAT) for multi relational graphs. The proposed method has better ability of capturing the long range information. Overall, this work is ok but not good enough for ICLR. #####Pros#####(1) The experiments on synthetic are well designed and can show the power of the proposed GR GAT. (2) This paper studies a meaningful and challenging problem; that is capturing long range information using GNNs. The current version did not well explain why the proposed model can help to model long range dependencies in Section 3. I think if this point can be improved, the novelty and motivation of this paper can be clearer.<BRK>Summary:    The authors propose a new gating based recurrent graph attention networks for multi relational graphs to capture long range neighbor dependencies. The authors provide an interesting analysis of current gated GNN models (in the appendix + Figure 3) in light of their ability to capture long range dependencies in graphs. Also, Additional results on single relational homogeneous graphs can help disentangle the effect of the proposed relational module from the main contribution, the gating mechanism. On the experimental front, adding more real world datasets would strengthen the paper. I would have strongly recommended the paper if it had more real world datasets. How does it compare with the GraphLSTM updates? The text about model variations mentions GATE and SGRU to be the same but in Table: 2, there is both GR GAT (SGRU) and GR GAT(Gate). (viii) WGCN results on AIFB ?
Reject. rating score: 4. rating score: 5. rating score: 6. rating score: 6. rating score: 6. <BRK>One of the most prominent weaknesses of the work as a whole is that there is little attempt to compare to sensible baselines. How far can we get with just flips and rotations, for instance? While the authors do compare against a  naive  augmentation, these results are misleading. The authors point out that  fine detail  can be obtained with just 1% of the training data, (Figure 3). * The paper states that MRI does not use radiation on patients: correct this to  avoids using ionizing radiation .<BRK>Traditional image augmentation methods can t be applied directly for this problem because MR images are complex valued. The results shown in the paper are highly encouraging. The paper is clearly written and is easy to follow. For the 1% experiments, did you choose 1% of slices or 1% of volumes? Since different slices of the same volume have a large amount of redundant information, these two methods are not equivalent. The authors mention using the E2E VarNet model, but that model was designed specifically for multi coil data. However, in practice it is important for the model to generalize to different pathologies.<BRK>The evaluations by the clinicians make the author’s claim stronger. + Overall, the paper is well written and might be easy to read by the readers who are not familiar with accelerated MRI. Not only for the sampling rate, but also details about the sampling pattern is important. Is it work for the super resolution task? Considering the limited results, a deeper analysis of the proposed method would have been nice. I cannot clearly see the novelty of the proposed algorithm except for scheduling. However, the analysis and comparison is not well provided.<BRK>A comparison with state of the art methods is missing and should be added. Since it is claimed that this can be extended to other MRI datasets, is it possible to add results for Brain MRI as well fo having diverse data and hence a better representation on the generalisation of the MRAugment model.<BRK>The paper is well written and the results quite promising on a rigorous test case. Still, the methods are novel, the presentation good and all steps are done rigorously so I can certainly see this being useful for a huge range of related applications. For this reason I’ll recommend acceptance. It could be interesting to have a standard U Net baseline. * All figures that are not “images” should be in vector format.
Reject. rating score: 4. rating score: 6. rating score: 7. <BRK>However, I think (a) additional baselines should be incorporated for evaluating the DNN solver, (b) the proposed explainer does not generate practically useful outputs for discovering new algorithms, and (c) the proposed explainer seems a bit flawed. It is not clear how to use the proposed algorithm for discovering new graph algorithms. The proposed explainer seems flawed for explaining the DNN based solver. My main concerns are on Q2, i.e., the practical usefulness of the algorithm. However, I think the usefulness is not well supported in the current state of the paper.<BRK>the paper has provided an explainable GNN framework using differentiable graph discovery algorithm. The experimental results has demonstrated the effectiveness of the proposed framework. However, I do have some concerns as follows:1) In terms of the explainable GNN, I doubt the presenting systematic explanation of the graph model is explainable. It could be still regarded as an open problem in AI transparency and I m not criticizing this paper has not provided the corresponding merits.<BRK>3.The novelty of the explainer model is not very clear. In general, the paper is well written, and the method is interesting. It sounds like the proposed model is hard to generalize to different datasets.
Accept (Poster). rating score: 9. rating score: 7. rating score: 5. rating score: 2. <BRK>## SummaryThe paper presents a new, more complex, dataset for the use of disentangled representation learning. The dataset is based on real and simulated images of the trifinger robot platform. There are 7 factors of variation with high resolution measurements of these factors. The authors also present a new neural architecture to scale disentanglement on more complex datasets and present a large empirical study on the performance of various techniques on out of distribution downstream task performance. ## Originally & SignificanceThe novelty of the dataset is clear. The in  and out of distribution experiments are possible because of the presence of both synthetic and real world data. The experiments run are repeated multiple times and the results are convincing. The experiments on out of distribution representation transfer are interesting and show that disentangled representations can lead to better transfer to out of distribution tasks. ## Outcome RationaleThis dataset is likely to be extremely useful to the community going forward and work disentangled representation learning is likely to benefit from it.<BRK>The OOD evaluation is novel, interesting, and informative. Though the downstream task is quite connected with the disentanglement evaluation itself, the consideration of this setting is a contribution to the community. The distribution shift considered here is shift in nuisance factors, a useful test but limited in its scope. "Our results therefore suggest that highly disentangled representations are useful for generalising out of distribution as long as the encoder remains in distribution" This statement can be seen as a bit misleading given the data is only out of distribution in terms of nuisance factors, not the factors the model was evaluated on disentanglement with respect to. The justification for training half of the models with gaussian noise is provided in the final page of the paper. If that is the case, though the dataset itself provides the ability to evaluate generalization, the evaluation prior to OOD evaluation does not evaluate generalization. Conclusion: This work provides significant contribution in experimental analysis on the performance of disentanglement with the inclusion of realistic complexities. 1, as well as PCL [2] and SlowVAE [3] (which assume laplacian transitions) could provide interesting comparisons. If some did, was there an underlying correlation between successful models that can be discussed, or was it simply random?<BRK>Its results suggest that disentangled representations can result in better out of distribution task performances. Strength:  Identified weaknesses of the previous datasets and proposed a new dataset that exhibits correlations between different variables. Provided thorough experiments on disentangled representations and their metrics on the proposed dataset. It would be great to propose a way to make the generalization better for the settings the models have trouble with (OOD2 generalization). This paper tried one approach by adding noise during training, but it leads to my second concern that the real world observation is very similar to the simulated data. With some gaussian noise, they would look similar. Therefore, it might not be sufficient to show that we can use this approach for sim to real transfer.<BRK>However, unlike infoGAN or ACGAN which explicitly learn disjoint feature representations for describing the attributes of interest (via unsupervised and supervised settings, respectively), the authors chose to address this task in a questionable "weakly supervised setting". This is a very strong assumption, since it is very likely that more than one feature dimensions would correspond to such changes. Since VAE are simply trained in a unsupervised way (even the authors called their setting a weakly supervised setting), I see no evidence why the resulting features would be any different from those derived from standard VAEs, and why improved disentanglement results could be achieved. Based on the above observations and remarks, I feel that the authors would not be able to deliver a work which is technically strong with sufficiently complete evaluation. Therefore, I do not think this paper is above the ICLR standard for acceptance.
Reject. rating score: 5. rating score: 5. rating score: 6. rating score: 6. <BRK>The paper proposed a novel simulation based testing procedure for conditional independence: X\perp Y | Z. The testing procedure incorporate the techniques of GAN, which is especially useful for dealing with high dimensional data. Instead of kernel based method that takes the supreme over a class of RKHS functions, the proposed testing procedure searches the maximum "discrepancy" over a class of neural network function by simulation. Empirical results show a well controlled type I error and better test power performances compare to existing methods and a cancer data application is discussed. This is an interesting paper combining kernel testing and GAN setting which can potentially broaden the scope of kernel based tests. In addition to the contributions, there are some unclear parts in presentation and concerns on the proposed schemes. The notion of characteristic kernel ensures that the null hypothesis hold iff the test statistics is 0. In this work, do you or how do you ensure the positive definiteness? Instead of RKHS kernel, it may end up being a Krein space kernel, i.e.RKKS.This may reduce the test power of the statistics in particular scenario, but it is unclear. This part is not entirely clear. Not entirely clear just from Thereom 1, instead, it sound more like asymptotic property. 5.Building up from the GCM type of statistic, instead of MMD, it may be better to refer Hilbert Space Independence Criterion (HSIC) instead of MMD. Thanks for the presentation.<BRK>  OverviewThis paper develops a test for conditional independence using GAN. The authors newly developed test combines the conditional distribution with GAN and regression based and MMD based tests to construct a valid test under weaker conditional requirements than the previous method. Comments.The paper points out some important issues with existing research. However, there are a few things I don t understand. The experiments show that the GCIT appear to have no power at all, but the experiments of the original paper (Bellot and van der Schaar (2019)) report that GCIT has sufficient power. Where does this discrepancy come from? The theoretical advantages and their relationship to the experiment are less clear. The paper states that the conditions required for GCIT are unsatisfied in general, but does this show up in the experimental results? The Type I errors appear to be a bit more or less dominant, but not by much. Could that be the reason for the poor performance of GCIT in the analysis for power? If so, then it should be clear why there is a significant difference with Bellot and van der Schaar (2019), as discussed above. How is the computational time of the proposed method?<BRK>The authors propose a non parametric conditional independence test that approximates distances in a Hilbert space of functions using a generative approach, both evaluating conditional expectations using samples from GANs and evaluating a supremum over a set of functions previously generated at random. The test incorporates benefits from different lines of research and is demonstrated to outperform alternatives in well known benchmarks. My biggest concern is that conditional independence testing is an unsupervised problem, there is therefore little scope to test for the goodness of fit of hyperparameter choices or the accuracy of approximations. The proposed approach has plenty of user defined parameters yet the sensitivity of performance to different choices is not investigated nor is there a discussion of sensible values to be recommended in practice. Some specific questions on this thread are as follows. Appendix C tests the goodness of fit of the GAN approximation by comparing observed and estimated distributions p(y|x). Why should this be a good indication that GANs approximate well p(y|z) or p(x|z)? Most consistency guarantees are asymptotic in nature. Would experiments as a function of sample size be possible to include in the paper? Minor comments:  The test itself is quite involved, with many moving parts that are described over various pages in the paper. A single data generating mechanism is used for performance comparisons. I think different multiple different choices here would be needed to test different aspects of the model.<BRK>This paper considers the problem of conditional independence testing, especially when the variables are high dimensional. The authors proposed a double GAN based algorithm. It is proved that the error of the test statistic is O_p(n^{ 2k} \log n) when the total variation error of the GANS is O(n^{ k}). The result of this paper is quite strong. Compared to the paper of Bellot & van der Schaar (2019)  which requires the TV error of GAN to be o(n^{ 1/2}), this paper significantly reduce the requirement to o(\log^{ 1/2} n). I did not check the full proof. Questions to the authors: In the description of Bellot & van der Schaar(2019), it seems that the data used for training the GAN and the data used for computing testing statistic are shared. However, in the proposed algorithm (Algorithm 1), the data are split into L blocks where GANs are trained by L 1 blocks of data and test statistics are computed by the other. If not, what is the key reason for the improvement of convergence rate, double GAN or the randomly generated h functions?
Reject. rating score: 3. rating score: 4. rating score: 5. rating score: 5. <BRK>Baselines are SPTM, SoRB and HER. ##########################################################################Reasons for score:Experimental evidence in the paper is insufficient to estimate the value of the approach. Interesting ideas about planning for exploration and learnable graph representations for MDPs. I would encourage the authors to fix the cons mentioned above and resubmit.<BRK>**Update after author response**: I appreciate that the authors answered some of my questions, but they did not address my two main concerns: insufficient baselines and writing clarity. **Clarity**: The writing clarity of the paper could be improved, especially in the sections describing the method. * "This drawback also makes generated graph non robust"   Please clarify why nonparametric representations are less robust. E.g., "The aim of this section is to learn a latent space representation of observations $x$ s.t.<BRK>This paper proposes a new method for learning graph representations of RL problems. Finally, there are some missing references:  An important one is *Huang, Z., Liu, F., & Su, H. (2019). In terms of cons, I think the writing can be improved in some places. In terms of pros, the proposed approach is interesting and novel, to the best of my knowledge.<BRK>This work presents a method for learning topological representations for MDPs, encoded as a graph, which could then be used to guide exploration/learning via a goal conditioned RL mechanism. The basic idea is appealing, as a form of an intermediate method between model based and model free RL. Such intermediate methods which are scalable for large problems are, in principle, of great interest to the community. However, I have some concerns regarding the approach. On its own this is a valid approach (being kind of a "hybrid" between model based and model free), but the use of the term  planning  (starting from the abstract) is misleading. I think the paper would benefit from a discussion of this point, making the modelling choices more clear/explicit. The fact that similar (?) But I think the discussion of its place within the context of prior work could be improved.
Reject. rating score: 4. rating score: 6. rating score: 6. rating score: 7. <BRK>Pros:  Targets an important problem, adversarial attacks semantically constrained as opposed to being constrained by an artificial norm ball. Extensive results with a wide variety of models, datasets, and more importantly, applications, with not only attack evaluation on standard models, but application to adversarial training, a user study, and evaluating against certified defenses. On the other hand, comparison to the literature is sorely lacking, there exists techniques which share much of the same functionality of the method [1], a comparison to norm based adversarials in the adversarial training experiment should have been done to clarify concerns that controlling for unrealistic adversarials is the source of the result, not the contribution of semantic adversarials, and the certified defense is not "broken", as the attack went outside of the defense s threat model. It is intuitive that semantic adversarials would provide benefit for the robustness accuracy tradeoff, but this experiment certainly does not demonstrate that due to the obvious confounders.<BRK>Although a similar idea has been proposed by Song et al.(2018), this work is along the same direction and achieves better performance. The experimental results show not only qualitatively confusing human vision but also quantitatively improve the performance on testing clean images. + The paper is well written and easy to read. However, I still have some concerns:  There’s no experiment to compare with existing methods such as Xie et al.‘20 and PGD. Although final results in table 1 shows that style based adversarial training benefits the performance, ablation studies of y_adv and eta_adv in both tasks should be conducted. Since the attack is in the feature space, the defense should also happen in the feature space [a]; Overall, I think the paper is valuable. [a] M. Lecuyer et al., Certified Robustness to Adversarial Examples with Differential Privacy: https://arxiv.org/abs/1802.03471<BRK>The paper presents a new method for generating unrestricted adversarial examples. Based on Style GAN, this work separates stylistic and noise modifications so as to control higher level aspects and lower level aspects of image generation. By handling style and noise variables separately and changing the different levels of synthesis networks, the model can input various types of perturbations in generating adversarial images. As the authors claim, the style variables from different layers affect different aspects of images. Generation of adversarial images are tested in both un targeted and targeted attacks. On the other hand, although the different layers of the networks are concerned with different aspects of the images and the proposed method can generate a variety of images, we may not be able to intentionally control specific aspects of the images. This is an incremental work on top of Style GAN so that the novelty of the paper is not very high.<BRK>###Summary###The paper proposes a method of generating adversarial samples to enhance classification performance. Specifically, it finds variables of pre trained generative model to produce images that the pre trained classifier gives wrong answers. The new classifier is then trained by adding these samples to the existing training dataset. This method achieved good performance because the distributions of the samples generated in this way is closer to the distribution of the real images than the ones generated with norm bounded perturbations. ###Questions### Is there a difference in performance between using non targeted adversarial samples and targeted adversarial samples? Which of the two to use depends on the outcome? What is the criteria that you divide layers as high , mid  and low level ones? For example, generation results in figure 3 using only one original image.
Accept (Poster). rating score: 8. rating score: 7. rating score: 7. rating score: 6. <BRK>add to the intro a defintion of "data splicing"  formalize problem of off manifold shapley values  It would be great if the authors released code for their experiments. Specifically, they enable scalable sampling from the on manifold conditionals.<BRK>Table 1 in the supplement seems to show that the supervised approach is vastly superior according to the proposed metric; the authors should also include a comparison with the off manifold approach (using the marginal distribution) to give a sense of how significant the difference is. I appreciated many results from this paper. 2.The metric for the on manifold value function was not explained clearly. A couple of questions and concerns about the methods and theory in this work.<BRK>This paper is focused on the off data manifold problem with Shapley values which is created by sampling data that is out of distribution. Unless the main differential contribution of the work to the existing literature is clear, I cannot change my score. Note that the problem is more prominent for the case of SHAP as the method is built on performance on all subsets of the input features and the paper makes a good case of showing the necessity of solving the off manifold data problem for Shapley based methods.<BRK>I read the rebuttal and the updated version of the paper. I think the authors did a good job resolving my concerns on novelty. The use of autoencoder is considered to mitigate the effect of data outside the data manifold.
Accept (Poster). rating score: 8. rating score: 7. rating score: 6. rating score: 6. <BRK>Where are the identical word probing results actually reported? I think this paper is going to be useful for the community and I know I will reference it later and direct others to it who are interested in learning more about position embeddings in transformers (whether or not it actually gets published). This paper studies position embeddings (PEs) in transformers, suggesting a few reasonable formal properties of PEs and determining whether these properties are captured by various choices for defining PEs. I am more positive about the paper now and have increased my score to an 8. I really enjoyed reading this paper. With some doable improvements and clarifications, I think the paper can become an excellent resource for others interested in representing position and distance in transformer like models. I like the idea of learned sinusoidal embeddings and think that idea can be potentially useful for other researchers. The experiments show that learning frequencies in sinusoidal PEs works better than using fixed sinusoidal PEs. Some other thoughts I had while reading: At least for language tasks with a given window, could we just re use the learned frequencies and use fixed sinusoidal PEs in the future with those same learned frequencies? Maybe given their experience, the authors could hand design useful general purpose PEs? I was super confused by the identical word probing parts of the paper. I don t know what the "This" is referring to.<BRK>The paper presents a systematic analysis of approaches used to encode position information in transformers and in particular BERT based models. These embeddings are characterized based on different properties that are either inherent from their formulation or observed empirically such as monotonicity, translation invariance, and symmetry. Visualizations of the dot products between position vectors for different PE strategies are presented as well that demonstrate the monotonicity (or local monotonicity), symmetry, and translation invariance. Overall, the paper is well written, motivated, and systematically studies an important design decision in transformers. The overall methodology is sound and should prove useful to the community when studying position embeddings in transformers. StrengthsThe paper is well written, well motivated, and is systematic in its claims, experiments, and methodology. It studies a variety of position embedding strategies and their conjunction and experiments with fairly realistic models and benchmarks. This would be interesting to see (especially the latter) because it does not satisfy monotonicity or translation invariance and violates the desiderata in eq (1)Is Figure 7 based on BERT fine tuned for NER on the CONLL/Ontonotes dataset?<BRK>This paper studies the position embeddings of transform based models, and proposed a unified position embedding evaluation method in three aspects, i.e., Monotonicity, Translation invariance and Symmetry, which can well summarise the properties of the existing position embedding methods. It is good that the authors summarise three property for position embedding models, and discuss four related position embedding models under the three properties. 2.The three properties proposed by this paper are suitable for most position embedding models. Extensive experiment details are provided in the appendix. The presentation and organization of this paper should be improved. However, what I see is just some position vector embedding similarities (i.e.Fig.2 and Fig.3) in terms of the four position embedding models, where the results are also somehow expected and intuitive. This paper lacks the discussion with the latest position embedding models such as,   [1] "Learning to Encode Position for Transformer with Continuous Dynamical Model". Overall, I think this paper indeed shows some interesting empirical results of position embedding models for BERT. ### Comments after the discussionThank you for your detailed response.<BRK>The first three properties seem well motivated (monotonicity and translation invariance), but it is not obvious that symmetry should be a property of an ideal PE, or at least the paper is not convincing on this front. nit: “since relative distance with the same offset will be embedded as a same embedding.”  > “the same embedding”  “compared to far way”  > “faraway”  “attends more on forwarding tokens than backward tokens”  > “forward tokens”?
Reject. rating score: 3. rating score: 4. rating score: 5. <BRK>In this paper, the authors propose a learn2weight framework to defend against similar domain adversarial attacks. It is necessary to discuss with these related works, and highlight the difference and importance of adversarial attack methods on NLP tasks. [ref1] Adversarial Examples that Fool both Computer Vision and Time Limited Humans[ref2] Minimalistic Attacks: How Little it Takes to Fool Deep Reinforcement Learning Policies(2)	The authors highlight “domain adaptation theory” several times. Please give a clear description on what it is. Based on the figure 1 (a), only correctly classified source samples are used while the definition does not show this. It is more reasonable to use source data to help generate target adversarial samples X’ which confuse the classifier to deviate the label f(X) \neq f(X’) where X is the original target sample. However, the paper generates source adversarial samples, which naturally may confuse the target classifier due to the domain divergence. How to differentiate the importance of the data shift and adversarial in the accuracy drops? The sections 5.1 to 5.3 are not linked well. I am quite curious how the proposed method differentiates from other transfer learning methods. Update: Thanks for the authors  response. After reading the response and the other reviewers  comments, I think the paper needs to be further improved, and thus I will keep my score.<BRK>Summary:The paper considers the adversarial attacks via a surrogate model constructed using data from a different domain. The authors propose a defense from such attacks by a special kind of adversarial training inspired by the idea of domain adaptation. Also, the proposed attack is not new. ICLR, 2017. Also, for this new attack, the authors don t compare a surrogate model attack trained using the same domain data, which would be interesting to compare. The authors use only one dataset, which is a bit strange for modern papers. For this dataset, they don t provide a full study, limiting the scope of experiments to particular pairs of source target domains. It is just a surrogate model attack but using a surrogate model training on the data from a different domain (as the authors suggest due to the unavailability of the initial domain data). The hyperparameter selection for them has a crucial effect on their success. I think that the inclusion of additional datasets (at least three) would improve the paper and make the conclusion by the authors more solid* Usage of surrogate models trained on other dataset is not new for general adversarial attacks [1 (mentioned in the paper), 2] and for adversarial attacks in NLP [3]* LSTM is not the state of the art model for the processing of NLP data* 4.2. what attack do you use? not explicitly specified. If it is similar to the presented accuracies, then why bother with a new method?<BRK>Authors consider a setting when an adversary has access to some "similar to target " domain data, and can use this data to generate a surrogate model. Then authors also propose a defense mechanism from this type of attack, Learn2Weight. This is a learnt network that, for a given example, returns perturbation of weights to the target model which will be applied to the target before inference. The paper is well organized and written, and easy to follow. Enough background is given for a reader to follow without the need to research around or going to appendix. Well done on clarity! I do have a problem understanding how effective this attack is (compared to other blackbox attacks) and how the proposed defense compares to standard domain generalization methods like learning domain invariant features. But how would you attack a pre trained Imagenet for example? Also you don t really have a way to calculate that your data is close to the actual target data. If other attacks are able to make target model performance worse than this type of attack, it is of less value to defend from a weaker attack4) Algo 3   what are the adversarial perturbations you are talking about?
Accept (Spotlight). rating score: 8. rating score: 7. rating score: 7. rating score: 6. <BRK>This would allow the algorithm to avoid returning `unknown` in cases like the right. # Score RecommendationThe method in this paper is novel and the results presented are compelling. As a result, the figure was slightly confusing for me when I initially looked at it. I expect that some other property of the network means that this is not an actual counterexample, but do not see which specifically. # Strengths*Novelty*: The paper presents a novel approach for verification that can be accelerated on GPUs. Given that it looks like there is enough space in the caption, it might be worth it to spell out what VRA is in the caption. # Post Rebuttal CommentsI ve increased the rating for the paper from 5  > 8 as the authors have addressed all my substantive concerns.<BRK>Summary:This paper proposes an algorithm to verify whether or not there exists an adversarial example in an Lp ball of size espilon around a given training sample. I m happy to raise my score. There is a short mention in the Related Work section but I found it pretty lacking. Is that correct? Is there a intuition or a result that could be given of when GeoCert and FGP are going to return the same result? C doesn t seem to be introduced anywhere (there is C_u for activation constraints).<BRK>The authors propose a systematic search over the convex polyhedral regions on which the network is linear, to find the decision boundary, so to certify local $\ell_p$ robustness. The proposed verification method is incomplete and returns, given an input either one of 2 certificates (robust or not_robust) or abstains from certification. In the case of $\ell_2$ robustness, significant speed ups are gained compared to prior work. Certifying local $\ell_p$ robustness is in general an important problem. The scalability to large networks seems to be an issue, although the proposed method significantly outperforms prior work. Suggestions:A potential improvement for Section 2 would be to include a simple running example, that showcases the algorithm step by step. Questions:  What would it take to make the proposed method complete? Given the generality of the approach and the speed up gained compared to prior work, i give this paper an accept. I will not change my score.<BRK>I think this is the missing piece in the current version of the paper. FGP can verify whether in an $\ell_p$ ball around an input $x$ adversarial examples exist or not. Since it s not guaranteed to find a conclusive solution, it has the option of returning "unknown" if the given point could not be certified. The paper proposes Fast Geometric Projections (FGP), a method to certify the robustness of neural networks with ReLU as activation exploiting the fact the such networks are piecewise affine functions. Overall, the method is clearly presented and achieves good empirical results. While I agree with the authors that training for provable guarantees sacrifices clean accuracy in most of the cases, as far as I know that is currently the way to achieve good VRA at meaningful thresholds.
Reject. rating score: 5. rating score: 5. rating score: 6. rating score: 6. <BRK>This paper designed a hypothesis testing procedure for detecting changes in episode sequential data. The method is demonstrated based on a non iid and non Gaussian setting for reward signals. The strength of this paper would be significantly boosted if the proposed method can be used to solve an non stationary RL problem. Moreover, it is a little unclear the specific setting of this work. There is no surprise that the RL feedback from an environment is highly correlated over consecutive time step if the underlying problem is an MDP. It seems that the paper mainly deal with per step reward without considering state and action information when detecting changes. after rebuttal I appreciate the authors’ effort to address my questions. I would expect to see how this method can solve or help solving a fundamental problem (e.g., reducing sample complexity) in RL or be applied to a novel application (e.g., nonstationary RL tasks).<BRK>It is assumed that the pre change (nominal) mean and covariance of each episodic is perfectly known or can be accurately estimated from reference data. The Uniform Degradation Test (UDT) and Partial Degradation Test (PDT) are proposed to detect the mean shift. And this paper has tried to make the problem as general as possible, such as considering non Gaussian distributions, etc. However, the technical contribution is very incremental. And the problem itself, although is proposed in the reinforcement learning setting, is of no fundamental difference with the classical mean shift in change point detection literature, for example, change point detection for a mean shift in multivariate Gaussian distributions. And I didn t see the classical Hotelling T^2 test mentioned in this paper, which is a classical and also widely used method to detect the change in mean/covariance, and it also utilizes the pre change covariance matrix in the detection statistic. Looking forward, I think this paper may be improved by expanding the horizon of the problem set up and possibly leading to new theoretical findings. After the author response, I raise my score by 1  Thanks to the authors for the detailed response and extended discussion on theoretical results and experiments, and I have raised my score by 1.<BRK>The authors present a novel change detection test for non i.i.d.data motivated by applications in RL. The paper is clearly written and presents both theoretical results and convincing experimental results. My two concerns are about the novelty of what has been proposed w.r.t.standard CDT procedures and on the fact that a consistent part of the material of what has been proposed in the paper is deferred to the appendix. In my opinion, the paper is not self contained. I think you should rearrange some of the material from the appendix to the main paper and viceversa. In your setting the change in the episodic reward is only about the expected values. What happens if the new reward distribution changes in terms of covariance \Sigma? Minor:"in RL ... life time of the task." I would have preferred a citation about this statement. assume strong assumptions  > require strong assumptions After rebuttals the authors significantly improved the presented work, including and discussing some relevant work which was previously missing.<BRK>The authors state in some places of the text that their method can be applied in statistic domain other than RL. However, for me, the entire proposed methodology does not relate to RL and is more general: it can be applied to any sequential statistics (series of random variables) that have a proper [auto]correlation structure (just see how the main statements). 2.Seem that the contribution is not enough for the current venue. I expect a clearer presentation in the main text why these results are non trivial and non incremental. As for now, the provided theoretical grounds looks as non enough for publication @ ICLR. A nonparametric sequential test for online randomized experiments. 610–6, 2017] where seq.testing is applied to A/B tests, but there is an earlier paper on this approach: [Eugene Kharitonov, Aleksandr Vorobev, Craig Macdonald, Pavel Serdyukov, and Iadh Ounis. Sequential testing for early stopping of online experiments. ACM.]After the author response, I raise my score by 1 (see my comment to them)
Reject. rating score: 4. rating score: 6. rating score: 6. rating score: 7. <BRK>#########################Summary: This paper studies heavy ball momentum in non convex optimization. This paper has proven the superiority of heavy ball method in some cases by showing that heavy ball momentum helps the iterate to enter a benign region that contains a global optimal point faster. Even though that the authors have tried to generalize it to solve the problem of top eigenvector computation and saddle point escape problem, they still focus on special subproblems of these two. Why are considered problem important on their own? And how can they be connected to problems that the ICLR community would be interested in?<BRK>In the paper it seems that it always speed up the performances, but this is not clear from the theorem. The results show that the algorithm leads to a faster convergence rate in comparison with gradient descent without inertial contributions. **Other comments :** * There is a change of notation between the one used for Fig.1 and the one reported in the appendix (d< m, n< m).<BRK>This paper studies the deterministic Heavy Ball (HB) method compared with vanilla gradient descent (GD) in nonconvex optimization. The first stage is to find/fall into a benign region (strongly convex region) and then the second stage can directly use previous HB results for strongly convex functions (i.e., linear convergence). Thus the main part/contribution is to show how HB could perform better than GD in the first stage. In this paper, they show this by providing Theorem 1 and 2 for these two problems respectively. However, I have some questions/concerns regarding Theorem 1 and 2. So only according to their Theorem 2, I am not convinced that HB is better than GD as the authors claimed since GD may choose different step size due to nonexistence of momentum.<BRK>This paper analyzes Polyak momentum in the deterministic case for two simple but important non convex problems: phase retrieval and finding the cubic regularized newton step. The other issue is that as far as I can see, these results improve by at most a constant factor of about 2 over the number of iterations required by ordinary gradient descent, which is not a huge amount. However, constants are important in practice, and many analyses of Polyak momentum in the non convex setting actually get worse when there is momentum, so at least this is going in the right direction :)I think the cubic regularization result seems the most promising for future development as it may have some application to generally showing faster a convergence on second order smooth non convex problems.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>Updated review  # SummaryThis work proposes an approach for model based optimization based on learning a density function through an approximation of the normalized maximum likelihood (NML). # Pros* Using estimates of the NML for model based optimization is an interesting idea. What are the models initialized to?<BRK>Given the datasets used in the    experiments of this work is are not of large scale, I think comparing with    a GP based BO is necessary. 2.One clear advantage of ths proposed approach is this method can scale to    large dataset, compared with GP, which scales cubically.<BRK>Summary: The paper proposes an approximation method, called NEMO (Normalized maximum likelihood Estimation for model based optimization)  to compute the conditional normalized maximum log likelihood of a query data point as a way to quantify the uncertainty in a forward prediction model in offline model based optimization problems.
Accept (Poster). rating score: 8. rating score: 7. rating score: 7. rating score: 7. rating score: 5. <BRK>This paper examines RNNs trained to perform a range of text classification tasks, and demonstrates that they can be understood using a dynamical systems analysis. The approach is based on recent works by Maheswaranathan et al, but extends them to a large range of tasks. This is a big step towards interpreting RNNs trained on NLP tasks, and I strongly recommend it for ICLR 2021. Concerns:The results for ordered classification (Fig 4) are a little puzzling. One possibility is that the specific 2d organisation in Fig 4 results from the manner in which the readouts were implemented. The legend says "fixed points", but are these fixed points in response to different inputs? Related work:  a recent paper by Schuessler et al (arXiv:2006.11036) suggests that the low d dynamics in the sentiment classification task can be traced to low rank structure in connectivity, as in neuroscience tasks.<BRK>### Reasons for score:  This paper is an interesting extension of the work from “Reverse engineering recurrent networks for sentiment classification reveals line attractor dynamics” (Maheswaranathan et al, 2019, https://arxiv.org/abs/1906.10720). The authors extend the above mentioned work by Maheswaranathan et al from sentiment classification to other classification settings, such as multi label classification. The authors find intriguing differences in the topology of these attractors for different types of classification. This work will be of interest to many researchers in the ML community. In my mind, the paper is an extension of work by Maheswaranathan et al (2019) and Maheswaranathan & Sussillo (2020). The paper was a great read. I believe that the authors meant no harm here, and they did cite Maheswaranathan’s existing work appropriately. pushed the hidden state in the opposite direction.<BRK>The efficacy of this class of models, is nevertheless lacking a mechanistic understanding of the properties that have enabled their success. 1.The network hidden unit sizes were chosen to be different for different architectures   it would be good to state why this was done, should the result depend on the hidden unit dimensionality. The major contribution of this submission is an in depth analysis of the types of dynamics that permit the **trained** networks to solve text classification tasks. Empirical evidence that the networks use low dimensional attractors ($ N\ll d$ where n is the number of, potentially not mutually exclusive, classes and d is the hidden layer size). Pending the authors response, I am rating it as marginally below the threshold. Despite the strong, and convincing empirical contributions, the manuscript suffers from some shortcomings. I would like to emphasize at this point, that I do not believe they invalidate the empirical results and hence the essential contribution. 1.Moreover, the authors further simplify the analysis by assuming that there exists a prototypical terminal $x_T$ which is given by the average input. The following are minor comments:1. 1.In Fig.1 the initial points are only marked for the artificial data.<BRK>### Paper SummaryThis paper sheds light on how trained RNNs solve text classification problems by analyzing them from a dynamical systems perspective. ### Review SummaryI found this paper to be interesting, well written and useful. When projecting the RNN hidden states to principal dimensions that explain most of the variance, the authors find (N 1) dimensional simplex attractors for N dimensional classification, 2D attractors for ordered classification, and N dimensional hypercubes for multi label classification. Finally, I agree with the authors that the paper motivates further work into understanding the behavior of RNNs from this perspective.<BRK>This paper presents an analysis on the trained recurrent neural networks (RNN) especially for NLP classification problems. The analysis takes the dynamical systems point of view and investigates the dynamics by looking at the Jacobians around the fixed points. This work founds low dimensionalility and attractor dynamics in the RNNs which might lead to a better undertanding of RNNs. After reading the manuscript, I am leaning on not accepting it. The weakness of this work is the lack of theoretical implications. On the integration of evidence, the possible mechanisms include, for example, fixed points, line attractors or sequences of stable fixed points (forming a path to the decisions). A typo in  As the position withing...  in page 5  arxiv:1906.01005 on continuous time GRU might be relevant.
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. rating score: 5. rating score: 5. <BRK>** There is some work studying bounds on the Lipschitz constant  of implicit models, although more of the flavor of Neural ODEs https://arxiv.org/pdf/2004.13135.pdf this work also appears to focus on the Lipschitz constant w.r.t.the parameters of the networks. In particular the generalization bound depends linearly in the width $h$**. This is in contrast to the naive bound for deep neural networks, which degrade with the depth. This generalization bound reveal a dependency on the strong monotonicity parameter $m$, as well as the size of the hidden layer and appears to be the first result of such kind.<BRK>In this case, setting a value of m is not sufficient for controlling the L_in, since the upper bound also depends on \|U\|_2. They derive analytical upper bounds to the Lipschitz constants both with respect to input perturbations (L_in) as well as with respect to the network s weights perturbations (L_w). These bounds depend on the networks parameters and do not involve exponential constant, as opposed to Deep Neural Networks that suffer from their Lipschitz constant being exponential in the depth.<BRK>#### SummaryThe authors of this paper derive analytic expressions for the Lipschitz constants (LCs) of monotone deep equilibrium networks (mDEQs) with respect to their inputs and learnable parameters. are used which are not defined in the text. The ability to control (an upper bound on) the LC with the strong monotonicity parameter $m$ is quite useful here.<BRK>This paper analyzes the Lipschitz constant of a recently proposed implicit depth model, the monotone deep equilibrium model (monDEQ). Pros:1.The paper is well written and easy to read. Could you explain this in more detail?<BRK>The authors consider the problem of estimating the Lipschitz constant of a specific type of network known as a Monotone Deep Equilibrium Model (monDEQ). Additionally, the ML field is not yet broadly interested in monDEQs. The theory sections are well written.
Reject. rating score: 3. rating score: 5. rating score: 5. <BRK>These should have been analyzed empirically or theoretically to understand the impact of the past history on the regret. This is not because the paper is not written properly but the topic is fairly new and a very few works have considered this problem setting. I believe the paper addresses an interesting problem but lacks sufficient analysis due to the realizability assumption A2 which doesn t apply for the given problem and the other reviewers feel the same way.<BRK>But it still does not look like a solid technical definition to me. Without a clear definition up front on these key notations, it is very hard to understand the entire logical flow. However, the paper has several issues, as discussed below. The empirical results demonstrate that the proposed method achieves good results comparing to other baselines. The paper lacks the theoretical result on their algorithm. What are the difficulties for the regret analysis comparing to NeuraUCB? The DNN is part of the proposed algorithm that needs to be constructed and tuned from data, but when taking its last year for TS exploration, it seems that the authors are treating this entire DNN as given by the environment, as a transformation from the context b(t) to a representation \phi(t), and thus making an assumption patterned from the Assumption 1 for linear bandit, which is entirely on the environment.<BRK>Online Limited Memory Neural Linear BanditsThe presented paper suggests a method for neural linear bandits that use limited memory. Is this rather \propto? The paper presents an interesting approach to a relevant problem but lacks novelty. Moreover, the presentation of the paper needs improvement (i.e.figures are not readable and results should be highlighted better in the tables).
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 5. <BRK>Given this paper is in the same nature as f divergence. My concern is that the previous approach has proved stochastic settings in some f divergence. If this part is the theoretical contribution, an optimization convergence bound should be provided. *Current paper still requires careful polishing for facilitating reading. The paper and the rebuttal are still dense, which make the readerdifficult to understand. Summary: This paper proposed a hypothesis based f divergence domain adaptation theory and algorithm. Cons:[1] The significance of the paper (theoretical and practical) is rather unclear. Based on these, I recommend a rejection but encourage a major revision for resubmission.<BRK>I should say that many of my previous concerns have been clarified. Again, I like the theoretical part. Nonetheless, I agreed with some other reviewers that the experiments seemed not to fully convince me. The key strength of this paper is, it enables a generalized version of f divergences that can be used for adversarial domain adaptation. This is valuable for UDA algorithms in many application areas. The paper was well organized and written. However, there are some major concerns as follows:(1)	Although the authors provided theoretical insight for their method, the performance improvements are not very significant.<BRK>I read the proofs, which appear to be correct. This paper studies unsupervised domain adaptation. The authors derive a generalization bound that utilizes a new measure of discrepancy between distributions based on a variational characterization of f divergences. Directing the readers to a third paper for important details such as experimental settings and results is not proper. However, this paper does have a few strong points. 1.The theoretical analysis in Section 3 is sound.<BRK>###############Summary: This paper proposes a new generalization bound for domain adaptation based on f divergences. In addition, most of the theoretical analysis follows standard steps of existing works. The paper is well written and easy to follow.
Reject. rating score: 5. rating score: 5. rating score: 5. rating score: 6. <BRK>##########################################################################Summary: This works proposes an new auto encoder variant based on an Optimal Transport (OT) penalty. While there are many such previous works of OT and auto encoders, this work proposes a joint OT penalty on data and latent space. Given the numerous prior works (properly cited in the paper), the novelty of the proposed loss appears limited to me. Theorem 1 also appears to be limited novelty over the Theorem 1 of Tolstikhin 2018. Additionally, the empirical evaluation of the method is only limited to small scale datasets. I agree that the "denoising" between observed and generated data is an interesting idea. I read the author s additional experiments on CelebA. In Figure 10, VampPrior is still qualitatively superior to the author s best result $SWAE(\beta^* 0.5)$. I have some skepticism over the reported results for WAE {GAN/MMD}, which are much worse than the results in the original paper (Tolstikhin 2018). The authors appear to have used different encoder/decoder architectures, which complicates the comparison. All told, I raise my score, but still harbor some doubts over the empirical advantage of this work.<BRK>In the paper, the authors propose a new family of generative auto encoders, named Symmetric Wasserstein Autoencoders (SWAEs), based on replacing the KL divergence between the encoding and decoding distributions on the traditional VAE framework into the Wasserstein metric between these distributions. I think the SWAEs is quite interesting but lacks novelty. Here are my comments with the paper:(1) The result of Theorem 1 is under the assumption that both the encoder and decoder are deterministic, which is quite restrictive. The result of Theorem 1 is also quite similar to the main result in the Wasserstein autoencoder work. (2) Simply replacing KL divergence between the encoding and decoding distributions by Wasserstein metric to have symmetric properties sounds not novel. What can we interpret the Wasserstein metric between the encoding and decoding distributions? Theorem 1 does not seem convincing to me. (3) In the experiments, the choice of $\beta   1/2$ seems to yield best results, i.e., we should balance the reconstruction loss and the discrepancy in the data space in the objective function (4). Can the authors provide some intuition behind that?<BRK>SWAE minimizes $p(x_d, z_d)$ and $p(x_e, z_e)$ in a jointly manner and shows better latent representation learning and generation. Moreover, the symmetric treatment for encoding and decoding shows an advantage in data denoising. The usage of the deterministic encoder and decoder could solve the problem of $W(p_{x_e}, p_{e_d})$ minimization, while it is difficult for the latent code since the latent codes from the prior and the posterior are not paired. The classification results and the reconstruction results of the case $\beta   0$  are missing. Especially 3c, it does not look like what we have seen in previous papers. For example, figure 2 in Makhzani et al, 2015 (https://arxiv.org/pdf/1511.05644.pdf) shows that the latent representations produced by VAE have several modes. I doubt this could be the problem of dimension reduction. It will be more convincing if the author could show the visualization of these models where $dim(z)   2$ and without any dimension reduction. For the reconstruction results (not the denoising reconstruction) shown in Figure 9 and 10, the images seem to be dynamically binarized. Moreover, the reconstruction from SWAE ($\beta 0.5$) and SWAE ($\beta 0$) seem to be binarized, which is not reasonable. In general, the idea of symmetrically treating encoding and decoding to solve with the Wasserstein distance is interesting and is worthy of study. However, some details in the experiments remain unclear; some experiments results and the corresponding analysis are missing. The authors might need to dig out more to support their method.<BRK>This paper proposed symmetric Wasserstein autoencoders (SWAE), which is a new type of generative autoencoders within the framework of optimal transport (OT). This work is based on Wasserstein autoencoders (WAE), but leverage a symmetric distance between the encoding distribution and the decoding distribution to better preserve the local structure of the data in the latent space. The paper is well written and easy to follow. Below are some minor issues that need to be addressed. Can the author provide results for full CIFAR10? 3.The FID of WAE GAN and WAE MMD in Table 2 does not look right, can the author provide implementation info?
Reject. rating score: 2. rating score: 2. rating score: 3. rating score: 4. rating score: 4. <BRK>The paper proposes to theoretically analyze whether self supervised learning can help FSL. As said in the paper, "γ0, δ are constants depending on the class distribution ρ", then how to estimate γ0, δ? The main concern is that Theorem 1 and 2 are quite loose. During discussion period, I noticed import missing references of this paper as written by Nikunj Saunshi.<BRK>*** Key idea justification ***This work shows that contrastive loss (for self supervised learning) is an upper bound of cross entropy loss (for supervised learning) and leads to a conclusion that this is the underlying reason why self supervised learning can help supervised learning in FSL. In conclusion, the proposed theory makes little sense and is also over claimed. *** Presentation clarity ***1) In general, the presentation of this paper is poor. 5) What is implied by the last sentence of Sec 4: Theoretically, if given an unsupervised set with infinite classes and data, the performance achieved by SSM can be very close to that by supervised training? *** Grammatical errors ***1) a episodic  > an episodic<BRK>#### Summary  The authors analyze a self supervised learning framework for downstream (supervised) few shot classification. Unlike previous works that consider unsupervised/self supervised pre training for few shot learning, this work provides some theoretical justification for its method. This should be noted. (Though comparison to UMTRA (Khodadadeh et al., 2019) is fair.) #### Recommendation  I currently recommend rejection (3), as the submission s poor writing severely hampers clarity and thus prevents it from meeting publication standards.<BRK>The paper establishes a relationship between self supervised learning (SSL) and supervised few shot learning (FSL) method and shows that when both are equivalent. Comment:1: The paper theoretically connects the SSL and FSL and shows when both will be equivalent. Theorem 1 shows that the supervised loss is upper bound by SSL loss by a linear relation (mostly scale+shift) when |C| >infinity then both loss is equivalent. I believe this theorem provides less useful information for a practical perspective. Could you please explain that? 4: In the N way and M shot, it is intuitive that when M increase the model performance will increase, but why with the increase of the N model performance will increase? 5: Omniglot dataset has 1623 classes, while in the paper it is written that "Omniglot involves up to 4800 classes" please check that.<BRK>This paper performs theoretical analysis of the relationship between supervised learning (SL) and self supervised learning (SSL) in the context of few shot learning (FSL). Using this formulation, the authors show that the self supervised training loss is an upper bound of the supervised metric loss function, implying that if you reduce the self supervision loss to be small enough, you can control the model’s supervision loss on the training data, and thus improve results on the downstream FSL tasks. Weaknesses and suggestions: 1. The paper is very difficult to follow. While the theory section (Section 4) is reasonably well written, the rest of the paper needs a substantial rewrite to improve clarity and accessibility. Unfortunately the writing quality makes it difficult  to make a strong case for the paper.
Accept (Poster). rating score: 8. rating score: 8. rating score: 6. rating score: 6. <BRK>This work extends previous results for particular symmetries and outlines a method for obtaining these parameterizations for any compact group symmetry. Technically, the paper establishes a Wigner Eckert Theorem for G steerable kernels, which in turn allows any admissible kernel to be expressed using a basis of kernels thereby establishing a natural parameterization. The paper highlights important ideas from representation theory that can be used to obtain paramaterizations for symmetry constrained learning models, and the mathematical methods could be of independent interest. The results obtained here are significant for any learning problem where there are inherent natural symmetries, as the authors point out this could be especially beneficial for data arising from physical processes.<BRK>The authors prove a theorem (thm 4.1) which describes a basis for the space of kernels in a G steerable CNN for any compact group G.  Steerable CNNs are similar to CNNs but replace channels with G reps and enforce an equivariance constraint on the kernels. Here, solving the constraint means to construct a basis of the space of steerable kernels. The theorem proved in this work unifies such previous efforts and provides a useful method for approaching further G.  This paper is a significant contribution to the field. Specific Additional Points:1.My opinion is that the language of physics does not add to the paper. While Clebsch Gordan and harmonic functions first arose in physics, they can be described in terms of representation theory. It would be better to use something more standard. Not only does this make the proof informal, it means the maps in the theorem are not even defined.<BRK>The paper under review is a very technical contribution to the study of group equivariance of convolution kernels. The most general tools from classical harmonic analysis and Lie group representations are put to work in order to provide the most general framework for the analysis of equivariance. The application section is in particular way too sketchy to convince the novice that this impressive work will be useful to the machine learning community and an effort in this direction should be made to clarify the expected impact.<BRK>For a physicist familiar with machine learning, the title of this work says it all. It is a lengthy explanation of how to use well known techniques from physics in constructing convolutional neural networks with a group symmetry. The paper also spells out what are likely to be the most used cases of U(1) and SU(2) and their quotients by discrete groups. If I had a student who needed this material I would instead give him or her the original Cohen Welling paper and a representation theory textbook such as Hall 2015 or one of the several textbooks they cite.
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 6. <BRK>In the paper, authors proposed to utilize the global statistics in local client updates to mitigate the client drift problem. They also prove the convergence rate of the proposed algorithm and evaluate its empirical performances on synthetic and real federated learning simulations. The following are my concerns:1) At page 2, analysis of fedavg, the last sentence "technically, it was a slightly modified FEDAVG version? 2) typo in the sentence of eq (1) "vour". I agree with reviewer 2 that the Lemma 7 is not correct.<BRK>This paper proposes a way to apply various variance reduction/momentum based method to the federated learning scenario, especially when there is distribution drift among the clients. The paper also provides convergence analysis for their methods and attains the best convergence result for their MimeMVR method. However, I find a key wrong in theoretical analysis. Specifically, in the proof of Lemma 7, the last second inequality in page 21 is wrong. Thus I have difficulty judging the contribution of this paper. I still have doubts about the proof of lemma 7.<BRK>The paper proposes a new framework for solving federated learning. Here are my main concerns of the current paper:1. The client drift issue is not clearly defined in this paper. However, MimeSGD depends on the extra Hessian assumptions (A2). 3.Assumption A2 seems to be a very strong assumption. 4.It seems that the algorithm with theoretical guarantees is different from the one implemented in experiments. 6.What is the definition of x^out?<BRK>Summary of the paper:This paper introduces the MIME framework which can adopt standard centralized SGD methods in federated learning environments and this framework handles the well known "client drift" problem. The quality and the presentation of the paper can be improved significantly. I believe it is $i$? Typos: Last line in the first paragraph of Related work, there is an extra "?P:". Pros:  Nice to have a flexible framework that can adopt standard centralized methods with similar guarantees. Extensive experiments validates the provided theoretical claims. I believe authors have a sufficiently addressed my concerns regarding the quality of the paper. However, considering this improvement and the concerns raised by other reviewers, I maintain my score.
Reject. rating score: 1. rating score: 5. rating score: 5. rating score: 6. <BRK>The paper claims $O(1/T)$ convergence rate. In fact, this is WRONG. The authors assume the Frobenius and trace norms of $n\times n$ matrices are CONSTANTS. ##########################################################################Pros:+ This paper develops a new method of distributed kernel k means. 3.Based on the right assumption that $|| \xi ||_F   G   O(n)$, the required number of iterations is $T   O(n^2)$. The algorithm is not communication efficient. First and foremost, I do not see a good reason for using the proposed algorithm. The goal of the algorithm is to find the top singular vectors of the random features, $A$. The solution to the trace norm regularized problem, $Z^*$, has the same singular vectors as K. By finding $Z^*$, you can find the eigenvectors of $K$. I found Theorem 3, which is the main theorem, is wrong. Typos:17th page: "The following two lemmas will be used in the proof of Theorem 4.” Do you mean Theorem 3?<BRK>The algorithm consists of two parts: a distributed stochastic proximal gradient descent (DSPGD) update rule, and a communication efficient mechanism (CEM) to reduce the communication cost. The main contribution is that the authors show, both theoretically and experimentally, that their proposed algorithm converges to the true solution of the SCO problem at O(1/T) rate. It is also proved that the communication cost does not grow with the number of samples N. In addition the authors characterize the error ratio between their algorithm and the original k means. In particular it is shown that the proposed algorithm approaches the baseline scalable kernel k means algorithm as T increases, both theoretically and experimentally. I appreciate the discussion of the motivation and related works in the first two section of the paper. However the authors  response to the proof of Theorem 1 is not the most convincing, which is a big part of the claimed contribution.<BRK>The paper proposed a new distributed kernel k means algorithm that has lower communication overhead compared to the available methods while does not require transmitting the data samples from agents to the master node and therefore claims to preserve the privacy of agents. The paper is rather difficult to follow and the novelty of the paper is not very clear to me. It seems to me that the major contribution of the paper is to come up with efficient tricks during the implementation of the distributed Lanczos algorithm (DLA) to find the eigenvalues of the kernel approximated by using the well known random Fourier features (Rahimi, nips 2008). In Section 6.2, the author says "According to the results in the four subfigures, it is shown that CEM can reduce communication cost of DSPGD by more than 95%."<BRK>Summary:This paper proposes a distributed version of kernel k means clustering where some federated structure is used to do distributed processing on the data. However, the way the algorithm is presented look like a patch of a number of things coming together one after the other with no general structure. This might be caused by the fact that the algorithm is only presented in the appendix. It is not clear how this is solved. Why developing a federated learning algorithm is a promising approach? The way the result is presented makes it look like the proposed method is a concatenation of other results, rather than the solution of a technical challenge in the problem. Numerical results are well presented,
Accept (Poster). rating score: 8. rating score: 7. rating score: 6. rating score: 6. <BRK>Although the proof system itself is not of much practical interest, I really like this approach since it allows for a much more rigorous way to study the natural generalization questions that arise in theorem proving since the data generation can be controlled to a great extent. (The usual work in this area that uses existing proof corpora does not easily allow for answering such questions due to the lack of such control.) The authors use this framework to study the generalization of two classes of networks commonly used in theorem proving (transformers and graph neural networks), as well as to explore the utility of MCTS in theorem proving. Furthermore, the ability to generate a large amount of synthetic data is of independent interest, and the authors refer to a recent work that has used their framework to generate training data for a different system. However, the authors could bolster their case by doing a survey of other papers in this area which are using real proof databases and see to what extent their results in this simplified setting agree with or disagree with the results there. (If so, this should also cause Goal 2 graph to change.) Why not generate the 1.5 million problems up front and then train on the entire training set? I am bumping up the score.<BRK>An approach to evaluate theorem proving using neural networks. Specifically, since for theorem proving the test data can be significantly different from the training data, the proposed approach develops a method to generate synthetic problems to simulate this. The paper is well written and has extensive empirical analysis for neural network based theorem proving. It produces a general approach that can be used to improve the state of the art in evaluation of neural network based theorem provers. I am not very familiar with  other approaches that can generate synthetic data for theorem proving, but it seems like this is first approach that can generate an infinite number of theorems with complex proofs which can evaluate generalization of the prover which to me seems to be a significant contribution. Further, the empirical analysis is extensive that includes several well known methods along several dimensions. I think this paper has sufficient merit with potential for significant follow up research based on the proposed benchmark.<BRK>The paper describes a synthetic dataset generator for inequalitystatements over ordered fields. The reason is to provide a test ofgeneralization ability of models in interactive theorem proving taskswith Lean examples given as motivation. A lightweight syntax treebased prover is used by the machine learning agents to attempt solvingthe generated statements. I am however still not convinced that the considered measurescorrespond well to the generalization ability that the paper wants toshow. For me the task is very simple in comparison with the claims. As such, I do not think that theresearch done in the paper supports the conclusions the authors draw.<BRK>It also trains learning based theoremproving on them and in particular compares transformers and GNNs. CoRR abs/1910.11797 (2019)[4] Cezary Kaliszyk, Josef Urban:Learning assisted theorem proving with millions of lemmas. The method for generating problems looks like quite a straightforwardapplication of the axioms to an initial statement. As I mentioned, just using the millions/billions of internal ITP/ATP lemmas has raised the performance much more in previous experiments. In general, I am also still quite skeptical that generating more and more synthetic corpora without good relation to real world math (and motivation by it) has much meaning and will lead to much progress in the ML for TP area. Theargument that there are not enough real world math data is flawed. Rather than being impressed by the wasted resources, I would advise the authors to focus on resource controlled setups and competitions such as CASC and CASC LTB. The comparison of transformers and GNNs is perhaps the most interestingpart of the work. While both settings have been used for ATP tasksbefore, this may be their first head to head comparison.
Reject. rating score: 5. rating score: 5. rating score: 5. rating score: 6. <BRK>This paper makes an attempt at combining semi supervised and active learning. Instead, this work attempts to use active learning to speed up the convergence to the asymptotic classifier (in terms of epochs) and semi supervised learning to achieve the exponential improvement in data efficiency. Strengths:   Integrating active learning into SSL techniques that perform well for image datasets is a good goal, as SSL techniques have dramatically improved for image datasets in the recent past. Promising empirical performance against a few other algorithms. Weaknesses:   The empirical results are only reported for a single dataset (CIFAR10). Although the proposed algorithm, Convergence Rate Control (CRC), is supposed to speed up convergence, only final accuracy is reported. Questions:   Can the authors describe more the "ill posed nature" of active learning? The issue I see with using the final layer is not performance related, it s that it seems to throw out the theory you claim to be using.<BRK>To optimize convergence rate, they try to select points that maximize the smallest eigenvalue of the empirical NTK over the final layer only, as an approximation (which the authors show seems to do similarly to computing the full NTK, when the next training episode of the active learning is warm started with the weights of the previous episode.Strengths:  The method is general to any SSL method, and the authors consider one of the more recent SSL methods, FixMatch. The use of SSL in the pool based active learning setup makes good sense. They use a nice tractable formulation of the convergence rate optimization objective through the eigenvalues of the NTK on the final layer only. However, there is not much theoretical or empirical evidence for this beyond some intuitions. Why is that?<BRK># SummaryThis paper introduces a novel method (CRC) to unify active learning (AL) and semi supervised learning (SSL). The paper claims that designing labeled datasets by querying can control the convergence rate. To design queries, the proposed method selects unlabeled data points that maximize the smallest eigenvalue of Neural Tangent Kernel (NTK). However, after querying, the model is reinitialized. I guess this degenerates performance. 1.Despite the interesting concept, the empirical results are not appealing.<BRK>This paper proposed an active learning strategy to improve the convergence rate for the semi supervised deep learning algorithm. When the SSL objective could learn a good approximation of the optimal model, the proposed method efficiently converges to the result with a few queries. The essential technique used here is the recent advance of the neural tangent kernel; that is, when the eigenvalue of the neural tangent kernel is large, the convergence rate is in turn fast. Inspired by this theoretical results, the authors provided the learning algorithm to maximize the smallest eigenvalue of the neural tangent kernel.
Accept (Spotlight). rating score: 8. rating score: 8. rating score: 7. rating score: 7. <BRK>When comparing ImpFlow and ResFlow, I suggest that you should additionally have a variant of ResFlow with the same *execution time* in addition to *number of parameters* as a corresponding ImpFlow. Together, this is a solid work that should clearly be accepted. This paper proposes a novel framework to formulate such invertible expressive functions implicitly.<BRK>ImpFlow is equivalently a composition of ResFlow and the inverse of a ResFlow. I think this paper makes a very solid contribution to the normalizing flows literature. This ideally should be accompanied by a reference or rephrased to be a conjecture.<BRK># SummaryThis work is about a new architecture for normalizing flows inspired by implicit neural networks. I checked the proofs in 4.2 and everything seems correct, great job! # Major comments## Pros:Overall the paper is well written and pleasant to read.<BRK>The paper has some typos and in many cases a spell checker could correct these. Even if ImpFlows are slower, it is really necessary to clearly highlight this difference in computation time. If the authors address the points raised in Weaknesses, I will consider raising my score.
Accept (Poster). rating score: 7. rating score: 7. rating score: 7. <BRK>The basic idea is to replace generator and discriminator in the energy based GAN with two source to target generation models. The discriminator(reverse generator) and the generator competes in a minimax game to reconstruct the data. The authors evaluated their framework on two tasks: image to image translation and silent video to speech reconstruction. The DINO method impressive improvement in both tasks. The proposed DINO framework is well motivated. The objectives in DINO are reasonable and novel. Important details are omitted in image to image translation and video to speech reconstruction.<BRK>This paper proposes a conditional energy based GAN technique for translation between data domains. I have tried to do my best in reviewing it, but I d appreciate any clarification of mistaken points from the authors. Overall, the idea itself seems reasonable: in conditional GAN based models, instead of using a discriminator that explicitly tries to predict whether the generated output is true or fake, the discriminator tries to maximize the reconstruction score of true outputs, and minimize it for fake outputs. I m not sure whether this is due to my lack of background knowledge in this field, or because the writing itself is unclear (perhaps a bit of both):1. It doesn t seem to be explicitly stated anywhere. 2.Given this, I was not sure if the baselines in Table 1 and 2 actually represent the state of the art in this domain. If not, why use these datasets instead of others? While I m not very familiar with the field, I do know that image style transfer is a big thing, and surely there are other datasets that people have evaluated on previously. 4.The description of Equation (1) was a bit hard to follow, as the role of the discriminator was not made explicit. 6.It was mentioned that MirrorGAN is the most similar method.<BRK>This paper presents a method for performing cross domain or cross modality translation models using a GAN flavored framework where two models are trained to translate in both directions simultaneously. [As a caveat: I am not well versed in this area of the literature]The paper is well written for the most part and the experimental results are promising. My main concern are the ethical implications of some of the lip reading experiments which go unaddressed. I found the use of the term "discriminator" confusing, especially in the beginning in the paper.
Reject. rating score: 3. rating score: 3. rating score: 5. rating score: 5. <BRK>In this paper, the authors proposed a new method to train DNN (partially) with fixed point weights and approximated natural gradients. Concerns: I have 3 major technical concerns and questions which lead to my initial rating to reject. Instead, the major baselines in the paper is training methods with low precision compute during training directly. 2.The definition of straight through estimator in this paper is not correct for general low precision fixed point training. The definition in the paper is only for 1 bit (binary) model weights; however in the experiment the authors considers 4 bit fixed point number.<BRK>## Summary The paper proposes a neural network quantization approach with a tanh based quantization function and claims that it is a good approximation to the natural gradient method. 2.Overall the paper is clearly written. ## WeaknessesThe main weaknesses of the manuscript in my opinion are as follows:1. Please clearly mention the dimensions of each variable and define them appropriately for all the equations. 4.Recent quantization techniques are not compared:	  For cifar experiments only comparison is done against the first quantization method BinaryConnect (Courbariaux, 2015) which is very old.<BRK>This paper proposed to incorporate local curvature information in the parameter space to assist the training of quantized model. Is repeated experiments conducted to reduce variance? However, it replaced the core part (FIM) in Eq.(8) with a smooth quantization (Eq.10), which is published before by another work. 2.This work used distillation and training of full precision model.<BRK>The authors propose an interesting method to train a quantized neural network with a natural gradient, which considers the curvature information of the model. 1.The authors assume that the connection between w and \hat{w} on the manifold can partially reflect the curvature distribution. As shown in Table 2, The authors didn t report the same number of baselines for each model.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>Conformal prediction (CP) allows for the selection of a set of candidate answers guaranteed to contain the correct answer with some probability. The authors propose two extensions to CP, 1. To extend validity for all admissible answers, 2. Reasons to accept: 1. The paper was well written and the approaches and experiments seem technically soundOverall, I believe that this would be a useful paper for the community, and based on the reasons given above I would recommend acceptance.<BRK>Summary:This paper presents two advances in conformal prediction, a field with information retrieval applications in which a set of candidate responses to a query is presented and the objective is to return a small set of responses with at least one of the responses being the correct response. The first contribution is a method in which the possibility of several admissible responses is modeled (rather than there being just one response) with the system being calibrated against the odds that a particular response is the "most admissible", i.e.most conforming to the joint query/response distribution being learned from data. Pros:Reasonably thorough experimental results demonstrating performance gains in terms of sensitivity/specificity as well as in terms of computational cost are presented. The paper is mostly well written and the theory is presented with a good amount of rigor.<BRK>The paper propose a conformal prediction (CP) approach in which the prediction output is not necessarily unique; and will be assumed to belong to a finite set. Then, the authors analyze how the classical CP set can be modified wrt to a relaxed requirement that it is sufficient to contains an admissible answer. This lead to a smaller set in expectation and a coverage guarantee is established, proving the validity of the method. Authors also provide a computational methodology to screen out non promising candidate. The paper is well written and provide practical numerical experiments that demonstrate usefulness of the introduced CP in "real" world. For instance in the latter, one could consider cascade parameterized by the optimization error.
Reject. rating score: 3. rating score: 4. rating score: 6. <BRK>The authors state that their network is able to calculate the acoustic scattering field in less than one millisecond for a given object. It is not clear how this compares to the baseline method or the state of the art (PointNet and DGCNN).<BRK>Edit after authors  revisions  The authors made some efforts to improve the exposition of the most obscure parts of the paper, but in my opinion this is not sufficient and I am still not able to fully grasp the connection between section 4.4 and 4.5 and the rest of the paper.<BRK>Strengths: The results for the method seem to beat out other similar point cloud based methods and I appreciate the application to a specific sound modelling problem. Their use of differential coordinates, use of a surface in latent space, and the construction of their feature vector are presented without much discussion of motivation.
Reject. rating score: 3. rating score: 4. rating score: 6. <BRK>* Some writing could be smoother and more terse in the Method section, i.e. " Minor points:* Methodologically, it seems the auxiliary variable strategy works well but I m not convinced it s the only way or the best way to solve the problem   both multitask and multi headed seem good at capturing the shape of the signal, with multitask often off by a constant. **Update**: After reading the rebuttal and revised paper, I am keeping my score the same. My prior is that there are at least 2 causal paths where you can predict SpO2 from ventilation signal: (1) hypoventilation >hypoxemia and (2) hypoxemia >hyperventilation.<BRK>Originality and Significance: Certainly the problem of learning blood oxygen levels is a significant one in high risk patients in ICU for instance. However, the originality of the modelling approach is not that unique.<BRK>Section 3 is not the right place to mention (some) results. The architecture implements "feature switches" that partition the data in a multi head manner with the ultimate goal of predicting auxiliary variables which will help the prediction. I like the idea of predicting one modality from another. My major concern is about the experimental section of the paper and some additional ablations (see cons below). ##########################################################################Questions during the rebuttal period:  Please acknowledge the potential use of cheaper and more accessible sensors. The structure of the sections could be improved as well.
Reject. rating score: 3. rating score: 4. rating score: 4. rating score: 4. <BRK>The main contribution of the paper is to modify typical message passing steps in graph neural networks to take more of the clause variable structure into account, and accelerate message passing in between clauses and variables, respectively. Questions to the authors (in no particular order):1  Please show comparisons with a state of the art optimization CSP solver such as IBM CPLEX s CP Optimizer or others.<BRK>Summary: The paper "Transformers satisfy" presents an improved graph neural network model to solve SAT problems. Prior applications of GNNs to SAT have used convolutional GNNs instead of Graph Attention Networks (GATs), and this work suggests a modification of GATs to improve their performance on the bipartite graphs encountered in SAT. What is cross attention?<BRK>### Summary The paper presents a model for inferring the solution of a constraint satisfaction problem over boolean variables expressed in *Conjunctive Normal Form (CNF)*. The proposed model builds on existing works which represent the factor graph of the CNF as a bipartite graph, and use a graph neural network for the learning task. The proposed model is evaluated on a set of benchmark SAT instances and is compared with an existing baseline method. It seems that the problem instances used in the experimental evaluation are all *easy* instances. I was not able to evaluate the difficulty of the instances from the dataset description.<BRK>This paper presents Heterogeneous Graph Transformer (HGT), a new architecture that combines useful properties of GNNs and Transformers to design HGT for combinatorial reasoning problems, particularly Boolean Satisfiability (SAT). It would be better to frame the work as a new approach for *satisfiable* instances of SAT.
Reject. rating score: 4. rating score: 5. rating score: 7. <BRK>This paper demonstrates that magnetic side channel information from a GPU (that is processing a deep neural net) can be snooped to recover the architecture and hyperparameters of the neural network. The paper also demonstrates that black box attacks mounted using a recovered model is quite powerful compared to traditional black box attacks. However, there is no core ML contribution made in this paper. The authors use standard ML models to map the side channel signal to deep learning model architecture. The use of model architecture consistencies as constraints is clever, but nothing significant in terms of contributions to the ML community. So, in my opinion, this paper is better suited for other venues such as cyber security conferences.<BRK>Summary:   This paper studies the effectiveness of inferring a neural network’s layers and hyperparameters using the magnetic fields emitted from a GPU’s power cable. The results show that (under certain assumptions) one can reconstruct a neural network’s layers and hyperparameters accurately, and use the inferred model to launch adversarial transfer attacks. Strong points:   The idea of using magnetic side channels to infer network structure is interesting. Attacker assumptions include:    have physical access to the GPU    know the exact input feature dimensions and batch size. However, I’m not sure if ICLR is the best venue for this type of contribution. This paper could be a much stronger submission to other security and system conferences. Comments & questions:  How do the authors imagine launching this attack in reality? How effective is this additional optimization compared with only using the initial estimation? Providing an example application does help readers understand scenarios where the threat model could apply. I adjusted my rating based on this better understanding.<BRK># Summary:The paper presents a method for capturing the shape (type of layers) and their respective parameters of a neural network through the magnetic field induced as the GPU drains power. In particular, the GPU is snooped using an off the shelf magnetic induction sensor which is placed along the power cable of the GPU. I share also the concerns raised in the other reviews that the paper might be better appreciated by an audience focusing on cyber security. However, I think that the subject can also be of relevance to ICLR as the paper made an effort to highlight the aspects more relevant to the ML community. The proposed method is able to recover the entire structure of various types of neural networks (including randomly generated ones) and the parameters of each step with very few errors. An interesting application is the use of the method to build surrogate models for performing black box adversarial attacks with very high success rates. In what range of sampling rates/placement distances the method works?
Reject. rating score: 5. rating score: 6. rating score: 6. <BRK>The proposed meta adversarial training (MAT) claims to learn a large & diverse collection of universal perturbations that aids the robust training. Specifically, this paper leverages the “reptile” meta learning method to learn the better initial values of universal perturbations, which may lead to better universal perturbations for updating the model. 2.The writing is sound. In table 1, why AT cannot defense transfer attack? 3 How & why does the initialization of the universal perturbations matters most? To be specific,  are there any justifications & explanations on the better initialization for aiding robustness?<BRK>Although the main idea of the paper is sound and empirical evaluations promising, there are some clarity issues with the writing of the paper: 1. Have the authors tried this when performing comparisons? Overall I think this paper is a solid piece of work, but the clarity of presentation has to be improved.<BRK>The authors propose a novel meta adversarial training method. In particular, to improve the robustness against digital domain attacks, the proposed meta adversarial training (MAT) combines adversarial training and meta learning, which reduces the computing cost compared with adversarial training by generating a set of stronger perturbations. 2.The proposed MAT is designed for robust defense by combining adversarial training and meta learning.
Reject. rating score: 5. rating score: 6. rating score: 6. rating score: 7. <BRK>Prior work in this domain learn an embedding space to compute reward between current state and goal. Then, the final state of a given skill s execution is used as a goal input to a goal conditioned policy, which is rewarded if it generates states that the discriminator identifies with this skill. ​​ ​# Strengths  The paper solves an important problem of unsupervised learning of goal conditioned policies. The current DISCERN baseline seems to be training the reward function on random exploration in the environment. ​  The section about disentanglement using information bottleneck seems orthogonal to the main contributions of the paper   about an unsupervised method to train goal conditioned policies. While the information bottleneck can always be used to improve generalization, it is unclear why its use is emphasized. It is rather more important to ablate the role of the intrinsic reward function proposed in this paper (as discussed in the above point). It is not always clear what the main contributions of this paper are. (c) Some parts of writing are incoherent and seem out of place at first. Are these goals just what were observed in training or are these manually crafted goal locations for evalution?<BRK>This paper proposes a method for combining intrinsic motivation on a state space with goal conditioned reinforcement learning (GCRL), where goals are defined in some “perceptual space,” such as text or images, which describe the current state. The authors propose to train an intrinsically motivated latent conditioned policy, using similar techniques as past work in which a policy maximizes the mutual information between a latent variable and the current state. The idea of using intrinsic motivation rewards to train a GCRL policy is an interesting and novel idea, and the experiments indicate that this is a promising approach. Currently, the writing does not make it clear that the comparison to RIG and DISCERN is not an apples to apples comparison: RIG and DISCERN do not assume access to the ground truth state, but rather operate directly in the perceptual space. This seems like an important detail, and it’s also unclear how the baselines could have been implemented in those cases.<BRK>Summary: The paper proposes a novel method for learning goal conditioned policy with images/text goals. Weak side: Several clarification on the motivation and details of the method is needed. Image/text goals is not intractable for current goal conditioned policies [1] 2. What do you mean by ‘extrinsic’ reward? (2) Therefore, I guess the authors wanted to claim they use ‘intrinsic’ rewards, which is a mutual information based reward. Now I have two questions for Section 3.2: 1. Why do we use this loss function Eq.(1)?It comes out of nowhere without intuition. In experiments, the effect of disentanglement is only demonstrated in a simple 2D task, which seems not enough. It seems super important, but I was not able to find its details in the paper. Significance: Learning goal conditioned policy with high dimensional goals is an important problem.<BRK>Summary This paper proposes an unsupervised learning objective for learning perceptual goal conditioned policies. The learning algorithm operates via alternating optimization, in which the skill conditioned exploration policy is learned jointly with a skill  discriminator  (inference network), and then the perceptual goal conditioned policy is learned using the discriminator as a reward signal, which essentially estimates the extent to which a robot is achieving a skill given a perceptual goal along the skill policy trajectory. A glut of experiments are used to investigate whether the method learns a meaningful skill reward function, whether it can achieve goals in various environments, how the method compares to related methods, and whether the specific  disentanglement  inductive bias for constructing the policy is useful. However, there are significant gaps in clarity that reduce my certainty in this assessment, and relatedly, there is some important missing discussion on the specific differences between the proposed method and prior work. The state representation for the archery task is unclear  The  fast imitation  procedure is unclear. The paper says the goals are the rendered states induced by the abstract policy, so how do the expert demonstrations get factored in? Significance In absence of knowing more about the specific differences between the proposed work and related works and the imitation learning experiments, the only thing that is clear is that the method seems relatively performant on an existing well motivated task across a large range of settings, and compares favorably to existing methods on this task. I don t think this aspect of the derivation follows from Jensen s inequality, as stated in the paper.
Accept (Poster). rating score: 7. rating score: 7. rating score: 5. rating score: 5. <BRK>ConclusionI think that the overall idea of reducing the computational load in 3d convolution architectures is a valid and important topic, as simply increasing networks and training data is not working for the majority of tasks. the channel tensorization can be used as intermediate building block e.g.in a ResNet alternately with a Res block. The paper shows competitive results on Something Something as well as on Kinetics 400  The visualization supports the claim that the attention mechanism seems to learn to focus more on relevant parts of the video clip.<BRK>The paper proposes a novel Channel Tensorized Module (CT Module) to construct an efficient tensor separable convolution and learn the discriminative video representation. Strengths:  The paper s novelty is the first method for exploring the spatial/temporal tensor separable convolution along each sub dimension. Results of the Sport1M dataset (standard video classification dataset) are missing. Since earlier modes were having better performance on the Resnet 152 model, the authors could have experimented with the Resent 152 model as well. The dataset used for the comparison of visualization in Fig.3 is missing. If authors can showcase the performance of proposed models on other domain datasets (say 4D fMRI or 3D medical imaging datasets), it will be more interesting. Typos:   Page7:  In our experiments, to ensure GFLOPs is comparable with other methods.<BRK>To achieve that, the authors propose to divide feature channels into several sub dimensions (called channel tensorization) and then perform group convolutions at each sub dimension sequentially to improve channel interactions. The paper also provides detailed ablation studies on the approach. Another downside of the proposed approach is that it is not sufficiently validated by experiments. As indicated in the work of X3D, the performance gain from using more clips (i.e.>5x10) in evaluation is small. X3d: Expanding architectures for efficient video recognition.<BRK>By decomposing the channel dimension into sub dimensions in the typically 4D video data (Time, Channel, Width, Height), one defines spatial temporal separable convolution for each sub dimension. This could improve the representation learning in term of efficiency and modeling quality. Pro: the experiments seem quite thorough. Would it be possible / sensible to apply tensorization on the time dimension?
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 6. rating score: 6. <BRK>Summary: This paper suggests a new decoding algorithm of linear error corrections codes based on self attention. Reasons for score: The main idea of using self attention for decoding linear error correction codes is interesting. My main concern is about the justification of the usefulness of the proposed scheme. I like this point, but I think the authors need to show the performance of the other existing schemes (other than the "baseline decoders" of the current manuscript) altogether to easily show the usefulness of the proposed method. Also, it would be better to clearly explain the complexity/cost of using the proposed scheme. For me, this sentence seems important as it might be directly followed by the statements that explain the usefulness of the proposed algorithm. For me, it is not clear why the top k (k>1) performance matters to measure the quality of the decoding algorithm of error correction codes for communication.<BRK>[Main Weaknesses] The paper s main weakness is that it seems the motivations for choosing four different BCH codes (in Section 5) are not justified clearly. It will make the authors claim stronger if they explain why these represent linear codes cases (unless the permutation decoding only applicable to the BCH codes). [Technical Comments] 1) Can this approach be extendable to other types of channels (e.g., channels with memory)? [Typographical comments]1) For better readability, Section 4 can be moved to later (e.g., after Section 5). 2) page 2: "a self attention model (introduced in Section 2)" should be "a self attention model (described in Section 2)".<BRK>The focus of the paper is error correction codes. In order to select the most promising permutation without running the soft decoding algorithms, two main ingredients are used: (1) node embeddings of the Tanner graph of the code via the node2vec method, (2) a self attention mechanism that preserves the similarity between two permutations through the node2vec transformation, resulting in close geometric representations. The node2vec embedding is pretrained on the Tanner graph of the code. A permutation classifier is trained jointly at the same time, outputting the probability that a given codeword and permutation will decode correctly. I find the construction proposed in the paper quite interesting. The experimental evaluation should provide a convincing argument. Only BCH codes were used for evaluation. It would be great to see evidence that the method scales to large code lengths (thousands of bits). Moreover, how does the method perform on codes with high rate? Minor comments:  It seems that WBP is not defined (is it weighted BP?)<BRK>In permutation decoding, one aims to decode a permutation of the received codeword in the hope that it will lead to successful decoding as compared to applying the decoding algorithm on the received codeword. The classifier itself relies on an embedding model for the permutations which utilizes a self attention mechanism to embed permutations. The utilization of self attention to this area is novel (to the best of my knowledge). The latter should be addressable with minor revision. Pros: 1.The paper utilizes the self attention mechanism to improves the computational complexity of permutation decoding. 2.The paper empirically demonstrates the utility of their proposed method on BCH codes. The paper does not present any broader ML techniques that might be useful beyond the immediate scope of the paper. 3.There is some room for improvement in the presentation of the paper. The discussion in Section 3.2 can be made more clear. How is the same node embedding v being used for all $i$ in $w_i   u_i + v$? After going through other reviewers  comments and the authors  responses to those, I am comfortable with my original score.<BRK>The methodology is based on a permutation classification procedure (trained beforehand), where each permutation is encoded into an embedding vector obtained using the concept of self attention, to account for the geometric similarity between transformations. It is unclear how this attention looks between the permutation vectors, but in the end what matters is the embedding obtained, and how it captures the similarity between them, and also, I believe, some relations with the syndrome. * In page 4, when indicating the dimensions for the matrices to learn, I believe the dimensions are wrong, as they should be $\mathbf{Q}, \mathbf{K}, \mathbf{V}\in\text{R}^{d_p\times{d_w}}$. Besides, the paper is nicely and clearly written, with all the important details explained and all the required background information, which allows perfectly understanding the methodology. IN BPL, although it is applied to Polar codes, the authors finally make use of only 5 different permutations, which is not that ineffective, and enable them to report a great performance. * The previous concern also takes me to Fig.3a, where we can observe how there is still a lot of room for improvement, as taking the 5 top permutations still yields some extra considerable improvement. * When performing the ablation studies, it is not clear to which of the codes those degradations correspond. I consider depicting such comparison quite important because, in some cases, it seems that the degradation may take the model to worse performance than rand WBP. ##### Decision, and key reasonsAccept, after discussing and further elaborating some of the previous concerns. Despite the previously described issues, I believe the paper presents an interesting method to advance the current state of permutation decoding. If not, perhaps please comment on the selection of permutations done in approaches like BPL, and how that selection criterion won’t be applicable here.
Reject. rating score: 3. rating score: 4. rating score: 4. rating score: 6. <BRK>This paper considers the maximum entropy (MAXENT) method for estimating underlying probabilities over a finite alphabet, i.e., the multinomial model. The authors compare MAXENT with the regularized maximum likelihood, that is the Bayesian estimator under the Dirichlet prior with a common hyperparameter, and the Bayesian estimator with a general Dirichlet prior in terms of the Bayes risk, i.e., the KL divergence from the true distribution to the estimated distribution averaged over the prior. Although the practical performance of MAXENT is of interest, the paper provides little novel knowledge about it. Minor:Right after eq.(15): \alpha_k^{[1]},..., \alpha_k^{[L]} (The last one should be \alpha_k^{[L]}.)<BRK># SummaryThis paper investigates maximum entropy (MaxEnt) inference and compares it to a Bayesian estimator and regularized maximum likelihood for finite models. Using numerical experiments, the authors find that the performance of MaxEnt deteriorates for sparse data generated from uniform models. Therefore, I would rather reject the paper in its current version.<BRK>In this paper, the authors discussed the maximum entropy method of obtaining estimators for discrete probability distribution. They authors then performed numerical experiments comparing the maximum entropy method under different constraints and the regularized maximum likelihood estimator. I find that overall the writing is fine but some parts were quite difficult to understand. In Bayesian statistics, you endow a prior on the model of the truth and not directly on the truth. The line after (15), do you mean $\alpha_k^{[1]},\dotsc,\alpha_k^{[L]}$?<BRK>2.This paper proposes a novel MAXENT method to compete with maximum likelihood in sparse data. The idea is original, and the motivation is strong in theoretical analysis. 3.By assuming a well defined prior Dirichlet density for unknown probabilities, it employs the average KL distance in evaluating the relevance of various MAXENT constraints, checking its general applicability, and comparing MAXENT with estimators having various degrees of dependence on the prior, the regularized ML and the Bayesian estimators. I’m confused about the application scenarios of the proposed method. The authors did not show any application value, though they claimed that MAXENT has a large number of applications in applied machine learning. The proposed method is not easy to understand and implement. The author should at least add one real data application.
Reject. rating score: 3. rating score: 4. rating score: 5. rating score: 5. rating score: 6. <BRK>### SummaryThe paper proposes a method to jointly learn: (a) a latent state embedding; (b) a latent action embedding; (c) a state transition model; and (d) an RL policy. The latent models should allow for better generalization over states and actions, and therefore result in improved learning, particularly for discrete action domains. It is unclear to this reader how to situate this work in relation to those. The approach needs to be discussed and evaluated in the context of other latent "world models", and to show benefits on more challenging problems. 4.3.1 component (iii): function g:  How is g well posed, given that it is inverting a possibly many to one mapping? How has this been tested emperically? Doesn t this also mean that some of the benefits of the latent space are lost, if working from possibly redundant state observations? How would these algorithms fare for the other problems? Instead, it refers to separate state and action embeddings, which are jointly trained during learning, along with the policy. Figure 1b: label the transition model, T4.2 Assumption 1: Given an _action_ embeddingConcluding sentence for the paper:  this makes a very strong statement that is not really supported by the results.<BRK>The paper proposes a framework of jointly learning a state and action embedding using the model of the environment, eventually using those embeddings to learn a parameterized control policy using standard policy gradient (PG) methods. Joint learning of state and action embeddings allows us to capture the interactions between actions in different states. As is, however, the paper needs a bit more work for three primary reasons. Firstly, the embedding for states and actions involves a joint optimization, but the embedding itself seems to be separate for the two. The properties of the learned embedding could be better explained. Second, the experiments do not clearly highlight why the joint state and action embedding might help learn a good policy. Page 1, Para 3 mentions the proposed method to bridge the gap between model and model free learning. In Equation (3), these are then used as distributions, rather than deterministic functions. 3.If the space permits, it is good to include an example where a joint state action representation will help in learning the policy. It would be more clear to use separate notation to represent the optimal set of internal policies, maybe \pi_i^*. 5.Looking at Figure 2(a,b,d) JSA seems to have worse asymptotic performance. It s good to see many of the experimental details mentioned. I would recommend including the following details:  	a. Also, more details on the reward function would be helpful; it seems like the agent can earn a high reward, even for wrong predictions, given the user is purchasing expensive items. 3.Gridworld experiments: There are some details which are missing from the environment. For example, what is the exact reward function? http://arxiv.org/abs/1806.06931  UpdateThank you for the update and response. Unfortunately, some of my concerns remain. The plots are now run with 10 runs, rather than only 5 runs in Figure 5. That is not possible, unless there is a potentially invalid choice in the experimental design. If nothing else, the standard error should change. The theory itself has some utility, since it is shown that learning in embedding space is equivalent. Nonetheless, this could maybe be shown more simply, and I am not sure Lemma 2 is exactly correct. Maybe you are suggesting that d_0 is some kind of delta distribution, but then it might be better to just sum over the same set of s.I am also a bit unsure about any smoothness assumptions required. The requirements on the one to one mappings between discrete state to continuous state make for a piecewise flat function that could be problematic for such gradients. More explanation is needed there.<BRK>This paper explores the idea of using state and action embeddings for more scalable learning. The idea has merit so I encourage the authors to continue working in this direction, but unfortunately there are a number of technical issues with the paper that I detail below. Letting $g:A\rightarrow E$ be the action embedding function, we can see that $g(a)   g(b)   e$, which means that any internal policy will be suboptimal, as it will choose the same latent action for both $x_1$ and $x_2$. Part of the issue may lie in the way the proof is structured. The main issues for me are:1. However, the way they ve included it in the definition of $v^{\pi}$ seems like it does _not_ depend on $s $ and is really just $Q^{\pi}(s, a)$. The other bug I found in the proof is at the top of page 12. Artificial I Intelligence 147(1 2): 163–223. The authors make a number of claims about their method working for continuous spaces, but this requires more details than simply replacing integrals for sums. Given that the authors motivate their work by claiming that existing algorithms don t work well outside of "simple" tasks, they should include larger scale experiments than the ones they are currently including, which are rather small. It s basically just converting the original state space into an isomorphic one. In the Introduction the authors refer to the ALE as "comparatively simple tasks", but they are not simple and are in fact more difficult than any of the environments evaluated in the paper. 2.**Lemma 1 is not correct. **    Consider the following simple example: an MDP with two states ($s, t$) and two actions ($a,b$). The optimal policy is to take action $a$ from state $s$ and action $b$ from state $t$, resulting in $V^*(s)   V^*(t)   \frac{1}{1 \gamma}$.<BRK>It proposes to use an environment model to obtain embeddings for state and action and then such representation should enable better generalization across state action space. Experiments on several gaming and recommendation systems are conducted to show the superior performance of the proposed method. Novelty.The idea is not new but the particular method of defining a policy in the embedding space seems to be new. The work may be of general interest to the reinforcement learning research community. Quality.There are a few theoretical and empirical issues in this work. First, one action can correspond to many embeddings and one embedding can correspond to only one action. Intuitively, one wants to enjoy generalization across different actions. Second, I do not see why the assumptions can get satisfied in practice. Third, based on the two assumptions, lemma 1 and theorem 1 are not that interesting. Furthermore, the bottom line says that theorem 1 indicates one can focus on the optimization of the overall policy \pi_0; however, theorem 1 indicates only the existence of \pi_0 equal to the optimal policy in the original MDP, it is unclear if optimizing \pi_0 according to Alg 1 can really lead to the optimal one. I think this is another serious concern of this paper. Although I agree with the general direction of learning some sort of joint embedding of state action pairs, I am not persuaded by the motivation of using the method proposed by the authors. Why such simple way cannot be used? In general, the experimental results are not really strong. Given the weak motivation of the proposed method and the proposed theory, I think the most important experiment should be designed to show the method is indeed superior to other intuitive baselines. As I mentioned, one baseline is to simply take both state action as input. Another intuitive baseline is to simply learn state action representation by using an environment model first and then based on the learned representation to learn a policy.<BRK>This paper addresses this issue by learning a joint state action embedding and learn an internal policy(\pi_i) on this embedded state action space instead of the original state action space. There are three parts of learning, 1. learning the embedding model that learns mapping from state to state embedding, 2. learning the internal policy, and 3. learning the mapping from action embedding to action space. The authors justify this approach by showing that the overall policy (\pi_o) can be expressed in terms of the internal policy (\pi_i). Furthermore, there is equivalence between the internal state action value function and overall state action value function and the authors show that updating \pi_i is equivalent to updating \pi_o. The benefit of learning a policy on these joint state action embedded space is that any policy gradient algorithm for continuous control can be used regardless of whether the original state action is discrete or continuous. The authors claim that learning on this joint state action embedded space is especially helpful in large discrete state action spaces because relationships between state and action are often not clear with discrete representations. They propose learning an internal policy backed by theoretical proof that show this is equivalent. Their results especially on the gridworld domain and slotmachine showcase the purported benefits of using their joint state action space embedding (JSAE). I would overall recommend a weak accept, and I think strengthening the experiment part would make this a much better paper. Was it because it is a simple algorithm without complex structure? No replay buffer is necessary? Second, I think there could be more discussion and insights into the various hyperparameters for JSAE. The authors hypothesize that it’s because the joint embedded space helps learn the relationship between states and actions. But were there any effects due to reduced embedded space? ), and other observations that the authors found while running the experiments would improve the paper a lot. SAC is known to have great performance on these continuous mujoco domains and it would be better to use SAC as the baseline and compare SAC JSAE. HalfCheetah is also known to be one of the easy environments in Mujoco; I would be curious to know whether SAC JSAE shows large improvements in high dimensional domains like Humanoid.
Accept (Poster). rating score: 8. rating score: 8. rating score: 6. rating score: 6. <BRK>Summary:The authors introduce a framework for sufficient conditions for proving universality of a general class of neural networks that operate on point clouds which takes as input a set of coordinates of points and as output a feature for each point, such that the network is invariant to joint translation of the coordinates, equivariant to permutation of the points and equivariant to joint SO(3) transformations of the coordinates and output features of all points. Notably, this class contains Tensor Field Networks (TFN). For a simple class of networks and for TFNs, the authors prove D spanning. Recommendation:The authors proof the useful statement of universality of a prominent class of neural networks, which is why I recommend the acceptance of this paper. I get a bit confused by the wording in Def 1.<BRK>**The authors claim to: (1) introduce a general approach for proving universality of rotation translation permutation equivariant models for point clouds; (2) prove universality of two recent rotation equivariant point cloud networks and (3) introduce two rotation equivariant architectures for point cloud processing**Strengths:**The paper is well organized and both the language and notation are clearThe authors consider equivariant representation learning which is of growing interest to the communityThe authors present theoretical insights for the success of recent architectures The insights themselves are leveraged to support the introduction of two new architectures**Weaknesses:**The novel architectures are described but not evaluated; it is therefore unclear what impact the simplification will have in practiceIt might be nice to point out rotation equivariant architecture that is not universal**Clearly state your recommendation. **Theoretical issues in deep learning is a relevant topic area for ICLR.<BRK>First, the authors derived two sufficient conditions for equivariant architectures with the universal approximation property. Then, they examined two methods based on the Tensor Field Network to prove that such a property holds for both of them. This paper is full of theoretical analysis, which is based on investigating the equivariant polynomials in the group theory. Therefore, it is difficult to verify the correctness and feasibility of the proofs. The authors do not provide experimental results to demonstrate the performance of the proposed new methods.<BRK>This work is a theoretical paper investigating the sufficient conditions for an equivariant structure to have the universal approximation property. They show that the recent works: Tensor Field networks and Fuchs et al., are universal under the proposed framework. Hence the study of the universality of network with such property is important to the community. Cons:  The paper is quite difficult to follow. In addition, the paper doesn t provide any evaluation of the proposed new universal architectures.
Accept (Poster). rating score: 7. rating score: 6. rating score: 5. rating score: 5. <BRK>### Summary This paper considers the problem of adapting a pre trained model for few shot learning in case there is a shift of distribution from the meta training set. If the new tasks significantly differ from the meta training distribution the model might need to be retrained from scratch but this is not always possible, so the authors propose to "repurpose" the model under the assumption that the support set can be used to re calibrate the pre trained model to the new shifted distribution. In practice, the uncertainty of the parameters is computed by using deep ensembles with perturbed MAML checkpoints rather than random initialization. High variance components are moved with lower step sizes. Does the method apply to that situation? Q0b: also the use of deep ensemble and the proposed UFGSM maybe can be useful in the supervised learning scenario to improve robustness. I would have expected the opposite because of the limited number of samples. The experimental campaign is carefully performed as well as the ablation.<BRK>The paper tries to solve a novel practical problem: adapting pretrained meta learning checkpoints to out of domain test tasks. Therefore, the meta training process which requires a relatively large data set is not practical. The paper also proposes to add task adversarial examples to the training set to help the meta fine tuning process. One main concern I have in mind is, existing domain adaptation or domain transfer methods are trying to solve very similar problems, i.e., the model is pre trained with large data set from other domains and you need to adapt it to the new domain.<BRK>The paper proposes to reutilize pretrained MAML checkpoints for out of domain few shot learning, combining with uncertainty based adversarial training and deep ensembles. In particular, the related work part provides a clear introduction of background work. 2.It is quite novel to leverage adversarial learning as data augmentation for meta testing in MAML. 2.For the ablation study, the authors mention that the best absolute performance (Top 1) is always obtained through some use of adversarial training.<BRK>Let us denote this as $\theta_0$ (2) In the meta testing stage, we go from $\theta_0$, given the few shot test data, via an SGD process (typical scenario), to get a final model that has good performance on the test data of the test task. This paper considers a setting (as I understand) where the test task is out of distribution of P(T). The proposed method contains two main parts: (A) We use an ensemble method to help understand uncertainty of the network, and finally use different step sizes for different layers for updating the network parameters at test adaptation phase, (B) adversarial training as data augmentation to help the test time adaptation process. I am not sure I entirely accept the authors  statement about testing tasks being out of distribution compared to the training tasks. In the original MAML setting, the test tasks can be entirely different from the training tasks (for example, we pick test tasks from different classes). And indeed, if we look at the performance numbers, the improvement is somewhat marginal. However, the arguments for why they are useful are quite ad hoc (to a degree that I feel superficial, no offense).
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. <BRK>In particular,  this paper tries to form a system of linear equations to find a training data point when the gradient of the deep learning model with respect to that data point is available. The authors have improved the paper and addressed my concerns.<BRK>Is this a general trend? Experimental results on MNIST and CIFAR10 show that the proposed method R GAP is comparable or superior to the classic DLG method. The authors also claimed the proposed method to be much faster than DLG baseline. My largest concern is over the lack of necessary experiments to show the advantage of R GAP.<BRK>The authors proposed a theoretical explanation of the gradient attack on privacy. Whether the proposed method is able to address those? Overall, this paper is easy to follow and well written.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. <BRK>  Overall:This paper analyzes the side effect of knowledge distillation in NAT where the lexical choice errors on low frequency words are propagated to the student model from the teacher. In my view, the submission is well motivated and the designed experiments and results are meaningful and convincing which deserves an accept.<BRK>The proposed approach is simple to implement. This paper follows up on the work (Zhou et al.) Moreover, both the metric used in the paper (AoLC) and the prior depend heavily on the quality of word alignment.<BRK>This paper does a great job of motivating the problem of lexical choice error propagation on low frequency words from the autoregressive teacher to the non autoregressive student. 2.The proposed prior knowledge approach is simple to implement, and yet provides decent improvements across all four datasets.
Reject. rating score: 4. rating score: 6. rating score: 6. <BRK>This paper provide a method for high order structure prediction problem. The features are also used in the proposed method for high order structure prediction. The kernel estimator also plays an important role in capturing the high order interactions in the evolving graphs. Second, the paper provides with theoretical analysis on the consistency and asymptotic normality of the proposed kernel estimator. Also, in the time complexity analysis, does the complexity of counting number of simplices of each d need to be considered?<BRK>I couldn’t see any insight for how information is encoded by the proposed method. The paper proves consistency of the estimator, meaning that the estimator converges to the true function in probability. I haven’t checked the proofs in details but I appreciate the analytical effort that was put into this paper. Strengths: 	For the problem of predicting higher order (incremental) structures in an evolving graph, authors propose a method which predicts formation of higher order simplices from existing ones, while capturing substructures between vertices of the simplices. These tasks are not aligned with each other and prior work is not designed for the experimental setup proposed in the paper. al.2018 or hypergraph based approaches? This is not properly defined and creates a confusion.<BRK>This paper presents an estimator that predict higher order structure in time varying graphs. 3.It would be nice if the authors could give an example of a scenario where the process is alpha mixing. The authors also present some experiments on real world dataSome comments and questions:1.
Reject. rating score: 5. rating score: 5. rating score: 5. rating score: 6. <BRK>6.I believe if CMP is generalized to other differentiable NAS, CMP is very useful as a search time reduction tool for differentiable NAS even it does not achieve SOTA. For this, this paper proposes binary neural architecture search and consecutive model parallel (CMP). 7.Instead of model parallelism, if we parallelize the learning of architecture parameters and network weights as below concept, it seems to be reducing the search time more than CMP. ##############################################################Summary:This paper provides the interesting method that leverages GPU memory resources more efficiently for supernet (meta graph) of differentiable NAS. The proposed method shows 1.2x faster search time compared with other model parallel methods and the highest performance among differentiable NAS methods in the experiment section. I believe that the subject this paper handled is important and I like the idea which parallelizes the model (supernet) which has high potential of usefulness. During rebuttal period, I hope the authors can address my concerns. This paper tackles the main problems of the neural architecture search field: 1) search speed 2) resource efficiency 3) scalability of search space. Although this paper shows many experiments, I have some concerns about the reliability of the experimental results for the baseline models as follows. Could the authors report the search results on CIFAR 10 of the proposed method under the same search space of PC DARTS? Since the batch sizes between NASP and NASB are different in Table 1, the effectiveness of each proposed binary neural architecture search is unclear for me. I guess the proposed model will be effective for large scale dataset such as ImageNet 1K. Could the authors validate the proposed method on ImageNet 1K?<BRK>####Summary:The paper proposed a binary neural architecture search with consecutive model parallelism to tackle the OOM problem for NAS. This approach effectively improves hardware utilization and saves GPU memory. ####Strengths:The idea of consecutive model parallel is cute, effectively overlapping the pipeline from two models. The paper is well written. However, the paper does not provide strong empirical results on larger models constructed using larger supernets. It can be true that larger search spaces make the search and optimization more challenging. But assuming spending more search and training time, the method should be converging to better models. Layer wise search space can be much larger than the cell based search space. The reviewer strongly believe the paper can make a bigger impact by enabling a larger search space and demonstrating SoTA performance on more impactful workloads, like ImageNet. There are many related approaches to reduce search time and improve search efficient, such as a latent space search via NAO, or using a surrogate cost function, or using search space pruning via MCTS.<BRK>This paper proposes NASB CMP, which overlaps sub tasks of forward and backward phases to reduce idle time across GPUs and utilize binary architecture parameters to reduce GPU utilization for heavy supernets. Experiments on CIFAR 10 show NASB  CMP runs 1.2× faster with a large batch size of 896 than other model parallel approaches in 4 GPUs. The large memory usage for NAS algorithms is a critical issue. The Consecutive model parallel (CMP) overlaps the two forward sub tasks and two backward sub tasks is novel, while the path level binarization is not new. Although the search cost is significantly reduced, people care about the quality of the search. It s hard to convince people that this approach is better. Given Cifar has a lot of randomness, most NAS algorithms need to demonstrate the effectiveness on ImageNet. The paper needs a more convincing evaluation.<BRK>##########################################################################Summary: The paper presents a method to run large batch size with supernets method for Neural Architecture Search (NAS). It also shows model parallelization method CMP that allows 1.2x search speed improvementUsing a large batch improves the test accuracy because it allows the model to train on wider variety of data in the backpropagation. ##########################################################################Reasons for score: NASB CMP algorithm that can use supernet with large batch and run fasterThe paper shows model parallelization method CMP that allows 1.2x search speed improvementThe paper also shows that it improves the quality of the models by using this techniqueThe paper is clear and coherentTesting the approach on other NAS Benchmarks (NAS bench201) would be interesting. Provide GPU system details that the experiments where ran on for the comparison with other methods.
Accept (Poster). rating score: 8. rating score: 7. rating score: 6. <BRK>Overall, the paper provides a comprehensive study of the impact of preconditioning/second order methods/natural gradient on generalization by giving a precise analysis in tractable regression settings, which illustrate conditions under which preconditioning is or is not useful for better generalization.<BRK>The analysis is described as difficult, although no details are provided into how this result was obtained. In this regard, I feel the authors should focus on a single phenomenon that is supported by both the parametric and non parametric aspects of the paper, for instance, how pre conditioning helps against misalignment. C3) The manuscript can be difficult to read. [2]   D. Richards, J. Mourtada, L. Rosasco "Asymptotics of Ridge (less) Regression under General Source Condition", arXiv:2006.06386 (2020) [3]   Wu, D. and Xu, J. "On the Optimal Weighted $\ell_2 $ Regularization in Overparameterized Linear Regression" NeurIPS 2020<BRK>Summary:The paper studies the effects of preconditioning on generalization properties in deep learning. By using a bias variance decomposition of the expected risk, the paper determines optimal precondition matrix $P$ for bias and variance. Finally, it extends the analysis to the reproducing kernel Hilbert. In particular, by decomposing the risk into a sum of a bias and a variance, the paper addresses the following points:1. 3.The paper is not well organized. For me, it is a collection of results that are unconnected.
Reject. rating score: 4. rating score: 5. rating score: 6. rating score: 7. <BRK>The paper investigates how well data augmentation can help improve the performance of contemporary deep learning models for Knowledge Tracing, which is a key task for educational AI. The authors propose three different types of data augmentation strategies: replacement, insertion, and deletion. The authors provide a detailed experimental section with ablation studies, highlighting the benefits of using their model in addition to recently proposed models. beyond just wanting to add noise in the training. In general, it is my understanding that this is 3 augmentation functions, something similar to dropout or synonym replacement. Also I don t think massive language models are relevant to your problem. What is consistency and contrastive learning? you reference 7 papers, but give no intuition about it s relevance to your work. I dont get figure 2 when reading the paper from end to end, I don t think it should be on the top of page 3 when it s referenced in the results section. there s a huge difference.<BRK>Knowledge tracing is a longstanding task in educational data mining and has been tackled by various studies. This paper proposed that three data augmentation methods (along with different types of regularization losses) can be applied to boost the performance of existing deep neural network models for knowledge tracing. Overall, the methods developed by this paper seem technically sound. In particular, the experiments are rather extensive, i.e., four widely used datasets were employed in the experiments and different variants of the methods were investigated and compared. 1.It would be good to provide a more detailed description of existing methods for knowledge tracing, e.g., what their limitations are and how the methods proposed can (theoretically) overcome their limitations? Any other evidence to show that overfitting is a common problem in existing deep neural network models for knowledge tracing? 3.Also, it would be good to provide additional data analysis results to support the assumption behind the three data augmentation approaches?<BRK>The authors show that various forms of augmentations can improve the performance on knowledge tracing. The experiments are conducted on ASSIST2015, ASSISTChall, STATICS2011 and EdNet KT1. The monotonicity constraint is specific to the knowledge tracing task though. More ablation studies on the hyperparameters would be beneficial. The paper tackles a less well studied task so more experiments should be added. Would consistency training leads to more improvements when the training data is limited? 2.How would the hyperparameter in insertion, deletion and replacements impact the performance? 3.Would more advanced augmentation lead to better performance?<BRK>This paper presents some enhancements for Knowledge Tracing (KT), in which predictions are made about the odds of a student answering a question correctly given a sequence of correct/incorrect responses to previous questions. If an additional correct question is added to the data, the odds of the student being correct on the next question should go up, and the odds should go down for questions being removed and/or added with incorrect responses. The learning algorithm s objective function is augmented with additional terms which encourage the model to obey these constraints. The experiments are reasonably thorough (4 benchmark datasets are tested) and non trivial accuracy gains are demonstrated, although dramatic gains are only achieved on 1 of the 4 benchmarks. A Google Scholar search of other ML work on monotonicity may also be beneficial if the authors seek to continue this line of research. al.I would have appreciated more information about the  skill sets  associated with each question and how that impacts the replacement. However, if there are multiple skills associated with the question, wouldn t it make more sense to choose replacements based on percentage skill overlap than a simple binary detection of any overlap? Further comments:One comment I have (and I recognize that not everyone)Some typos:Impose certain consistency or monotonicity bias on model’s predictions  > biases on the model’s predictionsFig 2 randomly insert intractions – interactions…even the student answered more questions correctly  > even if the student answered more questions correctlywhen other researchers will pursue to improve the generalization ability of KT models in the future > for other researchers attempting to improve the generalization ability of KT models.
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 6. <BRK>This paper presents parallels between algorithmic fairness and domain generalization literatures. remain to be understood. While the supporting experimental results are not very strong, the connections observed are interesting. ** While the introduction of the paper is written nicely and the ideas are communicated nicely, the mathematical exposition and presentation in this paper is not self contained. The author did not even acknowledge the existence of the prior work, REPAIR, in the revised paper. Have you tried a GDA version of the algorithm?<BRK>Summary: This paper studies the connections between algorithmic fairness and domain generalization. As discussed in Section 2, the “environment” in domain generalization plays a similar role as the “group membership” in algorithmic fairness. Strength:(1) The connection between domain generalization and algorithmic fairness shown by the paper is interesting. Weakness:(1) Other than the high level intuitions and examples, the paper does not provide any theoretical analysis of the performance of the EIIL for domain generalization.<BRK>I still find parts of the discussion in Appendix F to be unclear. I am not entirely sold on the general theme of this paper of exchanging lessons between fairness and domain generalization. At the very least, this requires a discussion.<BRK>The main contribution of the paper is to highlight the similarity between two active areas in ML namely "domain generalization" and "fairness".
Reject. rating score: 5. rating score: 5. rating score: 6. <BRK>This paper presents to model both inter sample and intra temporal relations. 2.The presentation of the experimental section is also hard to follow. Strengths: The idea is reasonable and the application is important. The notations are messy.<BRK>The paper proposes an approach for self supervised time series representation learning by using inter sample and intra temporal relational reasoning. If not, Eqn. However, the inter sample loss function seems to be a straightforward application of ideas in self supervised learning literature that rely on various augmentations to create positive and negative pairs of samples. Given the above, a more thorough and consistent description of the contribution in light of recent related work and empirical evaluation is needed.<BRK>**Summary**This paper presents a general Self supervised Time Series representation learning framework. The paper is well written and easy to follow. The organization is good. 2.The architecture is well motivated. The used dataset is small scale that makes the task simple.
Accept (Poster). rating score: 8. rating score: 8. rating score: 7. rating score: 5. <BRK>This paper studied the convergence properties of the proximal GDA algorithm for solving nonconvex strongly concave optimization problems. Overall I believe this is a novel and important work in minimax optimization. It conveniently simplifies the analysis of minmax optimization into the analysis of min optimization via Proposition 2. Moreover, under the general KL geometry of the Lyapunov function, they formally proved that proximal GDA converges to a single critical point.<BRK>In this paper, the authors analyze the convergence of a proximal gradient descent ascent (GDA) method when applied to non convex strongly concave functions. The related material are referenced and well discussed in the paper. To show the results, the authors provided a novel Lyapunov function and analyzed the convergence using KL local geometry.<BRK>## SummaryThis paper discusses the convergence of the proximal gradient algorithm in the case of KL geometry. I think its main strength is the simplicity of the discussed algorithm and I hope that it will lead to further extension. The work is purely theoretical, but I still think it could benefit from some numerical experiments, especially if the authors identified a practical setting that can be described by the paper s assumptions. 2.The Lyapunov function in Proposition 2 is quite interesting, but the quadratic term is not really explained. 5.The authors wrote "The Kurdyka Łojasiewicz (KŁ) geometry <...> has been shown to hold ubiquitously for most practical functions"   I think this is a big overstatement,  I haven t seen any example that would be relevant to the minmax optimization.<BRK>In this paper the authors analyze a proximal gradient descent ascent method for nonconvex minimax problem under specific assumptions (another name would be a forward backward algorithm). 3. page 14, Eq.25: the notation in the end is incorrect (as well as in page 4). Subdifferential is a set. I have two main concerns. 4. page 2, "The Kurdyka Łojasiewicz (KŁ) geometry provides a universal characterization...": I am afraid, this is not true, it does not provide a universal characterization. 5. page 2, "a very novel Lyapunov function": Adding more adjectives would only help of course. 1. page 12: $y^*(x_t)$ is the unique minimizer of the strongly concave function $f(x_t, y)   h(y)$, not of $f(x_t, y)$.
Reject. rating score: 4. rating score: 4. rating score: 4. rating score: 6. <BRK>The manuscript employs the well developed machine learning algorithms in an application in Geoscience and do not provide a novel learning algorithm or contribute to machine learning topics. This paper does not meet the  ICLR standards and therefore I can not recommend for publication.<BRK>This paper extends on previous works by Ahamed & Daub (2019), from a two layers MLP, two a Bayesian NN version of it, for predictiong wether a piece of material will rupture, under some conditions. The application to rupture physics is interesting, but does not seem groundbreaking. Do you have an epxlanation for that (and can you check the fit?)<BRK>* The description on figure 4 is confusing, does not seem to correspond to the presented images (either that or the text is unclear when selecting the important parts of the figures for the nodes mentioned). ##### Pros* The idea of the paper seems well directed, i.e., gaining insight on complex physical procedures using an approach that results in the combination of NNs and a Bayesian approach.<BRK>This paper proposes a Bayesian neural network for predicting if an earthquake will break a fault or not, overcoming  small data problem  and predicting model uncertainty. The problem is interesting, and the method is useful as the study on the weights means and stds is interesting. I also don t know if the findings of the paper are of interest for the ICLR community, but as I come from an interdisciplinary field too, I know how hard it can be to find an appropriate and yet good place to publish.
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 5. <BRK>In this work, the authors propose to use orthogonal multi path(OMP) block to improve the adversarial robustness of deep neural networks. [1] Feature Denoising for Improving Adversarial Robustness. From the perspective of network structure, this work needs to compare with related work of network structure in adversarial robustness studies, such as Feature Denoising [1].<BRK>\  From Table 2, does it mean the proposed method is not effective to improve the robustness for black box attack compared with vanilla adversarial training? \  I think for OMP a and OMP b, it is no longer considered as white box attack when we change the direction of the parameters of one layer to another orthogonal direction, as the authors described below Fig 4.<BRK>The authors experiment on standard image classification dataset and compute robustness to both white box and black box attacks, obtaining some improvements over plain GAT. The authors also experiment with ensembling other layers of the model but obtain worse results. The proposed method is interesting, however it increases the model size, hence it should be compared to a non robust or GAT model for the same parameter budget.<BRK>I look forward to seeing the authors rebuttal and comments from other reviewers.
Reject. rating score: 4. rating score: 6. rating score: 6. <BRK>Perhaps more (recent) literature review on quantum expressiveness of other variational circuits can be added. I think in some parts of the paper the authors use $n$ for the number of qubits, and then $\log n$. The fact that the depth of BPNN in hybrid quantum classical computing can be of $O(1)$ is a strong result that perhaps should be compared more with the literature on the power of quantum shallow circuits or constant depth circuits.<BRK>This paper provides new approximation theorems for a family of functions representable by hybrid quantum classical circuits. How would one train such networks?<BRK>The results consider a model with a date encoder, a quantum circuit, and then a classical feedforward neural net for post processing. Pros:The paper shows how some techniques used to obtain classical approximation theorems can be extended to quantum gates.
Reject. rating score: 4. rating score: 6. rating score: 6. rating score: 7. <BRK>An analysis of the resulting sequences finds that they successfully incorporate structure. The method for extracting structure is different, but the goals are very similar. My other big concern is the lack of rigour in the evaluation process. This paper both proposes a new method for generating sequences with improved structural characteristics and several new methods for evaluating high level structure. However, very little time is spent validating that these evaluation methods actually accomplish their goals. I would like to see something like a systematic human evaluation of outputs that shows human perception agrees with the automated evaluations. Even just a snippet of what the original program looked like, then the modification, then the new output. I think the second w was meant to be w’. **Questions for the rebuttal period**Please address the concerns above.<BRK>I m still borderline on accepting the paper, however, due to my concern (shared with Reviewer 3) about how meaningful the evaluation results are and whether they match what humans mean by high level and low level structure. The baselines are somewhat limited, and the evaluation metrics that the authors use are difficult to interpret. The presentation of these results is also quite confusing (see below). The authors cite a large number of works in the realm of neurosymbolic machine learning, but are not as thorough regarding music and poetry generation, both of which are subfields of their own right. The updated paper seems to be an improvement, although some of my original concerns remain. This was very difficult to follow. I think it would be clearer to just report accuracy for both, or, at the very least, describe what each of the columns are measuring. I also don t understand the Human row of this table. Remaining high level concern:  I m still not convinced that the results of this evaluation method are that meaningful. The statement "our approach outperforms BERT as a language model in terms of its own score" seems unfair due to the reasons described in the previous section.<BRK># Overall summaryThis paper proposes a generative model for sequential data structured which uses latent relational constraints and conditions upon them to generate the actual sequence. # Weaknesses  The method requires significant hand design of the constraints in order to work well. This may be difficult or counter effective when the constraints are not easily described for the domain at hand. It is not entirely clear when the relational constraint optimization will produce good results. After all, the goal is that the proposed method can model these sequential data with relational constraints better than the existing methods. I would be willing to revise the score if the authors can provide further explanation/data about this.<BRK>They use the SOTA generative models for both of the two sequence generation domains. They evaluate their approach in terms of both the low level and high level structures. I think this paper studies an interesting topic. However, as discussed in the paper, Young et al.focus on generating simple 2D images with repetitive patterns, and I think it is non trivial to extend that work to sequence generation domains in this paper. 2.What are the entropy results for the music domain? 3.Have the authors conducted any user study? I don t expect the authors to finish such a user study soon if they haven t done it, but would like to see a discussion if they already have some conclusions.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. <BRK>The paper proposes an algorithm for learning policies and internal models ("decision dynamics") from demonstrations. Overall, the paper is well written, the experiments are convincing, and the proposed method, Interpole, makes a meaningful contribution to the literature on modeling decision making. It would be nice to evaluate Interpole on tasks in which the demonstrator s decision dynamics operate on high dimensional latent belief states, to illustrate how Interpole scales with the complexity of the demonstrator s internal models.<BRK>To do this, they develop INTERPOLE, which uses Bayesian techniques to estimate decision dynamics as well as decision boundaries. The paper is well written and clear. The authors do a good job clearly stating the motivation for the work and differences from prior work. The authors consider both simulated and real world data. Adding to the weakness point above, the visualization in Figure 3 does not fully make sense. I think this is a key piece that needs to be evaluated and shown. Thus, I’m on the fence and would like to hear from the authors about this point. They evaluated the method with a few clinicians, and I m glad to see that they preferred the authors  method.<BRK>The paper proposes a method for obtaining an interpretable representation of some behavioral policy based on partial observations and in an offline learning setting. The paper is well written and the approach is clearly explained. Similar to your approach, they are also interested in modeling the agent and not the actual mechanics of the world. Can you discuss advantages of your model over theirs? Another advantage of AMM over INTERPOLE is that it can infer the number of latent states via a nonparametric Bayesian approach. In INTERPOLE, do you have any recommendation on how S can be chosen in a more general setting?
Reject. rating score: 3. rating score: 4. rating score: 5. rating score: 5. <BRK>As far as I can tell, this setup leads to quantization noise on top of analog noise. This is a very serious point since the authors just assume this claim to be true (first para of page 3) and that is the whole motivation. As far as I can tell, two old methods (LLoyd max and dithering) are used and that s it. The experiments only use quantization. One would expect that CACIM would be emulated somehow and we would see that indeed the proposed method improves CACIM s accuracy (which I don t think it would as discussed above). So CACIM was (erroneously) used to motivate the work but then completely forgotten. Post Rebuttal Comments:I thank the authors for their feedback.<BRK>Using quantization to make the deployment of CACIM feasible is straightforward and interesting. 2.The proposed method was validated on CIFAR 10 and ImageNet with different models. Cons:1.Combining quantization and CACIM is interesting. However, I am concerning the novelty of methods used in this paper. [Stock, Pierre, et al."And the bit goes down: Revisiting the quantization of neural networks." Quantization by grouping and k means is well known in this community. 2.In the abstract, the authors claim that  The analog weight has its unique advantages when doing quantization.<BRK>Summary: This paper proposes a method to train weight quantized neural networks. Strengths:   The paper is clearly written and the proposed method is simple. However, the reported results in [1] show that their 3 bit, 4 bit and 8 bit quantized models on ImageNet have  smaller accuracy gaps with the full precision baseline compared to the proposed method. One other concern is that while the authors claim that this method is proposed for compute in memory (CIM) system, and discussed in section 5 that the property of the CIM does not restrict the quantized values to be uniformly strictly, compared to digital systems, there is no empirical comparison of the efficiency (e.g.storage, latency) of the proposed method and other quantization methods in CIM. If so, when the uniform quantization in [1] already has good accuracy, using generalized quantization as in the proposed method does not seem quite well motivated?<BRK>Starting from the property of CACIM, this paper found that weight quantization fits CACIM s analog calculation process and proposed a general quantization method. Pros:1.Find a good usage of model quantization in a new hardware system. Overall, property of CACIM does not contribute to the design of quantization method. 2.Besides, the proposed quantization method is not innovative. Not to mention the noise aware training and STE. 3.This paper s focus is on CACIM, but experiments are not conducted on this hardware.
Reject. rating score: 3. rating score: 6. rating score: 7. <BRK>Originality:The content of this paper is not novel. Cons:This work tries to rigorously characterize the conditions for a rather intuitive task (reconstruction). There are a few serious issues around it. In addition, in reality, the activations are not necessarily sparse, especially for generative models. The combination of these caveats make these theorems  indications of little meaning. Second, in reality, we use much more complex architecture (CNN, attention, ReLU, Normalization) but these theoretical works can t easily go beyond simple MLP with ReLU, making these results even less meaningful. Thirdly, despite all the above, it is hard for me to reason why the theorems are significant in anyway in the context of ML, e.g.why uniqueness is important. I can understand the significance of existence and uniqueness in the context of differential equation but not ML. I know "sparse representation", and "representation theory", but not sure about "sparse representation theory". Eventually, we want to measure the recovered signal, not the latent code error.<BRK>SummaryThis paper proposes the conditions for the invertibility of deep generative models, and two pursuit algorithms for inverting them. The authors claim this to be the first work that provides provable guarantees of inversion for general non random neural networks. This is a very solid piece of work, with significant contributions on both the theoretical and practical sides. However, the impact of this work might be limited by the sparsity assumption, which is central to this work. It is unclear whether this holds in more general settings, especially for very deep models trained on large scale datasets. Cons1.It is unclear how well does the sparsity assumption in theorem 1 hold in practice for trained models, which may limit the impact of this work. 2.The claims of provable guarantees for inversion is exaggerated, as it only applies to Algorithm 1, which relies on an oracle to provide the true supports of all hidden layers. There is no such guarantee for the more general Algorithm 3. 3.The experiments are limited to toyish and simple dataset. 2.At the end of page 2, the complementary S^c_{i+1} is used before it is defined after eq.5.3.What is the distribution of the random input signal used in section 6.1? How is it chosen? 4.It might be helpful to summarise the sparsity assumptions from theorem 1 in the abstract or introduction, so that the limitation of the analysis and method is more clear for readers.<BRK>This is an important task, for example for inverse problems using generative priors. The authors introduce spark based conditions for the invertibility of each layer of the network, leveraging sparsity that is induced by ReLUs. Empirical results demonstrate the superiority of the proposed algorithm relative to baselines for inversion in particular parameter regimes. Theorem 1 on invertibility/uniqueness is a significant contribution in that it permits an invertibility guarantee for neural networks without random weight assumptions. There are a few minor issues the authors should fix upon revision:(1) In Section 2, the authors should state that n_{L+1} n.  (2) It is not clear whether the authors are simply restating Theorem 2 from Foucart and Rauhut or whether this is a novel contribution. The connection between the Theorem and the preceding paragraph needs to be clarified. The commentary on this point during the results sections could be more thorough. The paper does not say so, but this condition requires that the network widths are larger than a particular geometric sequence with growth rate 2. I believe this statement also holds true in the non random case as well. It is defined within Algorithm 1, but this should be clearly pointed out.
Accept (Poster). rating score: 8. rating score: 7. rating score: 7. rating score: 6. <BRK>Summary: The authors propose a novel combination of VAEs and Flow models, where the decoder is modelled through a conditional flow taking as input a “local” representation of the size of the input image and a “global” representation output by the encoder. Great:* Conceptually simple method that seems to work quite well in practice, for this class of models. A clear accept.<BRK>Pros: > I like the idea of conditional generative flows, where a low dimensional embedding captures high level features and a larger embedding latent space captures local representations. Overall, I like the paper and would like to see it accepted. To me, global variables in a generative model drives non iid samples, hence correlating samples with each other. At the end they are combining a flow generative model (typically trained using ML) with an encoder VAE like posterior approximation.<BRK>The paper introduces a mixture of flows with the specific intent to disentangle global and local representations, to improve visual quality of samples. The demonstrates improved visual quality over other normalizing flow methods. StrengthsThe paper introduces a straightforward latent variable model for flows which is designed in such a way that training on NLL gives good sample quality, which is measured in FID. Even further, the model also performs quite well on the NLL objective itself.<BRK>##### SummaryThis paper aims to improve a Normalizing Flow generative model, in particularGlow, by conditioning the flow on global information of the image in the formof a latent vector learned with the VAE framework. Some degree of local and global properties disentanglement is demonstrated in  the qualitative results, showing the proposed direction is a promising one in  that regard. Finally, another option would be that everything is trained with the negativelog likelihood cost of the normalizing flow.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. rating score: 6. <BRK>The paper presents a generative model to automatically generate data that is needed for contrastive learning, with a focus on the SimCLR framework, while the method itself is general. Experiments were conducted across multiple modalities, including image, speech and wearable sensor data. The effectiveness of the proposed methods has been demonstrated. In the abstract, it is said that the proposed method significantly outperforms baseline augmentations in speech (+9% absolute). Good to discuss this. The reproducibility of the work could be enhanced with providing more details about the experimental settings.<BRK>**[Summary]**The authors proposed the Viewmaker, which learns to generate augmentation for contrastive learning. They show that the method achieves comparable results when applied for CIFAR 10, but significantly outperformed baseline augmentations in the speech domain and wearable sensor domain. **[Reason for rating]**I consider this work to be simple and effective. **[Pros]**  Propose a novel generative model that learns to augment inputs  insightful analysis from Sec.4.1.1 to 4.2  Show the proposed method works for image, speech, and wearable sensors. The proposed method is well motivated in the abstract., where expert designed augmentations hinder the widespread adoption of self supervised representation learning methods across domains and modalities. **[Cons/Questions]**  Viewmaker cannot make augmentations like cropping and rescaling (as already discussed by the authors). Perhaps this claim should be validated by comparing it with a baseline where traditional data augmentation is used.<BRK>The paper proposes a method for automatic generation of data views for contrastive self supervised learning of representations. Authors apply their method on various image, speech and wearable sensor datasets where the proposed approach provides an improvement over other methods. The general idea of automating data augmentations for self supervised learning seems very reasonable to me and adversarial training framework is a very viable option to implement these ideas. For example, various rotations, contrast and saturation manipulations in the image domain are very difficult to reproduce within this framework and would result into a very high $l_p$ difference from the original image. 3.While I do appreciate a quite broad selection of data domains in the experiments, I think it is important to also evaluate the proposed method on ImageNet since it is a major and established benchmark with enough complexity that makes good representations really necessary for a god performance. Overall, I like the paper and would gladly increase my rating if authors could address the points above.<BRK>This can be expensive and hard to obtain in many data modalities. The paper proposes to automate this by learning to generate transformations tailed to each modality and sample. Pros:+ The problem is well motivated and the approach is easy to follow. + Results are shown for multiple modalities with good performance including speech and time series from wearable sensors. I agree that the method is easier and more general than methods such as Adversarial Autoaugment. It will be interesting to see how the approach generalizes to larger/complex datasets without an expert specified family of transformations or without a good generative model.
Reject. rating score: 2. rating score: 4. rating score: 5. rating score: 5. rating score: 7. <BRK>Isn’t the linear regression model a bottleneck here? Novelty The approach combines well established models and techniques into a novel framework.<BRK>Other proposed improvements:3. The reconstructed faces have a higher quality than previous work. However, the method is not conceptually different from e.g.[21], and the authors mostly used a better generative model, i.e.a better prior.<BRK>The approach consists in decoding brainresponses via the GAN latent space, and leads to state of the artstimulus reconstructions. Maybe I am missing  something here.<BRK>Conclusion: The novelty is limited and the author miss the opportunity to ask novel research questions.<BRK>This work proposed a novel perspective to the field of cognitive neuroscience and human brain mapping in functional neuroimaging studies.
Accept (Spotlight). rating score: 8. rating score: 7. rating score: 7. rating score: 7. <BRK>Specifically, RIDE consists of three crucial components: 1) a shared architecture for multiple experts; 2) a distribution aware diversity loss that encourages more diverse decisions for classes with fewer training instances; 3) an expert routing module that dynamically assigns more ambiguous instances to additional experts. Experiments are conducted on three long tailed benchmark datasets, i.e., CIFAR100 LT, ImageNet LT, and iNaturalist. The authors should carefully proofread the final version. The paper is well written and easy to follow.<BRK>This paper proposed a simple but effective method which significantly outperforms the state of the art method by 5% to 7%. The experiments are adequate and rigorous. Totally, this paper is a good workPros:1. 5.The proposed method is simple, effective and general.<BRK>It has 1) a shared low level feature extractor and multiple expert classifiers, 2) a distribution aware diversity loss to encourage experts learning different classification strategies, 3) an expert routing module that dynamically selects a subset of experts for each test instance to make a joint decision. This paper firstly increases the performances on all three splits (many /med /few shot), while most of the existing methods have to sacrifice the head for tail improvements. + The proposed RIDE framework can be applied to a variety of long tailed recognition methods. There is no guarantee that the involved early experts are more useful than the skipped ones. I think this paper shows a new direction for long tailed classification that we don t need to sacrifice the head performance for a balanced classifier anymore.<BRK>The majority of feature extraction backbone is shared among different agents and the classifiers of experts are trained with both classification loss and proposed distribution aware diversity loss. The whole paper is generally well organized. However, there are some technical issues authors should further address:1) In the introduction, the authors measure the mean accuracy, model bias and model variance by randomly sampling the Cifar100 a few times, and reported different methods in Fig1. For example, it is stated the bias also measures the accuracy. Also, why requires the diversity among experts if setting the lower temperature to tail classes is to encourage the divergent prediction, how both diversity and divergent exists simultaneously? 4) For experiments on ImageNet LT and iNaturalist, is the RIDE combined with the regular CE loss or other methods? For example, for each split (many, low) how the different expert behaves?
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. <BRK>The authors provide a practical way of calculating the required new quantities efficiently. However for FEDAVG, the optimization procedure CLIENTOPT could be something else, such as adam.<BRK>This paper introduces a new perspective on federated learning through the lens of posterior inference. The paper designs a computation  and communication efficient posterior inference algorithm—federated posterior averaging (FEDPA), which generalizes FedAvg. 2.The convergence result is weaker than those on optimization for federated learning.<BRK>The paper is nice and seems technically sound. Do you mean that F(\theta) is a log posterior or a  log likelihood? My main concerns is the degree of novelty. J.Corander et al.Parallel interacting MCMC for learning of topologies of graphical models.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. rating score: 6. <BRK>The authors investigate modular neural networks in a continual learning (CL) setting, where multiple classification tasks have to be learned in sequence. The authors focus on efficient forward transfer to new tasks. A many tasks benchmark is evaluated on the authors  method as well as a number of baselines. The paper is very well written and the explanations are clear. The experiments are fair and well executed. The main weaknesses of the paper lie in its originality and applicability. Dynamic architecture expansion for CL is a well studied approach (as acknowledged by the authors), and while picking an appropriate initial path with a cheap classifier is a good idea, determining how to expand from there remains difficult and largely expensive in the more effective MNTDP D version. This should be noted. It should be discussed that the presented method requires knowledge of task identity at test time. Edit: I have raised my score from 6 to 7 after the rebuttal.<BRK>This paper provides metrics, benchmarks, and algorithms that can evaluate transferability, not just catastrophic forgetting in continual learning. These methods are reasonable, but there seems to be a need for more justification for the five stream cases used in the benchmark for transfer evaluation. This paper provides a set of benchmarks for evaluating continual learning algorithms in terms of transfer and scalability, in addition to catastrophic forgetting, which has been mainly used in the past. Additionally, the authors propose MNTDP, analogous to the modular network, as a new continual learning algorithm to better meet the metrics assessed in the new benchmark. This paper is well organized and well written. I personally like the authors  claim that transferability should also be an important measure in continual learning. Another question is, in the case of scalability, what does it mean for regularization based or replay buffer  based rather than modular network based continual learning?<BRK>Firstly, it introduces a new set of benchmarks designed to proble different qualities that may be important for continual learning methods. Testing different properties of a continual learning algorithm, one by one, with different benchmarks, is a very nice idea. It has nice ideas to it, such as starting with the modular architecture of the most related task only. This works well with the specific benchmarks they propose. I was wondering why the authors restricted the transfer metric to be just for the last task. The paper could also mention methods based on IBP priors. The authors have made the paper stronger with the inclusion of stronger baselines, cleaned up presentation, and backward transfer.<BRK>This paper proposes modular networks with task driven prior (MNTNP) for continual learning. + Pros+ The idea of exploring different modules and structures for each task is interesting+ The paper is in general well written and easy to follow  Cons  The novelty of the proposed method is limited. The authors argue that the optimal model for permuted MNIST and split CIFAR are independent models because each task is distinct. The proposed approach also requires a task identifier to work with. It is not clear what algorithm is used in the experiments for the proposed method. Is the data driven prior always applied?
Reject. rating score: 2. rating score: 4. rating score: 4. rating score: 4. rating score: 4. <BRK> Summary This paper introduces a method for matching an ML pipeline to a dataset using the text features of the pipeline of and the dataset along with some additional metadata about the features of the data. A simple pipeline to dataset matching is unlikely to have a significant contribution to science or application. c) Many more pipelines or complexity of pipeline components. To claim Real time AutoML the authors need to demonstrate that the method worksa) For general AutoML tasks and search spaces such as architecture search, swapping pipeline pieces in and out. This approach focuses on the speed of the first suggestion (zero shot setting). c) The real time claim implies an “online” setting, wherein results are fed back and suggestions are offered in real time. The proposed algorithm is not iterative. What about datasets and pipelines which sound similar but are totally different. No structure learning is performed. What can make this paper better?<BRK>The running time for predicting a ML pipeline is short from the framework. Specifically, the proposed framework is novel because  it creates the dataset description embedding by BERT, extract meta features of the dataset, and generate data embedding from description embedding and the meta features. I understood limit of 3 seconds for zero shot AutoML since *Cardi* test dataset took ~3 seconds as per Table 3 in Supplementary. 7.What are the precise meaning of running time and prediction time in the paper? The real time is misleading readers that authors tackle the real time applications with AutoML. Their experiments are not strong enough to support the "real time".<BRK>4.In the current system, the authors assume a fixed number of AutoML systems, i.e., OBOE, AutoSklearn, TPOT, AlphaD3M, Random Forest. In particular, the AutoML job of a new supervised learning task can be accomplished without model evaluations, namely zero shot / real time AutoML. The meta module is constructed as a graph structure in which each node represents a dataset used for meta training. Pros: 1.The target problem in this paper is practical, and the proposed model, GAT is simple and seems effective. Cons: 1.The feature extractor method is based on a Github project, i.e., BYU. Thus, a more detailed elaboration on how to extract the feature is recommended. 2.The proposed work lacks theoretical or empirical support on why the current feature of the datasets can indicate the choice of the pipeline. 3.The proposed method is a systematic solution for AutoML rather than an AutoML method. Below are some questions: 1.<BRK>The problem that the authors attempt to solve is to determine what ML pipeline will perform best on any new dataset, without incurring in the extra cost of actually running a large number of such pipelines, as is typically done in AutoML algorithms. More in general the proposed architecture is not really clear until the reader reads all the details of the paper, a better and more self contained introduction would help the comprehension of the paper. The biggest concern for me however are the results, in particular how the method, although relatively complex, seems to perform no better (or only very slightly better) than random forests with default parameters, as seen in the results of Table 2, and Figure 2 of the Supplemental material. Unfortunately the paper misses strong and compelling evidence that the method really gives results than simple baselines. This would be interesting to know.<BRK>This paper presents a very interesting idea of utilizing the documentation for the data and the operators in the pipeline to generate meta features for meta learning. The use of the outputs of existing AutoML systems (such as auto sklearn, TPOT, etc) is also very intuitive and well motivated. It seems that the gain from the proposed sophisticated meta learning is not fully realized with the empirical evaluation. Beyond this, there are various choices made in the empirical evaluation which is not very well justified, and various technical details that are missing in the paper:  Why are we focusing on 3 seconds, why not 1 second or 1 minute? This is not clear from the description and is a very important part of the "zero shot" learning.
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 5. <BRK>The authors propose a modification of the option critic algorithm for hierarchical reinforcement learning. Specifically, the algorithm aims to maximize the mutual information between the options and their termination states. The authors develop an optimization scheme for achieving this objective and provide empirical results in a number of domainsThe empirical results help understand the scalability of the approach but they are less useful in evaluating how useful the proposed algorithm is in general. In addition, across domains, the general structure of the task is the same: there are multiple goal regions offering different amounts of reward; the challenge for the agent is to not get distracted by the lower offerings. So it would be informative to see the algorithm analysed in a more varied set of problems, including problems with a single goal region. Further discussion and exploration of it in the paper would be useful. Figures 2 and 6 are very useful. I appreciated the author s efforts to add diversity to the domains evaluated but they do not go far enough to change my score.<BRK>This is an appealing idea, and the approaches toempowerment (such as for DIAYN) are a great fit for the limitations ofthe Harutyunyan work. However, there were a number of issues I found with the paper whichcurrently leaves me leaning more towards rejecting in the currentform. Again, solid idea, but both the paper itself and theexperimental results (thus the method) need further work. Judging byFigure 1, none of the methods are reliably achieving the 2.0 goal. Andjudging by the error bars, it is difficult to say that A2IMOC isbetter than AOC. As with Figure 1, the learning curves in Figure 2 do not allow us todraw any real conclusions about PPIMOC being an improvement over PPO. But this is perhaps the onlypositive empirical result, and thus is a lot to hang the paper on.<BRK>I found that the analysis of the method in the revision is informative. Summary:This paper studies the problem of discovering options for exploration in reinforcement learning. To this end, they propose infomax criteria that maximize the information between options and option terminating states conditioned on the option starting states. The proposed method is evaluated at Gridworld/Mujoco four rooms tasks and Point Billiard environment, and the authors show that the resulting options are diverse. The performance comparison with important baselines such as termination critic (TC) is absent in the experiments. It is not clear that maximizing the mutual information in Equation (7) leads to diverse options. The paper should provide theoretical results or more experimental analysis to make the case. Comments:  Experiments on more challenging tasks, such as Montezuma s revenge from Atari games, could improve the claim of the paper. Aren t there any problems associated with the collapse of options or terminating states?<BRK>This is an interesting paper that investigates the use of options for improved exploration by encouraging diverse termination functions via a mutual information measure. The paper is well written and mostly clear (with a few points below):Overall I think the idea has merit, but I think the experiments fall short of demonstrating its performance. 2.Overcoming the coarse approximation for the infomax objective (7) (see point 5 below). What is the law of $X_S$ in equation (7)? This seems central to the algorithmic performance, but it s not clear how it gets used. 4.Above equation (13), the authors write "Supposing that the current option ot terminates at the $t + k$ step". This seems like a rather rough approximation; in particular, doesn t this simply encourage diversity of one step action transitions as opposed to option termination? 6.In Figure 1b the difference between A2IMOC and A2C does not appear to be statistically significant (there is major overlap of the confidence regions). 5.You should state equation (6) as a proper theorem.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. <BRK>In particular, the conceptually important distinction between challenges arising from working memory load and sequence length is tested by variations of the copy task with padded inputs, where relevant and irrelevant input bits are distinguished in a very simple way that is hardly met by real world scenarios. There may also be differences arising from different types of RNNs, and it is not clear to me to what extent one can make conclusions about all of them by testing on just one type. I tend to vote for accept. This paperprovides apparently the first systematic discussion and comparison of CL methods for RNNsThereby it provides an important service to the community.<BRK>Summary:The authors do an evaluation of the application of weight importance continual learning methods to recurrent neural networks (RNNs). They draw out the tradeoff between complexity of precessing and just remembering (working memory) in terms of the applicability of these weight importance methods. Overall, I vote for accepting this paper because the work is well motivated, thorough, and provides useful insights. + The insight into the tradeoff between complexity of processing and working memory requirements and its effect on the ability of the network to continually learn is very interesting. Similarly the fact that hypernetwork based approaches work better than other approaches most of the time is useful. + The analysis of the above tradeoff using a linear RNN is also interesting since it provides a nice intuition for why the tradeoff exists. Weaknesses:  The motivation and conclusions from the ssMNIST task is not very evident and the tasks doesn t seem to make a clear point. An analysis of why hypernetworks perform better would be interesting. So would have been some proposals for methods designed specifically for CL with RNNs.<BRK>This paper provides a systematic evaluation of the performance of different CL methods on RNN. The study suggests that high working memory requirements increase difficulty of learning new tasks, while the average length of input sequence is not strictly related to the difficulty of learning new tasks. The author proposes to overcome this problem by using a hypernetwork based CL approach, which shows promising results in the experiments. * The conclusion is well supported by analysis of intrinsic dimension and performance on different tasks. * The paper is well written and easy to followWeaknesses* It would be interesting to see results on more realistic tasks, like sentence classification. It would be interesting to see how different CL methods can reuse knowledge learnt from previous tasks.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. rating score: 5. <BRK>In this paper, the authors propose generalization bounds for GNNs, both convolutional and standard message passing variants. The result is a generalization of those for CNN/MLP architectures with relu activation functions. The analysis method closely follows those established in the former settings as well. The specific setting they consider is where each sample in the dataset is a graph. The resulting PAC Bayes bound is shown to be tighter than corresponding Rademacher Complexity bounds. A couple of minor comments/questions:1. But this is just for one node. I m guessing there s parts in the proof where the iid assumption is necessary.<BRK>##########################################################################Summary:This paper provides results of generalization bounds for two types of GNNs: GCN and MPGNN. The presented analysis follows the framework of Neyshabur 2017 to construct posterior by adding random perturbations so that the PAC Bayesian technique can be applied. The main contributions are the perturbation analysis for GCN and MPGNN, which results in a bound depending on the graph statistics. I vote for accept. This paper is well organized, with nice discussions on the state of the art as well as on the overall technical review. The paper provides a detailed comparison between the derived bounds with the existing bounds. The results of this paper are natural in the sense they generalize that the results in Neyshabur 2017 for MLPs.<BRK>This paper, by PAC Bayesian approach, proves the generalization bounds for the two primary classes of graph neural networks—graph convolutional networks and message passing GNNs. By experiments on four datasets, it shows that the generalization bound in this paper is tighter than the existing Rademacher complexity bound. This is an interesting question about generalization bound, especially, such a discussion by  PAC bayesian approach for graph neural networks is lacking. However, there are a few issues/comments with the work:1.The proof techniques in this paper are mainly from Neyshabur et al., 2017. In Figure 1, it seems to be the opposite, why? However, I think the results need to be analyzed more carefully, especially on the depth. Moreover, the novelty of the technology is relatively limited.<BRK>The paper essentially adapts Neyshabur et al.(2017) PAC Bayesian margin bounds for neural networks to graph neural networks and expectedly the bounds contain terms that depend on the degree of the underlying graph. The main technical contribution of the paper is a perturbation bound for GNNs from which the main results follow. The paper presents the first PAC Bayesian generalization bound for GNNs and the authors show that their bounds are tighter than the Rademacher based generalization bounds developed by Garg et al (2020) ignoring constants. While this is an issue with existing theoretical results for deep neural networks, the paper does not significantly improve the state of the art in theoretical understanding of GNNs in terms of new tools and proof techniques.
Reject. rating score: 6. rating score: 6. rating score: 6. rating score: 8. <BRK>This paper introduces a model agnostic active learning technique that maximizes the dependency between a batch and the rest of the unlabeled pool. For instance, expected error reduction (EER) is motivated by a similar intuition. The significance of this paper rests on its empirical evaluation as there isn t any justification for the heuristic algorithm beyond a conceptual motivation (which isn t unusual). It would have been nice to see the model agnosticity used by running experiments with different models beyond CNNs. In fact, if some other methods (which apply to CNNs) are discounted because they are not model agnostic, the experiments should really include these other methods or include more than just CNNs.<BRK>The paper introduces a new acquisition function for (batch) active learning that uses a variant of the Hilbert Schmidt Independence Criterion to acquire diverse batches that are informative for the remainder of the unlabeled set. Overall, I’m scoring the paper with a weak reject. Section 4 provides two convincing examples for this. The paper provides strong empirical evidence that its approach works much better on EMNIST and FashionMNIST. It provides performance comparable or slightly better to BatchBALD on MNIST and RepeatedMNIST, and it also shows that overall, it seems to pick from different classes more uniformly. Especially given the examples in the motivation in Section 4, another experiment with imbalanced classes would be helpful to show that the proposed approach helps with the issues detailed in its motivation. The number of classes seems to be missing. BatchBALD’s runtime complexity is also stated incorrectly, see Kirsch 2019.<BRK>The authors propose a novel acquisition function for active learning based on the (sample) Hilbert Schmidt Independence Criterion (HSIC) statistic. Figure 3 suggests a reason for why the proposed method outperforms existing ones on some data sets (although it would be interesting to get statistics which back up the claim that individual batches are more balanced as well as the overall sampling process). Experiments compare the new method to a reasonable set of SOTA active learning methods. Cons:The new method is competitive on all experiments, but can only be claimed to outperform existing methods on EMNIST and fashion MNIST. Would be interesting to see things like robustness to some of the approximation choices (number of MC dropout resamples for example).<BRK>The paper puts an additional requirement that the algorithm is model agnostic. Results are presented over MNIST, variants of MNIST and CIFA and show improvements over five previous active learning approaches and a random acquisition baseline. Particularly, experiments are presented on realistic domains, with neural networks, and show gains over a few different baselines. 2.ICAL is model agnostic which means it can be applied to decision trees, neural networks, complex ensembles, etc. 3.Experiments show that ICAL acquires a more diverse batch for acquisition. 2.No comparison with BADGE (Ash et al.2019) is provided. **Writing:**There are issues with writing in several places. It should be minimizing. 2.Unexpected full stop after "model s parameters" in the third paragraph of the intro.
Reject. rating score: 4. rating score: 4. rating score: 6. <BRK>This paper presents a differentially private method for training a generative model. The proposed approach is not well motivated. The experimental results show that the proposed method outperforms the existing methods for learning a generative model in a differentially private manner.<BRK>The paper proposes a method for training OT GANs using differentially private sinkhorn algorithm. So, the novelty by itself is minimal as sinkhorn GANs have previously been proposed. I am generally ok with incremental improvements in method if experimental results are strong. Hence, the model itself is not that great. Can you comment on this.<BRK>This paper proposes a novel architecture and training process for learning differentially private synthetic data generators. The authors don’t really discuss why this is, but my understanding is that the “adversary” is contained in the dual formulation of Wasserstein distance (as the minimum over Lipschitz functions of the difference in expectation between two distributions). Overall, the paper achieves a moderate improvement over the work of Chen et al with respect to a few simple measures of accuracy (namely, how well two DNN models do at classifying real data when they are trained on synthetic data).
Reject. rating score: 5. rating score: 6. rating score: 6. rating score: 6. <BRK>Strengths:1) The experiments are extensive, and clearly demonstrate the merits as compared to prior benchmarks for off policy RL. 2) The contextual discussion is clear, well motivates the proposed approach, and gives a nice overview of how importance sampling and off policy RL intersect. Therefore, I feel the conceptual contribution is not enough to warrant acceptance. Can the authors comment about how to estimate the successor representation efficiently? 3) The actual algorithm pseudo code is missing from the body of the paper, which is permissible because it is in the appendix.<BRK>***Summary***The paper proposes an approach to employ successor representation combined with marginalized importance sampling. The basic idea exploited in the paper consists of expressing the occupancies in terms of the successor representation and to model it via a linear combination of some features. (Experimental evaluation) The results presented in the experimental evaluation are partially unsatisfactory, as also the authors acknowledge. I did not find any fault, but I feel that the significance of contribution is currently insufficient for publication at ICLR. In particular, for a paper that proposes a practical variation of a theoretically sound algorithm, the experimental evaluation is essential.<BRK>Overall I think the idea is interesting and theoretically sound, but the experiments are not fully convincing. SR DICE is a two stage learning algorithm, i.e., SR learning + density ratio learning, both have hyperparameters to be tuned. GradientDICE and DualDICE are one state learning algorithm. I appreciate that the authors include deep TD and behavior R(\pi) as baselines. The empirical study has independent interest beyond SR DICE. I particularly like the idea of using successor representation for density ratio learning.<BRK>* I am worried about both the technical and experimental qualities of this work. In particular, $\phi$ is learned by minimizing state, action, and reward reconstruction error and $\psi$ is the discounted sum of $\phi$. If we consider a case where $\pi$ only exploits a very small subset of state action space, it is easy to see that the reconstruction error minimization in the dataset is not an optimal representation for the marginal importance ratio learning. * The paper is hard to follow. Overall,PROS:* The idea of using successor representation for learning marginal importance ratio is novel. Most of the concerns are addressed by the authors, and I raised my score accordingly.
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. rating score: 6. <BRK>The paper presents a framework for "disentangling" style and content from audio samples, a very interesting topic. The citation of previous work is good. I realize this work summaries derivations in the supplementary material, but ideally the central intuitions and actual specific bottom line criteria used would be much clearer. Intro: "Experiments demonstrate that our method outperforms previous works under both many to many and zero shot transfer setups."<BRK>The paper proposes a way to do voice conversion by learning a disentangled representation of the style and content of the audio. This disentangled representation is enforced by minimizing the mutual information between these the style and content encodings of the audio. The paper shows maths to derive its loss functions. Cons:1.Very difficult to understand/follow the central part of the paper. I think the paper in the current form might be interesting to the ICLR community.<BRK>This submission proposes a training approach for voice style transfer using encoder decoder framework and content and style representations. One of the MI based terms is the MI between content and style representations. Experimental results show that this approach leads to improved performance in speaker verification and speech similarity tasks. Experimental results in challenging zero shot conditions also demonstrate improved performance in speaker verification, speech naturalness and speech similarity tasks. Quality: The quality of this submission appears to be generally OK.<BRK>This paper proposes a zero shot voice style transfer (VST) algorithms that explicitly controls the disentanglement between content information and style information. There are two major strengths of this paper. First, it motivates the algorithm design from an information theoretic perspective. Second, the performance improvement is significant. The authors ascribe this to that I1 and I2 already suffice to train the good model. I would look forward to more thorough evaluations in the rebuttal.
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 6. <BRK>The proposed method consists of (1) pseudo labeled data selection based on prediction confidence for efficient training and (2) a data augmentation method named mixconf, which is a modification of mixup. Overall, the paper is well written, but i can t find much novelty of the proposed method. For the part (1), data selection for semi supervised learning is a quite well known idea. For example,1) The main assumption the authors made is "the loss calculated with incorrect labels tends to sensitivey increase when the data is augmented".<BRK>While familiar with semi supervised learning and label propagation, I must say I had some difficulties following part of the paper, partly because I was not familiar with the initial mixing methods and their justifications. * In equation (4), how is it that the loss is between an instance and a probability distribution over classes? * Section 2: what theoretical argument have we that the proposed approach will provide well calibrated outputs? The experiments seem to show that it works reasonably well on the three selected data sets (as did MixMatch), but do we have formal arguments indicating that this approach would provide well calibrated outputs in general? Also, how can we explain that more data actually degrade the calibration results, as one would expect calibration to improve with data? * There are also some typos remaining (in a small amount), so a final read would probably be helpful.<BRK>The paper uses selective training with pseudo labels. Moreover, MixConf, a variation of mixup, for data augmentation is proposed  to train a more confidence calibrated model. Finally, experimental results on the standard datasets  show the effectiveness of the proposed model compared to SOA SSL methods. The paper is well written, and experiments are sufficient to some extent. However, the technical novelty of the work is marginal. In ICML, 2019.<BRK>In this paper, a novel semi supervised learning (SSL) method that adopts selective training with pseudo labels is proposed based on confidence estimation. The confidence is used not only for screening candidates of pseudo labeled data to be selected but also for automatically deciding how many pseudo labeled data should be selected within a mini batch. Hence, how about the overhead of the proposed method?
Reject. rating score: 4. rating score: 4. rating score: 7. <BRK>This paper analyzes Dropout through the lens of k way interactions. Why not repeat the analysis of Figures 2 and 3 for this setup? The theory suggests that a higher dropout rate reduces the effective learning speed of higher order interactions. First, I would argue that the authors are _probably correct_ in their conclusions. This is at odds with statements in the paper. Either way, this portion of the paper needs to be _much_ clearer. The experimental section of the paper is interesting, but it has some serious flaws.<BRK>Fig 3’s  key findings: “the rightmost column shows that NNs with low rates of Dropout tend to massively overfit due to a reliance on high order interactions”, I see overfit, I don’t see why it is due to higher order interactions (row1, row2, row3 have similar trend) “because Dropout slows the learning of high order effects, early stopping is doubly effective in combination with Dropout. Although the paper has theoretical proofs/intuition and interesting experimental results, I don’t think I find convincing and sufficient evidence to support the conclusions, as opposed to some other hypothesis. How can we guess optimal dropout rate?<BRK>*Summary*The authors are analyzing to which extent dropout is regularizing the training stage of deep networks, showing that high order interactions are discouraged, this being a proxy for a better generalization capability once spurious co adaptations are removed. The paper can be still however improved by giving additional insights on the approximation of the ANOVA decomposition and this is something that I would kindly like to ask authors for the rebuttal stage. Although authors have partially analyzed this trend in the appendix, I believe that not only this needs to be added to the main paper (as the authors seem to promise for the camera ready), but a deeper quantitative evaluation is, in my opinion, necessary.
Reject. rating score: 5. rating score: 6. rating score: 6. rating score: 6. <BRK>In this work, the authors propose an approach for “truly” unsupervised image to image translation. [Paper strengths]  The setting of the "truly” unsupervised image to image translation is new (although might not be practical). For translation, no matter whether it is about language or image, we need to have target in mind. If no target is specified, translation does not make sense. For example, for Fig.3, if the source is a dog and the target is a dish, which is possible for the defined truly unsupervised scenario, then what will happen? The results are quite confusing. Comparing TUNIT across Tables 1, 3 and 4, it seems having more ground truth set labels does improve the performance at all, which is not reasonable. It addresses some of my concerns.<BRK>This paper proposes an unsupervised I2I translation method TUNIT where there is no any supervision signal. Experimental results look pretty solid. Some of my concerns are listed below:(1) Without any supervision, the selection of K sounds very important. I m interested in a more crazy value for K in Table 2. If a collection of images are given and the estimation of K is unlikely to happen, how should K be selected? (4) I suggest adding another line in Table 1 which is about TUNIT + using domain labels (with a classifier to predict real labels). If paired data is given, the proposed method might not beat its performance. Update:Thanks for the feedback from authors.<BRK>For example, a prior work that comes to mind is CUT [1] where the authors also target the unsupervised image to image translation and also utilize contrastive losses in patches of images. One could argue that in CUT they still require a set of domains whereas this paper does not but one could first do some clustering and then apply CUT which is quite similar to what this paper is proposing. In [2] for example the authors feed a reference image that serves as an exemplar from which they extract class specific styles which are then fed to the generator that synthesizes the output image. This paper tackles the problem of unsupervised image to image translation without making any assumptions about the existence of input pairs or input sets.<BRK>The paper introduced a more challenging setup under the problem of unpaired image to image translation, where no domain labels or image sets are provided. Towards solving this problem, the paper proposed a TUNIT framework with a guiding network, which could encode style codes for the generator and predict the domain labels for the discriminator. A contradiction exists that the author claimed the number of domains "K" is an unknown property of the dataset (in the 2nd line of Sec 2), but using the guiding network to predict the domain labels under the assumption that "K" is known (Eq.(1)).2.The description of "Style contrastive loss" (Eq.(4)) is confusing. The author claimed that the network may ignore the given style code $\tilde{s}$ and synthesize a random image from the same domain $\tilde{y}$ without Eq.(4), however, as we learned from Eq.(2), the "given style code $\tilde{s}$" and the "style codes of images from the same domain $\tilde{y}$" are similar to each other. In my point of view, Eq.(4) is used to make sure that the generated images show the same visual style features as the input reference images. 3.Since Eq.(2) and Eq.(4) have similar equations and maybe there are also some overlapping functions. [A] Momentum contrast for unsupervised visual representation learning.
Reject. rating score: 5. rating score: 5. rating score: 7. <BRK>For example in Proposition 1: “are close enough to the origin” **RECOMMENDATION**In its current form, I vote for rejecting the paper. x* is a vector. Some of the theoretical results and proofs are quite informal or vague. **CONS**The main weak point of the paper is the experimental section.<BRK>I find the derivation of the double sided cubic spline and the use of infinitely many ReLU s to boost the posterior covariance novel and interesting. Since the entries of $W$ is part of $\boldsymbol{\theta}$ the parameter for the entire network, $W$ is random because $\boldsymbol{\theta}$ is assigned a prior. Despite the authors  claim of doing an extensive theoretical analysis, I find that theoretical arguments quite heuristic in some places.<BRK>ReLU is not defined2. /  The paper addresses the issue of overconfidence of neural network outputs. I am voting to accept because despite of the mentioned above concerns of the method to be overcomplicated, the overall idea is interesting, the paper is well written and easy to follow, the paper addresses the important problem that has impact for the wide audience, the proposed method provides theoretical guarantees while in practice being used as a simple post hoc procedure.
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. <BRK>This paper proposes a new network architecture that combines 1) a state of the art deep neural network with high accuracy (but potentially no robustness certificate), and 2) a small certification network with high certifiable robustness (but not necessarily very high accuracy), using a selection network that adaptively chooses between these two networks. They show that by doing so, the new architecture is able to take advantage of both networks and thus obtain good natural accuracy with better certified robustness that significantly improves upon prior benchmarks. 3.Can you provide some interpretation of the learned selection mechanism $g_{\theta_s}$?<BRK>This paper focuses on improving the standard (clean) accuracy for certifiablyrobust models. So I cannot recommend accepting its current version. Theauthors propose a selection mechanism to choose between a certified model withlow clean accuracy and a naturally trained model with high clean accuracy. Ata high level, when the certified model cannot certify, there is no point to useit for classification. A naturally trained model (which cannot be certified aswell) is selected to improve standard accuracy. Overall I feel the paper still has room for improvement and there are several open issues, but it has been improved so it is marginally above acceptance threshold now. I think this is a good step. The proposed selection scheme can balance a certifiably robust model with anaturally trained but highly accurate model. However, it is not well demonstrated inthe experiments.<BRK># Summary of ContributionsThe paper presents an approach to trade off natural accuracy and certified robustness by combining a network with high natural accuracy (the “core network”) with a second network with high certifiable robustness (the “certification network”). The selection mechanism allows the combined system to perform significantly better than a weighted average of the core and certification networks (e.g.randomly assigning input to the core network with some probability $p$) would. ACE can consistently benefit from advances that improve the natural accuracy of the core network. In addition, as long as a selection mechanism can be found that is compatible with the certification network, it would be possible for ACE to leverage improvements in certified defenses. The term “natural accuracy” and “standard accuracy” is used interchangeably; the paper should settle on one. (Is this the standard deviation, perhaps?) During the comment period, the authors made progress in improving the clarity of their presentation. Overall, however, I continue to recommend an acceptance as the method to trade off natural accuracy and certified robustness is simple and significantly improves on the state of the art; for me, these strengths outweight the remaining issues.
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. <BRK>While the techniques are not particularly new (they are relying on the applciation of techniques appearing in earlier papers), and the idea to look at RNNs is fairly straightforward, I think this is an interesting and useful paper, with nontrivial estimates (that look correct, although I may need a bit more time to check).<BRK>I d be surprised if it is beaten (and that would be a very interesting result), but also I d be surprised if it s not matched (seems a simple enough predictor to discover if there is no overfitting). This is a valuable contribution. My main concern is on the empirical side. It is emphasized how this results in a proper kernel that can handle samples of different lengths.<BRK>This paper extends NTK to RNN to explain behavior of RNNs in overparametrized case. The paper proves the same RNTK formula when the weights are shared and not shared. Also, it seems that the proposed RNTK cannot outperform other SOA methods.
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 5. <BRK>The experiments done with a gaming setting (Starcraft II) is interesting. Spatial temporal point cloud modelling has many applications including weather forecasting as shown in the paper.<BRK>The paper proposes an extension of PointConv for spatial temporal point cloud modeling.<BRK>Summary:This paper proposes a new spatial temporal point cloud processing technique, which extends the prior work of PointConv for spatial point processing to the temporal domain.<BRK>In this paper spatio temporal point convolution are proposed, which can be used for sequences of sparse and unordered data. * The data sets consist of sequences with corresponding point data.
Reject. rating score: 3. rating score: 4. rating score: 4. rating score: 5. <BRK>UserBERT: Self supervised User Representation Learning  ######################################################################Summary:   The paper provides an extension of BERT to user data for pre training user representation in a self supervised manner. All the experiments are conducted on custom datasets. The discretisation of user behaviour signals over long term and short term to form “behavioural words” is quite reasonable  ##################################################################### Concerns:   The key concerns about the contributions of the paper are as follows: Overall, the novelty of this work is very limited.<BRK>##This work proposed a self supervised pre training approach to model users from user behavior time series data. I don’t see any papers discussed in the user modeling section of the related work, which raises concerns about the significance of this work. I don’t think the analogy between language and user behavior needs to be mentioned/adds any value.<BRK>The paper presents an approach to learning user representations based on activity patterns on e commerce websites and a user profile. This deserves to be discussed in some detail. Overall, the paper is a straightforward application of BERT pre training (with MLM only) to learn user representations.<BRK>Significance:I am not convinced that the result is significant. Mostly because the experiment is hard to be reproduced due to lack of description of modeling details and the dataset being used. I would recommend using an appendix section to explain it further. Is it a mean word embedding for each attribute ID? This also blocks reproducibility of  the paper results. Otherwise can you at least give more details (besides those already in 4.1) on the underline dataset in  the appendix?
Accept (Poster). rating score: 7. rating score: 7. rating score: 5. rating score: 5. <BRK>## SummaryThis paper presents a method to encode the minimal input feature discovery problem   finding the minimal set of features in a input that is necessary for a prediction   into a form that can is amenable to satisfiability modulo theory (SMT) solvers. In particular they first use the integrated gradients methods to score first layer neurons on the degree to which they influence the prediction. Then, they produce and solve an SMT problem that finds the minimal mask that changes these influential neurons. ## ReviewOverall I thought this was an interesting paper with practical utility.<BRK>This paper provides an interesting pos hoc explanation method to identify relevant features in an input that may inform a trained neural model s prediction. The author formulates this as an SMT solver task, but instead of making sure that the output prediction is similar (which involve multiple time consuming pass over potentially huge networks), they make sure that high influential neurons in first layer of the network are still activated. The paper as written is quite clear and I was able to parse the information with reasonable ease. As it is, I will recommend acceptance for the paper. 3.Why does bilinear interpolation not move data out of distribution ? For example, focusing on face of cat as bounding box and then blowing up should clearly put it OOD ? For example, say for original image, the set of influential neurons is IF and non influential ones are NIF. If the SMUG masked image activates all of IF neurons and only 10% of NIF neurons, we can get completely predictions.<BRK>This paper addresses the question of identifying which input features are most important for a neural network s decision. There are a couple of things that the paper combines in its final work: (a) using integrated gradients to score the first layer nodes, (b) restricting the search to only the top k layer one neurons, and (c) applying SMT to find the subset among them that best preserves the layer 1 activations. The paper argues in the paragraph titled SMUG vs SMUG_{base} that the latter does not provide sparse input features. It is not clear why sparsity is a desirable quality here. It would be good to clarify this. The paper claims that it is not a good idea to use an SMT based explanation that focuses on the final layer. If the masked inputs are out of distribution for the full network, then certainly they are out of distribution for the layer one activations too (eq 2). The experiments on images seem interesting (with the caveat about the need for SMT at all).<BRK>Summary: This paper improves the Integrated Gradient (IG) based model explanations by picking the top k activated neurons in the first layer and choosing a subset of inputs making sure top k activated neurons still active enough according to a certain threshold. Although the paper title suggests scaling symbolic methods (e.g.SMT based approaches), the proposed approach SMUG does not necessarily rely on SMT at all. Why is that? Questions:Q1: The authors argue "From Table 1, we observe that SMUG and SMUGbase achieve a significantly better score (−1.26 and −1.23 resp.)
Reject. rating score: 2. rating score: 3. rating score: 3. rating score: 4. <BRK>My review is going to be short because I truly believe that this paper, in the current form, does not reach the acceptance bar for ICLR. Despite, the fact the story behind SGD seems understood by the authors, I see no contributions in this paper.<BRK>Is this form of distillation considered in previous works before? Did the authors consider adding label noise to just the original labels? I would recommend rejecting this paper because I believe that the main result presented in this paper is already known [1] and this paper has not cited or compared with that paper.<BRK>Given the overlap, the submission does not meet the bar of publication. The high level conclusion in the current submission is the same as Blanc et al.In addition, the current submission has a weaker theoretical argument, since it is based on the SDE approximation which may not capture SGD as the noise distribution may not be Gaussian.<BRK>The paper shows that the unbiased label noise would favor convergence to points which stabilize model outputs against perturbation of parameters. Overall, there is a lack of justification regarding the claims in the paper. I won t recommend publication of the paper in the current state.
Reject. rating score: 5. rating score: 6. rating score: 6. rating score: 6. <BRK>This paper extends Prior networks models, previously introduced for classification, to regression problems. The presented approach extends this framework to regression tasks. In consequence, this work does not provide any new relevant insight into the problem of modelling uncertainty and learning models with well calibrated predictions. But, after many thoughts, I still think there is a limited novelty in this paper. adding baseline models to the paper and missing citations.<BRK>This paper mainly focuses on an extension to the regression task. Therefore, the contribution / novelty of this paper is incremental. Therefore, I would consider the novelty a minor weakness. There are no comparisons to other approaches for distillation of regression tasks. However, what about different OOD data? OOD detection for monocular depth estimation: Did you also trained the comparing models with the OOD data, e.g.DD?Comparing models: Have you consider comparing your model to other ones, e.g.[1, 2]?This could improve your paper and approach to show that it also consider existing work on regression distillation.<BRK>Summary of the Paper:        This paper introduces regression prior networks. Specific details:        I believe that this is a nice paper that illustrates an appealing method for uncertainty estimation in the context of neural networks. All this questions the novelty of the proposed approach. The authors should comment on the advantages of their method with respect to these techniques. The method proposed is also complicated and has several training parameters.<BRK>This paper addresses interpretable uncertainty quantification for data driven models. I believe this corresponds to the deep ensemble. The author contribution is thus clearly stated and positioned w.r.t.prior arts and tackle a non trivial issue.
Accept (Spotlight). rating score: 9. rating score: 8. rating score: 8. rating score: 6. <BRK>I still think this is a very strong submission and would like to see it accepted. The paper Introduces new tools from approximation theory. Please do so for both invariant and equivariant case, and consider stating it in the paper itself. Most importantly, the paper proves several important results on the expressive power of GNNs and introduces useful mathematical tools that I am sure will be used by the community. ”  > Among the architectures considered in this paper.<BRK>Summary:The authors prove several statements about the expressiveness of different classes of graph neural nets (GNNs): conventional message passing networks, linear GNNs (LGNN) and “folklore GNNs” (FGNN). The authors have a simple experiment that show in a limited setting that a practical implementation agrees with the theory. The authors derive a substantial number of expressiveness results from the general theory. Weaknesses & suggestions for improvement: 	The main paper only sets up the problem and states the main results, while all theoretical contributions are done in the appendix. Is this conventional language?<BRK>#### Typos:  "test to express the discriminatory power of equivariant architectures For this"  > "test to express the discriminatory power of equivariant architectures. #### GoalThe paper describes the approximation power of certain types of graph neural networks. It considers Message Passing GNNs (MGNNs), and two GNN type methods proposed by Maron et al., k FGNN and k LGNN. #### Quality  This is a great paper, well written, nice appendix, on an interesting topic. #### ClarityThe paper is clear and well written. The appendix is well organized, with an index that helps the reader find proofs and definitions. There is some novelty in the proof approach  New results related to k FGNN and k LGNN.<BRK>1.Summary:This paper compares the expressive power of three types of invariant and equivariant GNNs against the Weisfeiler Lehman (WL) tests, proves function approximation results for these GNNs, and demonstrates that 2 FGNN_E works well for the quadratic assignment problem. 3.Arguments for the recommendation and questions for the authors:a) It is nice to establish and summarize a thorough comparison of the expressive powers of different GNN families as well as k WL, and also to incorporate not only invariant but also equivariant GNNs into consideration. The value of 2 FGNN has also been demonstrated by the work of [1]. On the equivalence between graph isomorphism testing and function approximation with GNNs.
Reject. rating score: 4. rating score: 6. rating score: 6. rating score: 6. <BRK>In contrast to past works, this paper focuses on deeper understanding of the effect of partial client participation on the convergence rate by considering biased client participation. The obtained rates explicitly show the effect of client selection strategy and the trade off between convergence speed and the solution bias. The Assumption 3.4 seems problematic as together with Assumption 3.3 it implies that gradients of local loss functions $F_k$ are uniformly bounded. This is in conflict with Assumption 3.2 as local losses $F_k$ are assumed to be strongly convex. On the convergence of fedavg on non iid data. It is also nice that the theory, e.g.Theorem 3.1, recovers the result of unbiased client selection case without any solution bias. Towards flexible device participation in federated learning for non iid data.<BRK>##########################################################################Summary:The paper analyzes a biased client selection policy in the context of the federated learning paradigm. In particular, instead of random selection of the clients with a probability that is proportional to the size of the local dataset, clients with higher local loss values are selected. Despite being already used as heuristics, the authors claim that their work is the first one to propose a convergence analysis of a biased client selection mechanism in the context of federatedlearning. ##########################################################################Reasons for score: The paper is well written and the theoretical results look correct. The assumptions on which the theoretical analysis is based are quite stringent and could be further relaxed (especiallystrong convexity). Is it beneficial to perform more local SGD steps or does it become harmful for the convergence? How does this relate with the biased selection mechanism?<BRK>##########################################################################Summary:This paper studies federated learning (FL) and proposes nonuniform sampling of participating clients. Clients are selected according to their losses; clients with big losses are likely selected. The proposed algorithm has a rigorous convergence analysis. This paper has theoretical guarantees and strong empirical advantages. The experiments are conducted on small datasets. ##########################################################################Pros:+ The idea of choosing participating clients according to loss is an interesting and reasonable idea. The server must wait for their responses. 2 FMNIST seems to be the only used dataset. Even if it is big enough, I would like to see empirical results on other datasets, e.g., MNIST, CIFAR10, mini ImageNet, etc. But I am not convinced that this work is better in general.<BRK>This paper analyzes the convergence of FedAvg with biased client selection strategies. And the new strategy power of choice is designed based on the convergence results. This paper provides the first convergence analysis for a general class of biased client selection strategies. New concept, selection skew, is introduced as the measure of strategies. Based on the new concept, the analysis quantifies how the bias of the strategy affects the convergence speed of FedAvg. The performance of pow d is impressive in the FMNIST experiment, where it significantly improves the test accuracy under random selection strategy. Cons:1.Although the analysis is interesting and insightful, the effect of \rho seems to be limited.
Reject. rating score: 5. rating score: 6. rating score: 6. rating score: 6. <BRK>The paper explores the variational training of Bayesian neural networks. It proposes to improve the quality of the inferred variational posterior and computational efficiency of the procedure by (i) better initialization (mean parameters are initialized at the MAP) (ii) reducing variance in the Monte Carlo approximated evidence lower bound by increasing the number of weight samples (one per datapoint in a batch) (iii) a posterior regularization encouraging higher uncertainty on adversarially generated or other “near OOD” data. The authors use the term BayesAdapter to refer to the process of running black box variational inference from a fully factorized variational approximation with mean initialized at the MAP estimate and randomly initialized variances. Kingma et al., in their local re parameterization considered a variant with per data samples as well. If the goal of this paper is to claim that variationally trained BNNs (with the proposed improvements) are useful in practice, a natural question to ask is whether they are competitive with far simpler ensembling approaches that are able to account for the multimodality of the posterior surface, unlike variational BNNs. If not, it would be interesting to see cross performance — using PGD images for training and SNGAN images for testing. Do the authors have an explanation for this? Based on concerns about both novelty and experiments I am currently leaning towards a reject, but could be convinced otherwise based on the authors’ response and additional comparisons.<BRK>**Contributions**This paper proposes a post hoc approach to obtain model uncertainty estimates from vanilla pre trained NNs through MFVI fine tuning. Namely, 1) the authors re cast the KL divergence in the VI objective as weight decay applied to the variational parameters 2) the authors propose a variance reduction technique for the reparametrisation trick 3) the authors explicitly train their model to produce large model uncertainty on Out of Distribution (OOD) inputs. Empirically, the proposed methods seems to retain the strong performance, and much of the simplicity, of point estimate NNs while providing enhanced robustness in terms of uncertainty estimation. **originality and significance** To my knowledge, most of the proposed techniques (or variants of them) have appeared before in the literature or are simple extensions of existing approaches: Re casting MFVI as SGD [Khan et. al., 2018], Training on OOD measurement points to produce large uncertainty [Hendrycks et. al., 2018 and Hafner et. The paper is well structured and easy to follow. **pros*** Presents useful practices to make BNNs more mainstream with strong empirical performance. al., 2019] by explicitly optimising variational parameters to produce large model uncertainties OOD. **cons*** Exemplar reparametrisation is very similar to Flipout [Wen et. A comparison of the two would be appreciated. * The proposed technique for OOD detection is not very principled and has provides no guarantees. It seems empirically successful however. If this is the case, it is possible that models without uncertainty calibration training would benefit from using a different threshold. * The only baselines provided are other VI approaches.<BRK>This paper proposed one simple and effective way to trainBayesian neural networks (BNN). Pros:1.The proposed method is quite simple and cheap to realize, compared to previous Bayesian methods. 2.Extensive experiments on a diverse set of challenging benchmarks have been conducted, which shows several promising results of the proposed method. As described in this paper, most of previous methods, though paying much additional efforts than deterministic ones, do not lead to expected results, even with non diagonal covariance matrices. However, it is better to show the std metric of the result to make the comparison more convincing because the improvement of BayesAdapter in average value is in fact not very apparent, especially compared with MAP. 2.In evaluating the result of BayesAdapter,  MC samples are used. What if only using the mean value of the posterior? Compared to deterministic methods like MAP, inference using MC is more costly. 3.Based on results in Table 3, BayesAdapter  performs similar as baselines, which indicates that the improvement comes from calibrating the uncertainty estimation. It would be interesting to make such a comparison.<BRK>This paper introduces a fast way to get Bayesian posterior by using a pretrained deterministic model. Finally the variational parameters are optimized through standard variational inference (VI) training. To further improve uncertainty estimate, the authors propose an uncertainty regularization which maximizes the prediction inconsistency on out of distribution (OOD) data. Experiments including image classification and uncertainty estimates are conducted to demonstrate the proposed method. Thus the method is cheap and simple enough to use broadly in practice. The paper is well written and easy to follow. I mainly have the following concerns about the paper. One of the main motivations to use a pretrained DNN is that BNN learned from scratch is worse than its corresponding DNN. 2020] which the authors cited to support their claim clearly shows that BNN (with reasonable temperature) is significantly better than DNN in predictive performance. But the results of the proposed method seem to be worse than BNNs training from scratch (e.g.the ImageNet results in [Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning, ICLR 2020] are much better). I think the authors should revise the claim to be more precise. The authors argue that BNN training suffers from suboptimal local optima. I do not think it is true. Perhaps it is true only for a few BNN methods such as BNN using naive VI.
Reject. rating score: 5. rating score: 5. rating score: 5. rating score: 6. <BRK>**Summary**This work proposes a localized meta learning framework that adaptively determines a hyperprior for a specific task, derived from a PAC Bayesian analysis. **Detailed comments**The main idea of this approach is to adjust the global hyperposterior distribution by the information of the input task.<BRK>[d] The computational complexity of LML is not reported. Summary: This paper proposed a new localized prior PAC Bayes meta learning. It seems like a plug in approach for LCC. Detailed explanations[1] Paper organizationThe main contribution of this paper is Theorem 2 (and an improved Theorem 1). If there is a **particular** benefit to use LCC rather than other localized approaches, the explanations are highly expected.<BRK>  Summary and Contributions      In this paper, the authors proposed a localized version of PAC Bayes bound for meta learning. Actually, the two variances are different in the work of (Amit and Meir 2018). Following the PAC Bayesian theory and Line 154 156, the prior must be independent from the samples but could be selected from the distribution. Could the authors elaborate any guarantee of this algorithm to learn an effective v^Q so that this term is reduced? Moreover, I am not convinced by the results in E.4.<BRK>The paper presents an algorithm for offline meta learning, where tasks are drawn from a distribution and presented to a learner sequentially, the objective being to use accumulated knowledge in order to facilitate the learning of new tasks. Moreover, the authors go beyond current bounds by introducing a localized approach to data dependent prior learning, deriving an algorithm directly from theoretical bounds, and demonstrating its utility. This is not very helpful. Some discussion of this is called for. The form of the task complexity term in eq.(3) and (9) requires further explanation and elaboration given its pivotal role in the work.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. rating score: 6. <BRK>Summary:This work tries to find a compromise of model based and model free methods, using a teacher and student network . The teacher network is trained with meta gradients. It interprets the trajectories and provides activations for a student network that is supervised for a given task using the current state. Strengths:+ The paper is well motivated and solves interesting problem. Weaknesses:  Some claims made by authors are not validated. I suggest to add relevant citations in Sec.1. For example, where is the evidence of deterioration on the tasks that are potentially relevant? The evaluation is conducted using the self generated baselines.<BRK>This paper proposes a teacher student training scheme to incorporate the useful information of trajectory to improve the predictive performance of model free methods. The teacher network tries to "guide" the student network at the training stage by presenting an interpretation of the trajectory. The study in this work is interesting and important in RL. Searching for an optimal tradeoff between the two would benefit the practical uses. Do the authors have general principles on the design of the teacher and the teaching loss? This hand crafted data does not help with demonstrating the teacher learning the powerful interpretation itself. The argument should then be if the proposed method outperform model based methods given the same complexity (e.g.the number of parameters) or same amount of data.<BRK>This paper presents a student teacher framework, where the teacher network can be used to select and prioritize the relevant properties of the given dynamical system that should be learned by the student. Pros:  (significance) I think the presented framework is a powerful one, and has a potential to be applied broadly to many real world problems. The method was tested on a toy example and then applied to tasks with varying degrees of challenges. I get that the proposed framework avoids the *problems* of model based and model free methods, but I am having difficulties identifying what *advantages* of the two methods that the framework is incorporating. One of the central questions that is raised in the introduction is this: "What is the right way to incorporate information from different trajectories?". Overall, I have a mixed feeling about this paper and I currently stand between scores 5 and 6. **UPDATE:** My major concerns were addressed in the revised version of the paper.<BRK>This paper proposes a learning framework for predicting the labels of dynamic systems. Unlike existing model based approaches and model free approaches, the proposed model takes a middle ground and uses a knowledge distillation based framework. It uses a teacher model to learn to interpret a trajectory of the dynamic system, and distills target activations for a student model to learn to predict the system label based only on the current observation. Experimental results on both synthetic and simulated datasets confirm the effectiveness of the proposed framework. Predicting the behavior of a dynamic system has many applications. There are stronger baselines as noted by the authors. It would be good to add a running example to explain the various concepts and definitions used in the paper. The new version reads better. Since a positive rating is already given, I would keep it unchanged.
Reject. rating score: 5. rating score: 5. rating score: 5. rating score: 6. <BRK>This paper presents an approach to jointly pre train language models and representations for knowledge graphs. After rebuttal: I m also still not convinced by the experimental evaluation. (Maybe the gain in accuracy is only due to the additional information that is available in the knowledge graph?) Another natural question is why the authors have not made further experiments on other datasets and knowledge graphs?<BRK>How would fine tuning work on knowledge graphs that do not have entity descriptions? However, I believe the paper is not ready for publication in its current form as (i) the demonstrated improvements obtained by pre training with the added KG module seem minor compared to the computational overhead of having to compute entity and relation embeddings using GNNs; and (ii) experimental comparison to some relevant prior work is missing.<BRK>Or even have a GNN on top of that without language model? Experiments: The paper proposes a few baselines and compares the architecture with those baselines. However, there are several other works in this area. Doesn’t seem to have these problems.<BRK>Specifically, the paper replaces the entity embedding in one hidden layer of BERT context embedding, with the corresponding graph attention embedding that is obtained from the knowledge graph. The improvement over other kg+lm or purely lm baselines is consistent. Some of the baselines/ablations might be missing. The experiments have some flaws. I like the idea of having a joint training method for both the kg embedding and text embedding. I’d like to see the results on the three tasks in the experiments.
Reject. rating score: 4. rating score: 4. rating score: 4. rating score: 6. <BRK>Its key insight is that the entropy temperature in Soft Actor Critic should encourage the agent to explore unfamiliar states more and familiar states less, rather than globally encourage some expected target entropy. To this end, they make the target entropy and temperature both state dependent, using a curiosity model based on Random Network Distillation. Strengths:   The insight is described well and motivates the need for a curiosity aware entropy temperature for further sample efficiency. Weaknesses:  The justification of the instance level entropy temperature in Section 4.2 could be clearer. As is, it’s unclear why the instance level entropy is not redundant after the curiosity augmented target entropy, and vice versa. While the method achieves good results on the standard tasks, I am still curious about its performance on pure exploration tasks, and hard exploration tasks such as sparse reward settings. Recommendation:I am recommending to reject this paper. I think parts of the method can be more clearly explained and justified. There is also potential to better highlight the strengths of the proposed method in the experimental results, i.e., by including pure/hard exploration tasks. Questions:  The learning curves in Figure 1 evaluate SAC and CAT SAC for 200K environment steps. From the response, it seems that the proposed modifications to SAC do not and are not meant to solve the exploration problem in sparse reward tasks. Instead, its aim is to improve sample efficiency on standard dense reward tasks. The impact of the work then feels quite limited: the proposed modifications are specific to SAC and do not meaningfully improve performance on the sparse reward task.<BRK>Authors introduce curiosity to the target temperature such that the entropy is large in unfamiliar states, promoting exploration, and small in familiar states, encouraging more exploitation. To enable this, the authors introduce three components: 1) target entropy that is augmented with curiosity, 2) curiosity and hence state based entropy, 3) X RND that adds contrastive loss to ensure more robust computation of curiosity. In their benchmark experiments they show that their method CAT SAC shows superiority compared to SAC as well as other baseline methods. The authors have done a fair job introducing curiosity to enable better exploration by varying the target entropy at state level. The idea is interesting but I would recommend reject as the experiments need to be conducted more rigorously. This also shows that current results where SAC performs worse than CAT SAC could have been due to variance in random seeds. Comparison of CAT SAC to other baseline method performance seems less appropriate too. Results are based on SUNRISE paper (Lee et al.2020) which has not been peer reviewed and which have also done only 4 runs each. It looks like after the state is visited once the curiosity drops from 0.2 to 0.02 immediately. I’m not sure if it would be desirable to have curiosity drop suddenly after visiting it only once. For other minor details, I think the plots and labels in Figure 2(b) (c)  are confusing.I think the x axis should be index of each state, and prediction error of each state the label for the colormap.<BRK>Summary: The paper tries to improve exploration in continuous control tasks by augmenting Soft Actor Critic (SAC) with a curiosity module that increases the target entropy for unfamiliar states and decreases the target entropy for familiar states. To incorporate curiosity into SAC, the entropy coefficient is learned and dependent on the prediction error (coming from X RND) of the state. Novelty: The main novel component is incorporating curiosity into entropy to increase the target entropy in unfamiliar states and decrease it in familiar states. Pros: CAT SAC does improve over SAC on mujoco domains and it helps to have X RND component instead of vanilla RND. (1) Rather than adding curiosity to the entropy, what if we added it to the reward function? That should be a baseline. (2) RND doesn’t work that well with feature inputs. What about other notions of curiosity? (3) The method should be evaluated on harder exploration tasks (eg: ant gather and swimmer gather from Variational Information Maximizing Exploration (VIME; Houthooft et.al.)paper) and compared with VIME (or other exploration algorithms eg: why does hierarchy work so well?(nachum et.al.))Reasons for score: Weighing the above pros and cons, I vote for rejecting. Questions: Given c(s_t)is a scalar (as it’s prediction error), is g_{\delta}(c(s_t)) just m(c(s_t)) + b? I am happy to reconsider my score if the above concerns are addressed.<BRK>**Prior work in exploration**: While increasing policy entropy in regions of low  confidence makes intuitive sense, it is not actually clear simply being noisier in the face of uncertainty actually leads to good exploration (for example https://arxiv.org/abs/1306.0940 argues that these "dithering" style exploration is inefficient). It would be good to add additional comparisons to other methods for augmenting SAC to perform better exploration. It could be interesting to also explore how well CAT SAC compares to just using the (X )RND curiosity score directly as a bonus for exploration. **Conclusion**: Overall, I like the work. It appears technically sound, and presents a fairly simple and intuitive way to adjust exploration with SAC to better handle unfamiliar states (as far as any undirected exploration methods do at least). I would like to see a few more comparisons against other exploration techniques in deep RL, and perhaps some experiments ont asks outside of the standard gym benchmarks that focus more on the exploration problem itself rather than control (for example some sparse reward tasks). I would also like to see extended learning curves of CAT SAC vs SAC, particularly until we see the performance of each method saturate.
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 5. <BRK>This paper proposed a layer wise adversarial defense which added perturbations in each hidden layer considering the influence of hidden features in latent space from the ODE perspective. The main contribution of this paper is to generate perturbations with the idea of ODE in each layer. a)	To improve the limitation that the existing adversarial training approaches mainly focus on perturbations to inputs, this paper added perturbations in each hidden layer with the ODE perspective, which is not convincing enough to me. Why it is efficient to use the ODE method adding perturbation in each layer. As for the defense against attack method, this paper just used FGSM and IFGSM which are quite weak attacking methods. The proposed method may also be compared under strong attack methods, such as PGD and CW methods, since this paper targets defense.<BRK>### SummaryThe paper proposes to improve the robustness of residual networks (ResNet) by adversarial training with layer wise and gradient based perturbations. Also in [2] the authors analyze the link between input perturbations and layer wise perturbations. **The real novelty of the paper is its interpretation of such perturbations on ResNet using ODE, and its link to split decompositions. ** This interpretation is interesting and significant as it provides theoretical foundation to the approximation schemes. In Problem (1) $L$ and $f$ are not defined and it should be clearly stated that the formulation is specific to ResNets.<BRK>SummaryThis paper proposes to extend the commonly used input perturbation in adversarial training to layer wise perturbation, which adversarially perturbs all hidden layer inputs. It further analyses the perturbed dynamics from the perspective of ODE, and proposes two implementations based on different numerical schemes. 2.The ODE based analysis is interesting, and this direction may provide further insight into related work. Cons1.A major problem is that the layer wise perturbation is not well motivated and justified. This is problematic given that the improvements from LAD or LAD SM are relatively small   without the standard deviation, it is difficult to evaluate their significance. In addition, as an extension of input perturbation, is LAD( SM) comparable with PGD? I would be helpful to discuss this.<BRK>The authors proposed a new adversarial training scheme based on ODE techniques. But the perturbations can be found in the feature space. From the observation and the similarity between the layer wise adversarial attacks and ODE formulation, the optimization scheme was developed. If the pseudocode of the two proposed methods is provided, it would be easier to understand the proposed schemes. Strengths/Quality/Significance (pros):The authors studied an interesting construction. The proposed methods show that the adversarial training can be generalized to hidden representations. The generalization can be viewed as ODE formulations. The authors did not show the efficiency of the proposed methods. Clarify this.
Reject. rating score: 2. rating score: 5. rating score: 5. rating score: 6. <BRK>##########################################################################Summary:In short, the main contribution of this paper is to jointly combine the instance balanced sampler and the class reversed sampling in the training, where the latter is only applied to the last few epochs.<BRK>Cons:   Though effective according to the experiments, this method seems incremental and to some extent lacks novelty. + Compared to previous sota methods (BBN & Decouple) which adopted a 2 stage training strategy, this method is trained end to end.<BRK>Will this combination outperform the strategy in the paper? 2.The proposed approach is simple and interesting. Some of these concerns were addressed in the rebuttal, but not fully clarified.<BRK>The novelty is not enough for me. 2.About the experiments, (1) I wonder why the authors did not conduct experiments on ImageNet LT, which is considered to be one of the most challenging datasets. 2.The proposed approach is simple and effective on CIFAR and iNaturalist, and the ablation study and analysis is very comprehensive. #### I have some concerns:1.
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 6. <BRK>Though the paper contains several tables with ablation studies or side by side comparisons, it is hard to learn more from just the numbers in the table. Reviewer would like to see the analysis per category or per bounding box (currently the performance evaluation is mixed). W1: Most of the “findings” described in the evaluations are either known or somewhat expected.<BRK>Setup of the study: 1. The current model fairs well on $D_{s}$ that is a good sign about memorization. Once you understand the setup, the analysis in Section 4 can be quickly understood. Major concerns with the study: 1.<BRK>In the current form, it feels more like this paper only points out a problem that is already expected. In particular, most of the paragraphs are still simply spelling out the comparison results, without careful explanation of the insights. The conclusion is rather not surprising.<BRK>Summary: The paper provides a set of comparisons among different scene generation methods. 2.There are some concerns regarding the overall setup for the experiments. However, I do not see a clear evidence supporting this. provides a set of comparisons with other methods. However, I sill think novelty of the paper is limited as it is a conditional counterpart of [A].
Reject. rating score: 6. rating score: 6. rating score: 7. <BRK>The training and test loss are still decreasing at this point. However, I would like the author to discuss to which extent the derivation of this "single draw  bound differs from the result of Hellstrõm & Durisi (2020) they refer to. However, such bounds for randomized predictors already exist in the PAC Bayes literature for randomized predictors. Note that the proposed fast rate bounds only converge in this setting.<BRK>This paper derives bounds on the test loss under the random subset setting, which are expressed with conditional information measures, and have fast rates with respect to the sample size n. The derived bounds are compared with the practical performance of deep neural networks (DNNs) trained on the MNIST and Fashion MNIST data sets.<BRK>This paper extends results of prior work by Steinke and Zakynthinou, by providing generalization bounds in the PAC Bayesian and single draw settings that depend on the conditional mutual information. The emphasis in this work is on obtaining fast rates ($1/n$ vs. $1/\sqrt{n}$). The paper is very well written and clear.
Reject. rating score: 3. rating score: 3. rating score: 3. rating score: 3. <BRK>3.Previous work has addressed some of the issues that the paper seems to be aiming to address. The paper argues that the established (called standard) definition of adversarial accuracy has issues that need to be resolved, and then this work proposes a new definition (called genuine adversarial accuracy). Their definition aims to fix this by giving an alternative way of defining accuracy. The "issues" with previous definitions are not clearly discussed.<BRK>This paper proposes a new measure called "genuine adversarial accuracy" for adversarial robustness of a classifier. Strength of the paper1. The key concern about the paper is the lack of clear definitions on the important concepts, and therefore, on the proposed robust measure. The definition of $VB(\mathcal{X})$ could have been refined and some intuition about this definition could have been provided. I checked the proof for Figure 6 in Appendix A. They only compare the prediction of classifiers to that of 1 NN classifiers, which is by Theorem 2 optimal on the training set.<BRK>Other comments (not affecting score):  [This paper by Suggala et al.](https://arxiv.org/abs/1806.02924) also explores alternative notions of robust accuracy and are quite relevant. ** The authors provide a number of toy examples that are unfortunately not convincing. Finally they measure empirically how similar existing robust classifiers are to the 1NN classifier. trained models with the 1NN classifier.<BRK>The paper introduces a novel metric for measuring adversarial accuracy of machine learning models, dubbed genuine adversarial accuracy. One of my main reservation about this paper is the lack of significance. References are repeated numerous times, e.g.any mentioning of “adversarial training” is followed by the “(Goodfellow 2014)” reference, which is redundant and affects readability. The conclusions make several references to different parts of the Appendix which haven’t been discussed in the main body of the paper.
Reject. rating score: 3. rating score: 4. rating score: 4. <BRK>It assumes the variance of heteroscedastic noise is known as privileged information and suggests to reweight the samples by their noise variance in the loss. The major issue to me is the lack of novelty. Heteroscedastic regression is a classic problem in statistics. And reweighting using the inverse variance is a textbook method.<BRK>Just to clarify, the test loss reported in the figures, as a function of training steps: what is the *test* batch size? This also relates to the fundamental assumption underlying this work: access to privileged information, taking the form of knowledge of the stochastic noise variance affecting observed labels, at training time. The technical details of the proposed method are not sufficiently developed. Then, I think the relation of the proposed idea to simple linear models, for which heteroscedastic regression has been studied in great detail (e.g.[1], for a general reference), and for MLE (e.g., [2]), would become more clear and would give the opportunity for the authors to develop what are the merits of their proposed method. #########################################################################Main criticism:I think, overall, the main criticism I have for this work is that the contribution is not sufficient. Additional comments:A note on experiments using the UTKFace dataset.<BRK>In this paper, a reweighting technique is proposed to suppress the impact of heteroscedastic label noise in regression model training. The instance wise weight is determined by the estimated noise variance based on prior information of the label generation process. The downside of this paper is as follows: 1. It is a strong and usually impractical assumption to know a priori knowledge of label noise in the regression model training process. The proposed reweighing technique is not directly applicable in that case.
Reject. rating score: 4. rating score: 5. rating score: 6. rating score: 6. <BRK>This paper proposes an enhanced variant of the SREDA algorithm (Lou et al 2020), called SREDA Boost, that improves SREDA on two aspects: the initial complexity and the step size. It is not clear what is the problem solved in the numerical experiments? C2: Proposing a larger stepsize for SREDA compared to the original one. The authors also claimed that their analysis is new and different from SREDA. Since model (1) is nonconvex strongly concave, it can be reformulated into (2) as a stochastic optimization problem. Because the problem is strongly convex, this step can be done by several methods, including accelerated variance reduced schemes to further improve its complexity. Of course, this enhancement helps SREDA have better practical performance.<BRK>The paper proposes a SREDA Boost, which builds upon SREDA for nonconvex strongly concave minimax problem. The SREDA Boost algorithm is less restrictive to initialization and has an accuracy independent and larger step size. My main concern is the significance of the contribution.<BRK>This paper studies the nonconvex strongly concave min max optimization problem. I think the key to making SREDA Boost performs better than SREDA is the larger step size. The authors claimed it is the first zeroth order variance reduced method for the min max problem. However, I don t think the initialization complexities really matter, since they are always dominated by the complexity of the later optimization process.<BRK>The paper proposes a variant SREDA Boost of the variance reduction method SEDRA for solving nonconvex strongly concave min max problem. As SEDRA is already optimal, such modification does not improve the theoretical convergence rate, but it is beneficial from the practical perspective. I understand that the paper introduces a novel way for the complexity analysis, however the proof is very long and not easy to check.
Accept (Poster). rating score: 7. rating score: 6. rating score: 4. <BRK>The paper presents a new interactive environment which is both text based and contains visual simulation which are aligned. The authors also propose a first agent architecture which uses the visual observations as well as the text based (named BUTLER). The authors tested the generalization capabilities of the proposed BUTLER architecture compared to a seq2seq transformer model. Strong points:  novel environment for text based and aligned visual content (could potentially lead to follow up research)   a significant contribution to the community. have demonstrated that visual representation helps to generalize in these kind of environments (text + visual)  the paper is nicely written and easy to follow  the figures plots and tables are clear and help to understand the researchWeak points:  the complex system: e.g.,  a pre trained M RCNN, a pre trained text agent, and training the text agent using imitation learning (DAgger) biases the experimentation (makes the results less convincing). Maybe an intermediate naive baseline should have been considered.<BRK>If not, what is considered fully interactive? Rating after discussion: lowering to a 6, as I share concerns with R1 about experiments and generalizability of the proposed approach. The model decomposes the problem into three steps: (1) a perceptual module which takes as input an environment observation and generates a textual description of it including the objects and their spatial relations, (2) a goal planning module which takes as input the high level goal (which may require completing multiple subgoals), the textual description generated from module 1 and generates a textual description of a subgoal, such as an action the agent should take with arguments, and (3) a controller module which takes as input the state of the environment and the subgoal description generated from module 2, and generates a sequence of actions which execute this subgoal. The paper proposes a model and training scheme. The proposed training scheme focuses on pre training the second module. Reasons for score:I vote for accepting the paper. However, there are several assumptions and limitations of the proposed approach. Strengths:  A model which decomposes high level goals into low level action sequences is very valuable and interesting. Comparison of single goal vs. multiple goal models. Good set of ablations, experiments, and comparisons, although I am not sure why Section 4.3 only looked at a single task. As above, ALFWorld is manually designed and requires making decisions about what aspects of the problem to model and which aspects should be abstracted away. What is the difference between the high level goals and low level step by step language in ALFRED? If the Human Goals setting is using human written (natural language) goal specifications, then what are the goals in the other evaluation settings?<BRK>This text based environment is an extension of the TextWorld framework. Strengths:* The paper is clearly written. Weaknesses:* The main premise is that such a text based environment can be used to learn abstract (high level) policies that can then be transferred to an embodied agent to solve language specified tasks in a physically simulated (with visual input) environment. However, the main experiment to prove this claim in Table 4 falls short of proving this. The results in that table show agents learned with an oracle state estimator which means there is no visual input processing during this mode. It can also be noted that the Controller is also a heuristic module with no learning. * The performance of BUTLER ORACLE in Table 3 is similar to the performance of BUTLER on TextWorld (on All Tasks) which further proves that using oracle state estimator is essentially reducing the embodied environment tasks to TextWorld task. Overall: The strong motivation of this work is not supported by empirical results. Update after author response:The author response is much appreciated. However, my two main concerns remain unaddressed. The authors may add these additional experiments/results to Table 3 and 4 in further revisions for a stronger submission. * Table 3 is the main result of the paper which claims policies learned in TextWorld (TW) environment can be transferred over to ALFRED (ALF) environment under zero shot setting. (2) When evaluation is done on human goals (which seems to be the real test), the agent s performance is very low. (3) Why are the experiments only conducted in zero shot setting? * Since the transfer learning is happening from a pure text TW environment to a physically simulated (with visual input) ALF environment, it is more interesting/relevant to see how the language module pre trained on text only TW adapts to multimodal setup in ALF. This experiment was attempted in Table 4, however, as pointed in my initial review, this falls short of proving any claims made in the paper because the agents in Table 4 are learned with an oracle state estimator which means there is no visual input processing during this mode.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. rating score: 5. <BRK>The authors conducted a comprehensive set of experiments on choices of learning rate schedules for re training/fine tuning during iterative or after 1 shot pruning of deep convnets. Empirically, they reported that high learning rate (LR) is particularly helpful in recovering generalization performance of the resultant sparse model. Notably, this work has brought to attention an important but often overlooked aspect of network pruning: there exist complex interactions between the dynamics of optimization and sparsification, and as a consequence, it is only fair to compare two sparsification techniques when each of them are put in the _best_ optimization setup, respectively. There has been loss landscape studies of sparse nets during training (such as arxiv:1906.10732, arxiv:1912.05671) perhaps these could be applied to study the problem. How does weight value rewinding interact with LR?<BRK>It provides guidelines alternative to fine tuning for practitioners to obtain compact models with better performance after network pruning. * The observations of the random pruning are interesting and are aligned with the prior work [1]. The paper needs to improve its clarity. * Can you justify why it is necessary to include the learning rate warmup scheme for SLR and CLR, and why the paper only uses 10% of the total retraining budget? An ablation study is required here. * The observations for random pruning with learning rate restarting are interesting but more details are required. * The paper investigates the impact of different learning rate schedules for the re training, after pruning on the model pre trained by the standard stage wise learning rate schedule. This design choice is sufficient to provide some practical guidelines, but it may also blur the contribution: as CLR is quite different from the other learning rate schemes, it is natural to question if the performance gain is solely due to a better learning rate schedule (but not large learning rate). Can you also provide an ablation study in terms of using CLR for both the training from scratch and re training, and then compare both the accuracy and the accuracy drop scores? However, it is unclear to me if the same observations can be generalized to other CV tasks or even NLP tasks.<BRK>The paper proposes several learning rate schedules to compare, specifically a cyclic learning rate (gradually ramping up to and back down from the maximum learning rate schedule used during the original training phase) and a compressed version of the original learning rate schedule, and shows that these learning rate schedules outperform standard fine tuning and also learning rate rewinding, showing that the findings of prior work come from using a higher learning rate in general and not any specific schedule. "Rethinking the value of network pruning"# Update post author response:Thanks to the authors for the response. The more conclusive findings of the paper, that a high learning rate is important for optimization of pruned networks and that cyclic learning rates improve on learning rate rewinding, are a relatively incremental contribution# Overall recommendation5: Weak rejectI would be willing to raise this score if the authors address some of the weaknesses listed above. However, structured pruning can be an unreliable testbed for many of these techniques, as shown by [1].<BRK>The results show that high learning rate schedules (like cosine schedule) attain best performance in many different setting. Overall the work has a strong coverage of experiments and the results could be helpful to the community. However, I think the work misses some important baselines and require a bit more work on writing. "For CLR and SLR, the learning rate is increased from the smallest learning rate of original training to the largest one according to cosine function" probably the other way around Learning rate is decayed over time? "Being that said,"  > That being said  "there are notable differents between"  >  differences  "for future works." "Recently, Renda et al.(2020) proposed a state of the art technique for retraining pruned networks namely learning rate rewinding" I don t think this sentence is accurate. It s true authors claim SOTA, but I would argue they miss an important baseline in which the original training schedule of the iterative pruning algorithms are scaled according to the training budget as it is done in [1, 2, 3]. Overall, I like the direction of the paper, but I think the motivation should be improved and results should be distilled. "l1 structured" might be a more appropriate choice. I rather call of them fine tuning or warm restart, as all networks start with a pretrained network. This terminology would align better with the previous work.
Reject. rating score: 4. rating score: 4. rating score: 4. rating score: 6. <BRK>The proposed semi supervised contrastive loss seems to be a straight forward combination of the self supervised contrastive loss and the supervised contrastive loss [Khosla et al.2020].Therefore, the technical novelty is limited. Summary: This paper combines the self supervised contrastive loss with the supervised contrastive loss for semi supervised learning. If SuNCEt is also trained for 1000 epochs, would it converge to a similar result as SimCLR?<BRK>Pros:1.This submission is well written with lots of experiments. The claim is that supervised contrastive learning can speed up representation learning, which is well supported. Cons:1.Instead of proposing a new idea, this paper adopts supervised contrastive learning and discovers that supervision can help accelerate the pretraining stage. 2.Since this paper is investigating semi supervised learning, then some comparisons to existing literature is necessary. 3.Performance improvement on CIFAR is marginal. I read the limitation section in Appendix, but not clear how it is related to the final results. 4.I notice that the proposed SuNCEt loss is turned off after some training epochs.<BRK>Many recent works on self supervised learning (image classification using instance discrimination signals) eventually need to use all the labels in the linear evaluation phase to obtain the final performance numbers. The authors also point out a similar view in the last paragraph in Section 3. In addition, I think a "soft nearest neighbor loss" paper could be cited and compared (for example: Zhirong Wu, Alexei A Efros, and Stella Yu.Improving generalization via scalable neighbor  hood component analysis. The main contribution of the paper is the proposed SuNCEt loss, which is modified on top of the regular NCE loss in instance discrimination training. However, this “supervised constrastive learning“ only accelerates the SIMCLR learning process (by ~2x in terms of epochs from Table 1 and Table 2) and it does not significantly improve the accuracy over regular SIMCLR. Overall, I feel that the proposed loss is not a very novel idea (i.e., supervised contrastive learning) and the experiment results are not significantly better than prior arts.<BRK>**Summary**:This paper designs a new loss, called SuNCTt, to speed up the convergence of semi supervised training. The comprehensive experiments, also shown in appendix, support claims in the paper that the + introduced loss is helpful for semi supervised training  + Overall, the paper is well written and the results part is well structured. Is it possible to compare the results with theirs? It would be good to show the results of using cross entropy pre trained on ImageNet. In addition to the saving compute, I am also curious about the final performance on ImageNet after training for 1000(500) epochs. Both triplet loss and SuNCTt may do the similar thing, but in different forms.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. rating score: 6. <BRK>In this work, the authors propose to use out of distribution (OOD) data to improve the generalization of deep neural networks, especially against adversarial attacks. Theoretic analysis and experimental results demonstrate the effectiveness of such method. The idea is interesting and the paper is easy to follow. I am curious on what would happen if your OOD data contain some data that is overlapped with the data in training set. Unlabeled data improves adversarial robustness.<BRK>**1.Summary and contributions: Briefly summarize the paper and its contributions** In this work, authors looked at Out of Distribution (OOD) data from the data augmentation and regularization perspective and introduced Out of distribution data Augmented Training (OAT) based on their theoretical analysis which demonstrated that training with OOD data can remove undesirable feature contributions in a simple Gaussian model. The authors conducted experiments on both standard learning and adversarial learning and showed the effectiveness of OAT with strong results. Neat randomization test that analyzed the effect of OAT for standard learning. How exactly are you using the OOD data? Then it will be easier for the readers to follow the theoretical analysis. I think it will improve readability if Equation 9 is introduced earlier in the paper.<BRK>Summary: This paper seeks to remove "non robust" features by first hypothesizing that out of distribution image datasets share the same spurious features as the target data distribution, then performing adversarial training on the out of distribution data (against uninformative labels) to remove these spurious features. Strengths:  The method seems to be reasonably robust to the choice of OOD dataset, which makes the method quite flexible. I think that random OOD examples could also help because it can provide a regularizing effect   recent works [1,2] show that generic regularization such as dropout or early stopping improve adversarial training methods. It s unclear to me that the benefit is necessarily from removing non robust features. If you combine all the OOD datasets, do we get even more gains? Can you use in distribution unlabeled data with the OAT loss, and if so do we get a similar benefit?<BRK>This paper proposes a new data augmentation method that utilizes out of distribution data for enhancing generalizability for both supervised and adversarial learning. Then, a simple method motivated from the analysis is proposed and later verified by extensive experiments including both supervised and adversarial learning experiments. The proposed method is technically sound and extensive experiments are conducted to verify the effectiveness of the proposed method in different datasets for both the supervised learning and adversarial learning tasks. I am not familiar with the topic. My main concern is the technical contribution of this paper. The paper provides some analysis on this and proposes a simple method which combines in distribution and out of distribution data to train the model.
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 7. <BRK>##########################################################################Comments after rebuttal period: I appreciate the authors  efforts on increasing the clarity of this paper. According to the experimental results, I believe there is an implicit mechanism in the proposed method that achieves the ordering, but it is not clearly explained and analyzed. The methods were not clearly described. Many details are lost. How to cluster a tuple?<BRK>In order to perform anisotropic convolution on graphs, this paper proposes to project a local neighborhood into a unified virtual space by introducing anchor nodes. A theoretical analysis is provided to show the expressive power of the proposed graph deformer operation on graph isomorphism test. Minor Comment:* The chosen datasets are relatively small. "Kpconv: Flexible and deformable convolution for point clouds." Post rebuttal Comments:Thank the authors for the response.<BRK>Currently, I cannot see a solid support for this argument, which directly leads the failure of motivation in this work. The authors need to clarify this. There are some concerns for this work:1.<BRK>what about the diameter of the graphs ? Moreover, graphs are of variable size. 3  How different is the injective function proposed in this work compared to the one in GIC network ? The approach is well placed in the litterature, the organization of the paper is clear and the supplementary part is helpful including theoretical details and experimental ones.
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 5. <BRK>Update after the rebuttal:I read other reviews and response from the authors and I decided to keep my score. > Summary: In this paper, authors propose a new certified defense against adversarial patches. The main issue I have is that their probabilistic guarantees lack confidence intervals and therefore it is not clear how meaningful they are. Due to these problems, I cannot recommend acceptance for this paper. > Pros:I think explanations of the method are easy to follow and writing is solid, with some parts that require more clarifications. If I understand correctly, the experiments in Table 1 have additional transformation that is applied besides the adversarial patch?<BRK>However, the paper is poorly written, and many experimental setups are missing. The certification is defined as a guaranteed yes/no problem but the $p_c$ will relax the certification to a probabilistic problem. Pros:+The proposed method is quite general and intuitive. +Using a simple geometry and probability model, the proposed method can certify the robustness of the adversarial patch attack in a very efficient way. So, the contribution is not enough for ICLR. The hyperparameter $p_c$ is set as 0.95 in the experiment. So, if the $p_c   0.95$, is that means there is a 5% possibility that this image can be attacked?<BRK>The advantage of such a method is that one doesn t forget the fact that, whatwe actually want to certify is this "distributional" robustness (i.e.whereexpectation is taken over the true underlying, unknown distribution), not therobustness on the test set. are DRS and PG also probabilistic certifications (i.e.certifying robustness  with some probability, f.ex. in the conclusion: "This paper proposes a new architecture for defense  against"  > "This paper proposes a new defense against". and, more generally, is the word "certified" really appropriate inthis context? However, whether an analysis of the distribution of $n_{2to1}$ and $p_c$ willbe needed (as asked by other reviewers) might depend on how the authors willdefine adversarial vulnerability in the random setting, and what they try tocertify.<BRK>The authors propose a surprisingly simple statistical defense, that can certify the robustness of a classifier against patch attacks. The paper is charming because of the simplicity. As far as i understood the paper, the certification method is probabilistic due to the probabilistic intersection of sampled subregions with the adversarial patch. Then the number of overlapping subregions could be calculated precisely in advance and the certification would not be probabilistic. After reading the authors response, i think that this work would benefit from an experimental comparison of their random method against a method relying on a deterministic crop selection, even if the certification rates of the deterministic method are inferior, because the certificates both methods are yielding are different: The resulting certificates from the deterministic method would be deterministic instead of probabilistic.
Reject. rating score: 5. rating score: 5. rating score: 5. <BRK>It has two terms: an instance classification loss and a consistency loss. The novel part seems to be the consistency loss. It explicitly penalizes the dissimilarity between different views of the same instance. Good paper, accept+The proposed method is supported with extensive experiments. The proposed term L_C explicitly pushes positive samples to come closer based on cos similarity. Here by positive, I mean samples that are different views of the same instance. Compared to the state of the art methods reported in Table 2, the improvements are really really minor. In fact, in most columns, there is no meaningful improvement.<BRK>This paper proposes adding an additional loss term to instance classification, within the context of self supervised pre training. + related to above, empirical results and ablation study demonstrates the benefit of adding in consistency loss for subsequent downstream tasks+ qualitatively, adding the consistency loss seems to help the network focus on relevant/textured regions of the imagesNegatives:  Novelty is arguably somewhat limited, as the proposed method boils down to adding a term that encourages similarity between two views of the same image, very similar to contrastive learning. Empirical results are mixed   in general on par with existing methods. Performance is generally consistent across the explored tasks, but does not appear to be significant better than existing approaches. One data point that would be of interest is whether the proposed approach does better when training for more epochs, similar to methods such as SwAV or MoCo v2 on ImageNet linear evaluation.<BRK>This paper studies the instance classification solution for an unsupervised representation learning problem. Particularly, this paper proposes an additional consistency loss that is simultaneously optimized with classification loss, in order to penalize feature dissimilarity between augmented views of the same instance. Such consistency loss makes classification loss optimization easier and avoids large batch size. Extensive experiments on downstream tasks, e.g., segmentation and detection, show the effectiveness of the proposed method. Compared with previous instance classification solutions, the major contribution is that this paper introduces a consistency loss on augmented views from the same instance. The idea that compacts the augmented views is not new.
Reject. rating score: 3. rating score: 3. rating score: 5. rating score: 7. <BRK>This paper studies the problem of source detection in an epidemics when one observes the underlying graph and a snapshot of the population at a given time i.e.who is infected or not infected. The authors should compare their results to the results obtained by Shah and Zaman.<BRK>If so, why are then the confidence intervals not given for these curves? The current paper claims to (i) establish new fundamental limits on this problem, showing in particular that after some time the source detection becomes difficult, and (ii) to demonstrate the ability of graph convolutional networks to solve the problem and validate the results on real data. In terms of speed, training and inference should clearly be separated.<BRK>The theoretical results add to the contributions. 2   For a heavily empirical paper, the experiments are not comprehensive enough. are some of the areas that one would expect an empirical paper to cover and are missing in the current version of the manuscript.<BRK>Summary: Backtracking source of an epidemic (Patient Zero (P0)) is one of the important research topics of the current era that helps efficient resource allocation. Overall, this paper is well written and structured and friendly to reviewers. Comments: The framing of P0 in terms of learning problem and the proposal of GNNs for solving it is a valuable contribution.
Reject. rating score: 5. rating score: 5. rating score: 6. rating score: 6. <BRK>BNNs have been shown to be a more robust learning paradigm due to their uncertainty/stochasticity. Given the empirical observation that adversarially trained BNN posterior variances converge to zero (which the authors need to do much more to show as this is not a well established phenomena), the authors propose a hierarchical prior where they put a prior over the parameters of the Gaussian prior normally used  in mean field variational inference. The authors show that performing approximate inference with a hierarchical prior leads to an increased variational posterior variance, which the authors claim is correlated to the observation of increased adversarial robustness. One thing I will note on the experimental side of things is that having greater variance is indeed interesting, but it may or may not be correlated with increased uncertainty and this may be interesting to investigate in a future version of this work. I truly encourage the authors to continue to pursue this topic. This can only be done by exact Bayesian inference. It is not known, and likely not true, that for general approximate Bayesian neural networks (e.g.mean field approximations) the true or approximate posterior is Gaussian. Following the author s rebuttal I think the paper has benefitted from further experiments and from further clarifications. I would like to thank the authors for carefully considering my feedback and for modifying their paper in the directions I suggested. Ultimately, like I said in my original review, I think this is a very interesting and well motivated problem, but I still have a few doubts.<BRK>This paper studies the adversarial robustness of DNNs with Bayesian neural networks. Although BNN has been integrated with adversarial training for better robustness, this paper argues that the previous method lacks the stochasticity (i.e., the posterior tends to have zero variance), thus limiting the robustness performance. In this paper, a new hierarchical variational inference is proposed to enhance the robustness when integrating with adversarial training. The experiments show the effectiveness of the proposed method. Besides, I have few concerns about this paper. Does normal BNN models (without adversarial training) also have this issue? The parameters of PGD and EOT PGD are not stated (e.g., number of steps, step size, number of samples in EOT, etc.). Therefore, it is hard to judge the significance of the results. 3.This paper lacks the comparison with the state of the art methods. I suggest the authors to compare with the public adversarial training models.<BRK>Summary:The paper studied the adversarial Bayesian Neural Network and found that the stochasticity of it vanished. As stochasticity can help improve robustness against adversarial examples, the author proposed to use conjugate prior of Gaussian posterior to improve stochasticity of the model and robustness at the same time. Strength:Experiments show that the proposed method outperforms adversarial BNN and adversarial training on several benchmark datasets and the stochasticity of the proposed model is larger than adversarial BNN. Checked the original paper of adversarial BNN and found that the performances of adversarial BNN is much better than reported in this paper. In both papers, VGG16 is the base structure of BNN, but the reported performances of adv BNN and adversarial training are different in two papers on CIFAR10. They are evaluated under PGD and EOT PGD with $L_\infty$ in $[0,0.03]$. Conclusion:The idea is clear and novel but experiment results need more elaboration. However, I m a little bit concerned about the experiment results. If that can be addressed, I m willing to accept the paper.<BRK>Summary:This paper presents a new adversarial training for BNNs with variational inference (VI). This extension results in a stronger regularisation of the weights of BNNs, which can enhance the robustness against adv attacks and leads to a hierarchical inference. The method is reported to have better performance than vanilla adv training and adv BNN training on several benchmark datasets. The proposed method is a straightforward way to address the vanished stochasticity issue. Cons:  It is concerning that the reported performance of Adv BNN in this paper has a significant difference than that reported in the original paper. Given this fact, the performance reported in this paper seems to be ungrounded. For example, q has been used to denote the posterior but it denotes the prior in Eq.(5) The author response addresses my major concern on the experimental results.
Reject. rating score: 4. rating score: 4. rating score: 4. rating score: 4. <BRK>I believe critical experiments that are missing is unsupervised training say with dataset 1 and the fine tuning on dataset 2 and showing improvements on multiple task (However, even if this experiments are provided I still believe the paper lacks novelty, maybe invistaginting what properties are being transferred in multivariate time series and showing difference between transferring from unvariate to multivariate and vice versa will help). The code implementing the paper is not provided. # Weakness:  My main concern is the lack of novelty the paper is basically suggesting to use a  transformer encoder and add a dense layer before and after, and if we use unsupervised training of the transformer with the same dataset we ***may*** achieve better results. For regression, the proposed method was evaluated on datasets from the Monash University, UEA, UCR Time Series Regression Archive Tan et al.(2020a); for classification, the paper used the UEA Time Series Classification Archive (Bagnall et al., 2018).<BRK>This paper uses transformer to improve mutlivariate time series classification and regression using a BERT inspired self supervised loss. The authors show improvement over multiple standard datasets. The idea is interesting but some design decisions of the method (representation pooling, self supervised loss, need for finetuning) should be better justified. This means that the representations are not of fixed size (or contain padding representations).<BRK>6.Experimental settings are unclear. Actually, there are existing works that have tried to use the transformer for time series. It is with a shape of w by d where w should be your window length and d is your input dimension.<BRK>The authors targeted an important data format, multivariate time series, and extended the usage of the transformer to this format. 3.The selection of datasets needs more justifications.
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. rating score: 5. <BRK>Overall, the method achieves superior performance compared to standard codecs as well as other state of the art learning based method on the evaluated dataset (from Kodak). **Weaknesses**(W1) Runtime for encoding and decoding not listed. Also are there any limits in terms of image size the method can handle? **Strengths**(S1) The approach is clearly described, and the figures help to follow the paper.<BRK>Have the authors compared computational complexity? The main reasons why industry standards are not enthusiastic about deep learning approaches to compression is due to the computational complexity, not so much memory. The proposed method demonstrates good quality and memory usage gain. I think this work is a nice work, however I have two main concerns.<BRK>This paper propose two methods for improve deep image compression performance: (i) Global Reference Module and (ii) Mean shifting GDN Module (GSDN). The proposed method uses the mix quantization approach (Minnen & Singh 2020), but the evaluation of figure 7 is compared to Minnen 2018 as Context + Hyperprior so it is not fair comparison. In Figure 5, the meaning of σ s log is unclear and seems not appear to have been mentioned in the text. I couldn t understand why the number of channels are not the same.<BRK>The comparison results of whether progressive or not are missing. 4	Generally, the performance gain is very limited as shown in the RD curves in Figure 6. 1	The explanation of the proposed “confidence U” is significantly deficient. But the paper lacks the explanation and experiments to the rationality of the design of the progressive process.
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. rating score: 5. <BRK>Using DDEs is a novel technique in machine learning and can complement and build on the framework of Neural ODEs and help model systems with time delay dependencies and overcome some limitations of ODEs. The paper was well written with a clear description of the model and theory to support it as well as the algorithm to train it. 3) The authors claim that unlike NODEs, NDDEs can overcome the problem of mutually intersected trajectories in phase space. This can be especially important for systems with a time delay effect as in Figure 6 and 7.<BRK>Figure 2 could be more informative. This is mentioned in the discussion section, but I think the paper would benefit from an experiment involving a real world dataset with some sort of delay component, ideally in which NDDEs outperform NODEs/ANODEs. Figure 7 could probably be improved by reducing the number of different parameter values reported (e.g.3 columns instead of 6). The discussion paragraph "Extensions of the NDDEs" suggests a generalization to more complex delays, but all of the models in this paper ensure that the delayed value is always the constant initial value. Either way, it s not obvious how either of these would yield better representations.<BRK>This paper presents a modeling class of parameterized first orderdifferential equations that are conditional on some delayedpast states. This is a promising direction for the community to goto push past current ODE modeling limitations, but I recommend forrejection in the current form due to improper characterizationand evaluation with respect to prior work (more details below). # WeaknessesThe strongest weaknesses of this paper are the characterizationand evaluation in comparison to [Dupont 2019], which pointsout some of the same modeling issues and proposes analternative way to fix them.<BRK>This work considers Delay Differential Equations instead of ODE, which allows to implement more complex dynamics and thus achieve estimation of more complex functions. (5)	Experiments on image datasets(6)	The strong point of this paper is of course the proposal of the new variant of NODE, which comes with a novel algorithm and overcomes some limitations of NODE. I was interested by the examples of functions not covered by NODE and covered by NDDEand easily convinced by that. Major points and questions to the authors: 	More importantly, as a novel algorithm is introduced, I expect to see a complexity in time analysis. As for NODE I understand that the complexity in space is favorable.
Accept (Oral). rating score: 8. rating score: 7. rating score: 7. rating score: 7. <BRK>#### Summary of the paper :The authors propose to improve the sample quality of autoregressive models. The authors propose to (1)   smooth the input data distribution leveraging methods that have shown success in adversarial defense, (2) recover input distribution by learning to reverse the smoothing process. #### Pros :* The idea to leverage a method previously used for adversarial defense to density estimation is interesting and novel. * The paper is well motivated through the manifold hypothesis approximation (which results in densities with high Lipschitz constants) and compounding errors. * The theory is strong #### Cons :* The experiments on denoising and inpainting are only qualitative and suffer from a lack of quantitative evaluation. Therefore I would tend to accept the article. First, it is not clear that the proposed model is generating better sample than the MADE baseline on this specific dataset. In addition, in the 2d toy problem (i.e.ring and olympic) as the authors are choosing a gaussian smoothing both debiasing methods are usable.<BRK>Summary : This paper proposes an approach to modeling distributions based on a two step process which involves sampling a noisy x first and then applying a denoising function. The theory is grounded in other works in the literature that use the connection between denoising and the gradient of log p(x) with respect to x.I enjoyed reading the paper and I think that the authors are definitely working in an exciting area. It took me a few passes to realize that they were indeed learning p(noisy x). Otherwise it s easy to look at the pictures and to conclude that they are taking x from the training distribution, adding a small amount of noise, and then showing that they can remove the noise. Some more specific comments about the text. We understand what the authors meant by the context, but I recommend rephrasing this. I like figure 1 2 for how they illustrate the concepts well.<BRK>All models have limited capacity   what is particularly bad about the capacity of an autoregressive model being limited in this way? The paper demonstrates that this leads to improved sample quality compared to fitting the data distribution directly. Proofs  for theorems 1 and 2 should be referred to in the main text. Theorem 2 should also have log p(x) on the LHS? I didn t expect the sampling performance to improve substantially by adding just a single denoising step, and I think demonstrating this is a good contribution. Since a central claim of the paper is that the method results in improved sample quality, it might be good to add the Kernel Inception Distance ("Demystifying MMD GANs" Binkowski et al 2018) which has many favourable properties over FID, and is really no more difficult to compute. I m not sure I agree with this. Finally, the approach isn t really tied to autoregressive models, apart from the motivation given in terms of smoothing 1D distributions. It s fairly likely that the same idea could readily be applied to e.g.normalizing flows and that it would work well there also, so it would have been nice to see experiments featuring flows included here.<BRK>However, its sampling ability is not that good as explained in the paper. [Rec2].Some acronym for “randomized smoothing” would help in the 1st paragraph of section 3.1. ** I liked the idea, think that the paper is well written and I trust the results presented by the authors. Despite the randomized smoothing strategy is rather simple, it seems to work particularly well. The analysis and description of problems for sampling from autoregressive models is completely understandable to me and I agree with the manifold hypothesis held. I also read the updated version of the manuscript, which is clearly improved and the rest of reviews and comments by the AC. Looking to that, I agree with the rest of reviewers about the quality of the paper, so I raised my score and I recommend to accept it. Additionally, I particularly like how authors first present the idea on 1 d examples, later in the experiments, the method is validated with 2 d rings and finally, as stated in the introduction, with different image datasets. A lack of analysis about the optimal noise for randomized smoothing. I think that authors should remark that this is a reversible process.
Reject. rating score: 3. rating score: 6. rating score: 6. rating score: 7. <BRK>The authors of this paper propose a unified optimisation objective for (sequential) decision making (i.e., _action_) and representation learning (i.e., _perception_), built on joint (KL) divergence minimisation. Information theory of decisions and actions. In particular, the authors demonstrate how existing ideas and approaches to (sequential) decision making and representation learning can be expressed as a joint KL minimisation problem between a target and "actual" distribution. Such examples are (a) MaxEnt RL, (b) VI, (c) amortised VI, (d) KL control, (e) skill discovery and (f) empowerment, which are all cases of the KL minimisation between a target and an ``actual  distributions.<BRK>The examples shown in the paper and appendix give a good illustration of how people can make assumptions or design the terms to convert prevalent objectives into objectives that follow from this joint KL divergence framework. The general framework does somehow serve as the guideline, but my worry is that its effect will be limited as we still need to design the mapping for the terms in the general objective accordingly in different tasks.<BRK>The authors formulate a general framework that unifies inference, action/perception, control, and several other tasks. The framework is based on minimizing the KL divergence between a parameterized "actual" distribution and a "target" distribution. The paper is clearly written and provides a very thorough literature review. However, generally I question the scientific value of such all encompassing unifying frameworks, and this paper in particular offers no concrete formal or empirical results, while promising a lot. At the end of the day, the divergence minimization objective is nothing more than MaxEnt, decorated with various interpretations and decompositions. One of the issues is that the paper appears to treat the "heart of the matter" (i.e., the source of interesting solutions) as if it lay in the elegant and generic objective.<BRK>While the paper is, for the most part, well written and well organized, there are some gaps/ jumps that render understanding difficult. So far, so good. https://doi.org/10.1145/1143844.1143963in the "control as inference" section. This may also be due to the reason that it is only referenced in the appendix. I would not call this a recipe, but an outlook at most. 4.Fixation on KL divergence: This is more of a suggestion.
Accept (Oral). rating score: 9. rating score: 9. rating score: 8. rating score: 7. <BRK>This suggests using a sparse prior for temporal transitions of latent variables when modelling naturalistic scenes. The paper is very well written and full of convincing arguments. The evaluation is extensive (two baselines, one of SOTA from ICA and disentangled representations literature, and 14 datasets). It is a really good method of visualising disentanglement I agree with the authors that this is a much better way then showing latent traversals. The paper seems to be very good, though I am no expert on ICA. I strongly recommend acceptance.<BRK>##################################################################Strengths:  The paper addresses the important problem of unsupervised learning of disentangled representations. Overall, it is well written and easy to read. Hence, it would be good to clarify this particular point in the main paper. For the Kitti masks dataset, continuous natural transitions are considered in all underlying factors. I ve increased my score.<BRK>More specifically, after reading the paper I have a burning question:  How important is the Laplace prior over transitions? * The paper is clear and well written. # Conclusion:Overall, I recommend this paper to be accepted.<BRK>This paper introduces the SlowVAE to model transitions (of position, size, etc) in single object videos. Learning disentangled representations from data which is engineered to show changes in one generative feature at a time seems like cheating because we usually don t have easy access to such data (unless an agent actively interacts with an object). For instance, from the fact that object masks are projections of 3D objects onto 2D frames? Could this possibly explain why you found a heavier tailed Laplace distribution to be a good fit for the transitions in Youtube VOS and KITTI MOTS? Why work with discrete transitions at all?
Accept (Spotlight). rating score: 7. rating score: 7. rating score: 7. rating score: 6. <BRK>The paper presents a benchmark / dataset, HW NAS Bench, for evaluating various neural architecture search algorithms. The benchmark is based on extensive measurements on real hardware. The paper has a very good intention, i.e., to help and support non hardware experts in the neural architecture search process. I think the paper contributes a lot to that ambition, by providing a benchmark / dataset of hardware aware measurements / predictions that can be queried either by a person or a NAS algorithm. The network architectures that provide the search space are NAS Bench 201 and FBNet, and the measurements/predictions are obtained from three categories of devices, i.e., commercial edge devices, FPGAs, and ASICs). The work presented in the paper is important and can potentially have a significant impact, both in industry as well as in academia.<BRK>### Contributions ###* The paper proposes a benchmark for hardware aware neural architecture search (HW NAS). For this, the authors adopt two popular search spaces (NAS Bench 201 and FBNet) and measure/estimate hardware performance metrics such as energy costs and latency for six hardware devices (spanning commercial edge devices, FPGA, and ASIC) for all architectures in this search spaces. While the lack of generic NAS benchmarks has been addressed recently, the same did not hold true for HW NAS. Thus, the proposed HW NAS Bench fills an important gap and can prove to be very useful for practitioners and HW NAS researchers. Moreover, and related to the point above, it is not really clear how to rank different NAS methods in the proposed benchmark since there is no full evaluation protocol. ### Recommendation after Author Response ###I have read the author response and appreciate the effort spent by the authors on this response.<BRK>The set of analyzed hardware is limited3. 2.In Section 3, how long does it take to run all the measurements and estimations? It is suggested to add more details regarding the use of other network types, or at least analyze this different domain of NAS to provide a proper justification. While these examples may be representative, they could not cover the whole search space and characteristics, limiting the applicability of the benchmark in real world scenarios. 5.In Section 4, when analyzing the different hardware systems, there is the usage of absolute characteristics, such as FLOPs and latency, why are other relative characteristics, such as arithmetic intensity, not being considered? They could provide a better estimate and means of comparison, especially since the set of hardware is very wide, covering the whole intensity spectrum. 2.In Section 4.2, Figures 3 and 4, the axes are difficult to follow, especially since they are not repeated for the other graphs in the figures.<BRK>For example: the authors measure the correlation between inference times for the same network architectures on different hardware devices. The authors convincingly argue that properly performing on device inference time/energy benchmarks properly is challenging for practitioners because it "requires various hardware domain knowledge including machine learning development frameworks, device compilation, embedded systems, and device measurements." ## ClarityIn general, the paper seems clear and well organized. **Pros*** **The proposed dataset seems useful for research on hardware aware NAS algorithms. I m hoping the authors can clarify, since releasing raw benchmark numbers for FBNet may not be very useful unless they re accompanied by code that can train/evaluate any architecture in the FBNet search space. This is a limitation of the review process. ## Experiments presented in paperThe paper promises to release on device inference time measurements for NASBench 201, as well as a lookup table based inference time prediction model for FBNet.
Reject. rating score: 5. rating score: 5. rating score: 6. rating score: 7. <BRK>The paper introduces a meta modelling concept as an approach to achieve high quality uncertainty quantification in deep neural networks for sequential regression tasks. However, the paper needs more work for clarity and rigorous analysis. For example, equation 2 is not clear to me and needs explanation and/or related citations. The evaluation metrics were introduced (Eq: 3,4,5,6) to measure the effectiveness of the proposed method. There are two proposals in this paper: one is a meta modelling concept for uncertainty measurement and another is the evaluation metrics to evaluate the uncertainty. For the purpose of evaluating the proposed systems, it is also necessary to utilize some benchmark datasets from the literature.<BRK>**Overview**This paper applies "meta modeling" to the time sequence regression task. The idea is to meta learn a base model that not only fits the labels, but is also easier for a meta model to learn uncertainty quantification. Several variances are evaluated on two datasets: MITV and SPE9PR. The evaluation results on MITV and SPE9PR suggests that Jointly training approach out performs other variances and is more robust in the presence of dataset and model drift. However "meta modeling" is not a new concept, and it is usually referred to as meta learning and learning to learn in the literature. The proposed approach doesn t really fit into this category, as  the weight of base and meta model $\phi,\gamma$ are separately learnt in a multi task fashion (e.g., there are 2 tasks in this setup: one is the regression task for the base model and the other is the residual prediction task for the meta model). The two evaluation datasets are on limited domains.<BRK>In this paper, the authors propose a technique for uncertainty estimation in regression with neural networks. I do have some concerns about the experimental evaluation. For purely neural network based approaches, many would argue that these ensembling techniques represent the current state of the art. Metrics like continuous ranked probability scores do not assume a particular distributional form of output and are well studied and likely to be highly correlated with some of these more slightly ad hoc metrics. The bandwidth "metric" is also a little strange as a metric, as it doesn t depend on the true label y and rather just encourages confidence generally. After author feedback, I feel that the authors did address a number of my points, including one or two that were indeed addressed in the text that I must have simply missed.<BRK>In this work, the authors present a meta modeling approach to provide predictions with uncertainty estimates in a sequential task. The authors also incorporate the ability to make asymmetric uncertainty bounds. They apply this method and many baeslines to two datasets: MITV and SPE9PR. * Could you address how this work could be applied to other methods such as RNN s? Ultimately, I think this is a strong work that establishes an exciting method for uncertainty estimation. Because of it s strong presentation, novelty, and experiments, I rate this as a clear accept.
Reject. rating score: 4. rating score: 5. rating score: 6. rating score: 7. <BRK>It is argued, that the framework helps with dynamic composition of multi agent teams, which encompasses variable numbers of agents, as well as heterogeneous agents. The paper provides experimental evidence, that structured communication about the coordination of decentralized agents is beneficial, even if the communication frequency is enforced to be sparse. The paper includes results which suggest good generalization performance of the proposed algorithm wrt. This might very well be due to the paper proposing a specific type of communication (with global knowledge), while disregarding to argue about different types of communication in MARL and only comparing to an approach that does not explicitly involve communication. Given its focus, I further argue that the paper lacks related literature with respect to learned communication in MARL [e.g.compare with listed literature in a current survey, 3]. Further, I believe, the paper would benefit from disentangling the communication idea with the variational objective, which is more in line with hierarchical approaches (which is accounted for in the related work section). Other comments:The AI QMIX reference [1] changed significantly after the paper submission. An update of the reviewed paper with respect to this should be considered. In: arXiv preprint arXiv:2006.04222.<BRK>This paper addresses the important problem of being able to deal with heterogeneous teams of agents (that might change over time) in cooperative multiagent reinforcement learning. The language is not perfect in some places, but could be easily polished with additional proofreading. In my view, this does not provide enough evidence to be able to assess the general applicability of the approach, in particular because it is only evaluated in a single domain and much of the reported performance could be attributed to fine tuning of domain specific parameters. The paper is generally well written and relatively easy to follow, though many of the design decisions are not very well explained, and there is no explicit problem formulation regarding what optimal communication strategies would look like, which would help evaluate the advances reported in the paper with respect to the overall fundamental problem.<BRK>The authors design an adaptive communication strategy to minimize communication from the coach to the agents. Interestingly, there is almost no performance degradation even when the coach communicates as little as 13% of the time with the players. 2.The contribution in this paper is to propose a coach player framework for dynamic team composition of dynamic and heterogeneous agents based on deep Q learning with an attention mechanism and a variational objective to regularize the learning. The authors performed only one experiment in a resource collection task. It seems to be a relatively simple setting for me, but the investigation in another experiment will help us understand the effectiveness of the proposed method from more general perspectives. It may be confusing. after rebuttal Thank you for answering my questions. The authors added a new simple experiment and a code, whereas the manuscript at the current stage can improve the clarity.<BRK>Summary:This paper studies the dynamic multi agent team coordination problem, in which the optimal team strategy may change over time as the environment and the team members vary. Empirical studies demonstrate the effectiveness of the new framework. Comments:This paper is generally well written and clear. In the empirical study, COPA with variational objective outperforms the state of art benchmark. The authors also have an interesting observation that always communicating the optimal global game plan to the players is not always the optimal strategy. 2.As the authors claim that the coach is more useful when it can make the agents behavior smooth/consistent over time, the reviewer is wondering whether it would be helpful to communicate a smoothed strategy update to the players.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>Please consider providing more detailed statistical analyses (e.g.R^2) if the authors want to make this claim. (2) The experimental results are weak and incomplete, and comparisons against related work are missing. The clarity of this paper is substandard as many key details are ambiguous or completely missing. For example, how does the SMA memory buffer store features?<BRK>This paper proposed a two pathway neural network to mimic the interplay between the parvocellular (slow and fine grained) and magnocellular (fast and course) pathways in neural systems. It is well known that learn a weaker network by distilling a stronger network can result in stronger results for the weaker network. Third, the accuracy on Cifar 10/100 are low, far away from the well established SOTA. Finally, the paper might aim to be explanatory, but it falls short in clarity. The choice of the number of feedback steps is ad hoc.<BRK>This paper proposes a dual path CNN architecture with complementary roles (FineNet and CoarseNet) which is inspired by parvocellular and magnocellular pathways in the primate brain. My main criticism of this work is the lack of comparison with alternative models in the reported results. * The exact images used to produce each of the results are not clearly explained. I suggest the authors either remove or revise this statement. It is not currently clear if that is the case * page 8: restrict Boltzmann machine —> Restricted Boltzmann Machine * For results in Fig 5, how would alternative models like CORnet [1] perform on this task?
Reject. rating score: 3. rating score: 4. rating score: 5. rating score: 7. <BRK>This paper studies test time adversarial robustness through a maximin framework and illustrate non trivial robustness (under transfer attack) using domain adversarial neural network (DANN) to Linf norm and unseen adversarial attacks. While I agree that test time adaptation is an important and practical approach for adversarial robustness, the current version, in my opinion, does not deliver significantly novel insights, nor considering a reasonably practical threat model. Even in the test time adaptation setting, the "defender move first" setting should be more practical. To have a fair comparison, the authors are suggested to compare robustness on robust models such as TRADES [R1] and adversarially trained models with unlabeled data [R2,R3], so that the baseline models also use unlabeled data. The theorem presented in the paper is a natural use of maximin inequality.<BRK>This paper explores a new paradigm referred to as "adversarial robustness of test time adaptation". * The authors also mentioned theoretical interest, yet I don t think, with the current contents, this paper can be appreciated as a theoretical paper. 3.The paper also says "This threat model enables us to study whether a large test set can benefit a defender for adversarial robustness", yet I do not see any experiments (in the main paper) that correspond to this discussion. The appendix seems lacking this discussion either. Then why not also report performances on S? Yet a major focus of the paper is DANN, which allows such usage.<BRK>* The paper studies test time adaptation via DANN and its robustness in the maximin and minimax threat model. The authors considerably improved the paper and have addressed some of my concerns. * As stated in my initial review, since DANN is a central method in the experiments, it should be briefly summarized to make the paper self contained and also the specific trainingI think the core issue with the submission is that there is simply too much content for one paper: * formalizing 3 threat models * a proof of separation of maximin and minimax * empirical evaluation  on two datasets (MNIST, CIFAR10), three attacks (transfer, two adaptive attacks), three defenses (DANN, AdvS, TTT), and two settings (homogenous, inhomogeneous)Because of the page limit, a lot of details have been moved into the appendix, making the paper difficult to read. I think if focus were improved and the main document became more self contained, the quality of the work would be considerably improved. are missing. In particular its effectiveness in the homogeneous setting for CIFAR 10 reduces with the number of iterations k. This does not seem to be a reliable way of evaluating DANN s maximin robustness* I would imagine a strong adaptive attack could be built by generating adversarial inputs  with the objective of minimizing the loss of DANN s domain label classifier.<BRK>The paper explores adversarial robustness in a new setting of test time adaptation. It shows this new problem of “test time adapted adversarial robustness” is strictly weaker than the “traditional adversarial robustness” when assuming the training data is available for the “test time adapted adversarial robustness”. “Classic adversarial robustness”, or transductive learning v.s. Inductive learning in the setting of adversarial robustness. To proceed the thinking, they develop a good theoretical framework (the two threat models from definition 1 and definition 2) to formulate the two problems. And then consider a middle setting (definition 3) between the classic minimax and new maximin threat model. After reading the paper the only impression I get is they not homogeneous. More question about experiments:For FPA attacks, is there any baseline method we can compare the DANN with? In experiment (D), it says, “we also evaluate the accuracy of the adapted DANN models in the minimax threat mode”. But where are the results? Personally, I think it is helpful to cut off some content and make the main paper more clear, well organized, and strong.
Reject. rating score: 4. rating score: 4. rating score: 7. <BRK>The paper proposes to tackle the zero shot learning problem by learning class representation from commonsense knowledge graphs. Pros:  The motivation of using commonsense knowledge graphs to enhance zero short learning is interesting (although it has been explored in the previous work). Cons:  In term of methodology, the novelty of paper is very limited it uses Transformer to aggregate knowledge over graphs. Transformer and GAT are very similar, particularly in the setup of this work (e.g., without sequence/position embedding and the graphs are not fully connected). The empirical comparison to GAT based models in the experiments is not clear enough. and in this current submission GAT and transformer based models are better. It will be more helpful if the paper describes more details about the models in comparison, e.g., details about ZSL KG GAT such as the setup of multi heads. More comments:  The title of the paper may be made more specific, particularly given much work has been done by using commonsense/knowledge graphs for zero short learning.<BRK>The submission proposed to leverage a commonsense knowledge graph and an attention GNN based model to aggregate the node features on the graph for the problem of zero shot learning. The proposed GAT model is similar to the previous works, i.e., GCNZ, and DGP. To me, the model GNN and attention (Transformer in the paper) model have already been discussed in these two works and the only difference seems to be the knowledge graph, where the previous paper uses the WordNet while the current submission uses the ConceptNet. The appliance of the attention of ZSL has been a lot, such as [a,b,c,d]. The experiments do not support the claims:  The authors claim the model can scale to large size while in the experiment section,  the results on ImageNet is not reported. I am expected to see performance on the generalized zero shot learning since this setting is more practical and includes the prediction on both seen and unseen classes. Thus, I think the results on GZSL are also necessary to support the claims in this submission.<BRK>The authors propose a novel propagation rule that aggregates node embeddings by the self attention technique. It is infeasible to run GCN on such large scale knowledge graph. The method is evaluated on multiple zero shot learning tasks including object classification, intent classification and fine grained entity typing. I read the concerns from R4 and R5. Pros This paper is well motivated. The self attention or transformer based aggregator is novel as well. This paper only reports results on two small datasets i.e., AWA2 and aPY, in the zero shot learning setting, while the GCN baselines i.e., GCNZ, SGCN and DGP, are all evaluated on the large scale ImageNet in both zero shot and generalized zero shot learning settings. The authors fail to give some justification for these bad results. Writing can be further improved in the following perspectives. The justification for the bad results on the BBN dataset is missing. There are not enough implementation details in order to reproduce the results e.g., what are the text features used for the intent classification? Justification of the rating Overall, I think this paper has significant technical contributions. However, due to the issues I have pointed out above, my initial score is only 6 (marginally above the acceptance threshold.).
Reject. rating score: 2. rating score: 2. rating score: 3. <BRK>* First of all, the submission is not following the style. * The paper only has one page.<BRK>and the third one named "WARP." This submission cannot be accepted to the conference.<BRK>Using lightFM to solve this application is interesting. However, there is no modification on lightFM, except testing three loss fuction. The experiments are also not enough.
Reject. rating score: 5. rating score: 6. rating score: 6. rating score: 6. <BRK>#### SummaryThe authors propose a regularization technique that maximizes the entropy of the learned representation by regularising it with uniformity prior. The uniformity prior is imposed via an adversarial objective function. #### Weak PointsAlthough the method clearly improves the results, my main concern is with the novelty of the proposed method. 2.For uniformity regularisation, the authors propose an adversarial learning scheme. This way of inducing uniformity in the representations is also not new. Such contrastive objectives have recently been used to improve transferability of meta learned representations for e.g.in [3, 4]. [4] Doersch et al.CrossTransformers: spatially aware few shot transfer.<BRK>+ The paper has shown experimentations on different datasets under different learning setups, including deep metric learning and zero shot domain adaptation. Concerns:  Equation 6, which is the final proposed loss, seems incomplete, which seems like a key issue. Both of these efforts show task transferability for computer vision tasks. A feature space visualization of the proposed method and other baselines would have been very useful to directly compare and understand the claim and advantages of imposing uniform regularizer. How will the task space, in that case, look like?<BRK>In this paper, the authors claimed that uniformity in embedding space if the key for good generalization, and then propose an adversarial training based method to improve the uniformity of feature space. The claim is from previous work, thus the key contribution is the way to impose such regularization. One lacking aspect is that the authors provide no evidence on how the method works, neither quantitatively (the distance between uniform distribution and learned feature distribution) nor qualitatively (e.g.t sne visualization on the learned feature). The results look reasonable to me, and could demonstrate the effectiveness of the proposed method.<BRK>The authors argue that uniform priors for the high level latent representations improve transferability, which is beneficial in a number of tasks involving transference. The approach is evaluated on deep metric learning, zero shot domain adaptation and few shot meta learning. Strengths  The method is simple, yet effective.
Reject. rating score: 4. rating score: 5. rating score: 5. <BRK>The paper proposes FedMes to leverage devices in overlapping areas covered by multiple edge servers. Some of my concerns were addressed. The main premise of the paper is that communication with the central cloud server located at the higher tier of edge servers is costly and incurs significant delay. However, I still think that the novelty is fairly limited. Systems level experiments to thoroughly study the effect on t_c will greatly improve the contributions. It will be important to give an evidence that communicating with a cloud server or between edge servers incurs large delay. Further, the devices in overlapping coverage areas are assumed to be very symmetric. It will be helpful if authors can consider a more practical latency model, and/or provide more evidence for the values and assumptions used in experimental evaluations. The authors cite latency sensitive applications, e.g., smart cars, to motivate faster training time.<BRK>However, since each server has its own coverage in practice, the latency between the server and clients out of the coverage can be pretty long. Most of my concerns are addressed. The authors propose to use multiple edge servers, which have overlapped coverages. I agree with other reviewers that this paper can be further improved. Experiments on MNIST, EMNIST, and CIFAR10 datasets validate the effectiveness of the proposed algorithm: FedMes. This paper provides novel insights into a practical setting of FL. ## Pros  The multi server setting is interesting and practical. This trade off isn t clearly discussed in the paper. One can also generate some random topologies with arbitrary overlapping clients to test the performance of the algorithm.<BRK>However, the nonnegligible pitfalls of this paper are 1) the novelty is limited, 2) the challenge that they aim to address is unclear, and 3) their algorithm objective is not well formulated. + This paper shows promising experimental results compared with Hierarchical FL which requires more communication rounds. Cons:  Although following an interesting direction, the novelty of their proposed algorithm is limited, and the challenge of this setting is not clearly described. 1) The main focus of this paper is to decentralize FL to improve communication efficiency, but the tradeoff between performance and communication efficiency is not shown in the paper. FedMes actually requires more communication rounds, since critical users in the overlapped region need to communicate with multiple servers. Robustness of the proposed algorithm: Although I agree with the argument that "even users in the non overlapped region can help training in other ESs". An unresolved question is, when the number of users in overlapped regions is quite small, does their effects on other ESs reduce greatly as well?
Accept (Poster). rating score: 7. rating score: 7. rating score: 7. <BRK>Some discussion on the scope of the finidings/methods would be very helpful. The paper is very well written. 2.They do a simple, clearly described empirical study to understand what changes in representation happen in MAML during its training/testing and how to modify the MAML to encourage representation change.<BRK>Why does adapting only the penultimate layer count as representation change but adapting only the output layer is representation reuse? ***********After the discussion period, I have increased my score to 7 as the authors have provided a strong set of ablations and changes to address my concerns and those of the other reviewers. #### Decision:Overall, I am on the fence about this paper. The only difference is that instead of the final layer adapting and the remaining layers staying fixed, as in MAML, the final layer is fixed and the penultimate layer (now the final adapting layer) adapts.<BRK>This paper performs an investigation (with an associated new algorithm, BOIL), into the relative importance of representation change vs representation reuse in few shot learning with MAML.
Reject. rating score: 6. rating score: 6. rating score: 6. rating score: 6. rating score: 6. <BRK>The proposed technique is shown to be more accurate than a standard triplet loss based retrieval method and it performs at par with an FST based speech recognition system. While the proposed embedding method is a direct adaptation of the stochastic neighbor embedding (SNE) technique by Hinton & Roweis ( 03), the modifications have been described very clearly in this draft. As it stands, the experimental section in the draft is a bit thin:* For a more direct comparison with prior work on learning acoustic embeddings, it would be useful to see how the proposed embeddings fare on an acoustic word discrimination task (as described in He et al.2017) where the task is to predict whether a pair of acoustic sequences correspond to the same word or not. * The authors mention that the use of a hard binary distance as defined in Equation (7) was the best choice, rather than using softer definitions of distance. Some supporting experiments to show how different definitions of the distance function affect performance would be useful. (This could go into an appendix.) * Given that SNE lends itself well to visualizations, it would be nice for the reader to see visualizations showing how acoustic and textual embeddings of similar words cluster together. Update after author response:Thanks to the authors for addressing some of my concerns by conducting additional experiments that are listed in Appendix A. I have now increased my rating from 5 to 6.<BRK>Summary:This work adapts stochastic neighbor embedding (SNE) to acoustic segments to learn “acoustic neighbor embeddings” (ANE), which are fixed dimensional embeddings of variable length speech. They also learn embeddings of phone or grapheme sequences of words corresponding to these segments. Performance is then given on an isolated word recognition task, shown to outperform triplet losses as well as an FST baseline. Overall, I think there is a slight misalignment between ANE and multi view training (vs acoustic only triplet loss), which could be addressed in additional experiments as well as concerns that second stage $L_2$ distance training introduces unfair advantages to ANE over multi view training for comparison on isolated word recognition. This approach is strong for the isolated word recognition task versus the provided baselines (FST and triplet). Comments:  It seems like the main comparison between loss functions is being done between ANE and a multi view triplet loss, which is okay, but I think the better comparison would be between triplet losses that only operate on acoustic segments (e.g.Kamper et al https://arxiv.org/pdf/1510.01032.pdf). Also, since you’re using nearest neighbors to perform your evaluation, fine tuning after training the multi view approach with a second stage $L_2$ distance training would be fairer given that that’s what’s being used through nearest neighbor search at evaluation time I believe. ANE shows a well motivated method for learning an acoustic embedding space, but incorporation of the second view through $L_2$ distance versus a triplet loss isn’t compared. Additionally, an argument can be made for establishing $g_j$  an $f_j$ as roughly the same from Equation 14, but in practice it appears that the differences in these values actually help stabilize training as g’s are consistent for a particular word rather than varying for every acoustic instance. It would be nice to see additional results on some common acoustic word embedding datasets, or evaluations that include the word discrimination task using average precision (AP) in addition to word accuracy. It could be interesting to give a word discrimination evaluation (in AP) for just the acoustic embedding outputs (from $f$) for this reason. Additional evaluation using typical acoustic features would be nice for curiosity reasons as well as due to the above concern about common applications to low resource domains where high performing ASR systems may not exist a priori. Overall:I find application of SNE to acoustic segments interesting, but I think the presentation it could benefit from more direct comparisons.<BRK>In this paper authors propose a novel idea of acoustic embedding learning, called Acoustic Neighbor Embedding. Using stochastic neighbor embedding (SNE) idea of preserving the relative distances and optimizing Kullback Leibler divergence (KL), proposed in the paper embedding is constructed optimizing KL divergence (for acoustic) and $L_2$ distance between acoustic embedding and correspondent text embedding (for text). With experiments authors show that their approach is better than triplet loss approach used in the previous works. The paper itself very well written, with enough clarification to understand the main idea. ### Edit based on the authors  responseI believe the authors have addressed part of the major concerns that I and the other reviewers had. Based on the updated paper s version I change my rating from "5: Marginally below acceptance threshold" to "6: Marginally above acceptance threshold". So this could be considered as a good experiment for future work to show the great potential of ANE if it outperforms LM usage. Cons:  General application for entity recognition with the proposed approach will be not super easy: besides ASR system there should be also force aligning system which should extract segments where entities are presented. And the most complicated task is obtaining these force aligned segments. I don t see any points in the paper and author s comments why this is helpful/applicable/better than some another ideas. There is no comparison with the other acoustic features instead of "postreriograms" ("posteriograms" could have errors of ASR model itself and possibly not be ideal for acoustic embedding construction) both for triplet loss and proposed method. Previous work He et al., 2017 used MFCC for the triplet loss. About applications for continuous speech authors gave the comment "However, we are not even sure if speech recognition per se is the best application for ANE. Comments:  "However, none of the aforementioned papers have reported results in isolated word recognition. ":  Jung et al., 2019 reports average precision of isolated word recognition (if audio and text are given for the same word). We are hoping that the community will find other interesting uses, either with the embeddings themselves or the distances between embeddings.". This is more analysis of a model trained on particular dataset.<BRK>"it is not a good idea". The novelty of the paper lies in a new loss, which is based on stochastic neighbour embeddings (SNE). The proposed model is evaluated in a word recognition task, where an isolated spoken word s acoustic embedding is compared to the text embeddings and the nearest neighbour is used to classify the spoken word. One issue is that much of this is placed in an appendix, so it doesn t form a core part of the main thread of the paper;  I also disagree about one small point (see my separate comment to the Part 2 message below), but this is minor. **Note the edit at the bottom of this review, based on the authors  feedback. This will also make the work more valuable, in that it can be directly compared to previous studies. One potential issue with the triplet model in this paper is that I believe the model of (He et al., 2017) makes use of cosine similarity, instead of the Euclidean distance. Since labelled examples are available, it would also have been good to compare to a direct classification model, as in [3]. First, by defining the neighbourhood as in equations (7) and (8), it seems that this model essentially optimises the loss based on whether two acoustic realisations are from the same or different words, and no finer grained neighbourhood information is included. The section concludes that "ANE has the added subtlety of pushing or pulling with more  measured strength  based on how good the embeddings currently are," but if the loss is purely based on a weighing according to the word frequency, could something similar be accomplished by having a type specific margin for the triplet loss in equation (13)? One further suggestion is to look at more advanced sampling strategies in the triplet model, as e.g.in [1] or [6]. I would recommend that the authors include the above mentioned additional experiments; this would be a non trivial extension, and I, therefore, recommend the paper then be submitted a future conference. 1"  > "As we can see in Table 1"  "this beautiful equation".<BRK>This paper proposes a new approach to learn acoustic word embedding by adapting stochastic neighbor embedding (SNE) to sequential inputs. The acoustic word embeddings of two acoustic sequences are learned to be close in Euclidean distance if their transcriptions are the same, or far apart otherwise. The experiment results on an isolated word (name) recognition task show that using nearest neighbor search alone based on the proposed acoustic and text embeddings in tandem can achieve the same performance as a standard ASR model. 2.Well motivated by the extension from SNE. The proposed acoustic neighbor embeddings in this paper is a different way but shares similar motivation with the triplet loss, while showing more effective gradients. The paper claims it is the first work to achieve this. 4.Not required, but would be great to have more analyses in the experiments, e.g.:    How important is it to use posteriorgrams vs. acoustic features (maybe with a deeper embedding encoder) as the inputs for training the acoustic word embeddings? Visualization of the proposed embeddings, and possibly with comparison to that of the triplet loss trained embeddings. In general, the paper looks good and I would recommend it for acceptance.
Reject. rating score: 3. rating score: 4. rating score: 5. rating score: 6. <BRK>I find the problem setup a bit superficial and I was not convinced from the examples in the experiment section  that this is a meaningful real world situation. We dont know whether  this information improved the clustering. The notation in (5) is odd. z appears on the right side of the equation but not on the left side.<BRK>The paper proposes a method called DGC (Deep Goal Oriented Clustering) for clustering using side information in the form of a response veriable y. There are major issues to be addressed.<BRK>The claims of the paper are generally well supported with the explained experiments. The latent embedding is parameterized by a mixture of Gaussians. The authors run experiments investigating the effectiveness of their approach and the impact of the clustering component of their approach. Summary of Review: Clearly explained, intuitive approach for clustering+prediction, concerns over technical and experimental depth.<BRK>This work proposes a novel method, called Deep Goal Oriented Clustering (DGC), to incorporate such arbitrary “side information” into a probabilistic auto encoder based clustering algorithm. ### ClarityOverall the paper is clear and well written. The description and background of the model is precise and easy to understand. The authors demonstrate that, without incorporating the side information, correctly clustering points from either annuli is difficult for any clustering algorithm.
Reject. rating score: 5. rating score: 6. rating score: 6. rating score: 7. <BRK>The paper begins by considering a DGP with isotropic kernels across the layers and realizes that the Gram matrices are Wishart distributed. Based on this, the paper proposes to bypass the inference of the features and sample the Gram matrices directly from Wishart distributions. This insight, in addition to the layered structure of DGPs, gives rise to the proposed prior distribution. In terms of clarity, the readability of the paper is negatively affected by being too broad with the results presented.<BRK> ##### Summary:This paper proposes deep kernel processes (DKPs), which can be viewed as a specific kind of deep Gaussian processes where the kernel can be written as a function of the Gram matrix. The features in the intermediate layers are integrated out and the Gram matrix are Wishart distributed. My major concern is about the writing. Due to difficulty in posterior inference, the authors propose to use inverse Wishart prior over Gram matrices. The experimental results show the effectiveness of the proposed method.<BRK>##########################################################################Summary: The manuscript proposes a deep kernel processes model, where gram matrices are transformed by non linear kernel functions and assumed to follow Wishart distributions. ##########################################################################Reasons for score:  I think that method provides a new approach to implement deep kernel processes (it is fully kernel based compared to Deep GPs which is based on the feature based representation).<BRK>How does it compare to some of the more scalable methods (such as deep kernel learning where only the last layer is GP)? The paper proposes the deep kernel processes, which can generalize several existing deep kernel methods, including deep Gaussian processes and Bayesian neural networks. Combined with the new inference scheme, the authors showed the proposed method has performance gain over DGP and NNGP on many applications.
Accept (Poster). rating score: 8. rating score: 7. rating score: 6. rating score: 6. <BRK>Authors assessed how these subnetworks can be as diverse as independently trained networks. The use of MIMO makes this approach simple, while it can be evaluated in a single forward pass. CONCERNS:The authors claim that the benefits of using multiple predictions can be achieved ‘for free’, while their proposed model increases the number of parameters (even though by 1 percent)The paper has examined the accuracy and disagreement of the subnetworks, but a detailed evaluation on number of parameters is missing (i.e.where the 1% increase in parameters comes from).<BRK>SUMMARY:This paper describes a multi input multi output (MIMO) strategy for training several subnetworks inside a same and single neural network for robust prediction. The method is compared on standard benchmarks, across a wide range of metrics. Performance is reasonable with respect to a simple solution consisting in training an actual ensemble of 4 networks. WEAKNESSES:  I believe the approach to be original, but its similarities/differences with other multi input multi output (such as BatchEnsemble) could have been discussed much further to better appreciate the originality of MIMO. This is an exciting phenomenon that ought to be better understood.<BRK>This paper proposes to train a single network with M input examples and M corresponding predictions, and the M input examples are mixed to produce the M corresponding predictions. Although only a single network is learned, it implicitly consists of multiple sub networks due to the nature of multiple inputs and multiple outputs in training. In testing, the single testing example can be replicated M times as inputs, so that M outputs are produced by the trained network. The second one is about its practical potential. I am also a bit concerned that the network is trained on M independent examples (although the proposed method does allow for occasional identical examples), but is tested on M identical copies of the same testing example.<BRK>2) With the proposed training paradigm and proper test setting, the accuracy improvement can be seen and also uncertainty estimation. Cons: 1) They only report the inference time of one sample, but the total computation costs (e.g.MACs or FLOPS) are omitted. 2) The multiple branch networks are not only used in ensemble and broader usages exist. Pros: This method successfully uses the multi branch architecture to reduce the inference delay in ensemble, which is a rather novel idea. Pros: The shining points of this work are making ensemble for “free”. Cons: 1) The authors attempt to distract our attention on the computational costs of this MIMO architecture and try to make an illusion that it’s convenient in computing. I think it’s deceptive and tricky.
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 7. <BRK>However, I am unable to understand from the text why the proposed approach is not subject to the curse of dimensionality. In particular, if for every action dimension 10 to 35 weights should be defined by the policy, this creates a significant increase in the size of the search space (35^N). In particular, I would appreciate seeing a discussion about the size (in terms of the number of parameters) of the policies. It is also quite surprising to see that the considered task in figure 2 can mostly be solved with very few particles (for both of the compared approaches). The complexity of the search space is certainly impacted by the difference and the observed results might just be the result of this. I am also wondering how the analysis can be extended to the other experiments. It seems that the performance difference on the other tasks is significantly more subtle and it will be important to discuss this. Overall, the paper proposes an interesting method but should be more didactic on why it is not impacted by the issues that are affecting the other approaches.<BRK>Summary This paper presents an approach to multimodal policies based on Gaussian mixtures. However, the authors do not include a comparison to a standard mixture of gaussians policy, in which the Gaussians mixture elements are also state dependent. The authors state that the mixture of Gaussians presented "cannot support any discretization scheme". Thus, the fully state dependent mixture of Gaussians seems like the most relevant comparison for the PFPN approach, and should be able to rely on the sample Gumbel softmax trick for differentiable sampling. The most interesting contribution of the paper is the resampling scheme. However, there is minimal evaluation of the benefit of this scheme. I agree with the authors that the mixture of Gaussians policy is substantially weaker than their method, and is a useful baseline experiment to have. However, the added experiments with random sampling are somewhat worrying the performance improvement of the proposed re sampling scheme is quiet minor over random resampling. In the future, the authors may want to investigate the random resampling for the systems in figure 14.<BRK>The energy based policy is helpful for efficient exploration, as it can better model the uncertainty of an agent. 3.The main contribution of this paper is a GMM policy using particle filtering. This direction is not that exciting. Particle based variational inference with RL has also been explored by Stein Variational Policy Gradient and Policy Optimization as WGFs. It is good to see improvement empirically, but I am not sure the improvement source. An ablation study on this should be useful. 4.It is interesting to see the differentiable reparameterization trick. The dead particle issue will not happen as a repulsive force added in SVGD gradient step.<BRK>Post rebuttal update: The authors have addressed my concerns and the revised submission is much clearer, so I m increasing my score to 7. I must preface this with a caveat that I am not up to date with the latest results in continuous deep RL. Major comments:The biggest weakness of this paper appears to be that the results are only minor improvements (if they improve at all over the baseline). This is a major shortcoming because the proposed method is significantly more complicated than the baselines. If this additional complexity, and the additional hyper parameters, does not bring major benefits then this begs the question as to whether or not it is worth it. If there is some other advantage to using this proposed method over the others then this should be explained more clearly up front. I think a  Contributions  section that listed the major takeaways of the paper would be useful. Isn t each dimension independent in this setup? I don t fully understand section 3.4, it s quite unclear as written. Why is the two step sampling method  non reparameterizable ? Also the  concrete  distribution is not defined here, it needs to be discussed more generally for completeness, possibly in the appendix is space is an issue. Why is your method  more friendly to policy gradient optimization  than simpler methods? If the significance of the work, and the computational results can be better explained or improved I could increase my score again.
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. rating score: 5. rating score: 4. <BRK>The paper addresses the problem of performing medical image segmentation in the limited label scenario, i.e.the case where there is only a small number of manual expert segmentations available. For example, the best performing method for segmentation of ACDC (cardiac MRI) reported in Bernard et al., 2018 achieves significantly higher results than the baseline segmentation reported (”FS all”). I found the methodology interesting and well motivated. The main weakness to me is the evaluation.<BRK>*ReviewThe paper is well written with significant time spent setting up a clear explanation of the background information and challenges. Keep colors consistent for the proposed method. The proposed method uses several CNNs in combination.<BRK>### SummaryThis paper studies few shot segmentation for medical images where labeled data is hard to obtain. The experiments have shown that the proposed method outperforming several few shot learning baselines. The experimental results are promising and encouraging. Wei etal., STC: A simple to complex framework for weakly supervised semantic segmentation. The authors answer to reviewers  questions carefully and with great supportive details. It s unclear which part contributes the most. I m not  an expert from medical image field. So it s a little bit hard for me to evaluate the significance of the reported results and proposed methods.<BRK>Especially , for the pretrained network, it is not fair in few shot learning setting. This paper presents weakly supervised framework for image segmentation tasks with limited annotated data. Overall,  I think  this is an interesting paper and should be encouraged. But I still has some concerns as the application is very limited on medical images.<BRK>I think the paper is interesting and well presented, but there are several important aspects that, in my humble opinion, harm my overall rating of the paper:  Not clear to me what is the main original contribution and novelty of this work. Why the authors do not compare with other state of the art few shot medical image segmentation approaches (like [1])? Without a more extensive experimental comparison with prior methods is difficult to elucidate the actual empirical contribution of the proposed method.
Reject. rating score: 4. rating score: 5. rating score: 6. rating score: 6. <BRK>The paper discusses an analysis of the emergence of individuality in a multi agent system based on reinforcement learning. The emergence of individuality is based on intrinsic reward. This does not appear to the reviewer as emergence of individuality; his looks more like the emergence of different behavior (which can be seen as individuality, but it is more like forcing different behavior, not individual behavior, as interpreted normally when we study societies in my opinion). In fact the authors essentially impose the emergence of individuality from outside by giving a reward for being different. The reviewer wonders if the emergence of individuality at the end of the day might actually emerge just by considering individual learning models. This is not completely clear to the reviewer. is not sufficiently discussed by the authors. It seems to me that the individuality/differences are artificially imposed on the system itself. I would claim that this is difficult to prove by analogy as stated by the authors. However, it is unclear how this  is related to the fundamental problem of the paper, which is the emergence of individuality.<BRK>This paper tackles the problem of exploration in multi agent RL,formulated as a Dec POMDP. Moreover, the authors propose someregularization schemes to "break ties" early on in the training. The integration into MAAC is relatively straightforwardbecause MAAC uses independent critics, whereas the integration intoQMIX is more involved due to the Q function mixing step. I believe this is a very important problem being tackled by theauthors. I believethat the paper was well written, and the Introduction made it veryclear what exactly the paper s contributions were, which I greatlyappreciate. Unfortunately, I m not sure that I believe that the proposed bias istruly useful. Another option could be to simply encourage the agents to learndifferent policies, maybe measured via KL divergence of P_{agent 1}(a| s) and P_{agent 2}(a | s). Some other questions:1. How significant is the fact that you are ignoring second ordereffects in solving the bi level optimization in Appendix A.2? Have theauthors conducted preliminary experiments to prove that it doesn tmake much difference? 2.Looking at the shaped reward computation, r + alpha * p(i | o_i),it seems like if the classifier were naive and simply outputted auniform distribution, you would still be giving positive intrinsicreward in that case.<BRK>This paper contributes a method based on reward shaping to encourage the emergence of distinct agent behaviors in fully cooperative multi agent reinforcement learning (MARL), within the paradigm of centralized training with decentralized execution. Please be more precise. Using three illustrative environments where optimum team performance requires distinct behaviors among agents, the paper shows that 1) EOI outperforms the two base algorithms and other baselines that address exploration and diversity; 2) the two regularizers improve performance and help the intrinsic reward to serve as an inductive bias; 3) agents do perform distinct behaviors. Classification based intrinsic reward have been used for diversification in MARL in previous work (Lee et al., 2020, Yang et al.2020), but this paper provides a different formulation along with effective heuristics to speed up the initial training of the classifier. The experiments are clear in showing the benefit of EOI and EOI + regularizers when built on top of the two base methods. However, there are main points of concern. I am willing to raise my score if the main points below are sufficiently addressed. However, in section 3, the authors say that "EOI directly correlates individuality with the task by intrinsic reward", making it seem that EOI differs from Lee and Yang in that regard. It does not find some Q function that _optimizes_ the expected cumulative intrinsic reward. However, the initial formulation on page 3 (where the total reward is the environment reward plus the intrinsic reward) implies that the agents should maximize the expected cumulative intrinsic reward as well. It seems that this has a negative impact on the exploration by an arbitrary agent.<BRK>When the agents are homogeneous and optimized only through team rewards, it is easy to learn similar policies for each agent. Many current works model the above problems as task assignment or role assignment problems. In order to solve the shortcomings of the above methods, this paper proposes a MARL method based on reward shaping to encourage the division of labor between agents, and at the same time introduces two regularize terms to solve the problem of too similar agent policies at the initial training stage. At the same time, reward shaping and reinforcement learning are optimized simultaneously, forming a bi level optimization problem. The paper also designed three tasks that emphasize division of labor to verify the effectiveness of the algorithm. 1.Neither the MAAC nor the QMIX algorithm on which the paper is based has good scalability. This paper should additionally use independent learning algorithms as baselines, and apply the intrinsic rewards proposed in this paper to independent learning algorithms. I think the paper should additionally explain the limitations of the algorithm, such as which scenarios will be more effective and which scenarios will limit the learning ability of the agent. 3.The optimization process of bi level problems is very unstable. The algorithm proposed in this paper contains many hyperparameters, and the sensitivity of the algorithm to hyperparameters should be shown in the experimental part.
Reject. rating score: 5. rating score: 6. rating score: 7. rating score: 7. <BRK>The submission introduces a new approach for pre training models for question generation conditioned on an answer and a document. Results show that this method improves question generation performance compared to previous work, and that the synthetic questions can be used to improve question answering models. However, I think it needs to compare with stronger pre training baselines, and needs a more thorough comparison of the effect on question answering performance. Indeed, the abstract of the paper pitches the task as being primarily useful for generating synthetic data for question answering. That s fine, but given this motivation, I think the evaluation should focus much more on the downstream impact on question answering. This experiment would help understand whether the proposed method adds anything on top of more general pre training approaches. The paper convincingly demonstrates that synthetic questions improve a baseline BERT question answering model, which was already shown by e.g.Alberti et al (2019). It s important to include a baseline set of synthetic questions, as it s not at all clear that improvements on question generation metrics will correlate with usefulness for QA training.<BRK>Through several well executed experiments the paper shows that this type of pretraining can improve performance of several existing question generation models, and the resulting synthetic questions generated help in augmenting reading comprehension datasets. The authors clearly put effort in explaining all the methods and experiments precisely and with details. It is not clear how much of the benefit of pretraining comes from the specific approach used here, versus the fact that there is some pretraining on the decoder which generates the questions. We could learn more about this if there was a comparison to other pretrained models which have a decoder, e.g.T5, BART (Lewis et al, 2020). This seems to be a limitation of not just paper, but the prior works as well. In this case, is e_i,j normalized over all spans in the passage or only the ones which start at i? Some more discussion of the UniLM baseline would be good for people not familiar with that work.<BRK>This paper presents a model for unsupervised pre training for the task of question generation. The key idea is that this unsupervised pre training strategy is close to the actual task of generating question given the context and the answer. This is also the key differentiator between this work and other existing pre training strategies for question generation (e.g.Alberti et al 2019). Efficacy of the pre training scheme is shown via the fact that the pre training scheme also improves other question generation model. Strengths:* The pre training scheme is closer to the original task than other existing methods and can be easily scaled. * The paper is well written and easy to follow and the experiments and ablations were exhaustive. This is because, the current QA datasets do not ask annotators to generate all possible question from a paragraph. This would also eliminate the need to predict the number of answer spans in a paragraph at once. * It was not clear to me, how you generate questions which are unanswerable (e.g.those in Squad 2.0)* Although, it is good to see that training on the synthetically generated questions help in low data settings, I think the paper would be stronger and more convincing. Moreover, some questions in BioASQ need reasoning such as handling list questions, counting and it would be interesting to see if the performance on those questions improve.<BRK>### SummaryThis work presents a new multi step method to pre train a question generation system, which can then be used to create synthetic data to improve a Machine Reading Comprehension system. Then, they pre train a system to generate those questions by taking the selected answer and surrounding sentences as input, and generating the sentence which contained the answer. The paper could still be improved by clarifying specific points. The authors also describe their setting based on BERT but not the one with UniLMWhat is the dimension of the indicator vector that tells the model where the answer is located? Dynamic prediction of the number of answers in a paragraph doesn t seem to account for much improvement. Otherwise, the method really is novel enough without that part. Did the model evaluate the effect of using synthetic data on the other tasks? ### CorrectnessThe claims are mostly well supported by the experiments (to the exception of the dynamic K prediction). ##### Additional citationsThe pre training sentence prediction method is related to:  **Latent retrieval for weakly supervised open domain question answering**, Lee et al., *ACL 2019*
Reject. rating score: 4. rating score: 4. rating score: 4. rating score: 5. <BRK>In this paper, the authors propose a MULTI EPL for multi source domain adaptation. The key idea includes two folds: (1) to align label wise moment, and (2) to ensemble multiple feature extractor. (2)	The proposed label wise moment matching is not new in transfer. My major concern is on the technical significance of the method.<BRK> Paper summary The authors propose a novel method for multi source domain adaptation (MSDA). Weakness and concerns  Marginal novelty. The three techniques that the proposed method adopted are all similar to those already proposed in the literature. The design of the feature diversifying loss is not reasonable.<BRK>  Summary and contributions      In this work, the authors proposed an algorithm for multi source domain adaptation. Meanwhile, more empirical results are needed to validate the effectiveness of the framework. The problem investigated in this paper, i.e., multi source domain adaptation, is of significance. Weaknesses:      The technical contribution of this work is limited.<BRK>This paper studies the multi source domain adaptation (MSDA) problem. The technical details are clearly presented. In Eq.1, the authors minimize the discrepancy between every two distinct domains. Moreover, the ablation study presented in section 5.3, does not show a clear improvement by introducing the diversifying loss. The performance improvement compared to the state of the arts is limited.
Accept (Spotlight). rating score: 9. rating score: 8. rating score: 6. rating score: 6. <BRK>Moreover, to those with a background in AQC and deep learning, the paper is easy to read and clearly describes basic ideas and required technical details. Indeed, optimal scheduling of is a problem of theoretical as well of practtical concern as it makes or breaks the success of AQC but general, closed form solutions are hard to come by (or simply unknown at this point in time). Their experiments also reveal the approach to outperform previous. This paper presents, original, convincing, and interesting work on a problem of considerable practical importance in adiabatic quantum computing.<BRK>Summary:Deep neural networks are used for supervised learning of optimal optimization schedule for various problems in adiabatic quantum computing (AQC). The method show impressive performance on all of the problem instances, outperforming both simple baselines and recently proposed methods using reinforcement learning. Using the literal Hamiltonian as an input to the supervised problem scales quite poorly with increasing problem sizes. Recommendation:While the paper leaves open some questions about the generality and scalability of the proposed method, the novelty and performance of the method is promising. I would recommend acceptance.<BRK>I would like to thank the authors for the rebuttal. I still think the application domain of the proposed work is limited. ##########################################################################Summary:This paper concerns a specific application of machine learning in quantum computing: training classical machine learning models to predict the optimal schedule in adiabatic quantum computation. The loss function is well motivated and the empirical performances are convincing. The QUBO problems that can be solved by current quantum devices (such as D Wave machines) seems to be much larger (bigger than 1000).<BRK>**summary** the paper proposes to learn parametric form of optimal quantum annealing schedule. In addition to that providing training curves with train and validation errors as function of step would be also very useful. Is it the case that training the latter is easier for some reason? Do they share the rest of the layers between different problem sizes? Is it true that QUBO models performs better in this case?
Reject. rating score: 3. rating score: 5. rating score: 5. rating score: 6. <BRK>### DetailsI m curious about some of the hidden complexities in the algorithm. What are the effects of choosing it to be $n 5$ for the experiments instead of (say) 10? I fail to see why this approach couldn t have been studied in a much simpler linear function approximation setting where statistically significant results with fewer confounding variables could have been achieved. I found this fascinating and am curious if there is some structure that the proposed algorithm is able to take advantage of in this domain that RHPO is unable to replicate. # After discussion period:I have read all other reviews, resulting conversation, and have read the edits to the paper. I am lowering my recommendation from a 5  > 3 to reflect the new concerns; namely the validity of the ablation study as detailed in depth below.<BRK>It provides empirical results in a variety of domains, demonstrating that the algorithm can improve data efficiency. The paper is well motivated. The approach is sufficiently novel. Furthermore, my understanding is that these numbers have been taken from Zhang & Whiteson (2019). Misuse of the comma is prevalent throughout the paper. Additional information is present in the  appendix but I could not easily locate the relevant information (if it is indeed there). While the writing has improved, it stills lacks the clarity and nuance one would wish to see in a paper at this conference. The paper is not easy to read. The writing could be more nuanced in the discussion of results presented in Figure 3. Similarly, the authors write that they “achieve improvements when training mixture policies via RHPO”.<BRK>The text helps understand the figures, the figures do not help understand the text, so I would remove the figures. In the experiments, comparing MPO with HO2 allows to see a benefit from the use of options, with the proposed learning algorithm. Is it possible to have a small discussion of what do the options learned by HO2 do? In summary, I like the proposed algorithm, the core contribution of the paper, the contents of Section 3. Author response: the authors answered my question about the absence of learning curves, and provided extra details. Given my hesitation, I would therefore not vote for accepting this paper, but I acknowledge that the proposed method is original and interesting, so I would not mind if this paper were to be accepted.<BRK>The ablation study is well done, to separate the effects of different types, and gives practitioners some useful guidelines. There is one thing I am curious about, do you try the methods using some online data? Since the paper argues the improvement compared with online option learning, it would be great to also have some experiments using online data for a fair comparison. I am not that familiar with hierarchical RL, so I could not give a fair judgement of the novelty compared with previous option learning literature. I feel the off policy argument in this paper is less clear, is it just achieved by using a Q learning based method?
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. rating score: 5. <BRK>Although the model bears resemblance to NVAE (for which code is released), understanding the fine details is tricky, and the paper does little to aid in that effort. To alleviate this, non autoregressive models have been proposed, such as FastSpeech and Glow TTS. Pros:1.The evaluation of the model is done well, in a clear way.<BRK>Summary:This paper presents BVAE TTS, which applies hierarchical VAEs (using an approach motivated by NVAE and Ladder VAEs) to the problem of parallel TTS. Reasons for score:Overall, I think the system presented in this paper could be a valuable contribution to the field of end to end TTS; however, from a machine learning perspective, the contributions are incremental and quite specific to TTS. Finally, the quality of the speech produced by the system is only evaluated on a single dataset and uses only 50 synthesized examples in the subjective ratings. High level Comments:* The speed, parameter efficiency, and MOS results are quite promising. Please have the paper proofread to improve readability.<BRK>Post rebuttal and discussion Several reviewers have pointed out that the paper needs more comparisons/ablations with existing models (e.g.Paranet/Fastnet). Could the authors clarify how the duration modeling results in  monotonic  alignments? This type of modeling seems also to be used in the Glow TTS  work but with alignments determined through dynamic programming. Initial Review This paper proposes a non autoregressive (non AR) way to perform text to speech synthesis.<BRK>This is a minor concern, as long as the quality are good enough. In summary, based on my understanding, this paper proposed a new non autoregressive based text to mel model with quality regression but possible better robustness. My opinion is that it s a borderline for ICLR, since the importance of the proposed VAE was not well justified, and the quality was not as good as autoregressive model. For neural based TTS system, most of time is in vocoder.
Reject. rating score: 5. rating score: 6. rating score: 7. <BRK>However, the novelty and main contribution of the paper is not clear. The authors used a scoring model to score the composition of each segment, as well as the probability of having a specific label for the segment. The BERT language model is used in the paper to encode the input sequence. The training part is a more like a supervised training and a dynamic programming (DP) approach is used for inference.<BRK>The paper proposes a new algorithm for sentence segmentation which can be applied to various sequential tagging problems. The motivation and the description of the algorithm are clearly given, and the proposed method achieved state of the art results for most of the problems and datasets. The proposed method tries to find all possible segments in the given input sequence, to estimate the scores of the segments using pre trained BERT representations, and to find the best sequence of segments using the dynamic programming algorithms. In these views, the novelty of the paper is not high.<BRK>This paper presents a method called LUA, Lexical Unit Analysis for general segmentation tasks. LUA scores all the valid segmentation of a sequence and uses Dynamic Programming to find the segmentation with the highest score. 3.This method achieve the state of the art performance on 13 out of 15 data sets empirically. 3.Label correlations are used to mimic correlation scoring, however the transition between spans are not explicitly modeled. LUA is only used in inference stage.
Reject. rating score: 4. rating score: 4. rating score: 6. rating score: 7. rating score: 8. <BRK>I was not completely convinced by the arguments made by the authors and their motivation. Here are the major aspects which were unclear to me (refer below). Irrespective of Graph Matching problem, Social Networks can be a good application for verifying this. 6) The authors also mention that their deterministic learning approach is often more efficient while the generative learning method can be more accurate at the cost of additional overhead. Additionally I felt the paper needed more analysis/discussion.<BRK>This paper deals with graph matching, where the latent topology of the two graphs is not fixed but estimated during the learning process. (I recall that the paper deals with estimation of the graph topology.) In section 2, it is proposed to estimate both the topologies of the two graphs and their matching. In the real data analysis, the methods are compared through their accuracy scores and not on the estimation of the latent topology. I believe that the article should be clearer on that point.<BRK>The paper is well written in general, and the contributions are clear. There are some "." This may be a matter of taste, but to me, graph matching (or the graph matching problem) refers to the problem of, given two graphs, finding the bijection between the set of vertices that minimices some distance.<BRK>The authors address the problem of discrete keypoint matching. For an input pair of images, the task is to match the unannotated (but given as part of the input) keypoints. Experiments are conducted thoroughly and on multiple standard datasets. I do not think, this justifies making the co generative a central point of the paper.<BRK>Summary: The paper discusses the problem of graph matching (GM), which is the combinatorial (NP hard) problem of finding a similarity between graphs, and has various applications in machine learning. More specifically, the paper proposes methods to leverage the power of deep networks to come up with an end to end framework that jointly learns a latent graph topology and perform GM, which they term as deep latent graph matching (DLGM). Strengths: The proposed method seems justified. Other than that, their claims appear to be correct, and so is the empirical methodology.
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. rating score: 4. <BRK>+ There are extensive experiments demonstrating the empirical effectiveness of the proposed approach. Quality The paper is well written and the experiments are thorough and well executed. Related to the con listed above, a few additional experiments could be useful for gaining a deeper understanding of the method. Any other insight that the authors could supply regarding this general question would also be appreciated. The citations to batch normalization as used in domain adaptation seem appropriate. Significance This work seems significant to researchers interested in meta learning, domain generalization, and problems involving distribution shift in general.<BRK>The authors propose a method for cross domain few shot classification that learns to generate domain specific data statistics from very few training examples for domain independent batch normalisation. However, no information is provided at all in the main paper, which makes it very difficult to understand the setting of the experiments. Networks are trained within a meta learning framework using a KL divergence loss, which enforces estimated statistics on small support/training examples to match statistics from query sets where more data is available. STRENGTHSThe paper is well written and motivated.<BRK>Summary: The paper proposes an effective meta learning normalization, named MetaNorm, to infer adaptive statistics for batch normalization by minimizing the KL divergence. The module is lightweight. The proposed method is evaluated on few shot learning, domain generalization, and few shot domain generalization. Justification of rating:  Overall, the proposed approach is logical and sound. Code will be released in the future.<BRK>This paper describes a new method for normalizing few shot learning episodes. To remedy this, the authors propose a method called ‘MetaNorm’ which uses a meta learning approach to infer the means and variances to be used in the batch normalization layers that are employed in the feature extractor component. The idea of using meta learned hypernetworks to generate the means and variances of the normalization layers is good.
Reject. rating score: 4. rating score: 5. rating score: 6. rating score: 7. <BRK>Good experimental results show the effectiveness of the proposed method. *Strengths:+This paper studies unsupervised domain adaptation in the perspective of joint error, which I think is one of the most important issues in the deep regime. However, how to select a proper hyperparameter is not well stated. This paper can give the value of joint error empirically, similar to [iii]. In this point of view, the theory actually relies on assumptions about the $f_S$ and $f_T$. Additionally, in order to ensure that the bound is not trivial, authors even need to restrict $f_S, f_T$ in subsets of hypothesis. The assumption that $f_T$ could be achieved by source loss minimization and pseudo label training needs theoretical guarantees.<BRK>This paper presents a novel approach to tackle the problem of unconstrained joint error in previous unsupervised domain adaptation theory. It builds up a new upper bound that, under certain circumstances, reduces to an upper bound of optimal joint error. This paper is not well written and some parts are hard to follow. The authors should discuss on that work and directly illustrate the relationship between that work and the proposed one, and why the proposed method is better. 3.Although the joint error is indeed included in the proposed upper bound, in practice the authors have to use Source driven Hypothesis Space and Target driven Hypothesis Space to obtain approximation of f_{S} and f_{T}. 4.The benchmark results are inferior to the state of the art methods.<BRK>This paper proposes a new algorithm for unsupervised domain adaptation: taking the adaptability term (the joint error) into consideration instead of minimizing only the domain discrepancy. The authors also justify their method with some theoretical intuitions. Empirical results show that their method achieves state of the art performance. The paper is overall clearly organized and easy to follow. For the previous version, reviewers raised concerns about1)	The realizability assumption: f_1 and f_2 are not in H.2)	The derivation of the general bound can be confusing.<BRK>This paper studies the problem of unsupervised domain adaption, giving a theoretical analysis that yields a new upper bound on the target error. Positives:+ derivation of novel upper bound for target error+ demonstrates that two existing methods for unsupervised domain adaptation can be derived as special cases of the proposed framework+ ablation study demonstrates the relative improvements from each proposed component+ good empirical results relative to existing workNegatives:  one main concern I have is with the role of $\eta$ in the target drive hypothesis space constraint. First, it would ideally be nice to have some intuition about its role and how it might be set. I would have liked to see some sensitivity analysis to this value.
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 7. <BRK>This paper studies the loss landscapes of sparse linear networks. It proves that under squared loss, (1) spurious local minimum does not exist when the output dimension is one, or with separated first layer and orthogonal training data; and (2) for two layer sparse linear networks, the good property in (1) does not exist anymore when the conditions are violated. The authors also report experimental results to show that two layer sparse linear networks with two hidden neurons have spurious local minima. Overall, I vote for rejection. However, I was worried that (1) the proofs make incremental contribution compared with two existing works; (2) assuming activations are linear is too strict; (3) the insight given by the theorems is not clear; and (4) the applicable domain is not clear. Pros:+ The authors prove that (1) sparse linear networks do not have any spurious local minima under some assumptions; and (2) for two layer sparse linear networks, the previous properties do not stand anymore when the assumptions no longer hold. Cons: I was concerned about the technical novelty and significance. They are not justified in this paper. The authors do not state clearly what new proof techniques are used in this paper. However, most neural networks in practice _have_ nonlinear activations. I understand that it would be good to study a simpler model when a comprehensive model is intractable. The three aforementioned papers concern me. The insights of the given theories are not clear. Understanding the loss landscapes of sparse linear networks is important if we need to train them from scratch. Questions: It would be good if the authors can comment on the cons. An empirical investigation of deep learning theory,” ICLR 2020.<BRK>This paper studies the optimization landscape of (deep) sparse linear networks. As a result, an investigation of the optimization landscape of sparse networks, even in the simple case of a linear activation function, is timely and interesting to the ICLR community, since it can potentially shed light on the questions above. The main contributions of this paper can be summarised as follows:(1) If the network has a scalar output, then every local minimum is global (Theorem 1 for two layers and Theorem 6 for multiple layers). (2) The same conclusion (every local min is global) holds if the network has two outputs under extra assumptions (non overlapping first layer weights and orthogonal data). Overall, although the study of the landscape of sparse linear networks is an interesting topic, the submission is not particularly insightful in this regard. The results are quite weak and only show that spurious local minima can occur as soon as the output dimension is 3 (while they provably do not occur in lower output dimensions). The main weaknesses of the submission are as follows:(1) The paper does not really explain why neural networks can be pruned so well. It just proves that the landscape can be bad.<BRK>SummaryThis paper considers the optimization landscape of sparse linear networks. I think it’d be good to have a remark after Theorems 1 and 2 that they are extended to deep networks in a later section. If these conditions are not met, there may be bad local minima caused by the sparsity of the network. The paper gives some examples:1) For $d_y   3$, the paper gives a counterexample sparse network that has a bad local minimum. The paper essentially tells us that sparse linear networks have benign loss landscapes as in the dense linear networks if the output is scalar (Theorem 1 & 6), but suffer bad local minima when $d_y > 1$ unless some strong conditions are satisfied. In my humble opinion, the significance of the analysis in this paper looks rather limited and it does not provide new insights that carry over to sparse nonlinear networks. In addition, the clarity of the paper requires improvement. It would be better to elaborate more on these conditions. Also, I found the results in Section 2.4 difficult to understand; I think the statements of Theorems 3 and 4 are not clear enough. The terms “some projected data”, “influence for spurious local minima” are not defined nor clear. A more high level question is: how are these results related to the existence of bad local minima? Although it is claimed in the abstract that “no unrealistic assumptions” are made, I believe the conditions in Theorems 2 and 7 are quite strong. However I had the false impression that all the results only hold for shallow networks before reaching Section 4, which is at the end of the paper.<BRK>This paper provides an interesting analysis and direction to understand landscape of deep linear networks with sparsity patterns. In terms of main technical contributions, the authors prove that every local minimum is a global minimum in the case of scalar output with any sparsity structure, and show the existence of sub optimal local minima in the case of high dimensional output, analytically by considering a simple shallow network with a simple sparsity structure, and numerically by investigating the solutions found by an algorithm that converges to a local minimum. Understanding deep linear networks is an important topic for several reasons. One reason is that deep linear networks change its NTK during training, unlike the unrealistic deep nonlinear networks in the regime of extreme over parameterization. Moreover, from practical viewpoint, we know that practical deep neural networks change NTK during training, which seems to be one of the main sources of inductive bias to allow deep networks to perform well. The proof of Theorem 5 makes sense. On the other hand, the particular construction used in the proof of Theorem 5 is not general in the following sense. Given this target matrix Y and this sparse network, w_3 and w_7 are unnecessary, and we know a priori that we should make w_3 and w_7 to be zero. Indeed, the existence of the sub optimal local minima is shown by relying on the nonzero w_3 and w_7 in the proof. An interesting question to further improve the paper would be the following: can we construct suboptimal local minima with w_3   w_7   0 in this example?
Reject. rating score: 3. rating score: 5. rating score: 6. <BRK>This paper studies the top singular vector of the feature space learned by supervised and unsupervised deep learning models on CIFAR datasets. 1.While the authors emphasize the convergence of subspaces, the P vector defined in the paper is actually the top singular vector of the feature space, so it s actually about the convergence of the 1 dimensional principal subspace. In the context of SVD, the literature often studies the top $k$ dimensional subspace, which is represented by the $k$ top singular vectors, and the approximation error of the top $k$ dimensional subspace: $E \|X   U_k \Sigma_k V_k^T\|_F^2$, where $X$ would be the feature matrix in this paper, and $U_k, V_k$ are the first $k$ columns in the result of SVD. 2.This paper tries to emphasize the P vectors found in the features from different deep learning models are very close (for example, "no matter what type of DNN architectures or whether the labels have been used to train the models, the P vectors of different models would converge to the same one"). Actually it seems the angle typically converges to 10 to 20 degrees. It may be better to lower the tone, or quantify better (compared to the angles obtained by ..., the angles between P vectors are smaller). p value can guide our findings but is not always meaningful. For example, comparing Fig.7(e) and Fig.7(l), we may argue the latter has a better correlation but the former has a much smaller p value. The only convincing data I found is in Table 1, which shows P vectors can serve as an indicator of the model performance.<BRK>According to their empirical studies, the authors concluded that the feature spaces learned by different deep models with the same dataset would share common principal subspaces for the same dataset. It will not be affected by DNN architectures or the usage of labels in feature learning. I hope the authors carefully consider how to enhance this paper and make the conclusions more convincing. The authors also attached the source code for reference. 3.The usage of the P vector for predicting generalization achieves promising results. Cons:  1.Why can the similarity of P vectors be used to indicate the similarity of two distributions in the feature space? 3.The authors mentioned that the reference model used in Figure 4 (a) (c) is Wide ResNet28 trained with 200 epochs under suggest settings. 4.I would like to know why most models (such as Figure 4) cannot converge to zero after about 200 epochs training, and the angles are approximately 10 degrees. In other words, is there exists a threshold after which we can think the compared two models have a common subspace?<BRK>The authors identify an interesting empirical phenomenon: across a range of network architectures and training approaches (supervised, unsupervised, auto encoders), the feature spaces identified by these networks are similar. The authors introduce a specific way to summarize the feature space of a network as a vector (the top left singular vector of the num_examples x num_features matrix) and show that these vectors are highly correlated across networks. In addition, the authors show that the features spaces become more similar throughout training and are predictive of the generalization performance of a neural network. The paper presents purely experimental findings, but the experiments are sufficiently broad (e.g., covering different training approaches and datasets) so that this is not a shortcoming. Do the authors have a hypothesis for why it behaves different from the other methods w.r.t.P vector angles? Have the authors experimented with training approaches that explicitly encourage small angles between model and data P vectors? Why does the paper sometimes use angle and sometimes use cosine of the angle? It could be better to use one of the two consistently.
Reject. rating score: 3. rating score: 4. rating score: 4. rating score: 9. <BRK>The authors tackle the important problem of feature selection. They propose to use differentiable gates with an RNN architecture to select different subsets of features for each time point. I think the idea and method are interesting, and the method could be useful. However, I have crucial problems with the way the paper is presented.<BRK>This paper proposes an RNN model for adaptive dynamic feature selection, for efficient and interpretable human activity recognition (HAR). In particular, by using the adaptive feature selection technique, the average number of features necessary for HAR prediction can be very small (0.3%, 15.9%, 11.3% among all features) at any given time. The key concern about the paper is that the algorithm lacks practicality. Also, based on the current experimental results, it is difficult to say that features that were not used in earlier timestamp will not be used in later timestamp with a different context. Minor comments and questions:  Can you report the running time of each model? The performance of the adaptive method on the NTU RGB D dataset is quite poor.<BRK>This paper presents a learning based binary sampling mechanism for feature selection. + The experimental evaluations give positive results. These works should also been cited by this paper. Integrating Gumbel softmax sampling with RNN cells is very straightforward, and the motivation of applying Gumbel softmax is very similar to [a]. Yet no such results are reported in the paper. So it is very likely that the performance will become unstable as \tau changes. Showing such experimental results could be definitely improve the paper quality. Summary:Considering the concerns listed above, I believe there are problems that outweighs the strengths of this paper. They should be fixed before acceptance.<BRK>but could even generalise to measurement timings in clinical care to make the work of nurses more efficient, and reduce the stress caused by some medical procedures.. They have found that a smaller set of features. However, I think that this somewhat of an overpromise. The authors provide no data on this. It may be just an  estimate the derivative of the signal and ignore a new measurement, if it s time  derivative is small enough. As a summary , I support publication of the manuscript, provided  the authors modify the message on the interpretable features.
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 5. <BRK>The paper is well organized and easy to follow. And such architecture is not a first choice model for any of the four datasets. Only all four experimental datasets are physiological signals   ECG and PPG.<BRK>The connection of the probability in Equation (5) and previous sections are not close. It is not mentioned how to generate the pseudo label.<BRK>However, I find that the paper is not very insightful. Post Discussion After reading the author s response and other reviewers  reviews, I still find the novelty of this paper somewhat insufficient. I have the following concerns:1. Why the Gaussian assumption made in the paper is reasonable?<BRK>The experiments in the appendix fail to provide a coherent story or a discussion on why the method is not performing well in some experiments (e.g.~40% of the experiments in test set performance without an oracle). Post rebuttal comments:I d like to thank the authors for adding the experiments; the paper looks stronger now but unfortunately, the results on the new experiments are not that encouraging.
Reject. rating score: 4. rating score: 5. rating score: 6. rating score: 8. <BRK>This work studies the problem of parameter efficient transfer learning in the paradigm of pretraining/finetuning. In other words, the authors need to better motivate and justify parameter efficiency. Given that all the parameters of a big model are used in downstream tasks, what are the benefits of only modifying a few parameters? "This approach can become parameter efficient as the number of tasks increases as it only requires storing the nonzero positions and weights of the diff vector for each task. The cost of storing the shared pretrained model remains constant and is amortized across multiple tasks." Unfortunately, in real world scenarios, inference of  large models like BERT_base/large is usually conducted on servers or in cloud, where storage is not a big issue while latency (speed) is critical.<BRK>This work combines model pruning with transfer learning/multi task learning in NLP. The evaluation on GLUE shows some promising results with better efficiency compared to adapter networks. However, I am concerned with the motivation and applicability of the proposed method, such that I am left with the impression that the method may be hard to use in practice. In section 2, the author introduced multi task learning as the background. In practice, however, training some tasks together can improve performance (GLUE for example), but the proposed method is trained for each task independently and thus there is no positive transfer between tasks. This is an important extension that might be useful for the community. Besides, how sensitive they are compared to adapter networks? Missing reference:The idea of adding  residual  parameters for new tasks is not new in lifelong learning. [1] is also related of comparing pruning masks for pretrained models. Rusu et al., arxiv 2016[3] BatchEnsemble: an alternative approach to efficient ensemble and lifelong learning.<BRK>The authors present an interesting approach to learn task specific models with only a few tunable parameters. They propose learning a diff vector with a sparsity constraint and then pruning the vector using magnitude pruning. They also impose a structured sparsity constraint by introducing a group penalty. A few questions/thoughts which could improve the paper: * It would be good to list the epochs for training for each of the different approaches? Authors mention 2,3,4,5 epochs for training but would good to highlight the cost or savings of fine tuning with their approach. This would help understand the tradeoff of memory vs compute for the proposed approach. If the structure seems to help, then the model should be able to learn structure without the group constraint as well. As the size of pre trained models is growing quite rapidly, research that investigates parameter sharing and adapting a pretrained model to a new task with few parameters is essential.<BRK>This paper proposes diff pruning, an alternative paradigm for parameter efficient transfer learning of pre trained models. Parameter efficiency is achieved by regularizing $\theta_\tau$ to be sparse. The approach is evaluated on the GLUE benchmark where it achieves competitive performance to full fine tuning a BERT Large model and adapters while being more parameter efficient than both of them. Pros:1.The proposed method is intuitive and the different modelling choices are principled and well motivated. 2.The diff vector is distributed over the entire set of parameters of the model rather than focused in a few layers. Does a visualization of diff vectors of different tasks (such as using t SNE) reveal any interesting patterns? How much longer do you need to fine tune with non zero masks for magnitude pruning for sparsity control?
Reject. rating score: 4. rating score: 4. rating score: 6. <BRK>The submitted paper describes a very nice featurization library, AutoMunge, that converts NLP into features suitable for NNs. It s clear that the authors of the library have put a lot of thought into its construction, and it looks very useful. However, ICLR is about /learning/ representations, not about feature engineering. That would be a really interesting paper.<BRK>This paper introduces a library that preprocesses tabular data called Automunge. Whereas Automunge seems like a useful library, I am not convinced that it falls in either of these two categories. I suggest the authors target a different venue (e.g., PyCon, SysML, etc.) or elaborate on the scientific impact of their software (e.g., show experimentally that this framework allows practitioners to train better performing models).<BRK>I confirm that tasks like feature selection and string encoding are beneficial for applied researchers with textual data. I can see a wide interest in the community. I expected to see performance plots for different tasks (whether just for this package or with comparison to some baseline alternatives.As a minor comment, I don t think having "String theory" in the title is a good idea because this keyword is already taken to refer to another scientific topic ( a sub field of physics).
Reject. rating score: 3. rating score: 3. rating score: 4. rating score: 7. <BRK>Methodology:The paper tackles the so called open set classification where query examples outside any of the classes in the training set should be detected at inference. By combining the feature extractor based on fashionable deep models and the classical clustering methods (k means, GMM, etc), the paper empirically shows that this pipeline can address many open set problems in realistic scenarios.<BRK>can then be used to estimate the probability density function of features for use in OOD detection. Key contributions claimed are that pre trained nets have information about open world statistics and off the shelf net features along with appropriate choice of a low dimensional representation helps in outperforming conventional OOD schemes. 4. in 4.2 the authors use an  open  dataset for validation/tuning   this makes this dataset not open per definition. It may be true that it helps in the model generalizing better, but the terminology is still misguided. None of the tables in the paper provide error bars.<BRK>Empirical results in the paper suggest that simple statistical techniques can be quite effective in performing open set recognition. #### Clarity The paper is written well and is easy to understand. Experiment results are shown only for limited closed sets for training. Being an empirical paper it is expected for the paper to have more detailed experiments. (3) Authors mention in Section 4 that hyperparameters are selected based on a small scale validation set. Details about the validation set are needed to determine performance of the experiments.<BRK>I agree with R1 s concerns about overlap with two recent papers, but found the author response to be satisfactory. Overall, I will retain my accept rating. Fig 5 that shows how for open set semantic segmentation, the proposed method is a better alternative than training a binary classifier only when very little out of domain data is available to train onWeaknesses– Studying how/whether the choice of layer from which features are extracted affects performance would have been an interesting additionAdditional comments / suggestions– Fig 6 is difficult to read since some of the lines overlap, varying opacity might help with readabilityOverall commentsThis is an interesting and well written paper that proposes simple and memory efficient alternatives for open world recognition that consistently outperform more complex methods from prior work.
Reject. rating score: 5. rating score: 5. rating score: 5. rating score: 6. <BRK>The authors study adversarially trained classifiers and observe that the accuracy discrepancy between classes is larger than that of standard models. I found the paper interesting. However, I have one major concern: it is not clear that the phenomenon observed is a property of adversarial training. To summarize, based on the existing arguments in the paper, we cannot tell apart the scenario where robust training causes class disparity due to an inherent property of the method or simply because it increases the model s error rate. Overall, I do not believe that the paper is ready for publication but I would be willing to update my review based on further discussion.<BRK>Is that due to the point mentioned above or to what is discussed in Section 4.2? ###This work makes an interesting observation that techniques designed to maximize robustness to adversarial examples may have negative consequences on the model s performance. The discussion of related work is a bit "thin". Adversarial examples do not have to be "imperceptible", the main requirement is that the perturbation introduced does not affect semantics of the input. Unless the authors wish to demonstrate explicitly the connection between safety and certain definitions of fairness, in which case this connection should be presented more upfront in the paper. In particular, the definition considered seems to be based on parity but this is not explicitly stated there. Would the approach considered here apply to other definitions? It is not clear what is the applicability of the analysis based on robust/non robust features is beyond the toy dataset considered here. Does this create an artificial tension with fairness for the same reason that it creates an artificial tension with accuracy (because the p norm is not aligned with class semantics).<BRK>This paper begins with the empirical observation that adversarially trained models often exhibit a large different in clean (and robust) accuracies across different classes. The paper proposes an algorithm, Fair Robust Learning (FRL), to address this issue. The starting point is a standard Lagrangian based approach to approximately ensure constraints that the performance for each class should be close to the overall performance. The motivating empirical observations are an important contribution. In this case, it seems that even before adversarial training, we see a difference in class errors between the classes. Hopefully this can also be released along with the paper if accepted.<BRK>Summary:This paper introduces a fairness perspective on accuracy performance among distinct classes in the context of adversarial training. Strength:The paper makes an interesting observation on a fairness perspective in adversarial training. The theoretical study definitely offers a deeper understanding, yet it is analyzed under a particular setting Eq.(1) which I am not sure if it represents most practically relevant scenarios. As the authors mentioned in Section 6.2, this may be due to particular algorithms and data distribution. If that is the case, it would be good to see that the observation may not happen in other settings. But it was not intuitively clear to me why the unfairness issue occurs in the considered setting. There are many grammatical errors and typos.
Accept (Poster). rating score: 8. rating score: 8. rating score: 7. rating score: 5. <BRK>### Strong pointsS1: Clear explanation of the method in terms of its relation to prior work and theoretical motivation. W2: A bit more empirical validation of the theoretical arguments would strengthen the paper. I would be inclined to increase my score if the weak points I mentioned above were addressed, and depending on answers to my questions below. ### QuestionsQ1: how important is the LSTM architecture? Q2: I was a little confused about the LSTM notation. A bit more explanation of this notation would be helpful. Would it make sense to report std devs across examples for each method? ### Other comments:C1: I found the Figure 1 caption to be a little hard to understand and there s a typo.<BRK>All notation is introduced beforehand and it is easy to follow. The experiments show that this adaptive approach improves the performance of ALISTA. 4.The paper is very clearly written and well positioned in previously existing literature. The method is solidly justified and the experiments are convincing.<BRK>Cons:  Firstly, it is kind of a pity that the authors do not provide some real world experiments, e.g.compressive sensing, where the compression ratios are challenging indeed. This method is based on (1) the previous previous finding of the relation of the step size and threshold with the $\ell_1$ signal recovery error; and (2) the empirical observation of the correlation between the $\ell_1$ signal recovery error and reconstruction error. Experiments in synthetic setting show the superiority of AG ALISTA over ALISTA and other variants that follow it, especially in settings where the compression ratios are challenging, which is claimed to be more realistic in real world settings. Pros:The most interesting and novel part of this paper is the use of LSTM for the generation of the step size and threshold parameters.<BRK>This paper adds LSTM to adjust the step size and threshold for LISTA, an optimization algorithm of sparse regression problems. Still, I found the experiments to be a bit insufficient to convince me of its improvement over LISTA or even most vanilla solvers: Figure 3,4,5 all showing MSE to some iterations when only one optimizer reaches its optimality, or even not one reaching optimality. On top of this, no mentions of the actual running time of the optimizer as LSTM could be really slow. small questions:What is the point of the study showed in figure 1&2 as by definition,  as $W$ is already supposed to be an isometric mapping?
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. rating score: 5. <BRK>This submission presents a rigorous analysis of a subset of ways in which machine learning models can fail when encountering out of distribution (OOD) samples (often referred to as train/test skew or as train/scoring skew in industry). In that case, what is the OOD "shift"   the prevalence of the minority group at test time? I agree with this statement on page 5: "any algorithm for solving OoD generalization should at the least hope to solve these easy to learn tasks well." The experiments were thoughtful and well designed, and their results are presented effectively: each plot, it seems, illustrates a particular point or supports a specific argument in the paper.<BRK>This paper investigates the reasons why machine learning models usually fail to generalize out of distribution even in easy to learn tasks where one would expect these models to succeed. Here is the example. Pros:+ The problem studied in this paper has been one of the most important in the community and this work has a meaningful attempt on the theoretical side. However, the authors claim that these two skews are “not just a sufficient but also a necessary factor for failure of these models in easy to learn tasks“, which I think might be overclaimed, even in the easy to learn tasks defined in the paper.<BRK>Cons:  This paper is written is a way that s confusing and frequently difficult to follow. The experiments focus on a variety of synthetic distribution shifts. While this may be useful in understanding the constructions in the paper, it s not evident to what extent these  skews  and the  spurious/invariant  distinction given here can explain the lack of robustness observed in practice on "real" or "natural" distribution shifts. Update after rebuttal:Thank you to the authors for their detailed response.<BRK>Overview: The authors study the out of distribution generalisation problem in detail wherein a model may incorrectly use spurious correlations in the data to make predictions on data at test time. I would have liked to have seen some exposition of these problems in a real high risk setting. The approach taken in this paper is to a) study tasks that are easy to succeed on, b) show that OOD failure occurs even in these easy settings. The authors subsequently show that geometric and statistical skews are necessary for failure.
Reject. rating score: 3. rating score: 5. rating score: 6. rating score: 7. <BRK>Summary:The paper presents a system for collaborative training where two central servers compute the model update using two party computation. Claiming Byzantine robustness seems too strong when the two central servers have to be semi honest. Cons:  The main issue I have is that the authors claim in Section 4.3 that they "can" use full precision (real) values in the computation but the underlying techniques (secret sharing and Beaver triples) have only been proposed for integer/quantized values. The authors should either present credible secure floating point computation or change their claim to quantized computation.<BRK>This work proposes a method to robustly (<.5 adversarial workers) aggregate model updates using two non colluding servers. (somewhat discussed in the lit section)   The experimental section is lacking a bit. While the paper proposes a novel idea with significant improvements, the paper is lacking wrt putting it into context of the existing field and a more detailed interpretation of the experiments would be welcome. The authors discuss related work that relies on public key infrastructure and requires pairwise secrets between clients.<BRK>The paper proposes a method combining privacy and byzantine robustness for distnace based aggregation. This is a relevant and interesting topic. The approach doesn t introduce fundamentally new techniques but combines existing ideas to realize a more powerful solution.<BRK>3.A wide array of byzantine robust aggregation rules can be incorporated easily into the framework. The paper introduces a two server protocol to handle privacy concerns and Byzantine threats in a Federated Learning system simultaneously. The algorithm requires that the two servers should not collude. 2.The proposed algorithm is shown to have theoretical guarantees.
Reject. rating score: 4. rating score: 5. rating score: 6. rating score: 7. <BRK>The empirical results measured by FID are good, and the experiments on higher resolution datasets like LSUN 256x256 is appreciated. However, the reviewer would like to point out some possible issues as below. Meanwhile, previous works have already shown that controlling the whole spectrum is important and beneficial for GAN training, e.g.Fig 1 in [2]. The theory in Section 2 is about a simplified model (linear network) under another setting, and the reviewer is not convinced that the result there (convergence is upper bounded by a quantity related to the condition number) can resolve the issue and justify the importance of condition number. Another possible issue is computational cost.<BRK>This paper relieves this issue by introducing a preconditioning layer. The authors found that the instabilities are accompanied by large condition numbers of the discriminator weight matrices. Some theoretical evidence should be provided. In Section 1, the authors suspect that an ‘adequate’ weight matrix spectrum is also important for GAN training. In addition, it would be better to provide intuitive understanding for the proposed theorems and claims. 4.In Section 2, this paper only considers a deep linear neural network. However, it is impractical for some real world case.<BRK>The paper proposes a new concept of pre conditioning layers. The idea is creative and technically interesting. The authors argue that not only large singular values matter, but also the condition number. The baseline method is a GAN that is no longer state of the art. The description is a bit vague. If there is no demonstration of visual quality improvement I would be quite skeptical if an improvement really has been made.<BRK>Motivated from this observation, the paper proposes to control the condition numbers of the discriminator layers, by adding preconditioning to the weights. The results show that the proposed approach makes the training more stable and achieves better sample quality on several datasets. [2] Miyato, Takeru, et al."Spectral normalization for generative adversarial networks." If you do the exact computation, then I have a question about the scalability of the approach. I wonder how your theorems and results would change considering this difference (e.g.how the theorems would change if you are controlling the condition numbers of the reshaped kernels instead of the layers, and how the results would be if you strictly controlling the condition number of convolutional layers)? * Another missing related work is [3], which discussed the importance of condition numbers in the generators of GANs.
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 6. <BRK>This paper proposes a new calibration error measurement named UCE (Uncertainty Calibration Error) for deep classification models. It consists in doing a calibration in order to achieve "perfect calibration" (i.e., the uncertainty provided is equivalent to the classification error at all levels in [0, 1]), relying on normalized entropy for multiclass classification. A point with this UCE metric is that is has some interpretability properties in terms of its value, and is said to be robust to the number of bins used. The proposed metric is well explained, and justified, although I am wondering how well stands the assumption that the normalized entropy approaches the top 1 error for reasonable number of classes (e.g.C 10, as with CIFAR 10, or C 100, as with CIFAR 100). The properties presented are interesting. Moreover, looking at the results in detail (Table 1), UCE does not appear to be particularly strong, having a worse calibration than ECE and ACE on CIFAR 10, but slightly better on CIFAR 100, assuming that we want it to be increased to reach the real error rate obtained. In terms of potential impact of that paper, I still need to be convinced.<BRK>Therefore, given the focus on calibration measures, I m confused as to the motivation behind comparing to NLL & Brier score directly (beyond the overconfidence analysis from Guo et al.(2017)) as a means of motivating the usefulness of UCE. SummaryThe authors focus on the important problem of improved calibration measures as compared to the (now fairly standard) expected calibration error (ECE). Interestingly though, NLL, Brier score, ECE, ACE, UCE, and MMCE (i.e, all metrics other than accuracy) point towards entropy regularization being superior. p. 8: Rejection & OOD Detection: This has been studied previously for unnormalized entropy, which should yield the same results. Overall, at the end of the paper as a reader, I m still left with questions of whether UCE is truly a better calibration metric. However, I don t believe the remaining experiments make a strong case that the metric (1) provides a better measure of calibration, (2) yields consistently improved model performance when used as a regularizer (though it s interesting that it can be used as one!), or (3) allows for improved model selection. p. 4: The definition of perfect calibration can be traced back to Brier (1950), and, unlike ECE, is not limited to only the max predicted probability. While this is interesting theoretically, this assumption seems too strong for empirical settings, and I think this affects the interpretability of the metric as claimed in the conclusion.<BRK>The work proposes a novel uncertainty metric, relates this to existing methods and provides robust evaluation of the various merits of this approach. Can table 2 include a non regularized baseline as well to study this? it is said that UCE performs on par without regularization; then what is the point of proposing UCE as a regularizer? Are there values not shown here where calibration error does change? However, the proposal of the use of the metric as a regulariser and a OOD scoring function seems unproductive and if so, distracts from the core contribution. This core contribution is understudied in the work. The work would benefit from more analysis into the computational tradeoffs, and evaluation of the signal that the proposed metric provides on model selection for downstream uncertainty tasks. This appears to be the basis of the improved results in table 1.<BRK>This paper proposes a new metric for uncertainty calibration, based on comparing the entropy of the marginal class probabilities conditioned on predicted class with the entropy of the predicted probabilities. The metric avoids the failure mode of ECE, where predicting the relative frequencies of classes results in perfect calibration, and can be used as a regularizer in a loss function. The paper demonstrates that regularization with UCE yields better calibrated uncertainty on CIFAR predictions without sacrificing accuracy. The paper is well written and well motivated. Which loss function was used to produce the results in Table 1?
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. <BRK># SummaryThe paper finds that at extreme sparsities (>95%), existing approaches to pruning neural networks at initialization devolve to worse than random pruning. The paper presents a modified saliency metric based on SNIP, allowing for calculating salience of partially pruned networks; this in turn allows for applying an iterative version of SNIP, as well as a variant of iterative SNIP that allows for rejuvenation. These pruning techniques are evaluated, showing that they maintain accuracy at high sparsities. Some discussion of this is presented in App. Is there a reason to present Iter SNIP at all? # Overall recommendation7: Accept# Other comments and suggestions  Small typo: "We" is capitalized in the middle of the first sentence of Section 5. Figure 4 left: would it be possible to also include the saliency obtained from the FORCE metric in this plot?<BRK>The proposed method FORCE shows great performance when compared to rencelty proposed SNIP and GRASP. I see clear contribution in this paper to the field of pruning at initialisation and it is a clear accept from me. The novelty of this paper is clear to me. 3.The paper is well written and easy to follow. and the proposed iterative pruning at initialization is easy to apply in practice. Both VGG19 and ResNet50 cannot be considered as efficient model architectures. It might be more convincing for the paper to test on recently proposed efficient network architectures such as the MobileNet family.<BRK>Summary: Author observed that beyond a certain level of sparsity, existing pruning methods hat pruning at initialization performs even worse than random pruning. The author proposed FORCE and Iterative SNIP to handle this problem. These methods consistently significantly outperforms other methods on this problem. New effective methods proposed by author. Weaknesses: The author only shows that his methods works better than SNIP and GRASP at super high sparsity. We wonder how it performs when sparsity is not that high. The importance of this problem is weak, although author improved performance in this case. I wonder whether this is truly useful in practice. The writing of the paper is good. It is a narrow area, but the paper is deep and through. But overall, it is still a good paper, though the area may be very narrow.
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. rating score: 5. <BRK>The proposed network is verified in few short recognition task and VQA task with comparisons to state of the art methods. +This paper is well written and the core ideas and network design are well illustrated and explained in the paper and supp video. +State of the art results on few shot recognition, especially on one shot recognition. The object centric disentangling and 3D shape prototype learning seem to play complementary roles for the results. It is not clear how the proposed methods, e.g.AdaIn disentangling and rotation invariant prototype can be easily generalized to other scenarios including deformation (pointed out in the paper) and part based composition.<BRK>It aims at learning disentangled 3D representation of input images. The paper is well written. The experiments are quite extensive. My concerns are mostly about experimental evaluation. There are some important studies missing, and other results not well justified. First, some important ablation studies are missing, especially in Section 4.1. Is the proposed representation algorithm only working with prototypical networks? I also have serious concerns about the generality and applicability of the claimed shape style disentanglement. The limitation on generality will greatly restrict the application of this framework in real world images. This is also related to another minor comment about the setup of few shot style recognition in Table 1. So the "16 style classes" in the paper indicates that the authors are treating pairs of (color, material) as the label for objects.<BRK>This paper describes an approach that learns a disentangled shape and style representation of objects in a self supervised way from RGB D images. The approach is based on various components, like a 3D feature volume, a bounding box detector, and a disentanglement network. I ve updated my score in light of these additional results. Various applications of this representation  are shown, examples are few shot shape learning and Visual Question Answering. Disentangling style and shape for example allows to detect object independently of style (something easily done by humans) and generation of scenes from language utterances. Overall, it seems like a good direction to try to go for a full 3D(+style) representation to get more flexible and general models. The experiments indicate that the main concepts help in the down stream tasks. If not, what is preventing applying this approach to more realistic images and objects? Is this a real example that was rendered by the proposed approach? An elaborate system like this would benefit strongly from this. what is the influence of the granularity of the 3D feature map? Post rebuttal  I d like to thank the authors for the response.<BRK>The paper claims that the main contribution is "to identify the importance of using disentangled 3D feature representation for few show learning". 3) While there are several experiments given, it is unclear how valuable the results and comparisons are. It seems that most if not all of the explored settings have not been addressed in the other works that this paper compares to. This makes it very hard to understand if the proposed approach really has any benefit when it is used only in non published and non standard settingsSo while the model formulation is quite sensible and combines in a meaningful way previous ideas and approaches, it remains unclear what can be taken away from this paper beyond the rather specific experiments mostly on simulated data (and some unclear real world veggie experiments)  post rebuttal  Thanks for adding the experiments for Replica   these at least seem to suggest that the approach can work on more complex scenes than shown initially in the paper. I still find the comparisons and ablations weak as the particular training setup and model are the key contribution for the paper and thus without a proper ablation it is hard to know what exactly to take away.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>That is, the task of clustering the entries of an input vector into sets of coherent subspaces. Quantitative analysis of the performance of the three algorithms is provided by means of synthetic experiments. The paper is well written, with sound mathematical formulation. The contributions proposed by the authors seem to have enough novelty and relevance for the community, and both theoretical and practical contributions are thoroughly motivated and discussed. The experiments section show limited results regarding the choice of the number of clusters (only 2 or 4). * Given the attention paid in the paper to motivating applications (a full section) I miss a section in the Experiments where the proposed approach is validated with real data from any of the mentioned applications. At the same time the algorithm presented (RansaS) is based on random sampling which seems contradictory. What about the K means assumption of isotropic clusters? * The choice of just l1 as a baseline for comparison is a bit arbitrary. I wonder why the other mentioned approaches (mixed integer programming or random sampling) were not added to the evaluation.<BRK>Summary: The paper introduces the problem of subspace spitting, in which an observed mixed features vector is to be partitioned such that the identified partitions match with given subspaces. The paper is generally well written. While the paper has a dedicated section on motivating applications, they are not that convincing. The examples provided seem to be included to justify the proposed model. Isn t it obvious that the span of the restriction of a subspace to a given partition of size m, the whole R^m? I believe the main result can just follow from this simple observation. Reproducibility: the authors did not include code for their developed algorithms in the supplementary material. Impact: Provided that the problem setup and model are better justified, I believe this work could open up new research questions in machine learning and data analysis, including (mixture) variants of well studied problems on matrix completion and robust learning.<BRK>This paper introduced a new setting in which variables in feature vector are divided into different groups and in each group, variables are generated by sampling within linear subspace. Three algorithms are provided to cluster the variables into their generative subspace. They also provide motivating applications for this new setting in metagenomics, recommender systems, and robust learning. I think the new setting is potentially interesting and the proposed algorithms are good. Please elaborate on that. Then, the new r by r U_\Omega^k cannot be invertible as it is not full rank in row.
Reject. rating score: 4. rating score: 5. rating score: 6. rating score: 6. <BRK>The scientific novelty in the paper is very limited. The exact calculation/definition of the convolutional transducer is not clear. What are the differences? Or the model is very weak compared to current state of the art? Why is that? However, the scientific novelty is limited, and also the experimental section has several problems. At least some details about this should be given. E.g.more tasks and experiments should be done where it is useful to have such a generic differentiable WFST software, which is currently hard to implement otherwise. This is specifically important for efficient training. E.g compared to the existing implementation above, or other existing implementations for CTC. Is the WFST always represented statically, or does it support dynamic composition, which would be done on the fly when traversing the graph (like WFST decoders in speech recognition usually do it)? And the experiments should have fair comparisons to the literature.<BRK>This paper presents how weighted finite state transducers (WFST) and a few common operations performed on them can be integrated in a differentiable model, and therefore contribute to the training of complete systems. The benefits brought by the availability of WFST based differentiable operation in deep learning libraries are clear and very relevant. As rightfully mentioned by the authors, Kaldi implements sequence discriminative loss functions, either lattice based or lattice free, based on WFSTs and on GPU. Although the level of details on CTC and ASG for example would be sufficient for application specific conferences, I feel like a reminder of how and why these loss functions are computed would be nice for ICLR since not all readers may be familiar with these losses. Regarding the implementation, which to me is the main contribution of this paper, I would expect more details about runtime and efficiency compared to other implementation of CTC and ASG for example, which by the way would not be too hard to modify to include the proposed variations (even though it would be reimplementing them for each new case, when the proposed method would be generic, which is indeed a very nice thing to have!). Regarding the experiments, a comparison with the state of the art would be interesting. I understand that the page limit is tight and does not allow to present the models in details, but the reference to the paper presenting TDS in the main text at least might help the reader understand better section 5.3, which is difficult to follow when one is not familiar with that architecture. However, the novelty of the idea itself is very limited and the improvement over the GTN idea is not clearly stated.<BRK>"The kernel transducers can be structured to impose a desired correspondence. The paper details how some specific WFST models can help implement models such as CTC or ASG, presents a less clear application to convolutional models, and presents results evaluating the use of differentiable WFSTs for tasks in ASR and handwriting recognition. Section 3 gives a more or less standard outline of the WFST framework, but only in Section 3.2 is auto differentiation discussed, and it s a very bare bones description, along the lines of, "we did it." I think the paper assumes the reader is familiar with the TDS / convnet seq2seq models previously proposed, but I for one am not. I ll leave it up to the authors how, or if, they want to acknowledge this point in their draft, it s really just a comment   just to say that for some in the "end to end" world, WFSTs are less relevant than to others, depending on the nature of their models.<BRK>Summary: The authors introduce a  library for differential weighted finite state transducers. This is not due to theoretical limitation of WFST but rather to a lack of available implementation and the need of important computational power to train them. The authors show that this new library can be used to encode the ASG criterion, by combining the emission graph (coming from a NN for example), the token graph (base recognition units) and the label graph (the sequence annotation) on one hand and the emission graph and a language model graph on the other hand. ##########################################################################Reasons for score:    I am very pleased to see an implementation of the GTN approach which has been proposed more than 20 years ago. However, implementation details are not given or explained and experiments are still preliminary. * the section 4 on learning algorithms is not very generic as only an implementation of ASG is first presented then a comparison to CTC. WFST is too short to be really understand the proposed model.
Reject. rating score: 5. rating score: 6. rating score: 6. rating score: 6. rating score: 7. <BRK>I would like to hear the authors’ responses to make my decision. [1] Zhong et al.RTFM: Generalising to New Environment Dynamics via Reading. This paper considers collaboratively to learn “entity” representations and natural language explanations with a reinforcement learning framework. For example, the term “entity” is very ambiguous. I read several recent papers in the natural language grounding field but still puzzled about the term (for example, the semantic meaning of “entity” in  [2] is different from this paper). After reading this paper, I am not sure which part is the main novelty. It might be beneficial to have some discussions on this part. Other minor points:   I am interested in the O Map baseline, which seems to be a very good upper bound of the proposed approach, I am surprised to see that the EMMA approach outperforms the O Map in the training settings. It is suggested to have some further analysis.<BRK>Summary:This paper is studying the problem of learning to interpret manuals / textual information about the task, with the goal of faster learning and generalization in RL. (3) With slight modifications, the environment proposed in Zhong et al 2020 should be suitable for addressing the main topic of this paper, why introduce a new environment? Reasons for score:I find the topic interesting and relevant, and the use of human generated descriptions (in contrast to procedurally generated manuals as in Zhong et al 2020) is welcomed. I think the paper would benefit from identifying and focusing on one or two of the more specific issues and exploring them in depth.<BRK>The paper presents a model for entity grounding from its textual description for a text based language game. From what I understand, the game here itself is substantially simpler than that of previous work (Zhong et al 20), which involves varying goals and modifiers. Their architecture deviates from existing approaches (Zhong et al 20, Narasimhan et al 18) which did not require the model to learn a mapping from an entity to its description either by providing a mapping between objects and their textual descriptions or using entity names plainly. It would have been a lot more convincing if they use their model on the existing game environment, instead of creating a whole new game specifically designed to test their idea. The paper is clearly written and easy to follow, except for some parts (BAM parts weren’t easy to follow). The model seems to be doing well in this constrained setting (Table 2). Could the authors provide how this model can be applied to more challenging and complex game scenarios, where there s no one to one mapping between entity description and an entity, and the goal is more complex?<BRK>The paper considers the task of training an agent to act following a manual expressed in natural language. The manual describes the roles and the behaviors of the entities in the environment. It is shown that EMMA is more effective than simple baselines. The paper is mostly clearly written. The paper can be seen as another proof of concept paper for acting based on a manual, but it should be noted that it is not the first one of its kind [1]. In several places in the paper it is mentioned that the model learns “mapping between entity IDs in observation space and their symbols in text entirely through *interaction* with the environment.” I am not sure what interaction means here. Looking at the formulas, my understanding is that EMMA establishes a correspondence between the observed object symbols and the entities based on the entities’ descriptions. Doesn’t it have the complete access to the roles and behaviour of every object? It appears common in the field of RL to not ask for such justifications and happily accept gridworld studies motivated by generalization to “new environments”. But I would like to flag that for an outsider this disconnect from reality may seem troublesome.<BRK>I have a few questions on clarity but overall the paper was well presented. ## Quality & ClarityThe paper is generally fairly clear. There are a lot of details in this paper and some of them did not quite feel fully developed (understandable given the space constraints), such as justification for certain modeling choices. In Section 6.1: Multi task Performance, I was not quite able to grasp why the single combination tasks are more difficult. Overall though, I was able to easily understand the main points of the paper and the data was clearly visualised in graphs and tables. This would demonstrate that the kind of structure present in the tasks is learned and can be applied to different kinds of entities / a different vocabulary.
Reject. rating score: 3. rating score: 5. rating score: 7. <BRK>This paper proposes an MPC algorithm based on a learned (neural network) Lyapunov function. In particular, they learn both the Lyapunov function and the forward model of the dynamics, and then control the system using an MPC with respect to these models. Furthermore, the authors’ approach is closely related to learning the value function and planning over some horizon using the value function as the terminal cost (indeed, the value function is a valid Lyapunov function, but not necessarily vice versa). The authors should clarify their contributions with respect to these papers. They only consider two environments, the inverted pendulum and car, both of which are very simple. Post rebuttal: While I appreciate the authors  comments, they do not fundamentally address my concerns that the paper is too unclear in terms of the meaning of its technical results to merit acceptance. However, then, the number of samples required would still be exponential in the dimension of the state space.<BRK>In this paper the author proposed an MPC algorithm in which both the dynamics function and the Lyapunov function are parameterized with neural networks.. Specifically leveraging the results of Lyapunov networks (2018 CORL paper: https://arxiv.org/abs/1808.00924) for learning Lyapunov functions, the authors derived an MPC algorithm for quadratic cost/reward problems and also proved the stability, robustness, and sub optimality performance. To demonstrate the effectiveness of the algorithms, the authors also evaluated this approach on the simple inverted pendulum and car kinematics tasks. In general I find this paper presents a comprehensive results of a model based control method that is very popular in the control theory community. Is this loss function identical to the Lyapunov network 2018 CORL paper? On the overall, I find this paper s algorithm interesting. However, there are several technical question listed above, and one high level concern is its novelty.<BRK>While the majority of reinforcement learning algorithms rely on trial and error, which may damage the system, the authors introduce an algorithm for safe exploration and control. Accordingly, the authors propose a scheme allowing to learn a Lyapunov function $V$ from demonstration data only, through a loss function that penalizes increments of $V$ along one step transitions. 2.By bringing together existing results and techniques (MPC stability analyses, value based RL analyses, LuyapunovNet), the authors manage to relax several assumptions of prior works (no need for access to the perfect dynamics or a stabilizing policy, but only to a demonstration dataset) which makes the approach more practical. The same as in equation (3)? 3.One of the main claim of the paper is the ability of the method to expand a demonstrated safe region.
Accept (Poster). rating score: 8. rating score: 8. rating score: 7. rating score: 4. <BRK>#### SummaryThis paper addresses the issue of incorporating commonsense into large pretrained language models. This methodology is used to try to bake in commonsense into models. #### Strengths(1) The use of a self supervised approach is great because it requires no annotation and the training procedure is simple. During inference time if the concepts were shuffled in a different manner would the model still be able to generate the correct sentences? which seems that the model isn t as robust to newly seen inputs#### Detailed CommentsIf spacy was also used for POS tagging along with tokenization this should be made clear. Is this T5 with additional epochs? I think this should be made clear. It is nice to see a smaller model is beating a larger model on some metrics"The difference between CALM and CALM (Joint) is that the former is initialized by the CALM(Mix)." Also I don t see CALM (Join) in the table. A sentence like "Running I am" is not grammatically correct.<BRK>Summary:This paper proposes the “Concept Aware Language Model” (CALM)   a pre trained T5 Transformer is trained on self supervised intermediate tasks to learn relational commonsense knowledge, before fine tuning on downstream tasks. The intermediate tasks include (1) concept to sentence (c2s) generation   given a list of permuted concepts (verbs and nouns), generate the target sequence, (2) concept order recovery (cor)   given a sequence with the order of concepts (verbs and nouns) shuffled, generate the original sequence, (3) given a sequence and it’s perturbed version (concepts shuffled), generate the sequence (classification but as a generation task). The goal of the paper is to show that carefully designed objectives for self supervised intermediate task training add relational commonsense knowledge which helps improve model performance on downstream commonsense reasoning tasks. might not be acquiring during the large scale pre training phase. S2    As shown by results in Table 1 on 5 commonsense reasoning tasks, the intermediate task training proposed in this work improves performance over and above the T5 model (and variants including with salient span masking for concepts). This would show how much value c2s and cor are really adding. Presently, (a) it’s unclear if the designed objectives are providing commonsense reasoning above something the model can know from autoregressive language model scoring, and (b) it appears that the objectives are not designed to add relational commonsense knowledge of the sort where we know apples don’t grow in the ground. I do in general quite like the paper, and the responses here are thought provoking.<BRK>This paper suggestsan intermediate training regime that can be used between pretraining and the end task finetuning. One way this can be seen is  that the slopes of the T5 and CALM lines are very similar after an initial “bump” which T5 likely needs to calibrate to the new distribution. Altogether, I think this paper makes an interesting contribution to the question of: How can we get the most pretraining signal from unstructured data using off the shelf tools? Experimental results show improvements over both the base T5 model and the large T5 model. CALM shows better results with less data than the base model. The objectives suggested are cheap to compute and seem to increase the signal available in the data. Extensive results show improvements over a base model and a larger model across a range of tasks. Using “concept” to stand in for verbs and nouns is somewhat confusing. > However, in every task except CommonGEN the authors do not discuss any methods that are even close to the state of the art. For CSQA, the best number in this paper is 63.32 vs. 79.5 on the current leaderboard. > On the generative task CALM performs closer to SOTA, but it improves only slightly on T5. I still feel that the authors’ use of “concept” and “commonsense” is vague, when their method can be defined more clearly with more mundane terminology. In practice, the authors use nouns and verbs as their concepts, which is fine in terms of pretraining objectives, but surely does not capture the generality of concepts.<BRK>This paper proposes two self supervised pre training tasks to further pre train a pre trained language model for commonsense reasoning. Experimental results show that the pre trained language models fine tuned with the two proposed tasks can lead to improvement on five commonsense reasoning benchmark datasets. Strengths: + The idea of teaching language models through self supervised learning tasks is neat. Second, the proposed tasks are applied only to T5. I am wondering if it is effective on the other pre trained language models. Third, the performance improvement on the classification tasks appears marginal. A deeper analysis of the proposed method would have been nice to understand which part is effective in the new task, keeping content words or not using mask out, what if only concepts from a knowledge base is kept instead of content words? The CALM model proposed in this work performs worse than the SOTA models in three out of four metrics on CommonGen, despite it uses less model parameters.
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 6. <BRK>I understand that they are defined in the appendix. Figure D.2 shows that sqrt(n)/(sqrt(n)+...) decreases to zero with n going to infinite. However, this quantity is non decreasing as a function of n and it converges to 1 when n diverges!! Page 6 after lemma 2, the authors stated that Thm 1 shows the first convergence rate for ellipsoidal TR methods. If the non zero term is not in the sub sampling for all t the bounds you mentioned may not be satisfied. You can have these bounds but only in a probabilistic manner as in the Blanchet et al.work (this work is cited in the paper)...<BRK>Main contribution is a trust region based algorithm they call "Stochastic Ellipsoidal Trust Region Method" thats flexible to include both full, and diagonal matrix as the preconditioning matrix. I think the authors could substantially improve the emperical results in the paper by including commonly used adaptive methods as baseline (such as Adam), and providing results on stronger baselines, and break down on computational effeciency of the proposed approach in more details. Questions/comments:a) There is Appendix C that states that batch size used first order method is 32, vs for this method authors use 128/512 and then compare backprops.<BRK>This paper analyzes adaptive methods like Adam and AMSProp, and shows that they can be re interpreted as first order trust region methods with an ellipsoidal trust region (Lemma 1). The approach proposed in the paper is interesting, but the significance of the paper is not clear.<BRK>The paper proposes novel stochastic ellipsoidal trust region methods  inspired by adaptive gradient methods and studies the application of them with adaptive diagonal preconditioners. Interestingly, the paper shows for the first time that, adaptive gradient methods can be view as first order TR with ellipsoidal constraints.
Reject. rating score: 4. rating score: 5. rating score: 5. <BRK>  The idea of combining learning representations and ensemble clustering is interesting and possibly promising. I think this paper in its present form is not ready to be published though. Have the authors performed any analysis on this? The description of the algorithm is often too vague and is fragmented in mini sections, and the flow that brings them together is unclear. What s the motivation for using a multi layer perceptron to further reduce f1 and f2? Part (a) does not help at all in understanding the approach.<BRK>The authors propose a learning based approach for image clustering. The authors seem to be not aware of that work. However, the authors seem to miss the the point that LA is not just another consensus clustering approach which they forgot to include into literature review since it does not report clustering metrics. I encourage the authors to improve the manuscript in this direction and resubmit to a different venue.<BRK>This paper studies the effect of combining ensemble learning approaches with deep clustering. However, I am not sure that the results presented in the paper are enough to support the claims. (+) The writing is in general clear and undestandable. ( ) The description of the main algorithm seems to be more intuitive than innovative. The authors can expand their discussion on this. These seed ideas could be good for this venue.
Accept (Poster). rating score: 8. rating score: 7. rating score: 7. rating score: 6. <BRK>PROS:  As far as the reviewer notes, this approach is novel in the (now increasingly crowded) set of alternatives for molecular generative models. The authors have a model that compares favorably to the baselines  The authors use a very relevant set of optimization parameters for the multiobjective task. The paper is well explained.<BRK>2.The method is novel and the experiments demonstrate the effectiveness of the methods compared to previous methods. To this end, the authors proposes an alternating approach consisting of an explainer model and a molecule completion model. The paper tackles the problem of molecule property optimisation.<BRK>The aspect of explainability is novel. The presentation of the paper is mostly clear. Maybe this is something the authors could comment on in the rebuttal.<BRK>Update: I read the reply and thank the authors for the clarifications. The notion of explainability is not sufficiently discussed in the paper and the claim(?)
Reject. rating score: 3. rating score: 4. rating score: 4. rating score: 6. <BRK>This does not appear in the results of the red/greentetrahedralization results. The method is trained (as far as I can tell) on somegroundtruth cloth simulation method (this is not revealed). How are the weights wkj determined? Callibrating for the expected result quality ateither venue, I would recommend acceptance. This appears to be crucial to the method but left out. 5) Finally, this paper claims to provide a "Skinning a parameterization ofthree dimensional space for neural network cloth". This isn t questioned untillater when all sorts of issues appear due to overlapping and inverted elements. There was no reason to think that skinning such a thick tet mesh was a good ideain the first place. 4) This paper is far from replicable.<BRK>Inspired by [2], this paper trains a neural network to learn the per vertex offset as a function of body pose. It has the potential to be applied to other cloth related tasks. The inversion and robustness issues are addressed. This paper is clearly organized and well written. There are sufficient technical details presented in the paper. It is not clearly which component of the method enforces temporal consistency. Association for Computing Machinery, 2020.<BRK>Towards this, they propose to use tetrahedral parameterization using well known techniques in computer graphics community. The kinematically deforming skinned mesh (KDSM) formulation for tetrahedral parameterization is borrowed from Lee at. al.This is a very niche topic and I am not confident that the general audience stands to benefit from this specific formulation for clothes. al significantly limits the scope of the paper.<BRK>However it looks to me that this paper is more suited to the graphics conference like SIGGRAPH. The are several questions about the experimental part of the paper. Is it possible to add more comparisons on the other clothes or object types? Minor issues:  Figure 1(d) looks not intuitive, does not look like (d) is modification of (c) and (d) does not look as shirt at all. Supplementary material should go along with the paper as a set of Appendixes. Paper contain weird green artifacts in the end of first and second pages which should be removed.
Reject. rating score: 4. rating score: 4. rating score: 4. rating score: 5. <BRK>Update: The added generalization tests and performance numbers strengthen the paper, and make the aim more clear. This finding is not very surprising, considering that this method directly supervises on the pressure correction module, while the baselines do not.<BRK>Was the model sensitive to this? The problem partly is that the dataset generation description itself is not very comprehensive, and seems hard to reproduce without access to the source code.<BRK>The paper deals with the prediction of 3D Lagrangian Fluid Simulations. I could imagine that the method would fail. Therefore I would rather vote for a reject.<BRK>The reason for that is mainly the evaluation, which uses very limited data (number of scenes, sequence length, variety) and is not very convincing.
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 6. <BRK>Summary  This paper proposed a problem in algorithmic fairness where labeled examples for some demographic groups are completely missing in the training dataset and still the goal is to make predictions that satisfy parity based fairness constraints. In the case where a dataset has *zero* labeled examples for some demographic groups, this is such an extreme situation that it is a clear red flag that there is a large bias in the collection process and/or the data collection design was poorly done what is the justification for continuing to use this dataset as is? Is there any real life scenario where one is forced to use this problematic dataset (this could be irresponsible, even unethical), instead of trying to get labels for the "context set" (which is assumed to be available!) It also does not explain why the paper s method (to massage a clearly problematic dataset) is any less unfair. The paper also does not cite some related work on algorithmic fairness with missing demographics, e.g.Recovering from Biased Data: Can Fairness Constraints Improve Accuracy? Clarity  The lack of theoretical guarantees for the algorithm makes it unclear what assumptions are needed for the algorithm to do something meaningful in  rectifying  the extremely large missing pieces in the original training dataset. Since the clusters are not explicitly named (i.e.no labels), how is this a "perfect dataset", defined as one where the labels y and group s are independent?<BRK>#SummaryThis paper studies zero shot fairness where the demographic information is partially unavailable, but assuming the existence of a context dataset that contains all labels x all demographics (including the invisible). The paper proposes a disentanglement algorithm that separates information of the label and demographics, under two zero shot settings: 1) learning with partial outcomes: both labels and both demographics are available, but for one of the demographics only negative outcome is present; 2) learning with missing demographics: one of the demographics is completely missing. The paper is clearly presented, with careful analysis over each of the proposed component, with proper ablation studies. #Cons  The biggest concern I have is the clustering part of the context set into a perfect set. This seems to be a prerequisite for the disentangle algorithm to perform well. However, there is no guarantee over the clustering quality, and this is partially reflected in the experiments (table 1 & 2) as well. In addition, how does the distribution of the label x demographics on the context dataset affect clustering quality? The experimental results seem to present different trade offs for the proposed approaches. There doesn t seem to be a single algorithm that has a clear better performance compared to the baselines. Or, what if I have a context set, but some of the quadrants are also missing, and even worse, the missing quadrants are different from the ones missing in training? #Over recommendationI think this paper studies a very interesting problem but some further analysis, e.g., how the distribution over the context data affects the results, and how to make the algorithm work reliably better in practice, is needed. Overall I think this is a borderline paper.<BRK>The authors also show that even if the context dataset is not perfect, the presented method successes to mitigate an unfair bias. The strong points of this paper are as follows:  This paper introduces a potentially interesting problem, the invisible demographic. The weak points of this paper are as follows:  The experimental results have a high variance. It involves not only the target data points but also unobserved data points available in the world. I cannot follow the description of the algorithm. My recommendation is rejection. Also, the proposed method is not well motivated, and its merit is unclear. I am very suspicious about the experimental results. The standard deviations for the fairness metrics shown in Table 1 and Table 2 are considerably high. It is a rare situation where records with a specific combination of the target class and demographic group are missing. Therefore, it is unclear that the proposed method has merits compared to the existing ones.<BRK>############# Summary of contributions ##############This paper introduces the problem of enforcing group based fairness for “invisible demographics,” which they define to be demographic categories that are not present in the training dataset. ############# Strengths ##############  The paper is organized well, and the problem of “invisible demographics” is described and motivated well using concrete examples. The architecture of the proposed method is documented clearly in Figure 2. Their architecture builds on state of the art techniques such as DeepSets (Zaheer et al.2017).Using DeepSets, the discriminator in their architecture estimates the probability that a given batch of samples, as a set, has been sampled from one distribution or the other. The authors do not provide any description of hyperparameters tuned, or any use of a validation set for hyperparameter tuning. The paper states an interesting and practically relevant problem of enforcing fairness with “invisible demographics.” The methodology is overall well documented, and the experimental baselines make sense. It would be interesting to see how the clustering techniques compare when the context set includes more than two protected categories, there is initial strong data imbalance between those groups, and the “invisible demographic” has relatively few data examples in the context set. Awasthi et al.Equalized odds postprocessing under imperfect group information.
Reject. rating score: 5. rating score: 5. rating score: 6. rating score: 8. <BRK>**Weak points**:My major problem with the paper is the seeming disparity between the models in the experimental comparison. A more fair comparison would be to take the NVAE architecture and apply techniques from *RAE* [2] / *2 stage VAE* [3] to it. As a result I bump by score to 5, but I think the paper still needs more work to make a sound argument for the proposed idea. **Conclusion**: the results presented in the paper are impressive and the quality of samples is indeed very high. It feels like the authors did overly focus on presenting a new method and have not given the prior work their best effort.<BRK>The main concerns are,* The idea is somewhat novel but very similar to ideas developed in  [1,2] and (Bauer & Mnih, 2019). While the results reported in [1] are not competitive to those reported in this work, it is probably be due to differences in model architecture. Therefore, a fair comparison to prior works [1,2] and (Bauer & Mnih, 2019) is required using a common model architecture. The paper should qualitative demonstrate that NCP leads to reduction in the number of "corrupted" images. To do this one possibility would be to demonstrate that the worst sample image in a batch from the NCP approach is on average significantly better than that from the plain NVAE approach.<BRK>Prior approaches have overcome this problem by increasing the expressivity of the prior through autoregressive models, and/or using hierarchical latents, EBMs with MCMC sampling. The authors combine this approach with the use of hierarchical latents and produce really good performing generative models on a host of benchmarks with good looking samples. Post Rebuttal:I believe the positioning of the paper could be improved but at the same time empirical results in the paper are strong. I am adjusting my score to 6 with a confidence of 4.<BRK>**GENERAL**The goal of the paper is to model the marginal over latents in VAEs in such a way to minimize the mismatch with the aggregated posterior. However, the FID scores and the quality of generated images are very convincing. **Deficiencies:**D1: In this review, I kept using "a non trainable expert" or "a non trainable marginal" for the base prior (the term used by the authors). In my opinion, it is an interesting connection. It would be easier for a reader, if this information was included in the text. **AFTER REBUTTAL**I would like to thank the authors for their rebuttal and all updates. I appreciate all new results and discussions. R2: Section 3, first paragraph: The authors stated that: "Recently, energy based models have shown promising results in representing complex distributions".
Reject. rating score: 5. rating score: 5. rating score: 6. <BRK>In this paper, the adversarial training is reformulated as a combination of stationary distribution exploring, sampling, and training. A Hamiltonian system is proposed to model data samples from their initial states, and is shown as the general form of FGSM. The sample generation method is proposed via contrastive divergence with few training iterations. Experiments have been validated on datasets. The FGSM/PGD based attacks are formulated as the degeneration of HMC, as explained in Sec.4.2.However, the experiments on the benchmarks consistently indicate PGD performs better than the proposed method ATCD. As ATCD utilizes a more advanced HMC, there lacks explanations of why the results do not correspond to the theory. 2.The proposed ATCD is claimed to efficiently generate adversarial examples while the performance seems to suffer from limited iterations. Is it possible to increase the iterations of ATCD for performance improvement? 3.As the efficiency is claimed as a major contribution of ATCD, the computational complexity and time cost compared to other methods (e.g., FGSM, PGD) shall be reported as well.<BRK>Summary: In this paper, the authors reformulated the generation of adversarial examples as an MCMC process and present a new adversarial learning method called ATCD, which approaches the equilibrium distribution of adversarial examples with only a few iterations by building from small modifications of the standard Contrastive Divergence. Extensive results with comparisons on various datasets show that ATCD achieves a trade off between efficiency and accuracy in adversarial training. The proposed algorithm ATCD views the generation of adversarial examples as a sampling procedure. Specifically, it can be seen as performing HMC sampling. Also, it modifies the adversarial example generation objectives using a modified contrastive divergence objective. The different objectives or the sampling noise? 2 .In Eq (13) what is Q0 and Q1? Here since the equilibrium distribution is unknown (fixed but unknown right?), how to compute the objective here with rho and lambda parameters? And why using different rho and lambda helps? 3 .Notice that even adversarial training based algorithms could cause obfuscated gradient problem, therefore, it might be a good idea to further evaluate model robustness via totally gradient free methods, such as hard label attacks. I would suggest the authors to also evaluate using the following method: “RayS: A Ray Searching Method for Hard label Adversarial Attack” KDD (2020)In order to make the experimental results more convincing. ICLR (2019). "On the Convergence and Robustness of Adversarial Training."<BRK>Summary:This paper proposed a new adversarial attack method by using Markov chain Monte Carlo. The experimental results demonstrated the effectiveness of ATCD. 2.Experimental results with comparisons on ImageNet, CIFAR and MNIST datasets show that ATCD achieves a good trade off between efficiency and accuracy in adversarial training. Nature accuracy and robust accuracy are sometimes conflicted in the latter epochs. It seems like some plots like Figure 3 may answer the question, but Figure 3 only plots the first 40 iterations (I guess it means  epochs  here), while the total epoch is 105. So only observe the results of the last epoch may not fair since maybe different methods have different convergence rates. 2.Some hyperparameter settings and sensitive analyses like $\rho$ and $\lambda$ are missing. 3.Although, the experimental results show the efficiency of ATCD, the formal time complexity analysis of ATCD should be performed.
Reject. rating score: 3. rating score: 4. rating score: 5. rating score: 5. <BRK>The authors only compare their results with a model that works with a random baseline, and it s not convincing. It believes that the disentanglement of beta VAEs comes from the local PCAs, which coincides with global coordinate alignments, and this strange behavior stems from the assumption of diagonal posterior. Thus the global representation of beta VAEs is sensitive to local changes.<BRK>The authors do not demonstrate how a method that could decorrelate the added noise signal from the original dataset would have any further benefits.<BRK>The work, therefore, does seem to have merit. How is $c_j$ selected from the set $\{1,2,3,4\}$.<BRK>Could you please unpack it? So perhaps the authors mean to indict mainstream definitions/expectations of disentanglement instead? Results from varying the regularization hyperparameters.
Accept (Spotlight). rating score: 8. rating score: 8. rating score: 8. rating score: 4. <BRK>The paper presents a linear time and space attention mechanism based on random features to approximate the softmax. The difference between theoretical speed up and experimental speed up is honestly discussed, and the overhead of the random features is not swept under the rug. I had read "Rethinking Attention with Performers" when I reviewed this paper, and I originally thought it was the same paper, but (along with notation being different) they start to differ on page 3.<BRK>Nowadays, some people are still staying away from attention because of its quadratic time and space complexity. This is quite impressive. Based on my experience the Linear Attention with ELU non linearity can bearly match the performance of the original attention mechanism. The authors provide several in depth analyses in the appendix. I like the experiments in C.2. It is nice to see that the authors confess that the training is actually increased when using the RFA compared to the original Transformer.<BRK>Summary* This paper proposes a linear time and space attention variant that matches (or exceeds) the accuracy of standard attention while maintaining the speedup of prior work in linear time/space attention. Weaknesses*  The improved accuracy and speed over the baseline transformer are great, and the experiments serve to nicely illustrate those independently. al [1] underperforms softmax attention, while this work gets comparable performance by changing the kernel. * Extension of RFA with a gating mechanism appears to be effective, but I do not believe the claim that it is hard to apply this to softmax attention is valid, leaving the main contribution an exploration of a couple different kernels for linear attention.<BRK>Original Attention is O(M^2 d). I think the story starts with pointing out the importance for long sequence but turns to the topic on short sequencewhich is confusing. 6.Time analysis on language modeling is not presented. 3.Is the speedup over total computational time or just the attention part? Specifically, is thereany feed forward computation involved and how many layers of the models used in comparison. The latter is typically used in two different ways in the transformer architecture, each resulting in a different computation for RFis confusing as the RFA is now redefined. Is this correct? I think I d like to see a discussion ofsufficient number D analytically or empirically.
Reject. rating score: 3. rating score: 4. rating score: 5. rating score: 7. <BRK>Therefore, the effectiveness and generalizability of the proposed approach are not clear. The paper also describes various log related applications based on the proposed log representation.<BRK>3.There is little discussion about the results of the experiments. 2.It seems that the paper just applies the Transformer model to the log representation task and there is no comparison between the proposed method and other log representation methods in the evaluation part.<BRK>Most of the log entries consist of a set of key words (presented in a readable format) and some arguments (can be numeric). The usefulness of log embeddings are shown on multiple log downstream tasks. 1.The technical contribution of the paper is very limited.<BRK>Weak points:  The levels of abstraction could have been connected more clearly with the transformer model and the log processing applications in the experimental part. Strong points:  The paper is well written.
Accept (Poster). rating score: 7. rating score: 7. rating score: 7. rating score: 4. <BRK>Overall, this paper is very interesting to read. The idea of refining the noisy image iteratively is reasonable, which makes the image content for training progressively better. There are still some areas that it could improve:1. Although it improves the PSNR, the motivation is not clear. This should be discussed. Proceedings of the IEEE International Conference on Computer Vision. 2019.3.It would be great to have natural images in the experiments to validate the idea. In particular, showing that the proposed method can reduce and noise and reveal more image content and texture. "Benchmarking denoising algorithms with real photographs." 2017.4.It is good to have a table or flowchart about the iteratively training, to make the paper easier to read.<BRK>This paper addresses a challenging task of blind image denoising where a single noisy image is provided with assumption that it is zero mean, additive and independent from the original image content. N2N or deterministic training needs explicit or implicit knowledge of clean image in order to be trained whereas the GAN2GAN method does not, leading to more realistic and efficient training. For blind denoising, this work produces impressive results for synthetic and real world blind denoising. The experiments were done with extensive datasets and baselines. Although the paper is solid, I am not sure how this work compares to well known algorithms for blind image denoising:  Residual Dense Network for Image Restoration  High Quality Self Supervised Deep Image Denoising  CycleISP: Real Image Restoration via Improved Data Synthesis  Real Image Denoising with Feature Attentionjust to name a few. If the authors can provide comparisons or discussion, analysis on these algorithms and comparison, it would be helpful.<BRK>This paper proposes a framework to train a network to remove noises, which are zero mean, additive and independent of the clean image, with only noisy images and without knowing the noise statistics. The proposed framework can remove the noises from the input noisy image. Then, it adds simulated noises into the denoised image to generate a pair of images and train the next network to further remove noises and it does this process iteratively. The experimental results show that the proposed method has good performance under simulated Gaussian noises as well as WT and CT datasets. I have several concerns and suggestions for this paper:(1) One assumption of the proposed method is the noises and signal are independent which is not true for most of the scenarios. What the results will be if σ_0^2 is not large enough? Can the network still effectively remove noises if y<y_0 which means the residual noises are not significant in the images? (10) For a fair comparison,  do the two N2C networks have the same network structure?<BRK>Learning denoised network from noisy images has been developed by Krull et al., 2019; Batson& Royer, 2019; Laine et al., 2019. The main difference is the use of generative learning. If so, the contribution of the paper is limited. It is not clear whether the performance gains are due to use such larger capacity models or not. For the real noise images, why do the authors evaluate the proposed method on the microscopy and medical images? How about the results on the real world natural noisy images?
Reject. rating score: 3. rating score: 5. rating score: 7. rating score: 8. <BRK>This paper mainly deals with the theoretical support for the loss function meta learning and focuses on illustrating the generalization superiority of the TaylorGLO method [1]. Although the generalization performance is the core aspect of machine learning, I have several concerns as follows. 1.Since the TaylorGLO method [1] is also under review in ICLR 2021, I can not judge the value of this paper. But, what s the connection between the training dynamics and generalization, or what s the hypothesis between these two in this paper? 3. what do the theorems provided in this paper want to tell? I don t get the points that the authors want to tell. More intuitive explanations should be given followed by the theorem.<BRK>This approach is novel and interesting in that the loss function is also learned on data. The analysis of the TaylorGLO loss and another learned loss function Baikal loss near zero error reveals interesting properties of preventing overconfident predictions. The authors should include some discussions or illustration of the Baikal or TaylorGLO loss in this paper to make it more self contained. As a question for Section 5, does the condition in Theorem 3 guarantee the trainability of the TaylorGLO loss (sufficient condition)? Or there are potentially other constraints needed? Overall I believe this approach has merits in discovering new interesting functions for learning, followed by study of the loss function s properties by humans. But I am not convinced if we should directly use a learned loss function in training.<BRK>Summary:The paper addresses the setting of meta learning loss functions and in particular analyses the effect of the loss function on the entropy of the resulting learned function. In particular it shows that TaylorGLO learned functions tend to lead to higher entropic, and thus more regularized, neural networks, than when they are trained with the cross entropy loss. The paper also discusses that the property of high entropy predictions can lead to better robustness against adversarial attacks. The result from Theorem 2 is to me weak in the sense that by itself it does not give any intuition in what is important for a loss function to reduce entropy, and what is important for the magnitude of it. For me both Theorem 1 and 2 rely too much on intuition, or are  not attractors  and  strength of entropy reduction  well defined terms? The results in Table 1 are essentially the same after adding the invariant, the experiment is not convincing to me. (I understand that this is not the point of the paper, but to me that would be still an interesting comparison)<BRK>They provide analysis of the attractor states under the optimization of a suite of loss functions. They can also make non differentiable feedback differentiable. The choice of adversarial attack robustness to demonstrate the value of optimizing the loss function for an alternate metric is a sound one. The differences in attractor dynamics are dramatic (but also are less surprising). Table 1’s invariance results are clearly presented. I would like to have seen a measure of meta training stability or consistency in addition to or instead of accuracy, backing the claim about improved stability moving with the evolution population size. But there the definition of zero training error itself is modified, and so their metric may not capture very similar optimization dynamics. The paper’s writing clarity is very good. The decompositions in section 3 are well factored. It appears that Theorem 4.2 basically describes label smoothing, though they don’t say this. Originality:One challenge with addressing the originality in the paper is understanding what novelty should be attributed here and what should be attributed to the original TaylorGLO paper. “Thus, values less than zero imply that entropy is increased, values greater than zero that it is decreased, and values equal to zero imply that there is no change.” Significance:One major question in this work concerns the generality of its findings. A typo on page 6! The method’s added complexity makes the method unlikely to be used unless it can clearly differentiate itself from other regularizers.
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 7. <BRK>The paper shows that given a set of d patterns, there exists an assignment of GNN weight that fits this d pattern output, so there exist some assignments of weights to GNNs that cannot generalize to larger graphs. Based on the existence of a set of bad parameters, authors claim that GNNs will fail to size generalize. a) In the main result Corollary 3.3, authors claim that because there exists a weight assignment of GNN that cannot generalize to lager graphs given discrepancy on d pattern, then GNN will fail to generalize to larger graphs given d pattern discrepancy. The existence of a bad set of weight parameters does not imply training GNN will necessarily converge to this parameter. Self supervised training of GNNs is not new, the fact that pre training can improve robustness to larger graphs is also not new and have been shown in previous works. The pattern tree task is not significant either. Some references that demonstrate size generalization is a well known issue. Barrett et al 2018. Joshi et al 2020. Dai et al 2017.<BRK>This paper theoretically discusses the size generalization problem in GNNs. It introduces the concept of d patterns and shows how generalization is related to the distribution of d patterns. It is also not clear how the proposed method for improving size generalization is related to the theorem in Sec 3. Suppose we view each the prediction on each node as a single task, and the input is the d hop subgraph. The discussion in this paper does not reveal to be very relevant to the  size  of the graph. As pointed out in the author s response, some efforts are made to **experimentally** (1) demonstrate the effectiveness of the proposed method on a real dataset which might not be solvable by constant depth GNN, and (2) demonstrate in real datasets there is a discrepancy between the degrees of small and large graphs.<BRK>The paper considers the important problem of lack of generalization of GNNs to graphs whose sizes are much larger than the graphs on which they were trained on. The authors propose a theoretical explanation by arguing that this lack of generalization is due to a mismatch in the “d patterns” (essentially the pattern of neighborhood around nodes) between the training and test graphs. Understanding and improving size generalization in GNNs is an important and timely topic. While I do agree that a mismatch in the d pattern distribution can lead to poor generalization (Corollary 3.3 and Equation 1), there are a few aspects to this claim that I do not understand. As far as I understand, thm 3.2 says there exists a GNN that can predict the labels correctly for every p_j \in A^c.<BRK>The paper argues that the ability of constant depth GNNs to generalize is not dependent on the size difference, but on the difference in distributions of nodes  neighborhood features, which authors call "d patterns." The paper shows theoretically that a GNN can be trained to achieve zero loss on small graphs, yet fail to generalize to larger graphs and the loss on these graphs will be dependent on the difference in d pattern distributions. Strengths:* Shows strong theoretical and empirical evidence of GNNs inability to generalize to graphs larger than those seen in training when the distribution of d patterns of the graphs differ, showing that techniques like regularization will not help in these cases * Provides a first step to mitigate problem by using domain adaptation methods and in particular using an intermediate task of identifying the d patterns in each graph. 2.The focus of the work is on size generalization and in particular small to large graph domain shift. Is this the case, why or why not?
Reject. rating score: 5. rating score: 5. rating score: 6. rating score: 6. <BRK>### OverallAuthors used BERT alongside to a 2D position embedding based on a sinusoidal function and a graph based decoder to improve performance on document information extraction tasks. * Pre trained models could be useful. It is hard to tell what are the standalone contributions of the paper, and what is coming from other works. Authors could have provided more in depth details (visualizations, analysis, examples) to show main differences between the proposed approach and baselines (specially LayoutLM). * In the abstract, authors say "BROS utilizes a powerful graph based decoder that can capture the relation between text segment"* Though in the text such a component (that is from other work) is only mentioned twice without further detail. (I assumed authors used the same strategy as LayoutLM). What is the impact of a good OCR for training and testing (prediction of new, unseen documents)? * In the results section there is a typo: *"performances with a large margins of 2.32pp in"*.<BRK>The paper proposes the pre trained language model BROS which aims to leverage both text and spatial information to improve information extraction on documents. However, the area masking strategy does not show significant improvement over the LayoutLM and the graph decoder is proposed in SPADE which is not new. Pros 	The paper introduces the area masking pre training strategy that can be seen as a natural generalization of masking language model in the 2D plane. BROS utilizes the graph based decoder from SPADE and improves performance on downstream tasks. I do not think it is qualified for the ICLR conference.<BRK>Summary:The paper provides a novel pretrained language model for document understanding named BROS, which adds spatial layout information and new area masking strategy. I deem that the pre trained language model based on BERT that encodes spatial information is useful for 2D document. The paper addresses siome limitations which are very important for document understanding: spatial information, spatialrelation, and the information of text blocks. 2.This paper provides comprehensive experiments, including both qualitative analysis and quantitative results, to show the effectiveness of the proposed model. It would be more convincing if the authors can provide more cases in the rebuttal period.<BRK>> Summary: The paper studies the problem of large scale pre training for semi structured documents. It proposes a new pre training strategy called BERT relying on Spatiality (BROS) with area masking and utilizes a graph based decoder to capture the semantic relation between text blocks to alleviate the serialization problem of LayoutLM. BROS could achieve robust and consistent performances across all the four permuted version datasets, which demonstrates that BROS is adaptive to documents from the practical scenarios. > Major concerns:  For Section 3.2, the author didn’t even provide the pre training objective for the area masked language model. I’m not so clear about the function of $\mathbf{t}^{ntc}$. Do the authors agree with my conjecture?
Reject. rating score: 2. rating score: 3. rating score: 4. rating score: 4. <BRK>We give below some elements to help the authors in increasing the relevance of their work and paper. The introduction is too long, describing many elements that are not necessary for the paper. The authors focus on the fact that other methods are sensitive to initialization and they may converge to local optimum. This doesn’t mean that it is independent of the initialization. As FastICA sometimes outperforms all the other methods, this means that the proposed method should provide better results that FastICA throughout iterations, because the optimization problem is supposed to be convex and it converges to the global optimum; However, this means that the method depends on the initialization. This means that it converges to an optimum that is not a globale one, as FastICA converges to better optimum solution.<BRK>This work still needs a significant revision and, in my opinion, cannot be accepted in its current form. The ICLR submission is similar to the earlier one, hence the similar (but updated) review. The log linear model models a discrete probability distribution of ordered events. As such the authors introduce a specific ordering for BSS that I failed to understand. what is an s ? what is the intuition behind (1) ? What are the assumptions about the sources and mixtures ? 3) The experiments consider artificial mixture of images and artificial mixtures of synthetical signals with little practical significance. 4) The introduction of the paper could be improved as it seems to reveal some misconceptions about blind source separation (BSS).<BRK>______________________________________________________________________________This paper uses an information geometry based model to perform blind source separation. The problem is definitely significant and should be of interest to conference attendees. Pros:IGBSS, the proposed approach, has many advantages such as convexity and potential nonlinearity allowing it to adapt to nonlinear mixing effects. Only a few experiments are performed. At the bottom of page 3, it s stated that the partial ordering allows for higher order interactions. Other comments:In Table 1, FastICA performs best wrt RMSE in experiment 2 with third order interactions and wrt SNR in experiment 2 with second order interactions. The authors should fix this.<BRK>##########################################################################Reasons for score:  This is a complete work. The idea of formulating blind source separation as statistical estimation in a log linear model seems to be novel. ##########################################################################Cons:  1. The main argument supporting the proposed algorithm is that non convex optimization is bad and convex optimization is good. This is in general not true. The introduction to the log linear model and natural gradient descent is quite long but not very readable to a non expert in the two topics.
Accept (Poster). rating score: 7. rating score: 7. rating score: 7. rating score: 6. <BRK>4.The paper is well written and easy to follow. The use of data flow as additional input and the proposal of structure aware tasks are well motivated adaptations of pre training to code.<BRK>* What is the ratio of edge connection? * They propose two pre training tasks for learning representation from source code and data flow.<BRK>This paper extends CodeBERT to include elements of dataflow inaddition to the comments and sequence of code tokens. It  appears to me that it s a slightly simplified version based on AST  and some idea of data flow. Detailed comments:  In general the paper is well written.<BRK>This paper proposes GraphCodeBERT as a Transformer based pretrained model for programming language that incorporates data flow information in the graph representation of variables in the code. I don t think BLEU is a meaningful metric for code translation and code refinement, and it can be misleading.
Reject. rating score: 4. rating score: 5. rating score: 6. rating score: 7. <BRK>The results also apply to neural networks in the NTK regime. (2020) using RKHS and Eluder dimension techniques. A discussion of power law spectral decay would definitely improve the quality of the paper.<BRK>2.The proofs seem to be correct. While the paper is a logical extension of some prior work, I am not convinced of the usefulness of the setting or algorithm proposed.<BRK>An \sqrt{T} regret bound of the proposed algorithm is obtained. Overall, this paper is very well written, the problem is well motivated, and the claims and proofs looks solid.<BRK>If this is the case, can the Q function be solved exactly? While the algorithm itself is neat and clean, the paragraph describing its implementation is not very rigorous. If I understand correctly, there is no assumption about the structure of Q function in this paper.
Reject. rating score: 3. rating score: 4. rating score: 4. rating score: 6. <BRK>This paper considers the problem of secure aggregation for federated learning, where the goal is to design a protocol that allows the server to aggregate models from clients without learning anything about any individual model. However, I still think the paper lacks the mathematical rigor required for a theoretical security/privacy paper. The main idea is to use a sparse random graph as a communication graph as opposed to the complete graph used by (Bonawitz et al., 2017). Some of my queries were clarified. As an example, for the same threat model in the paper, it is not clear if (Bell et al., 2020) would need the strong assumption on dropouts. (a) In Definition 2, the eavesdropper model (or threat model) has not been properly defined. The proof is not rigorous (partially due to the ill defined privacy requirement). (c) Sufficient details are not provided in experiments. (https://eprint.iacr.org/2020/704)Even if one considers CCESA as a parallel and independent work, it will be helpful to acknowledge the above paper.<BRK>This paper proposes a secure (or private) algorithm that is communication and computationally efficient for the purpose of federated learning. The main idea is to allow each client to share its public keys and shares them secretly with a subset of its clients. The main theoretical contribution is potentially useful. Consequently, the analysis leading to Theorems 3 and 4 are overly simplified and the insights on p^* may not carry over to real world settings. If p is only slightly above p^*, this small error probability is unlikely to materialize. Thus, the discussion here is weak. This leads me to think that there is a great deal of looseness in the analyses.<BRK>This paper proposes an efficiency improvement on the "secure aggregation" (called SA in this paper) protocol of Bonawitz et al.For context: the SA protocol allows a group of clients holding secret values to compute the sum of their values with the help of a reliable server. The main issue is the security argument, which is not properly developed (and not obviously correct). membership attacks use only the final trained model (or even just its outputs)—hiding the intermediate gradients doesn t help. This would allow for clear and refutable claims, and a clear discussion of the new protocols limitations. See, for example, this paper for discussion: https://eprint.iacr.org/2018/997* The idea of replacing the complete graph with a low degree expander to save communication has been used elsewhere.<BRK>Summary: The paper proposes a secure aggregation framework for federated learning that is communication computation efficient. My biggest concern is the novelty of the paper, which seems to be not significant. Specifically, the proposed algorithm s main contribution is generalizing the existing secure aggregation framework (Bonawitz et al., 2017) from the complete assignment graph to an arbitrary graph. The only modification is on the assignment graph, while the framework itself is still the same as (Bonawitz et al., 2017). Moreover, the idea of limiting communications over a lidistributed learning over the Erdos Renyi random graph has been studied and analyzed extensively in the literature.
Reject. rating score: 3. rating score: 4. rating score: 4. rating score: 6. <BRK># Summary of ContributionsThe paper proposes a formalization for one aspect of what makes adversarial examples suspicious, positing that visible perturbations to the foreground arouse more suspicion. Based on this proposed threat model the paper proposes the dual perturbation attack, which perturbs the image with small perturbations in the foreground and larger perturbations in the background, with the background and foreground distinguished either by a provided mask or the DeepGaze II model, while maintaining a low saliency score in the background. However, the fact that the attacks succeed is not really meaningful, as the models attacked are _not_ trained to be robust against the magnitude of attacks applied. Having a significant proportion of samples vulnerable to PGD attack are also vulnerable to the dual perturbation attack would be a convincing demonstration that the dual perturbation attack is a strong attack (specifically, that perturbations primarily in the background are sufficient to change the classification of these images).<BRK>The authors propose to use recent work from DeepGazeII to detect saliencies of various pixels. In terms of the main problem looked at in the paper, I am not convinced that it is well defined. If that is the case, then the comparison between the attacks need to be fair and I think this point about fairness of comparison need to emphasized as it is slightly confusing. However, the problem is essentially $\ell_2 $ or $\ell_\infty$ balls on some subsets of the pixels. More generally using the same model to measure saliency as well as to construct adversarial attacks is not properly justified and secondly, I am not convinced that putting a large perturbation on the "background" as determined as DeepGaze  is a proper side by side comparison with AT where AT is allowed  much smaller perturbation.<BRK>In fact, the core contribution of our paper is to address this issue. However, most of the results (Figures 4 and 5) seem to show that models are much more robust against dual perturbation attacks when trained with dual perturbation samples. The results shown in the appendix, especially for transferability, are similarly marginal (compared against the AT PGD model, which is the only other  robust  model the authors test against). It is strange, but not suspicious. Secondly, the relation to physical attacks is not clear. The authors point to physical attacks as both a motivation for studying adversarial samples in general, and also for the distinction between foreground and background. only work from one very specific angle! Here are some other minor comments that I hope the authors will find useful:   Better clarity on the form of the adversary s utility function in (1) would be helpful.<BRK>The rest of this review is separated into comments which I would be happy to discuss with the authors, and other minor aspects that the authors can take into account in their revision. Is this a limitation of the the DeepGaze model or some other aspect of the approach? However, I believe this setting is not any more difficult than the standard PGD attack: since the perturbation is separated into disjoint foreground and background pixels, the projection is exactly equivalent to the standard projection over each set. Upon looking at the algorithm in the Appendix, this is exactly what is done by the authors. 3.The presentation of the claims of improvement in standard adversarial robust accuracy are somewhat misleading. Among these, Cohen et al 2019 is listed. However, this is not adversarial training; Cohen et al 2019 is a certified defense with guarantees, and is quite distinct from the adversarial training paradigm described in the text.
Reject. rating score: 4. rating score: 4. rating score: 5. <BRK>The paper proposes to communicate predicted local states between neighboring agents to address the problem of delayed information in networked multi agent reinforcement learning. + The idea of communicating predicted local states is interesting and could mitigate the problem of delayed information.<BRK>To reduce the delay of global information, the authors propose an imagination module to predict future information for communication. The agent predicts its future state and shares that with its neighbors. The information delay is an important problem in real world applications.<BRK>##########################################################################Summary: The paper provides an interesting way to add structure to MARL problems that have delay in the communication of state information. This is a good problem to study and a useful add on to existing work studying communication architectures in MARL settings. #########################################################################Things that would improve readability:  What does it mean to share the policy with the agents around you?
Reject. rating score: 3. rating score: 4. rating score: 7. rating score: 7. <BRK>The authors of this manuscript propose an unsupervised learning framework for 3D segmentation of biomedical images. This work conducts experiments on toy dataset, the Brain Tumor Segmentation dataset, and cryo EM data. The experiment demonstrates competitive performance of the proposed method. The idea of hyperbolic 3D convolutional VAE is interesting. The paper will be more clear if the authors could further polish the manuscript. It would be better if the authors could elaborate the novelty of the proposed model. 3.The biologically inspired toy dataset does not look close to a biomedical dataset. It will be better if the authors could select some of the state of the art unsupervised 3D segmentation methods as baselines.<BRK>Overall, the unsupervised 3D segmentation task tackles one major pain point of the medical imaging field, where the professional annotation is hard and expensive to obtain. This work adopts 3D VAE to map 3D patches into a hyperbolic latent space, then apply clustering followed by the Hungarian algorithm to finish the segmentation task. Though with merits on the introduced hyperbolic space and the gyroplane conv, I have the following concerns and questions.<BRK>The paper considers learning hyperbolic representations for unsupervised 3D segmentation. Since the approach is used in the unsupervised setup, how are hyperparameters tuned? This needs clarification. However, it is known that hyperbolic representations perform better than Euclidean representations to representation trees in low dimensional space. Could we have an ablation study of the impact of higher dimensions for both hyperbolic and Euclidean representations? In conclusion, I think that the paper is interesting, but needs some clarifications.<BRK>Practical advances in unsupervised labeling are a welcome addition to application areas relying on 3D segmentation. This paper is able to exploit the recently developed approach to hyperbolic convolutions in a variational autoencoder training with a simple addition of a hierarchical triplet loss. Notably, this simple idea leads to performance improvements over other existing unsupervised or self supervised methods. # Weaknesses and commentsThe limited technical novelty of the contribution, as most of the innovations are although recent but already published elsewhere.
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 7. <BRK>I agree, but that does not mean we cannot look at the combined change of $\beta$ and $\gamma$. I m interpreting this as the change in the parameters $\gamma$, which are part of the overall parameter vector, $\theta   (\gamma, \beta)$. **Original Review**This paper is focused on understanding whether a model fitted model is going to have out of distribution issues. The clarity of the writing is also an issue.<BRK>All the IRM based methods rely on some type of signal from the training data to train a good OoD model. or does one have to rely on some new measures to estimate the out of distribution performance of the model. Clarity: The writing of the paper is average. However, it is not clear why would one do that for REx. have already established this point. Hence, breaking down the predictor in the context of REx and analyzing the influence on the classifier does not make sense.<BRK>**MAIN CONTRIBUTION**: The authors propose an influence function based index to determine how well the model will generalize to OOD samples and whether OOD methods are needed in the first place. I consider, in particular, the lack of “the robust learning objective” important. Main reason: While I find the paper interesting and the line of inquiry promising, I believe it is not yet ready for publication, especially due to the weakness of the experiments section. (PAIR) 2.**Lack of benchmark OOD generalization diagnostics**: Are there other papers out there that try to quantify how well a model will generalize to OOD samples?<BRK>Summary:     This paper tries to understand the following question   a) Given a set of environments   when would we expect an ERM solution to be completely bad in the out of distribution (OOD) generalization sense. b) Given a trained model, how can we certify that the model is good in an OOD sense when we dont have access to a new environment. Only in the colored MNIST experiments this becomes clear.
Accept (Poster). rating score: 8. rating score: 7. rating score: 5. rating score: 5. <BRK>Experiments demonstrate that this can be used for tasks such as image composition, image completion, attribute modification, and multimodal image editing. The method is simple and effective, the results are impressive, the experiments are thorough, and the paper is very well written and easy to follow. This is a clear accept in my view. **AFTER REBUTTAL**After reading the other review s and the author responses, my opinion is unchanged: This is a well written paper with a simple and effective method, and a clear accept.<BRK>I like this paper and I think it represents a very through provoking and promising idea. Yeah, ok so you added a mask? But what does that _mean_? ICLR (and other conferences) should consider going to 10 pages with some “length must be proportional to the contribution” clause, because papers like this would be faster to write AND read if they were a bit longer. As an official reviewer I will read the supplement, but most others will not. Sec 4.4 / Fig.7 were very interesting for me, so please let those stay :) As a summary, I find the idea clearly described, interesting, and likely to have many applications in future. The evaluation could certainly be better and the difference to earlier mask based methods more clear. Sec 4.4: Most of the time “c” is called component, but at least once it’s a “segment” instead.<BRK>As a point of clarity, it is not always clear which experiments use generated images and which use real images. I m worried about regressing to W+ latent space with the StyleGAN variants. This would presumably make the composites also retain all their artifacts instead of falling on the manifold of generated images. The imperfect nature of the regression network seems to be necessary for the image manipulation to succeed, but this is not addressed or analyzed in the paper. In one direction the image quality falls, and in the other direction the amount of control falls. It is unclear if there is a sweet spot where both are good, and the examples in the paper do not convince me that there is. Overall the retaining of context does not seem to be very good.<BRK>In this paper, the authors propose a latent space regression method for analyzing and manipulating the latent space of pre trained GAN models. This paper addresses an interesting problem of manipulating the latent space of pre trained GANs. As can be seen in image completion in Fig.1, the contents in the inverted image are perceptually different from the input. Based on it, technical novelty of this paper is significantly limited and I could not find the discussion about it in this paper. The authors discuss about image inversion methods (GAN prior methods such as [1]), but did not compare them. State of the art works need to be compared to verify the effectiveness of the proposed method. Thus, I do not change my rating.
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 6. rating score: 6. <BRK>__Summary__A "quantum deformed" generalization of a probabilistic binary neural network is introduced, which can be either run on a quantum computer or (for certain simplified cases) simulated with a classical computer. __Strengths__The fusion of primitives from quantum computing with a variational Bayesian framework is interesting, and seems like a promising general means of leveraging the complementary strengths of ML and quantum computing. The MNIST and Fashion MNIST experiments are rather weak, with the only baseline being the closely related model of [1]. However, quantum supremacy experiments are not designed to be useful for real world problems (see [4] for a detailed discussion regarding this point).<BRK>The authors define a quantum version of a binary neural network (all weights and activations are 0 or 1) by first defining a classical stochastic generalization and then upgrading the stochastic part to a quantum process. The quantum network is simulated on MNIST and Fashion MNIST. The quantum network shows improvements in test accuracy, but those improvements are attributed to increased parameterization. For that reason, I cannot recommend this paper for acceptance. 2) By the same token, is there any benefit from using the quantum deformed model over the classical stochastic model?<BRK>The main point in the author s rebuttal is that the major contribution of the paper is a novel QNN that can be efficiently simulated. However, the proposed method of simulation is only an approximation of the real run through CLT. The author provided some conceptual justification of this approximation but there is no numerical verification. The approximation can be inaccurate when the variables in the summation are correlated or the number of variables is small. It also presents a training method that can be run on a classical computer, based on efficient simulation of specific quantum circuits and approximated computation of the distribution of the activations. Compared with the classical stochastic binary neural network, the quantum realization may perform efficient "deformation", which creates correlations among the input activations and the weights. This model also looks to be new. 3.It is not clear why a modification as in Section 3.3 is needed for classical simulation. Significance:In the experiment session, it is reported that the performance on MNIST is better with deformation than without it.<BRK>Combining the complex amplitude and binary neural network the author introduces a new class of quantum neural networks which are the generalized probabilistic neural network. By creating entanglement between the activation and weights they show that this new form of DQNN can be simulated on classical computers for certain classes of problems that hold low entanglement. As a numerical experiment they show modest gain in accuracy on real world data both MNIST and fashion MNITS data. It probably would be disadvantages compare to the QNN in Farhi s paper. 4.Also, while the tensor network enjoys a concrete parametrization of entanglement with the bond dimension, it s less clear for me how they can tune the entanglement within their formalism. 5.The authors have multiple referral to exponential advantage (or quantum supremacy) in quantum computers which are either incorrect or at least misleading in this context. The authors conclusion about limited advantage of quantum inspired deformed neural networks is not correct as it could be simply explained by the over parametrization of deformed model<BRK>The fundamental idea in this paper is to endow classical signals with a complex Hilberspace structure so as to harness the probabilistic nature of quantum mechaniscs for pattern recognition based on quantum computing principles. Experiments with image data corroborate this claim and demonstrate that simulations of the proposed quantum deformation showed improved accuracies when compared to  classical probabilistic binary neural networks. Overall, the paper presents an interesting approach towards quantum computational intelligence which, though likely not yet realizable on real quantum hardware (due to technical limitations such as measurement noise or decoherence times) can also be simulated digitally (in an arguably elegant manner). However, there also are concerns regarding the  quality of this manuscript.
Reject. rating score: 5. rating score: 6. rating score: 6. rating score: 7. <BRK>The paper proposes the IMA model, a scalable model that learns modality importances and robust multimodal representations through a novel cross covariance based loss function. If not, the author should make a more clear explanation of the *importance network*. The text is quite hard to read, there are many places in the paper that are not explained clearly, especially the related work.<BRK>In this paper, the authors are motivated by two properties that are often missing from multi view or multimodal algorithms, namely robustness to missing modalities at test time, as well as learning the relevance of modality/samples to the so called shared latent space in an unsupervised manner. This is done by a cross correlation loss that learns high importance when there is high correlation between modality/sample encodings and the shared latent space. The experimental results demonstrate that the importance mechanism improves results, at least for the specific datasets and experimental setting. >  The cross covariance loss function (and in general, soft orth constraints) have been used in the context of private shared space models (e.g., stemming from the classical Inter Battery Factor Analysis). In many ways, it would be interesting to review and link this literature with work dealing with discovering shared representations (e.g., Deep CCA, Andrew ICML 2013), as this work could potentially be considered an extension of these methods. > attention mechanisms are not mentioned in the paper, however Eq.1 is reminiscent of an attention mechanism. Could we consider this approach as a form of attention autoencoder, where the attention weight is used to indicate importance?<BRK>This paper presents a multimodal Autoencoder framework that learns the multimodal latent representations alongwith the importance of regions in each modality’s representation space in an unsupervised fashion. This paper presents an elegant importance based model and architecture that takes into account various local and joint loss functions along with alignment factors to represent the Autoencoder model. How would the performance be with missing modalities? Comparison to other Autoencoders: How does this compare to denoising Autoencoder? How does this compare to Wasserstein autoencoders and the variants such as the multimodal factorization model neural architecture? Figure 2: Any relationship or companion to self attention weights and word level importances   Number of network params compared to MVAE model that the authors have compared to?<BRK>Summary:This paper tackles the problem of multimodal representation learning by proposing an importance based multimodal autoencoder (IMA). The advantages of their proposed IMA are two folds: it is flexible to remove some modalities, as the loss function is easy to include any combination of observations; it allows to learn modality specific features along with the shared latent representations. 2.The idea is novel. They addressed the important problems of multimodal representation learning, which could have wide applications in multimedia, computer vision and speech/emotion recognition context. in the first stage, when the importance network is kept constant, does the network output a constant number (zero or one or other number)?
Accept (Poster). rating score: 8. rating score: 7. rating score: 6. <BRK>I m wondering if authors can provide some insights about why the proposed method can achieve better performance than CCT when they both include the consistency training and data augmentation in the designs. Inspire by recent success in the semi supervised learning (SSL), a novel calibrated fusion strategy is proposed to incorporate the concept of consistency training with data augmentation into the framework. Pro:+ The proposed one stage training framework is elegant compared with two stage methods in this area which include one step for pseudo label generation and another step for refinement then semantic segmentation training. It would be good to make this information clear in the table.<BRK>** SummaryThis work addresses the task of semi supervised learning (SSL) in semantic segmentation. Following recent SOTAs in SSL, this work also advocates for the use of pseudo labels on unlabeled data and heavy data augmentation. The main novelty of this work is the novel way to construct higher quality pseudo labels: besides the pixel wise classifier s probabilistic outputs, the authors leverage as well CAM based activation maps, named as SGC, as an additional pseudo label source. The authors conducted extensive experiments with lots of ablation studies to validate the proposed framework. May the authors produce a performance analysis over T? Why does the proposed method have an advantage there? More and more segmentation works report results in urban datasets like cityscapes or camvid. It would be interesting to see results on those datasets.<BRK>The authors use a Self attention Grad CAM (SGC) and segmenter to generate the pseudo labels during training. The paper is incremental and the proposed approach is a combination of a lot of existing approaches. But I also want to highlight that the experimental section is strong and detailed. The proposed method achieves good performance in the low data regime**Cons:**  The overall approach seems incremental because it is a combination of a lot of existing approaches and there is not a strong technical contribution. I think the related work section should be in the main paper instead of the supplementary.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. rating score: 5. <BRK>It is better to avoid this confusion. ##########################################################################Pro:+ The paper is clear and well organized. Zeng et al.Graph sampling based inductive learning method. + Extensive experiments are conducted to demonstrate the consistent state of the art performance of the proposed method.<BRK>The paper is well written with good clarity, while the proposed method is novel and significant to the research community. comprehensive experiments across multiple datasets, evaluating AdaGCN in terms of computational efficiency, accuracy, dependency on the number of layers. Questions  While comparing MixHop against AdaGCN, the authors mention that AdaGCN does have generalization guarantees from Boosting theory.<BRK>[2] It compared to the existing related work to illustrate the benefits of the proposed AdaGCN. Cons:[1] The simplified graph convolution might be vulnerable to the noisy nodes. That is, when there exists one noisy node with abnormal attributes, this simplified graph convolution might be significantly degraded. Thus, the higher order convolution in the proposed method might become worse. [3] In Section 4.3, it shows that Fast GCN has fastest speed in Pubmed, but slower than GCN on Cora ML and MS Academic datasets.<BRK>The objective of this paper is to design a deeper graph models in an efficient way for better performance. The computational efficiency and performance of the proposed algorithm are evaluated using the task of node property prediction on several public datasets. The performance of AdaGCN is slightly more robust than previous methods. 3.Some notations are confusing and misleading. It is better that the authors could include the time and memory complexity of each algorithm.
Reject. rating score: 5. rating score: 5. rating score: 6. rating score: 6. <BRK>Summary:The submission suggests a generative model with a normalizing flow based on a renormalization group idea. The experimental section is solid and I would consider increasing the score if the differences to previous work are made clearer. Comments:Does the choice of the temperature for the prior has a large influence on the learned features? Negatives:Similar flow architectures have been used before in different contexts (mostly physics) as also mentioned in the paper, but I feel that it is not so clear how the proposed normalizing flow model differs from previous work with a renormalisation group (NeuralRG).<BRK>## SummaryThe paper proposes a method, named as RG flow, which combines the ideas of Renormalization group (RG) and flow based models. +.The visualized receptive field of latent space representation shows meaningful semantics at different levels, which is verified on CelebA. It seems like a combination of existing methods, including Flow based methods, renormalization group and receptive field. Specially, compared with the style based generator[1,2], where the sparse prior distribution is enforced only in the input z latent space, I don’t find superiorities of the proposed method. Does it work on higher resolution? .There is no qualitative and quantitative evalution to compare the performance or show the improvement gained by the proposed method.<BRK>The paper proposes a new architecture for flow based generative models. The model imposes a hierarchical structure over information at different scales. The paper shows that the hierarchical structure results in disentangled features at different levels of abstractions. Some more background/examples of the renormalization group in physics / meaning of the disentangler/decimator would be helpful  There is no evaluation of the image inpainting performance.<BRK>Summary:The paper introduces an RG Flow model   a hierarchical flow model based on the idea of the renormalization group. Pros:  Novel and interesting idea. The proposed method allows for separating the features at different scales (at low, mid, and high levels) due to the hierarchical structure of the model. UPD: I am satisfied with the authors  response, and therefore I increase the score. Challenging common assumptions in the unsupervised learning of disentangled representations.
Reject. rating score: 5. rating score: 6. rating score: 6. rating score: 7. <BRK>In this paper, the authors present a federated continual learning framework. However, this cannot support the author that the proposed method can handle the negative transfer. I assume that this is top 5 attention results. Moreover, This figure shows that empirically, using attention can focus on more important tasks/features and this should not be in the main contribution, and this is a well known phenomenon. Decomposing the parameter parts are also interesting. **Strength**To my best knowledge, the problem setting is quite novel. Some parts of the methodology lack explanation and the experiment results cannot support all claims of the authors. This indicates different tasks have the same penalty. I do not see why this works since some tasks could be very similar to other tasks while some tasks are very distinct. In figure 6, it seems that hyperparameters are very sensitive. The plot of learned attention (Fig 5b).<BRK>Combination of federated learning and continual learning is a timely problem. Given the trending popularity of either of them it s the time to tackle this problem. The problem that is tackled is nice but the proposed formulation looks incremental. Why do one need to find A^i for a previous task and find a new parameter for that? Isn t that task already gone?Although, does this mean that the parameters to be estimated at each step is growing with the number of tasks? The experiments look overall good. However, the part that shows alleveriating catastrophic forgetting seems rather less elaborated. How many consecutive tasks does the proposed method handle? This works look like an increment on the top of (Yoon et al, 2020). Like making their approach adapted to a federated learning case. Thus, the contribution of the works is rather limited.<BRK>This paper investigates a new problem – federated continual learning by Federated Weighted Inter client Transfer. The experiment results in two contrived datasets demonstrate the effectiveness of the proposed method. Weakness:  The optimization procedure for Eq.(2) is not provided. The following are some questions that I concern. 1.The authors address the importance of federated continual learning from the aspect of continual learning, but is there any difference between federated continual learning and federated learning considering that most existing federated learning methods (fedavg and fedprox) are agnostic of client id? 4.For the training objective Eq.2, intuitively, authors propose decomposable parameters and want Base parameters B to be sparse with the help of task adaptive parameters A. However, it is interesting to see that there is no constraint to encourage B and A to focus on different aspects. The authors are encouraged to show that the base parameters (m*B) are more sparse than the model trained with existing federated methods with similar sparsity constraints.<BRK>The authors propose a federated continual learning setting where each node has a non iid stream and a different dataset. I would like further discussion on the differences to Yoon et al The results are good and evaluate a lot of  relevant factorsWeakness:  Although the setting proposed is interesting, certain aspects of it seem artificial: although it seems very relevant that each node is a different dataset, strong non iid behavior per node seems not realistic for many settings  What happens when some nodes start learning much earlier than others  A discussion of challenges in these settings and other potential methods  Results are shown for very simple LeNet architecture only  The algorithm proposed is interesting, but more motivation and other possible alternatives in this setting would improve the paper
Reject. rating score: 4. rating score: 5. rating score: 6. <BRK>Overall, the method is well motivated and the paper is easy to follow. * The improvements are within the range of variance as compared to SPOS. The only additional ingredients here seem to be (a) interleaving GCN with the data collection process in an online manner, and (b) weight sharing.<BRK>GOAL demonstrates superior performance compared to SoTAs. Also, how to decode the parameters back to the neural architecture discrete representation is not clearly explained in the paper. Second,  this method can work well for small models and small search spaces, but can be hardly applied to larger models. The evaluation on only NAS bench partially verifies the reviewers concerns. Second, compare a non graph neural network based approach with GOAL and show the necessity of using a graph neural network.<BRK>The authors address the Neural Architecture Search problem. This should nicely demonstrate where your main technical point is. The end of Sec 5.1: Currently $\tau$ cancels in the definition of $q$. The point seems to be that softmax with very low temperature reduces to a hard one hot vector but I do not understand how the authors use this precisely.
Reject. rating score: 5. rating score: 5. rating score: 6. rating score: 7. <BRK>##########################################################################Summary: This paper introduces a framework to utilize the synthetic data as augmentations in the scene graph generation task, which is able to narrow the domain gap by decomposing it into several discrepancies between the two domains. They are the first to propose the synthetic to real transfer learning for SGG. ##########################################################################Pros:+ The limitations (long tailed, noisy, and ambiguous) of the SG dataset have long been noticed in the SGG field. Yet, due to the high costs of collecting the SG dataset, it s hard to provide an ideal dataset for large scale SGG. This paper introduces a novel idea to augment the SG dataset through synthetic data and transfer learning, which may inspire the later researchers. It looks like the proposed method can only be applied to the dataset with limited scenarios. It s okay but lots of details are missing, which makes the audiences hard to follow, e.g., the details of GRL used in appearance discrepancy and prediction discrepancy. ##########################################################################Reasons for scores:This paper introduces an interesting direction to augment the scene graph learning, but the proposed method looks like it only works well on a few limited simple scenarios. If I was wrong, please kindly address my concerns above.<BRK>## SummaryThe paper tackles the problem of sim2real transfer for scene graph inference. **unclear focus**: the paper claims two seemingly orthogonal contributions: (1) applying sim2real transfer to the problem of scene graph inference and, (2) introducing an approach for modifying the training data distribution to better match the "real" test data distribution specifically for sim2real domain adaptation scenarios. Without a more detailed explanation it is hard to follow the discussion in the "Results" paragraph of section 4.3 that discusses the worse baseline performance. Further, the mentioned dataset sizes in the experimental section are confusing since the proposed method is continually re generating its synthetic training data which makes it unclear whether the comparison to baselines operating on a fixed dataset is fair. **no analysis experiments**: the experimental section lacks experiments/visualizations that give a more detailed analysis of the novel part of the proposed algorithm. (it anyways seems to be only used in one out of the three experiments, why only there?) In its current form it is not ready for acceptance.<BRK>The paper addresses the problem of learning scene graphs from synthetic data and unlabeled real data while performing well on real data by narrowing the content and appearance gap between the two domains when training on synthetic data. ### Strengths:[S1] The paper addresses a relevant problem: Learning from unlabeled data can be an important component in scaling vision systems to the real world. The authors do acknowledge this and put it in context. Nonetheless, it would strengthen the case for the paper if the authors could elaborate more on their expectations when encountering more challenging visual relationship data, either with more relations, more complex relations or more object types. What part of the method would need to be changed? Would I need to add something to the model? [W3] I would like to see more discussion on the limits of the proposed approach: What are the expectations on fundamental limitations, e.g.computationally or in terms of representation? As a main weakness of the submission, the presented evidence is largely on toy data or very domain specific ("autonomous driving"), however I do feel that there is sufficient contribution and insight.<BRK>The proposed paper introduces a novel approach for scene graph generation with a focus on bridging the domain gap between synthetic and real data. The proposed model learns the sim to real scene graph generation based on labeled synthetic data and unlabeled real data. Overall, this is an interesting paper that has everything going for it. The topic this work addresses is important from a computer vision, robotics, and computer graphics perspective, the method is technically sound, the results are promising, and the method is evaluated well. Moreover, the paper is well written and easy to follow. Therefore, I support accepting this work to ICLR. Currently, the work does not discuss any limitations. As is, it is not clear in which situations the method fails. I would encourage the authors to add a discussion on failure cases to the final version of the paper.
Reject. rating score: 3. rating score: 3. rating score: 4. rating score: 5. <BRK>I don t think this paper is good enough for acceptance. The writing. 2.The novelty. 4.Missing important literatures and comparisons. There are vast amount of work for learning representations on such graph. By applying the embedding to specific problems doesn t justify the method s superiority.<BRK>The second concern is about novelty. The main hypothesis of this paper is that different products of the same browsing session can be thought of as different augmentations of the same session. Overall, the paper is clear and easy to follow. However, I have a few concerns and questions for authors.<BRK>Experiments show that the unsupervised BYOL alone does not perform well in this setting. 2.Experiments empirically confirm the benefit of the proposed modification to the BYOL objective. The choices made in the paper should be explained and justified. 3.Experimental details are not clearly described. The nature of "some problems" should be clarified and possibly mentioned in the main paper. ### RecommendationI vote for rejection.<BRK>To overcome this, they had to add the category constraint, and their experiments prove that without it, the model becomes random. The input used in the paper of product title and category are usually widely available for such datasets. The concerns are detailed in the cons section and hopefully the authors can address my concerns in the rebuttal period.
Accept (Spotlight). rating score: 7. rating score: 7. rating score: 7. rating score: 6. <BRK>It would be interesting to consider the setting where just the image *label* is private. A plausible explanation for this phenomenon is that extra features can reduce the number of iterations required in SGD, resulting in better privacy and/or less noise. The paper is quite well written, and I found it easy to follow even though this is not my area of expertise.<BRK>This article is about a topical issue: performance degradation of of deep learning models trained with differential privacy (DP). The paper is very well written. Notice that sigma^2 C^2   noise is added to the summed gradients, and sigma^2 C^2 / B^2 to the mean. arXiv preprint arXiv:2007.03813, 2020(these references are not included in the paper).<BRK>The paper shows that linear model on top of ScatterNet can outperform CNN for DPSGD training on a few generic image classification tasks. In Sec 4 "Models with handcrafted features converge faster without privacy", I guess the results can be explained by the fact that simpler model (linear) has a lower capacity than more complicated model (CNN) so requires less training time even with lower learning rate. This can be pretty valuable for researchers and practitioners in the field. The experiments and discussions on the learning rate are quite interesting and inspiring to me.<BRK>The paper presents an analysis of differential privacy in machine learning, with a focus on neural networks trained via differentially private stochastic gradient descent (DPSGD). The main focus and the message in the paper is that the handcrafted features work better compared to learned features during training of NNs and having more training data results in better outcomes (i.e.a better privacy utility trade off).
Reject. rating score: 3. rating score: 4. rating score: 4. rating score: 4. <BRK>However, I am currently leaning towards a reject because of two main reasons: The first being the clarity of the presentation in the paper that makes it hard to identify (i) novel contributions, (ii) key algorithmic and technical details   the main paper is supposed to be somewhat self sufficient; with the current version, it was significantly hard for me to follow through the presentation even when repeatedly referring to the supplement.<BRK>The paper is generally well written, and the authors target on an important and challenging problem of learning how to search. The idea is novel and very interesting.<BRK>1.I do not see a formal definition of SDSL. Thanks for the rebuttal and revision. Otherwise, it is hard to conclude if this paper has made any progress. The denominator is constant for all search methods.<BRK>In hashing based retrieval, the sampling is based on a distribution with PDE monotonic to the distance [1]. Claim: In the introduction of the paper, different data structures such as graph based Efanna, HNSW, and ONNG. 4.Experiments: This paper only presents results in image search settings.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. rating score: 4. <BRK>I like the idea of this paper and think that finding new representations of 3D shapes in deep learning approaches is important and interesting. The paper in its current form does not do this due to the concerns raised above. Can you clarify this statement both here, and in the paper? I believe that the authors have adequately addressed my concerns, and have made a good effort to improve the quality of their work and so I am raising my score. > The ablation you provide in the supplemental is not sufficient. This is absolutely necessary. > There is a lack of quantitative comparison in this paper. You need to provide a comparison to contemporary methods for 3D reconstruction from images. > You write: "Unlike meshes or voxel occupancy functions, this representation can easily be edited and tuned after 3D reconstruction". In addition voxels and occupancy functions can be converted into mesh representations and so also editable in these software as well.<BRK>The paper proposes a self supervised method to fit a template (represented as a union of Coons patches) to a certain 2D sketch. The qualitative results of the method are shown in several different objects. The paper does not clearly state if the code and the data will be made publicly available, but since the code is attached to the submission I assume this is in the will of the authors, and this is also a contribution. CONS  Quantitative analysis: the only quantitative evaluation is reported in the supplementary material. For the acceptance I would recommend adding some more quantitative analysis, both for ablation and for the shown results. About my points, I agree with other reviewers that the quantitative analysis is a bit limited (I think it is also the main criticism), but the introduced ablation and the new Figure 6 (numerically comparing against other SOTA methods) are convincing.<BRK>This paper presents a method that leverages parametric surface patches as the fundamental representation in the task of shape modeling and reconstruction. This method requires a pre generated template for each shape category. Empirical results have demonstrated the performance of the proposed method in sketch based shape reconstruction and 3D shape interpolation. Cons:  It is not clear to me why such representation is advantageous over conventional polygonal mesh based representation. There are no quantitative evaluations in the paper. Final Rating  The revised version of the paper with additional experiments has addressed my concern on the limited advantage over prior deep 3D representation. Fig.6 in the revised version has shown the potential of the proposed approach in generating directly usable representation in downstream applications, including CAD design and manufacturing. I hope it could be properly addressed in the final version.<BRK>The representation of parametric patches have several advantages compared to prior works (whose patches are represented by neural networks). It can create sparse, compact, interpretable, and editable shapes that can be directly imported into many industrial design software. The paper’s evaluation of the method is very limited. 3.There are potentially missing related works. While the paper’s idea has its value as the representation could be useful for editing in many industrial software, but it requires more sophisticated evaluation (quantitative evaluation, more baselines, more tasks) in order to show case the effectiveness of the representation. With that, I do not recommend the paper for ICLR.
Reject. rating score: 5. rating score: 5. rating score: 5. rating score: 7. <BRK>The main contributions of this paper are twofold. Overall this paper is well written and easy to follow. The problem is well motivated, and the proofs of the main propositions are clean and easy to check.<BRK>Otherwise, the contribution of this paper would be limited. This paper has solid theoretical results (propositions 1 and 2).<BRK>2.Novelty: Reading the paper, I challenge the novelty of current algorithm/ manuscript. Paper is well written, it s easy to follow and it provides necessary background for the reader to follow. However, this is not reflected in the experiments, and experiments are in small domains.<BRK>I really enjoyed reading this theoretical paper. It is very well written and easy to follow. The ideas presented are interesting. Why not provide this approach in your experiments ?
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. <BRK>Summary:* This paper proposes an optimization problem to adopt insert/replace operations (program obfuscations) to generate adversarial programs. The formalization of the problem is very elegant, and is convincing.<BRK>1.The choice of model on which to evaluate the approach is poor; seq2seq is a weak baseline for function naming tasks. "Learning to represent programs with graphs." 1.Results over the baselines and seq2seq model seem to be very promising.<BRK>The formulations for site selection, site perturbation, and perturbation strength provides a principled way of generating adversarial programs by casting it as a constrained optimization problem. Reasons for score:The central contribution of this work is the addition of a formal approach to select perturbation locations along with the types of transformations for adversarial program generation.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. rating score: 6. <BRK> SummaryThe paper proposes a new framework, Dynamic Concept Learner (DCL), which learns by watching videos and reading questions/answers. DCL achieves state of the art results on the CLEVRER dataset. The learned representations are also shown to be useful for other tasks, such as grounding and retrieval. Weaknesses/High level commentsCounterfactual questions remain particularly hard to answer, do the authors have some intuition as to what may be missing in their model? Why is that? Currently it operates on synthetic images as well as synthetic language, what will be necessary to move to more realistic domains?<BRK>Additional experiments on new CLEVRER Grounding & Retrieval applications demonstrate the generalization ability of DCL trained with the original VQA task on other CLEVRER related tasks. > Strengths:*  The paper is well written and easy to follow. > Some concerns and suggestions:  My major concern is that the evaluation is based on a synthetic toy video dataset and it is simplistic compared to real world videos. A lot of details about the DCL model, neural programs, and dataset are provided in the appendix.<BRK>3.The paper conduct experiments on different evaluation settings including video causal reasoning, video grounding and generalization experiments. 2.It’s better to show the learned concepts visually as one of the strengthens of is explain ability. Is the trajectory refinement and model learning an iterative process? 3.Is this paper using some pre trained object recognizer and attribute classifier which acts as some kind of pseudo labeling? 4.In the generalization experiments, does the model trained and test using the same domain dataset?<BRK>(2) The idea of dynamics prediction to support predictive and counterfactual questions is new. This makes the proposed framework as a whole interesting IMHO. Cons:Despite the pros above, I have some comments on the paper:(1) I found the paper is quite hard to follow. In addition, some details are missing in the paper. (3) One of the main weaknesses of this paper is they only evaluate their method on one synthetic dataset which is CLEVRER. It seems to me that the proposed method is particularly designed to solve this dataset. I am willing to raise the rating if the author could properly address my concerns.
Reject. rating score: 5. rating score: 5. rating score: 6. rating score: 7. <BRK>This paper proposes a non autoregressive neural machine translation model that does not require multiple iterations to achieve a good translation quality. The key difference to previous models is that during training it uses decoding to estimate the number of words to randomly sample (proportionally to the error) as opposed to random sampling a fixed number of them and uses this sampling strategy to mask tokens. The evaluation shows that the proposed model outperforms previous non iterative ones and performs on par with iterative ones in some cases while being significantly faster which is promising (but it still relies on reranking based on an autoregressive model). It would help simplify wording and make more clear statements. The connection to curriculum learning was a bit hand wavy and hard to follow. Was this the intended connection to this line of work? It s not clear from the provided description of how this is done. This already has its own training cost, so increasing it more could lead to a situation where the benefits during inference are overshadowed by the computational cost from training. How did the authors come up with the number of reranking candidates for each model? It looks like the number is different for each model; this should affect the quality of the model. There seems to be this inconsistency between the notation in the diagrams and the notation in text, which is very confusing.<BRK>The authors propose Glancing Transformer for single step parallel text generation. If I understood their technique correctly, the only difference in the training algorithm between Mask Predict (Ghazvininejad et al., 2019) and their method is the selection of "number of tokens to mask (`mask num`)" in the decoder s input. Although the reported results and ablation studies show a significant impact of this simple change, I think more exploration of this technique is possible and should be done in the paper. The authors argue that random sampling may not be the most efficient strategy, but it s the easiest one, and has been shown to be powerful in models like BERT. E.g.one possible strategy to exploit this could be selecting tokens that the model was not able to predict correctly based on the hamming distance comparison. Based on these concerns, I am currently inclined to recommend rejection. While I find the idea of incorporating curriculum learning very interesting (together with strong results as demonstrated by the paper), I believe that more exploration of strategies to sample number of masked tokens, and sample words from the reference sentence is necessary to make the paper publishable. I have described this point in more detail in the Concerns above. Minor Comments :   There are many grammatical errors in the current version of the paper that the authors might want to revise.<BRK>GLAT incorporates several changes which result in a model which is state of the art in several MT categories for non autoregressive models and without requiring iterative sampling. *Strong points of the paper** The paper clearly lays out the suggested model changes, and how they related to previous work. * The model and changes are described well and clearly. *Clearly state your recommendation (accept or reject) with one or two key reasons for this choice. *I believe this paper is marginally above the acceptance threshold, though I think there is a clear avenue to improve the paper and change my rating to accept. My main criticism of the paper is that is it unclear how each of the two changes contribute to the overall improvement being seen by the model. Also, I have two questions which I think also should be answered, but don t require any further experimentation:3) What is the impact on glancing sampling to training time? I feel that if the authors answer these questions (ideally with WMT benchmark data for the first two), along with addressing the more minor points I list below, that I would feel comfortable increasing my rating to "accept". Finally, I think most of the writing is clear, but there are a few points where it becomes quite colloquial and difficult to follow, I think an additional pass cleaning up some of the structure could be quite beneficial!<BRK>Compared to previous work, biggest contribution of the proposed method is that it improves the training of NAT model with a similar idea of curriculum learning, while keeping the inference time unchanged, setting a significant improvement for non iterative NAT without reranking. It would be a good baseline for future research on non iterative NAT models. However, I still have the following comments and questions:  Methods(1) Why wouldn t the model gets stuck at predicting only part of the words correctly? As described by the algorithm, the model will sample more reference words as the inputs of the decoder if the prediction is incorrect. However, the loss is only calculated for the remaining words. I guess the random sampling strategy might be the key but it would be good to know answers from the authors. (2) Since the model only updates in the second pass where the inputs are always mixed with reference words and source embeddings. There will be a clear mismatch between the second pass and the first pass. (3) Hamming distance is quite weak. What is the input to this function? Steps?Experiments(1) The proposed training process is in fact very similar to Mask Predict except the inputs (Encoder hidden states instead of [MASK]) and adjusting the number of reference during training.
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 6. <BRK>Summary: The authors proposed to first extract a subgraph $G_u$ for each node $u$. Then use GNNs to extract the hidden representation $h_u   GNN(G_u)$. The subgraph extraction uses PPR Nibble with is a conductance based local clustering method. Pros:1.The model seems to be more efficient compare to GNN with global clustering method such as Cluster GCN. The experimental results are insufficient to verify the proposed method. 3.Insufficient related work on local clustering and PageRank based methods. The model proposed by the authors that has the best performance is LCGNN Transformer. However, it is not clear whether the performance gain is due to the local clustering procedure or the transformer. However, as pointed out in [3], there are also practical graphs that are heterophilic or low homophily. Although this is not the main theme of this paper, the existence of heterophilic graph should not be ignored. Reference:[1] “Predict then Propagate: Graph Neural Networks meet Personalized PageRank,” Klicpera et al., ICLR 2018.<BRK>[Summary]In this paper, the authors study the connection between GNNs and local clustering, and find that short random walks in GNNs have a high probability to be stuck at a local cluster. Based on this, they propose a light and scalable GNN learning framework called LCGNN, which first adopts the local clustering method PPR Nibble to partition full graph into subgraphs, then use GNN modules on subgraphs for training and inference. [Cons]  The proposed method is somewhat incremental since it only adds a local clustering step (with an existing clustering method) before adopting GNN models. The experiment is not very sufficient and supportive. 2.How do clustering hyperparameters $\alpha$ and the maximum cluster size affect the results? 3.No visualization for the clustering results or the learned node embeddings, which could help understand the effect of local clustering, is presented. There are many typos to be corrected.<BRK>This is an interesting work on GCN. The idea is to form local graph for each node using PPR Nibble, a local clustering method proposed before, and then use transformer on top of the local graph as encoder for node classification and link prediction. Without this study, it is hard to tell what is the novelty of this paper and whether the local clustering is useful. 3) All the theorems are not derived by this paper, but from other papers on PPR Nibble. And will this theorem works for the graphs in the experiment parts? 4)  Besides PPR Nibble, there are many local clustering methods or even using on line clustering so that the whole graph is not needed to fit into the memory to form the clustering, it will be interesting to see how various clustering methods work under the framework.<BRK>The existing PPR Nibble is adopted for the local clustering search. ##########################################################################Pros:+ The paper is clear and well organized. + The analysis of the connection between GNNs and local clustering is also interesting. Although the idea of using local clustering is very interesting, it is straightforward to apply an existing local clustering algorithm into GNN especially considering the existing methods that utilize the global graph partition. The reason for this should be given. The advantage of the proposed method over the methods based on global graph partition (e.g., ClusterGCN) is not well illustrated. It is better to make this clearer.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. rating score: 5. <BRK>The mapping is obtained from masked autoregressive sampling with a decoder trained as part of a conditional VAE. ##########################################################################Reasons for score:  Overall, I vote for accepting. The experiments could be improved and I make suggestions for that. The paper leverages a re parametrization of the search space to make search better and in this case to even allow unconstrained continuous optimization methods for the problem of routing in a way that successfully generalizes to unseen instances (the best solutions to routing problems are problem specific). + If the approach is size specific then any unseen problem instance size at test time will require generating new data and training, which would limit the impact of the approach.<BRK>This paper proposes a method to learn a continuous latent space via CVAE to represent solutions to routing problems. Combined with differentiable evolution search algorithms, one can search in the learned latent space for solutions to new problem instances at test time. They are also competitive with established expert designed algorithms such as LKH3. The proposed method is novel. My concerns have been adequately addressed and I raised my score to 7.<BRK>The authors propose an algorithm for routing problems by (1) using conditional variational autoencoder to learn a latent space for solutions, and (2) performing black box continuous optimization such as evolutionary algorithms in the space. The presentation and writing of the paper are excellent. Although the method is very neat and general, the idea of learning a latent space for solutions to combinatorial search problems is not new. Also in the experiment section, it would help the readers understand the approach better by including ablation studies such as applying evolutionary and random search methods directly in the solution space. In general, I think this is a borderline paper mostly due to its weak contributions.<BRK>}$ This paper proposes a new approach to solve routing problems based on (1) training a variational autoencoder (VAE) to model the optimal solution of problems (i.e., supervised learning) and (2) applying continuous search methods for decoding at test time. }$   I think the idea of transforming the combinatorial search problem into a continuous search problem is interesting. }$  The proposed framework is not particularly novel when compared to the existing works on de novo drug design using DNNs (which is also a combinatorial optimization). This severely limits applicability of the proposed framework. I encourage the authors to provide more results on large scale experiments, since this is where non exact solvers are needed. In what situations would users be encouraged to use the proposed framework?
Reject. rating score: 4. rating score: 5. rating score: 7. <BRK>This paper discusses the use of copulas for the multi agent imitation learning scenario. The paper addresses an interesting application of copulas and is generally well written. Efficient imitation learning for MAS is a challenging problem, hence the paper is well motivated. While I like the overall idea of the paper, there are some concerns which the authors should address:1. The authors claim that learning a copula is more efficient and scalable, however I don t feel this claim is well justified in the paper.<BRK>Theorem 1 seems like a powerful tool for multi agent imitation learning, and I think this paper is a promising initial step. Wouldn t you need to train on multiple tasks that share the same underlying copula but have different marginals, or on multiple tasks that share the same underlying marginals but have different copulas? It would be nice to discuss the weaknesses of the proposed method, as well as directions for future work. The dotted lines in Figure 3 are very difficult to see because they are small and because they are dark gray against a dark green background. [1] https://openreview.net/pdf?id Hyg JC4FDr Update after rebuttal Thanks to the authors for addressing my concerns.<BRK>Summary:The paper proposes the use of "Copulas" to capture dependencies among agents in multi player environments. Overall, this seems like a novel approach with promising results on a few experimental set ups. The paper motivate the problem well and describe the experimentation clearly. It seems to be a uniform distribution, I assume this applies for only the lower figure. The authors have mentioned heir intuition behind some of the results in Section 5.2. Given the above points, novelty and significance  marking this as accept.
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 6. rating score: 6. <BRK>This paper addresses relation extraction problem for distributed platforms for privacy concerns. The relation extractor is set to the conventional piece wise CNN and the main contributions focus on dealing noises in the distributed settings. Pros:* A new method for relation extraction in the federated learning to address privacy concerns. Cons:* Lack of novelty. If this is not specified for relation extraction, more tasks are expected to demonstrate it is a general algorithm.<BRK>This paper explores relation extraction with distant supervision in the federated setting and focuses on handling the label noise problem from automatic distant supervision by Multiple Instance Learning based methods and proposes Lazy MIL. Strengths: + This paper considers relation extraction in the federated setting, which is a new direction in this area;+ The mentioned label noise problem is a real problem in distant supervision, and it’s intuitive that this problem exists in the federated setting;+ Experiments show the effectiveness of the proposed method;Weaknesses:  The contribution of the paper is weak (in the context of the expectations of ICLR)   For baselines in experiments, it’s not clear how to use baselines in the federated setting.<BRK>Overall, this paper brought up an interesting challenge for this NLP sub task. However, it is not clear to me the necessity of compromising accuracy while doing parallel computing, and model innovation is slightly weak. Experiments over two datasets show promising results. 2.It is necessary to use pre trained language models like MTB (matching the blank) paper as the encoder because improvement over the current baseline could possibly be mitigated by a stronger encoder.<BRK>Strong points* The method is very simple to implement therefore it might be widely adopted as a baseline. * The denoising step is specific only for federated learning and distant supervision. Weak points* The paper would benefit from further proofreading. Possible improvements* "Lazy MIL almost does not leak the corpus information in each platform"   can you make this statement more precise? overview of?<BRK>The proposed approach has been applied on two relation extraction datasets and has reported gains. the paper is well written, clearly motivation and addressed real world problem   interesting work: blend of distant supervision and federated learning for NLP taskWeaknesses:  the paper lacks novelty in terms of methodology   Distant supervision for relation extraction (PCNN and MIL) and the federated learning methodologies used in this work have been inspired from existing works. This works combines the two. the experimental setup needs more clarity Questions:1. How would the Lazy MIL system bootstrap without such an assumption (no same entity pairs)? In real world, it is not the case. 3.How to obtain a minimum viable global \Theta? Results:  the experimental results show noticeable gains. It is surprising as the NYT dataset is well investigated in distant supervision settings.
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 6. <BRK>Summary:The paper presents different regularizers that promote representation diversity in order to prevent value function collapse and lead to better performance. However the number of environments is quite small. I assume that the ensemble networks used N times more weights that the simple DQN. It is mainly to compare for a fixed computational budget how much the proposed methods are better. This review is an educated guess and I am not at all an expert in the field of overestimation in statistics, economy or reinforcement learning.<BRK>Diversity within an ensemble is undeniably desirable  The proposed methods do improve performance on interesting benchmarksPossible improvements/Weaknesses:  There are missing steps in the chain from motivation to method, but these steps can easily be done and verified by measuring the appropriate quantities systematically. Otherwise, this is just a "my number is bigger than your number" paper, which isn t very valuable for our scientific understanding of deep RL. The authors emit the hypothesis that "representation similarity between neural networks in an ensemble based Q learning technique correlates to poor performance. It might be valuable to test these metrics in the RL setting as well, I suspect the conclusions/motivation of this paper might differ somewhat. This is not a very strong claim. The conclusion claims that the proposed method can "maximize the diversity in the representation space", but this is not measured, only hypothesized.<BRK>This paper proposes to improve ensemble based methods such as Maxminand Ensemble Q learning by regularizing the representations for theensemble members to increase diversity. The authors use a variety ofmeasures of inequality to provide regularization (which increase thatinequality of representation among ensemble members). I think the experimental resultscould be strengthened in a number of ways: more domains, single set ofhyperparameters, further empirical analysis of the effects of thedifferent inequality measures used for regularization. Pros:Interesting idea and seems effective based on experimental results. But, why are these the similarities that matter? Section 5.1Hyperparameters appear to have been tuned per domain, which makes mesceptical about the results as a whole.<BRK>Q learning is known to have overestimation bias. The authors study a specific observation and try to tackle it by regularization technique to maximise the diversity of representation space. Five different regularization functions are evaluated in the paper. Note that the reviewer is not very familiar with methods to introduce diversity in representation, but based on educated guess, the proposed method look interesting.
Reject. rating score: 2. rating score: 5. rating score: 5. rating score: 7. <BRK>Second, almost all of the gains of this method appear to come from the pooling method: In Tables 2 and 3, WaveMesh alone consistently underperforms SLIC. Given that this paper did not use any of the existing superpixel evaluation metrics, it is difficult to compare it to prior work. This suggests that the goal of this paper is reasonable and the method can likely be motivated. Weakness:The authors provide little theoretical justification for the use of wavelets as they are used in this paper.<BRK>Quality: The motivation of this paper is great, and the proposed WaveMesh is interesting. In general, it is a high quality work. Originality: The proposed image specific superpixeling algorithm WaveMesh is novel and try to circumvent the limitation of SLIC. However, the insufficient experiments affect its persuasiveness. 2.WaveMesh is a superpixeling algorithm that is not coupled with classification algorithm, but all the experiments are performed on SplineCNN. 3.How to evaluate the effectiveness of the image dependent threshold T?<BRK>2.In Table1, the results of the proposed method are not significant. More specifically, they introduce an algorithm to compress images in the pixel domain and it leads non uniformly distributed and multiscale superpixels. This paper introduces a wavelet based superpixel algorithm and a spatially heterogeneous pooling. 2.The paper provides good initial results, showing that to some degree their method is generalizable.<BRK>This isn t a negative for this paper (indeed, it could spur such research in the future), but perhaps something that s based on hierarchical clustering (on top of SLIC) might work better. One drawback of the wavelet approach is that the boundaries of the superpixels have to be regular and axis and aligned with the downsampling phase (have authors considered variants that are based on overcomplete wavelet transforms?). The idea of converting a tagged/thresholded wavelet coefficients into a quad tree structure is interesting, and indeed natural in retrospect.
Reject. rating score: 2. rating score: 2. rating score: 3. rating score: 3. <BRK>Overall, even by the metrics provided in the paper, the contribution is very unclear. Without clarification of this, and addressing the above comments, I would recommend this paper is rejected. There are other terms used which do not match well with the english meanings. There is no link to the literature that these are good/accepted terms to use. At minimum, there should be some discussion as to why these specific terms were selected and a comment made about.<BRK>This paper tries to take a GAN based approach to monophonic music composition. The model presented here doesn t address this limitation in the existing literature and, arguably, doesn t generate locally coherent music either. There is a lot of evidence that surveys are a poor way to evaluate creativity in music composition (e.g.http://ccg.doc.gold.ac.uk/ccg_old/events/ecai06/proceedings/Moffat.pdf) because it is easy to unintentionally mislead or bias your participants. The melody continuation task has clear evaluation measures, which are more reliable than a survey. Generally, there are also a lot of spelling and grammatical errors. Please spend more time editing your writing before submitting.<BRK>\newlineThe primary problem with this paper is its lack of clarity. Small and picky, I realize, but the pervasiveness of this logical sloppiness makes it hard to follow. The evaluation is somewhat problematic as well. I find there to be several problems here that make this paragraph hard to follow. In summary: I would be glad to read a clear version of this paper, and would not hesitate to change my score if appropriate. However, I am not absolutely certain that the evaluation is correct, because in fact I can t evaluate the system itself very well based on the description given in the paper. or some other possibility?<BRK>2) The main "idea" in the paper is to use hand engineered musical features as an intermediate representation for generation. The paper has many issues that need to be addressed:1) The language of the paper needs a lot of editing and is quite difficult to comprehend. I m pretty sure I understand the proposed system at a high level, but a lot of the details are unclear to me due to the awkward language and at times non standard vocabulary. 4) Even if the model conditioned on hand engineered features were clearly superior to an unconditioned model, this result would probably not be of broad interest to the ICLR community.
Accept (Spotlight). rating score: 8. rating score: 7. rating score: 7. rating score: 7. <BRK>For example, in the experiments shown in this paper, they  compare performance of deep equilibrium linear models with linear models and deep neural networks. The main results from this paper is uncovering the dynamics behind these deep equilibrium linear models.<BRK>The paper discusses the theory of deep equilibrium models with linear activations. The paper then analyzes the gradient flow dynamics of such models.<BRK>The authors prove two results: first, they establish linear convergence to the global minimum under the relatively strict assumption of a "local" PL inequality; secondly, they show that the dynamics of the deep equilibrium models differs from gradient descent dynamics and, in fact, is related to a trust region Newton method.<BRK>> Summary: This work focuses on the study of (global) convergence and gradient dynamics of a recently proposed family of models, the deep equilibrium  (linear) models (DELM) under common classes of loss functions.
Accept (Poster). rating score: 7. rating score: 7. rating score: 7. rating score: 7. <BRK>## SummaryThis paper introduces a semi supervised learning procedure that does not require labeled adversarial data to learn an ensemble model that is robust to adversarial attacks on classification tasks. ## QualityThis paper is very well written; the design decisions of the training procedures are all supported by ablation tests and comparisons to other modern adversarial baselines. ## ClarityThis paper is very clearly written! ## OriginalityAs the authors have mentioned, improving diversity in ensembles is not a novel approach to improving robustness to adversarial attacks; the originality of the method lies in the parameterization of diversity through a DPP component and multi view complementarity. ### ExperimentsDo the authors have insight in the significant gap between ARMOURED B and its variants for a large $\epsilon$ budget with $L_\infty$ PGD? Am I incorrect?<BRK>**Update** : Since most of my issues have been addressed, I have changed my rating from 6 to 7Summary:This paper proposed ARMOURED, a semi supervised training algorithm that combines multi view learning to utilize unlabeled data, along with diversity regularization to decrease inter model transferability for adversarial inputs. ##########################################################################Reasons for score:The proposed regularization terms of using unlabeled data and an ensemble of models with different views to indirectly promote adversarial robustness are quite interesting. The fact that it leads to better robustness without explicitly training for it shows that the authors  intuition in using this regularization term is, in fact, sound. However, I must point out that the idea of using augmentations to enforce consistency on unlabeled data is now new. ##########################################################################Cons:  Since this is primarily a paper that focuses on adversarial robustness (ultimately), I feel some very basic yet important changes are required. Please address and clarify the cons above.<BRK>### **Summary**: This work introduces ARMOURED, a new method for learning models that are robust against adversarial attacks. The method uses **multi view** learning (as in using multiple models with different parameters to cast their votes/views on a given sample), semi supervised learning to pseudo label new data based on a consensus, and a diversity regularizer. ### **Reasons for score**:  My recommendation is to accept the paper. I was expecting to see additional experiments with extra unlabelled data to get a better feeling of this component. ### **Questions to be discussed during the rebuttal period**:Please, address the questions/comments expressed in the **Weaknesses** section.<BRK>This paper considers training an adversarially robust model in a semi supervised setting. The authors propose an ensemble based algorithm for this goal. The algorithm uses a regularization term to induce diversity in the ensemble. The algorithm also leverages the idea of multi view training in semi supervised learning to make use of unlabeled data. In fact, some of the figures in this paper are quite similar to those in Pang et al 2019. After author response: I have read other reviews and the revised version.
Reject. rating score: 5. rating score: 5. rating score: 5. rating score: 5. <BRK>Pros: The proposed SAUM2 is novel. As a contribution, the work introduced large margins between classes in a source domain. This is relevant in a cross domain sentiment analysis problem. The result shows that the resultant model is domain independent which is Ok for a general application. This is so because it was not shown how Theorem 1 was an explanation of Algorithm 1. The following minor issues need to be revised: 1. Abstract: The 3rd sentence needs to be revised    per each domain  is ambiguous. Also on Page 2, under contributions, the phrase  in the embedding matches this distribution  is ambiguous.<BRK>The authors presented a theoretical analysis leveraging on previous results for SWD for domain adaptation. This seems to be an important claim in this paper, as the authors named their approach a "max margin" approach, and they argue that it is this effect that is the reason for the good performance of their model. As a general domain adaptation paper, the results would be more convincing with another data set. As an application paper for cross domain sentiment analysis, the authors failed to compare against recent work such as [2], [3] and [4]. However, I think the current submission needs further work.<BRK>In this paper, the authors propose a new method to improve cross domain sentiment analysis. Therefore the drawn samples will keep larger margin between classes in the source domain. The experimental results demonstrate the efficacy of their method. Cons:1.The proposed method is very straightforward. c) It is not enough that only two values, i.e.0 and 0.99 are assigned in Table2. Typos:There are some typos in the paper.<BRK>This paper proposes a new domain adaptation SAUM method that learns a large margin classifier between different classes for cross domain sentiment analysis. Experimental results on Amazon multi domain review dataset empirically demonstrate that the proposed SAUM method can outperform the state of the art domain adaptation baselines. Moreover, detailed theoretical and empirical analysis are provided to demonstrate the effectiveness of the proposed method. Strengths1.The paper is reasonably well written and structured. However, this paper lacks detailed discussions and comparisons with existing discriminative feature learning methods for domain adaptation.
Reject. rating score: 5. rating score: 6. rating score: 6. rating score: 7. <BRK>This paper formulates the condensation polymerization as a constrained optimization with prior structural knowledge. This paper proposes a framework to solve the problem and demonstrates its effectiveness in a few shot benchmark. Thus, polymer retrosynthesis also seems to be practically important. This paper well explains how to apply a single step retrosynthesis model (trained in a reaction benchmark) into the polymer retrosynthesis problem. All sub steps (except domain adaptation) are reasonable and easy to understand. Concern (or Weakness) \#1: Domain adaptation  The domain adaptation is emphasized throughout this paper. However, I think this adaptation is hard to provide a meaningful gain in general, (a) fundamentally in the few shot setting and (b) practically as shown in Figure 4 (right). Details of (a) and (b) are described below. It means that the stability constraint will filter out some wrong predictions in $p(u|r)$ from PolyRetro USPTO. I think one fold should be used for validation. While the authors well formulate the polymer retrosynthesis problem and well explain the sub steps, they seem somewhat straightforward. Concern (or Weakness) \#3: No qualitative study  In retrosynthesis, top k accuracy cannot reflect practical scenarios since multiple solutions can exist. Thus many papers often provide their success/failure cases and allow readers to evaluate them. As I mentioned in the second concern, designing Poly Retro USPTO is somewhat straightforward given the constraints of the proposed problem. Thus I think PolyRetro USPTO is a more proper and stronger baseline. Why are they in the Appendix? I think they should be presented in the main paper. I want to know I correctly understand how mlp retro and seq2seq retro work. I think its definition should be provided. Or, are they not important? Why the monomers should be symmetric? Conclusion: While this paper focuses on an important problem, I have several concerns mentioned above, so  I think this paper is on the borderline.<BRK>This paper focuses on polymer retro synthesis problem. This is a novel problem and is very challenging because of the very small amounts of training data available (<100). They use reaction templates collected from small molecule reactions and formulate polymer retrosynthesis as a constrained optimization problem. The authors claim that this is the first learning method that takes constraints in polymer retrosynthesis problem. The paper is well written and easy to follow. Overall I am positive about the paper as it proposes a new important tasks and provides a method that works well to tackle the task. The usage of reaction templates from small molecules as well as the ability to deal with with small amounts of training data is potentially useful and can serve as a model for few shot modeling in this domain for other tasks as well. As for weaknesses,  I think the the baseline transformer performance of 0% top 50 recovery can be improved (and hence not a representation of true baseline). [1] Schwaller et al: Molecular Transformer: A Model for Uncertainty Calibrated Chemical Reaction Prediction<BRK>########################################################################## Summary: This paper proposes a method for the retrosynthesis prediction of polymers. A challenge in this problem is the lack of synthetic data for polymers. The method attempts to leverage models for small molecule retrosynthesis predictions (where there is more abundant data), as well as domain specific constraints derived from the chemistry of a particular class of polymerization reactions. The method is shown to outperform some baselines that are commonly used in small molecule retrosynthesis. I think the paper proposes a novel approach for polymer retrosynthesis that performs better than some of the baseline methods. However, I have some concerns, especially about the overall problem formulation of polymer retrosynthesis. However, in polymer synthesis, there is a much less defined target polymer structure (we have a distribution of different polymer structures), and the synthetic procedure required to create the target polymer in condensation polymerization is typically a single step mixing of the monomer building blocks. But the polymer induction part of the modeling, where we start with a given polymer repeat unit and convert it to the unit polymer, makes much less sense because in a real use case why wouldn’t you just perform the analysis (eg designing a new polymer or performing retrosynthetic analysis) directly on the unit polymer or monomer building blocks, with the knowledge that the target polymer structure is essentially just a repeated form of the unit polymer structure. It would be interesting to see the distribution of the average number of unit polymer candidates for each of the 52 examples. *The additional seq2seq baseline for monomer proposal in Figure 7, where the repeat unit is converted to the unit polymer using a very simple heuristic (by adding the most common end group pairs) shows pretty competitive performance compared to the proposed PolyRetro model, and I think this simple heuristic is actually a very reasonable addition to the baselines. *The PolyRetro model seems to have very marginal improvements over the PolyRetro USPTO model, which seems to suggest a simple one step retrosynthesis model is already pretty good for the polymer induction step?<BRK># summary #This paper is concerning the retrosynthesis of polymerizations from monomer candidates. A polymer is a very long chain of unit polymers. Therefore conventional retrosynthesis models do not suit well for polymerization since they focus on applications on small molecules. The paper defines a problem of predicting a unit polymer and monomers, given a polymer repeat unit (Eq.5).A unit polymer can be decomposed into a polymer repeat unit and end groups. I think this polymer challenge is quite new, and polymer synthesis is important for real applications. Overall, the paper is well written and readability is satisfactory. Problem definition of Eq.5 seems straightforward but at the same time reasonable. Technical sections (Sec 4. and 5) are easy to read: finds little difficulties to understand the main idea. I cannot identify the technical novelty of the proposed polyretro method. In Sec 3.2, "we use Retro*", but which parts of the algorithm are borrowed from Retro* and which parts are not? Since this is a new challenge, it is difficult to assess the significance of the target recovery rates in experiments. This result itself is important to confirm that the typical retrosynthesis model is incapable. However, such a ``weak baseline is not much informative to assess the significance of the proposed method. It can be a non ML approach or a commercial software with block box algorithms.
Accept (Spotlight). rating score: 8. rating score: 7. rating score: 7. rating score: 6. <BRK>## Second reviewThanks for taking all my comments seriously. In case the authors were not aware of this, an other interesting approximation to RTRL was published in [b], the authors may or may not comment about that too. There are technical details that should be given for clarification:  The authors might want to provide details on the computation of the complexity of one or two of the essential component of the table to make it more accessible to the reader. It would be great to publish that along with the paper! JAX is not yet very well spread, and we see here that it is a very promising tool for custom gradient in RNNs. ## SummaryThe authors describe new algorithms to train sparse recurrent neural networks, these algorithms are described as variants of RTRL. How much would the performance decrease? This is an important topic since recurrent networks are not efficiently trained with BPTT. Did you use sparse matrix cuda kernel, how good was it?<BRK>For example, in page 6 the authors mentioned that they use a one layer MLP to get 1024 hidden units which are mapped to 256 unit software, but do not clarify if a non linearity is applied to the 1024 units. Parameters sweeps should be extended if the optimal parameter is at the edge. BPTT, however, is not suitable for online learning. This is not suitable for an online learner that has to learn and react in real time. SnAp, the methods proposed in this paper, is one such algorithm. In page two, the paper introduces a function $g_{\phi}$ for mapping the state to the target and then says that the goal of the learner is to minimize loss with respect to $\theta.$ Shouldn t the loss be minimized with respect to both $\theta$ and $\phi$? They argue and show that for highly sparse RNNs, SnAp can be scaled to $n > 1$. The new algorithm, SnAp, is clearly presented as an approximation to RTRL. First, it s not clear how the hyper parameters for all the methods were tuned.<BRK>## Second ReviewThe author s thoughtful response has clarified most of the missing details in the paper. It is true that idea is interesting and theoretical analysis are promising. How can one ensure that the sparsity pattern at start is the optimal one for any network? I would encourage authors to make it public, and provide key insights for training RNNs using snap. This paper does add significant pedagogical value, which can benefit complex task such as grammatical inference. I m increasing my score from 5 to 7 and I hope this paper is accepted. Continual learning of recurrent neural networks by locally aligning distributed representations. ## SummaryPaper introduces snap which adds sparsity to the influence matrix extracted from RTRL which acts as a practical approximation for RTRL, snap is extension of prior work on snap 1 used to train LSTM, and authors have shown that one can train dense as well as sparse RNNs using snap achieving similar performance as BPTT on real as well as synthetic dataset. Does current sparsity measure work on variant of RTRL? Does network roughly converge to similar performance with optimal sparsity or sparsity measure changes as other regularization approaches are introduced?<BRK>This work presents a method, named SnAp, that takes Real time Recurrent Learning derivations and proposes to approximate its computations with sparse approximations to make them more computational tractable. The method assumes a sparsity pattern on the parameters of the network that leads to the relationship on how the gradients could be updated. The relationship between neurons can vary every time the parameters are updated. Also, complexities for Snap in table 1 don’t seem to consider the computational time of computing the sparsity pattern (even for a random pattern). When n is big, the experimental results show a better and competitive performance to BPTT. What are the results of TBPTT when stateful training is applied and how do they compare in such case? Please describe all the details. These are my considerations not to accept this paper.
Reject. rating score: 4. rating score: 4. rating score: 6. rating score: 6. <BRK>This work proposed an algorithm called action guidance that trains the agent to eventually optimize over sparse rewards while maintaining most of the sample efficiency that comes with reward shaping. The authors examine three sparse reward tasks with a range of difficulties to prove the effectiveness of action guidance. However, I don t think this paper is fully prepared for submission as the method is not novel enough and there exist some possible issues that need to be discussed and resolved. A concern is that if there exist several auxiliary agents, how do you arrange the shaped rewards to each auxiliary agent? Is it means that the agent using shaped rewards has the same optimization direction as the one using sparse rewards? I m not sure if this is fair enough as the effectiveness of action guidance is not clear in this setting.<BRK>The paper introduces an approach for learning policies across multiple MDPs and using those policies to improve learning performance on the task that the agent designer cares about. The presentation of the idea is clear. Given such an assumption, it is natural to understand why the current approach works. The scope of the current work is limited to RTS domains. It would be useful to describe the MDPs that the authors have considered for their experiments? 2.It seems like the different policies can be different only if their corresponding reward functions are different. If so, in many domains, the approach relies on careful design of different MDPs to get the approach to work.<BRK>Therefore I am keeping my score unchanged. The authors propose a reward shaping method to learn faster a reinforcement learning task. "Probabilistic policy reuse in a reinforcement learning agent." 2006.Usually, when you are trying another "agent" you are implying that this agent will explore by itself, which is not true for your method. Section 1 could be improved by more explicitly discussing the difference between the current paper and each category of related works. It is not very clear to me exactly how the agent selects which policy to follow at every step. Maybe it would be better to have an algorithm in the manuscript.<BRK>The authors made use of a simplified RTS domain and demonstrated that their approach outperformed a more naive shaped reward approach. The basic idea of this paper is simple and elegant, and the paper is well written. The paper is also well written and the video examples are effective at conveying the results. I have a number of concerns with this current paper draft. This further leads me to believe that this may not be the best environment to test this approach. It’s also somewhat disappointing that the PLO results are inconclusive, this indicates that the work is perhaps still somewhat immature. However, my concerns listed above hold me back from stronger support for the paper in its current state. 3.Do the authors not have a clearer sense of why the PLO results were inconclusive? Or what experiments could be run to delve into this further?
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. rating score: 6. <BRK>In the paper the problem of escaping from a minimum (the old Kramers escape problem) is analysed in the light of SGD, characterizing the SGD dynamics using stochastic differential equations. The main result of the paper is the characterization of mean escape time from the basin for SGD (Thm.3.2) and Langevin dynamics (Thm.3.1). **Points that needs to be clarified :**The authors comments on the effect of large(er) learning rate on the overall escape rate, but in that case the analysis that is based on continuous time equations will not generalize straightforwardly.<BRK>Overview: The paper aims to explain how SGD converges to flatter minima using density diffusion theory and shows the effects of Hessian dependent covariance noise versus injected white noise. Clearly, the direction is very interesting and relevant and I think this is a good paper with a clear analysis and numerics which validate the theory. I also think this paper improves on previous related other research (e.g.the Levy noise analysis). The analysis and assumptions are clear. In your opinion, do the results hold across different loss functions? In my own experience I have observed differences in MSE loss and classification loss.<BRK>The paper develops a density diffusion theory to reveal how minima selection quantitatively depends on the minima sharpness and the hyperparameters. In particular, the paper analyzed the dependence of mean escape time from the valley with the Hessians on local minima and saddle points for both SGD and SGLD, and revealed the exponential dependence of the mean escape time with the sharpness. With this simplification, the authors can greatly simplify the integration using second order Taylor expansion around the critical points. I would like to see some discussion on why it is the case for mean escape time. However, in high dimension cases when we have multiple valleys around, how do we define the saddle point exactly?<BRK>This paper develops a density diffusion theory (DDT) to reveal how minima selection quantitatively depends on the minima sharpness and the hyperparameters. This paper is the first to theoretically and empirically prove that SGD favors flat minima exponentially more than sharp minima, which is novel. Furthermore, the paper is well written. Some shortcomings are listed as follows:First, the concept “valley” is frequently used in this paper, but it seems that no formal definition has been given for “valley”. Similarly, in Theorem 3.2, when the Hessian matrices $H_a$, $H_b$ and $\Delta L$ change fast, they cannot well reflect the flatness of minima. After rebuttal:I thank the authors   clarification. I keep my rating.
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 7. <BRK>This is not case. This fact is also true on the grid graphs. 2.The data augmentation is proposed in Section 2.7. The authors claimed that the advantage of the proposed method is that it does not influence the data but applied on kernels. However, there may be some issues here for changing kernels. In this work, the kernel is acting as a kind of message passing directions on the graph. The message passing patterns are an important part of the graph. These datasets are not commonly used in the community. The authors may want to clarify this and add more datasets for comprehensive evaluations.<BRK>In the framework, gradients of the eigenvectors of the graph Laplacian are used to define “directions” on the graph. My main concerns are:1. The theoretical development is difficult to follow. It is hard for readers to find in the paper what are the steps of the proposed algorithm and understand how it works. 1.This paper proposes a novel idea. Defining directions on graphs is not a well addressed problem in current GNN models, and using the gradients of the low frequency eigenvectors of the Laplacian to define directions seems novel and interesting to me. 2.The insight and analysis are not clear. More importantly, I am not sure about the correctness of the theorems and corollaries.<BRK>But I am not perfectly certain of their correctness. In addition, the proposed GNN is theoretically sound in that it is an extension of CNNs on a grid graph in a certain sense (Theorem 2.7). Yes**Clarity**Can I understand the main point of the paper easily? Regarding the data augmentation, although the proposed augmentation method works empirically, I am not sure the soundness of the method. The explanations are easy to understand. Is the organization of paper well? Also, it proposed a data augmentation method using vector fields. This sentence is not appropriate, as it reads that this paper derives corollaries from a conjecture, which is not proven yet. Considering that, it looks that Corollary 2.4 and 2.5 are not proven theoretically. I understand it when a vector field in a Euclidean space. I want this paper to clarify it. This does not equal $F_2$ in general. Claim 3 is theoretical.<BRK>The authors achieve good results on several benchmarks. Strong points:The proposal is highly novel. The paper is mostly clearly written. The theoretical analyses contribute to the understanding of the work. Weak points:  It is unclear how parameters are used in their model. Still, when an eigenvector is used from a degenerate eigenspace, the method appears not equivariant to node re orderings. This also means that when using the proposed method on a square grid, which the authors do on CIFAR10, the method is not equivariant to node re orderings. Recommendation:I recommend to accept this paper, as it proposes a simple to use method to build more powerful graph nets. In spite of my concerns about equivariance, it appears to perform well in relevant benchmarks. Are some of the proposed models indeed not equivariant on certain graphs? I share reviewer #1 s concerns about corollaries 2.5 and 2.6.
Reject. rating score: 6. rating score: 6. rating score: 6. <BRK>The paper is well motivated and studies and important topic, but unfortunately it is let down by the presentation of their contributions which is confusing and at times misleading. as a map from Y  > U... but that s a little weird and should be explained explicitly. Of course, things get more complex if there is some constraint on H such that the identity isn t included,  but this isn t discussed. The presentation of the method in section 4 also needs work: the domain generalization problem is presented as the problem of finding h that maximizes the mutual information between Y and h(X) in the worst case environment under the constraint that Y\indep E | h(X). The experiments show the method shows promise (though they should report both IRM & REX [Kruger et al 2020] s performance for coloured MNIST to make it clear that there are better methods on that dataset)...[Kruger et al 2020] Out of Distribution Generalization via Risk Extrapolation<BRK>In this paper, the authors propose a gradient based learning framework, with a two part objective function in which one part improves the informativeness about the target variable, and the other part enforces the invariance of the relation. The paper is well written and, for the most part, is easy to follow. Specially, regarding Assumption 2, if we are assuming some of the causal mechanisms are changing across environments, why the one corresponding to the target should not change? Although the assumptions are strong, same assumptions were considered in few other works such as (Peters et al., 2016). Compares to existing work with the same assumptions, this paper provides a good implementation method that is an improvement over past work and would be of interest to the ICLR community.<BRK>The paper presents a new gradient based framework for learning invariant mechanisms (often called "relations" in the paper) from data drawn for multiple environments (data generating processes). A key idea of the paper is that training data drawn from different environments can be exploited to learn mechanisms that remain invariant across those environments. While true, this is unsurprising and well established. The paper could be improved by spending less time on the known results (or at least making clearer connections to prior work) and spending more time clarifying what is genuinely novel about the proposed ideas.
Reject. rating score: 3. rating score: 4. rating score: 5. rating score: 5. <BRK>The authors address this problem by augmenting existing architectures with a VAE framework. ## Pros:  The paper has a novel and interesting direction as robustness to distribution shifts has not been studied before in 3D human motion modeling. Experiment results on the H3.6M and CMU datasets show that the proposed approach is useful on out of distribution (OoD) test cases. Additional comments    Figures should be improved. The losses in the tables are too high compared to the actual task. The authors should compare their models on the main task as well. In the context of H3.6M and CMU datasets, this might not be straightforward due to different skeletal configurations. Yet there exists a much larger benchmark for 3D motion prediction: AMASS [1]. It would be very easy to train on a subset of datasets and test on the remaining ones as all the datasets follow a unified skeletal configuration. In other words, it is not an independent metric/method/framework for assessing the existing models’ OoD performance.<BRK>The paper presents, firstly, a new benchmark (based on Human3.6M and CMU datasets) for human activity and motion with a high degree of out of distribution examples, and secondly a hybrid framework for human motion prediction which is more robust to out of distribution samples. The proposed behchmark is also highly valuable to the community. * Secondly, the experiments are not adequate in that the method is only compared to a GCN without the generative model   and not with any of the other state of the art in motion prediction.<BRK>Summary:This paper proposes a method and benchmark for out of distribution modeling and evaluation of human motion. They evaluate against state of the art human motion methods, and show favorable performance against them. Pros+ Generative model formulation for human motion prediction+ Benchmark for testing out of distribution performance in Human 3.6M and CMU Mocap+ Proposed generative model outperforms baselinesComments / Suggestions:  Interpretability claim:The authors talk about facilitating interpretability in the abstract, however, I fail to find any clear experiments suggesting this. Evaluations:The evaluations provided in this paper are based on euclidean distance measured with respect to the ground truth. MSE is not a fidelity metric. I suggest that the authors address the concerns raised by the reviewers in future submissions, and it s highly likely that the work will be more solid.<BRK>This paper presents a generative model to solve the OoD problem in human motion prediction. Experiments are performed on H36M and CMU benchmarks for illustrating the efficacy of the proposed approach. Pros:1.The paper is good in writting and easy to follow the idea2. The perspective of using generative model to deal with OoD problem in human motion is novel. Cons.1.My major concern is the effectiveness of the proposed approach.
Accept (Poster). rating score: 7. rating score: 7. rating score: 7. rating score: 6. <BRK>The paper proposes an effective explanation method based on a notion of robustness defined by the authors. However, some points that should be addressed before publication. Maximally invariant data perturbation as explanation. In this way, the user can understand which is the best compromise between robustness and speed. The authors do not specify in the main paper (or it is not easy to find) which are the classification models explained.<BRK>In this work, the authors propose defining this set as the set of features that are easiest to attack adversarially (in an $L_p$ sense). It is a bit unclear to me why considering adversarial perturbations is a priori any more convincing than, e.g., considering blurring out or adding noise to the selected features, but they serve slightly different purposes and it s reasonable that these methods could be complementary. I had a couple of questions about these baseline comparisons:1. I think this is a useful exploration of an alternative means of quantifying feature importance, with intriguing results: somehow, optimizing for adversarial robustness also seems to optimize for the score on insertion/deletion games. Further exploration of that issue (or at least, elevating some of the many appendices on that issue to the main text) would, in my opinion, increase the impact of the paper.<BRK>Evaluation is limited w.r.t.datasets and methods compared against, however. * Overall, having more non image experiments, and associated discussion, could be helpful. Right now almost all results are images, with one small text example, and I wouldn t be surprised to see very different results on different types of data. **Update**: The authors  update is comprehensive, well thought out, and demonstrates significant improvements to the paper; I have raised my score to reflect this. * The adversarial robustness framework is presented very clearly and seems to get at a different question than previous benchmarks, which is a useful contribution. There s a lot of room here to boost the value of the paper, in my opinion. is that I don t have an intuition for why it should be the case.<BRK>The main contribution of this work is the proposal, implementation and validation of a new evaluation criteria/measure for explanations based on robustness analysis. I am not very familiar with using “human study” for a user evaluation, use user study. It looks to me that the user study is an afterthought, a good attempt to complement the paper, but either is properly done or removed. It might be that I got lost in all the evaluations, and I cannot figure out if the real features the model used to make the prediction will be found, or just those that make the prediction change…. While reading, I found some small grammar issues; please, double check the text.
Accept (Poster). rating score: 6. rating score: 4. rating score: 4. <BRK>The method is applied to the problem of continual learning to overcome the catastrophic forgetting and memory limitation on the storage data. 3.The validation has been performed using low resolution images (32x32)4. The system uses a pretraied Style Transfer Network with Imagenet. 2.Clarity of the paper.<BRK>It is argued that GANs generate new samples which may not belong exactly to one of the classes, so a new generative model is proposed. Specifically, besides the reconstruction loss, content loss is introduced utilizing the idea of content transfer from the neural style transfer algorithm. I have some basic concerns. (1) First of all, the idea of generating new samples for replay is not motivated well enough; in the experiments, even the model replaying on original images takes memory in few hundred MBs.<BRK>The main difference is to use autoencoders on images instead of features. Summary: The paper tackles catastrophic forgetting for continual learning. It shows significant improvements in the experimental parts. It proposes to train autoencoders with Neural Style Transfer to generate previous images.
Reject. rating score: 6. rating score: 6. rating score: 7. rating score: 7. <BRK>The transformer is combined with a linear dynamical system to enforce Koopman features and is trained using the reconstruction and prediction loss. Finally, the proposed algorithm is applied to the different tasks with 1, 2 & 3 dimensions. It s a bit surprising that the authors don t cite https://arxiv.org/pdf/2002.09405.pdf, which would also be an interesting but not necessarily required baseline. ### Quality, Originality & Significance:While the paper is clearly written and well executed in terms of experiments and baselines, the paper is missing originality and significance. There might be a good chance as the Lorenz system is a polynomial dynamic system. If so how do the learned features compare to the analytic features? Furthermore, the paper lacks to address the real challenges of learning dynamical systems (*in my opinion*). Is the transformer model able to learn a good dynamical system with multiple time scales? To increase the significance of the paper the authors would need to address one of these two questions. ###  Conclusion:All in all, I think the paper is well written and the performed experiments are well executed. To improve the papers the authors would either have to address messy real world data or dynamical systems with multiple time scales. I am open for discussion, why this model is a significant advancement over prior methods, but right now I don t see that.<BRK>The state at each time step is embedded into a continuous vector using a pretrained encoder decoder model based on Koopman’s theory. The experiments are performed on three physical systems and generally show that (1) a transformer model outperforms alternative machine learning methods, (2) a transformer model with the proposed embedding outperforms transformer models with alternative embeddings based on autoencoders or PCA, and (3) more transformer layers help (but only slightly). **General comments**:This is, to my knowledge, a new application area for transformer models, and the fact that they outperform alternatives could be interesting to the ML community. Furthermore, the application of transformer models is not entirely standard, in that the paper proposes learning embeddings that are specialized to the application area. The proposed approach is compared both with alternative (non transformer) techniques and with ablations of the transformer model. **Questions**:The proposed embeddings are based on a neural network based encoder and decoder pair and these are trained either with an objective based on Koopman’s theory or a standard AE objective.<BRK>Quality  The experiments are clear and the results are easily understandable. In all three experiments, the paper achieves compelling results with low errors compared to baselines, especially for high number of time steps. I m a bit confused about the infinite dimensionality of the state observables and how the Koopman operator handles it, whereas in the Figure 2 shown the Koopman operator K looks like a banded diagonal linear operator. It is not apparent why equation (3) leads to the construction of the encoder decoder model shown. Some minor typos such as "on going" which should be "ongoing"Originality  This work uses a Transformer model instead of recurrent networks to perform dynamical system simulation. The paper also proposes using an embedding model.<BRK>Two main steps are described: Transformer model formarkovian prediction of time series, along with a Koopman inspiredmethod to learn embeddings of the state space. The interaction between the main training steps (embedding andtransformer parts) is not clear in the paper: pre training of theembeddings, followed by a fine tuning step (or not ?). This is anissue of the paper since this interaction is important for NLPapplications. Nevertheless, the ideas are really interesting. In the introduction, authors claim that : "Standard deep neuralnetwork architectures such as auto regressive, recurrent and LSTMbased models have been largely demonstrated to be effective atmodeling various physical dynamics (...) However, the current literature is focused on systems of limited complexity and domain size." It is maybe important here to better characterize the term complexity,why it is limited ? The notations in the section 2 are a bit heavy and maybe it could beeasier to follow one of the experimental example, without loss ofgenerality, to introduce the whole picture.
Reject. rating score: 3. rating score: 4. rating score: 4. <BRK>This is fairly obvious and does not bring in any insight. Thee reviewer strongly suggest that the author write it step by step to make it clear? Second, the empirical results are not convincing. The author needs to prove it.<BRK>In equation (5) it is not clear which $ \omega $ is being referred to. The paper provides theoretical motivation for variance regularization. Moreover, there is no indication that the Fenchel duality tricks are doing anything useful empirically.<BRK>The paper is not well written. What does it mean? Third, it is unclear why the proposed regularizer is suitable for offline RL.
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 5. <BRK>This paper explores matrix exponentiation as an alternative non linearity in a neural network. Experiments are provided on synthetic examples, and standard image recognition benchmarks in a limited setting and show some promise. Cons:1.I think the key factor missing in the paper is perhaps a lack of a solid motivation for using the matrix exponential. 4.The experiments are very limited, and networks that use convolutional layers are shown to significantly outperform the proposed non linearity. Post Rebuttal: Thanks to the authors for the detailed response.<BRK>I furthermore find the passages on dynamical systems and lie groups to be still lacking, for the same reasons as detailed above. I would argue that this is misleading, since the results in later layers of a deep neural network depend on the activations in a highly nonlinear way. The authors do provide some experiments to this end on swiss roll and meteorological datasets.<BRK>This work proposes a novel machine learning architecture (or M layer) that is in the form matrix exponential. This paper could test this setting on some larger scale benchmark such as ImageNet if possible. This work uses the results in Figures 2 and 3 to demonstrate it. Thank the authors for the detailed response. After reading the response and the comments of peer reviewers, the rating is altered as follows.<BRK>Pros:The paper is written in a nice easy to read way. The robustness result is something, but it follows from a very basic result on matrix exponentials. Section 3 is nice throughout ; simple and easy to follow yet interesting. Cons:I hate to be that reviewer, but the paper should go further to motivate the use of the expm function. To motivate using expm would require far more extensive experiments, even if this requires some heavy computational resources.
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 6. <BRK>My main concern for this paper is around several factors that I will list from the most important to minor. i) It is unclear to me when and how generator training should be biased according to the class label, which the authors do by encouraging the latent space to be predictive of the class/target label. Now this question is fundamental to me in terms of the goals of the counterfactual explanation. In the first case, I would rather see counterfactual explanations that are not in any way or form biased by the generative model, and hoping there is a perfect generative model that captures the entire distribution of the samples this model is supposed to generalize on. ii) This brings me to my second question around empirical evaluation.<BRK>The experimental part of the paper tests the proposal by using different datasets and some metrics that are adapted to their definition. Minor points:  To have a more complete overview of the topic I would recommend to include some papers related to the concept of "algorithmic recourse", which identify some limitation of the counterfactual explanation approach. This last point is not saying that to lie within or close to the data distribution of the training data is an undesired property for counterfactual explanations, but I miss a sounder motivation. For this reason, in order to check if the proposed methods represent a clear step towards "interpretability, a comparison with causal based counterfactuals is necessary.<BRK>This paper presents a new approach for generating counterfactual explanations. The authors conduct experiments on a number of real  and mixed valued datasets, which is welcome in a field where broad experimentation is historically lacking. References:The authors have missed a number of key citations. Moreover, in the introduction, the authors suggest that counterfactual explanations are being used for practical applications, and/or for bias reduction, both without citations. perhaps replace with "provides meaningful explanations as to what features would receive favorable treatment" (not actions). of the model" & "data distr. Perhaps I am mistaken.<BRK>Except for a few issues, the paper is well written and easy to followCons:  The results are not uniformly in favor of the proposed method when compared to the unsupervised approach applied by prior work, and to the authors’ credit, they acknowledge that in the text. I recommend that the authors consider discussing some of the works on counterfactual selection from those fields in their related work section.
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. rating score: 6. <BRK>Moreover, an additional analysis using influence functions leads to the hypothesis that  robust neural networks might have learned to classify using example based concept learning like in human beings. However, the paper s review of the transfer learning literature is superficial and misses some relevant related work such as "Rethinking ImageNet Pre training" by He et al., ICCV 2019. And more generally: if stronger transferability is mainly due to increased shape bias, wouldn t it make sense to pretrain explicitly for strong shape bias rather than achieving this indirectly via adversarial training as proposed in this paper? The main prior work is Shafahi et al.(ICLR 2020), which also studies transferring adversarially pretrained models to other tasks. In summary, I think the main hypothesis studied in the paper is original. One shortcoming is that all target tasks are image classification tasks. ### Recommendation ###In summary, I think the paper is a nice experimental study of a clearly stated hypothesis with potential practical impact.<BRK>This paper tries to investigate and understand if and how adversarial training helps the models trained on the source domain transfer easier and faster to target domains. With extensive different configurations (such as fine tuning strategies) in experiments, the authors show that robust models transfer better than natural models with less training data from the target domain. Strengths  The idea is interesting and have a potential for impacts in the community. Extensive experiments and investigations how and when the robust models works better than natural models is good to demonstrate the main ideas of this paper. Weaknesses  Even though it was shown by the experiments, it might need to have more theoretical understanding why the robust models transfer better or have better representations than natural models. In CIFAR 100 and (especially) CIFAR 10, fine tuning one conv. The target domains except CIFAR 100 and CIFAR 10 are all digit datasets, so its application to real world problems may be limited.<BRK>**Summary of paper:** This paper investigates how "robust" (adversarially trained) models can improve the transfer of representations, finding that they transfer better. **Originality:**   This is the largest potential problem that I am most unsure about. I m very familiar with work on statistical learning theory and generalization overall, but I m not an expert in transfer learning or adversarial method and I m not sure how well these works are reviewed, so I m not sure how novel this work is. The experiments are well done and well explained though, and I think this is a good contribution even if it is less original than it is made to seem due to the lack of context. However since all experiments are with images, I d suggest making the title and abstract specific to that domain. I like the conclusion as title format; I find it very engaging and helpful for skimming especially since there are many experiments.<BRK>Also, the paper conducts an empirical analysis of the trained models and shows that the adversarially pre trained models uses the shape of the images rather than the texture to classify the images. The analysis is interesting and insightful. Meanwhile, the transfer is done to the domain of lower complexity, and some important comparative ideas are not extensively investigated. 4, Reasons for Recommendation:The reader will benefit more from the paper if the authors can justify their use of adversarial training as the regularization in the pretraining process. I believe that this research warrants some comparative study for dropout, weight decay, as well as random perturbations.
Reject. rating score: 3. rating score: 6. rating score: 7. <BRK>Summary: This paper systematically presents a large scale empirical study on the disentangled representation learning when the underlying factors are possibly entangled. From the results of purely unsupervised settings, the authors have discovered the shortcomings of the existing metrics of disentanglement as well as the poor learned representations (in terms of disentanglement). However, with the help of small amount of factor labels or other weak supervision signals, recent approaches could learn fairly perfect representation. First of all, it is worthy to pay attention to the possible correlation between factors when you intend to learning a disentangled representation. And the whole empirical results are carried out by very large number of experimental batches, which to some extent could well support the conclusions displayed in the paper. As you have mentioned in related work, there were some papers noticed the too ideal assumptions of traditional VAE based models which may not be held in practice. IMO, the linear dependency between only two variables is far from reality as well. (2)	In line with the former limitation, diagnostics of the potential entanglement should also not be limited to pairwise level, which cannot scale up to high dimensional latent factors. (3)	The novelty of Section 4 is somewhat limited as all the correction methods and even some conclusions were proposed by the previous work.<BRK>The paper studies the behaviour of disentanglement methods and metrics on data where a couple of factors of variation (FoV) are correlated, a more realistic setup compared to the usual independent FoV setting in the literature. The paper shows how the correlation in the FoV is reflected in the representations learned by the models, and claims that the widely used disentanglement scores fail to capture these correlations. A couple of solutions that use weak supervision are suggested. I agree that this is an unrealistic assumption, and only holds for the synthetic datasets used in the literature. 2.The experimental evaluation of the paper is extensive3. The paper is presented clearly for the most part. However this argument ignores an important confounding factor, which is the behaviour of the models (trained with losses originally designed for data with independent FoV) when trained on a dataset with correlated FoV. Without understanding the behaviour of models after training, it is difficult to draw any conclusions from Figure 2. 2.I also have doubts regarding the conclusion itself, that all existing metrics fail to capture correlations in the training data. I think this only holds for some metrics and not for others. Suppose the representations that we are evaluating are the ground truth FoV values. Then the BetaVAE and FactorVAE metrics will give a perfect score regardless of the degree of correlation by design. 4.In Section 2, I think that the statement “it has been shown that purely unsupervised learning of disentangled representations is impossible (Locatello et al., 2019b)” is a wrong interpretation of Locatello et al.They show that optimising marginal likelihood in a generative model (such as a VAE) cannot achieve disentangling without any inductive biases in the model. In Section 4.2, the claim “This kind of extra knowledge is often available at no cost , e.g., in temporarily close frames from a video of a moving robot arm where some factors remain unchanged” is unjustified. We still need to know the number of factors that have changed, which usually requires human labelling8. The weak supervision for the correlated FoV when applying Ada GVAE relies on being able to generate data where the correlation is broken, which seems like an unrealistic assumption. The authors seem to address this by assuming a causal relation between the two factors. Overall the paper does address an important problem in the disentanglement literature, but the conclusions drawn from the extensive evaluation are either unsurprising or unjustified. It might be helpful to also look at the disentanglement metrics for just the two correlated factors, to further highlight the differences between different models.<BRK>The paper conducts a large scale study to investigate whether statistical correlation prevents learning disentangled representations (according to human defined ground truth factors of variation). Pro:This is a timely contribution to clarify problems in evaluating disentangled representation learning algorithms. The paper argues that assuming statistical independence is unrealistic, in practice factors of variation are often causally independent but statistically correlated. This seems like an important missing piece in current empirical evaluation benchmarks. There are several interesting observations: 1.The existing metrics for disentanglement do not apply to situations with statistical correlation between the factors of variation. New metrics will be needed. 2.For correlated factors of variation, even though disentanglement fails, the latent space still extrapolates to never seen combinations. 3.Several semi supervised or weakly supervised methods for disentanglement work well when the factors of variation are correlated. Con:Section 3 and 4 are a little hard to follow. There are many results with no clear logical connection to each other. Maybe it’s better to have some bullet points of the empirical findings, then point to specific paragraphs that explain the empirical methodology that produced these findings.
Reject. rating score: 4. rating score: 5. rating score: 6. rating score: 8. <BRK>2) The paper needs to improve its preciseness and clarity. This also hinders readability of the section where the authors introduced their own method. I do believe it is an interesting approach. "it induces a generalizable equivalence relation between data, and the manifold structure of out of sample data can be derived by taking the quotient of this relation" (Introduction): What is a generalizable equivalence relation between data? The paper mentions that a multi generator scheme is used but there are no more details than that.<BRK>The authors propose a method to train deep generative models on quotient manifolds and show improved performance on some simple standard test sets. Overall I find this an OK contribution, but it would be strengthened by either giving more sharp theoretical results or by using more up to date experimental methods. This isn’t really state of the art (almost everyone does resnets). The baselines are old, and for some of them I know for sure that there are better results available out there.<BRK>This is not obvious and need to be properly defined. To me, this needs further investigation, and while reading the paper, I thought some interesting ideas will come up during developing non linearity. Although the design using quotient structure is interesting, the choice of sharing same vertical component is a easy consequence of principal fiber bundle theory. Can authors comment on that? 4.The experimental setup is a bit under developed.<BRK>The paper proposes QMM, a new generative modeling scheme that inherits the multi generator scheme but involves an essential regularizer enforcing the encoder compatibility. QMM considers generic manifold structure by the generalizable equivalence relation between data, thereby taking the quotient of this relation and driving the manifold structure of untrained data. A major difference in this paper is that the additional regularizer enforcing the encoder compatibility and the quotient of the plausible equivalence relation.
Reject. rating score: 5. rating score: 5. rating score: 7. <BRK>The main contribution of this paper is a combination of graph neural network embeddings and RL to guide the search more efficiently. While the figure serves the purpose of illustrating the exploration idea, it is a bit confusing. This would cause issues to the branch and bound policy, but nonetheless it is interesting to think whether your method can be adapted to this case within a different search framework? Have you performed experiments on the latter two settings? The authors motivate their problem with applications in drug discovery, chemoinformatics etc. While this fact does not render the contributions of the author(s) useless, it does reduce their value in terms of application domains, that are not appropriately discussed in the paper. Overall I found the paper to be interesting, but there are some non trivial issues that need to be better addressed.<BRK>The motivation of this paper is clear and interesting, as it’s important to explore the maximum common subgraph in biochemical domain. In this paper, the authors conduct a lot of experiments to demonstrate the effectiveness of the proposed method. Despite of this, the presentation of this paper requires improvement because many important details are missing, which makes it hard to follow. It might be interesting to see whether the proposed method greatly reduces the search time compared with state of the art algorithms as the number of nodes increases.<BRK>The paper deals with the problem of Maximum Common Subgraph (MCS) detection, following a learning based approach. Definitely, most heuristic baselines might not be able to scale to graphs with more than a few thousands of nodes, but I would be expecting to consider some large scale network containing a few tens of thousands of nodes for the evaluation of GLSEARCH. Besides, the supplementary material describes in detail most of the aspects of the paper. The ablation study is interesting and demonstrates that the chosen architecture of GLSEARCH has consistent behavior.
Reject. rating score: 3. rating score: 6. rating score: 6. rating score: 7. <BRK>The authors of this paper study opponent modelling in partially observable Markov games, following the _centralised training, decentralised execution_ paradigm. In particular, during training the assume access to all agents  (both ego and other agents) local observations and actions, while at test/execution time they control the ego agent with only local information. The authors show empirically that their method perform competitively in a set of standard multi agent environments. The claims about novelty and comparison to literature is questionable. The authors **do** use non local information during trained to train their VAE, an idea that is very much common in the "centralised training, decentralised execution multi agent paradigm, i.e., Dec POMDPs". 2.How does the proposed method do compared to standard Dec POMPD solvers, e.g., [1 4]? Counterfactual multi agent policy gradients. Social influence as intrinsic motivation for multi agent deep reinforcement learning. In International Conference on Machine Learning (pp.3040 3049).<BRK>This paper considers an algorithm for learning and using an opponent model that is only conditioned on an agent s local information (history of actions, observations, and rewards). The authors show that with static opponents, the output of the encoder is informative, and conditioning the agent policy on local information plus encoder output outperforms just using the local information. The paper was well written, and was to easy follow. Like Reviewer 4, my view of MARL is more general than requiring all agents to be learning, even if most work does have one algorithm training multiple seats. I don t think this actually changes anything in the current draft, but should hopefully not appear in future edits. The related works should include discussion of the HiP MDP paper. It doesn t seem relevant whether or not the unobserved, unknown variables correspond to different but similar environments, or different but similar opponents in a single fixed environment. +++Section 4.2 "In Sections 1 and 2, it was noted that most agent modelling methods assume access to the opponent s observations and actions both during training and execution. I m trying to get some idea of the magnitudes of the rewards, which are based on Euclidean distance.<BRK>Each agent has access to local observations only but is still required to cooperate with opponents (which use either heuristic or stochastic RL trained policies). In each instance of the environment, the agent considered interacts with single opponent, drawn from a fixed set. Overall, I find this to be a well executed study of learning opponent models with a VAE. The write up is clear and easy to follow, and the experiments show good performance of the method, along with a base  and topline. I m however a bit surprised by the poor performance of the NOM baseline on the speaker listener environment. Some suggestions for further improvement:  I found Figure 1 confusing as I understand that the actual opponent policies do not have access to the latent variable Z, and that three items are predicted from the latent space: the opponent s actions, observations and rewards. For LBF in Figure 3, I would suggest that the authors expand upon the fact that there is no discernible structure in the opponent embeddings. I would also suggest to clearly state the dimensionality of the learned embeddings in Appendix D   from the current text I would assume it is 128?<BRK>Positives:  The paper is well motivated and clearly written. I found it easy to read. The problem is significant and the approach is a natural fit. In other opponent modelling work, I ve seen opponent aware agents do *far* worse than a baseline agent in those settings. Recommendation and Justification:I think the paper should be accepted. I m not listing these citations as a suggestion to cite them (they are related to this work, and the topic is much broader and longer than the papers cited by the authors, but this paper is fine without the particular citations I ve listed above). In the intro the authors describe using  opponent  as a neutral term to mean  other agents in the environment , and I m sympathetic to that as I ve encountered this awkward phrasing in my own work. In Level based Foraging, do agents observe their own level? In an *actual* adversarial setting, even if the opponent s policy was static (i.e., not updated in response to LIOM s policy, as in the cited Ganzfried papers), the opponent could still exploit any mistakes LIOM might make through its static policy, possibly driving its performance below that of NOM. This technique focuses on the creation of a portfolio of useful counter strategies for use against a broad set of opponents, such that at least one counter strategy will be effective against any particular (and previously unknown, not trained against) opponent. I found this to be very good for supporting the main claims of the paper. However, I would really have liked to see even a small investigation of robustness, even with static opponents (e.g., not with adapting opponents or worst case opponents as in the Ganzfried and Sandholm papers cited in the conclusion, although I agree with the authors that that would be a great next step for future work). If not, best to note the differences. Does it do *worse* than NOM, by making painfully incorrect assumptions about the opponent? I suggest abbreviating it in the description.
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 6. rating score: 6. <BRK>Summary:This work proposes a fully explored masking strategy, which maximizes the Hamming distance between any of the two sampled masks on a fixed text sequence. The motivation is to reduce the undesirable large variance of MLM objective, based on the hypothesis that randomly sampled masks in MLM would lead to undesirably large gradient variance, which as a result typically hurts the training efficiency with stochastic gradient optimization algorithms. Strength:The hypothesis from the variance reduction is interesting. It might be better to tighten them and put the proofs in the Appendix into the main body of this paper. Why not using a larger model (e.g., Roberta large)?<BRK>To reduce the variance due to the sampling of masks, the authors propose a fully explored masking strategy, where a text sequence is divided into a certain number of non overlapping segments. And they show this technique improves accuracy in downstream tasks. This idea is novel and interesting to me, and the derivation and experiment results look encouraging. Below are my major concerns:If the major motivation is to reduce gradient variance, can we just use larger mini batch size? In the experiments, it is not reported that the learning rate or the mini batch size is well tuned for the baseline. I d like some confirmation that larger batch size won t get much improvement for the baseline model. It ll be good to have some ablation study of the combined effect of using only one data sample in a mini batch, and the full explored masking. In experiments, mainly accuracy is shown, but since the major motivation to reduce gradient variance, why not show some comparison of gradient variance of MLM and MLM FE? ", do you mean Table 3? Do you mean the expected hamming distance? Or we are assuming x is fixed? Please be more clear.<BRK>The paper argues that randomly sampled masks in masked language model can lead to large gradient variance, and hence it proposes a new masking strategy called fully explored masking with theoretical support to reduce the variance. 2.The proposed masking strategy is empirically compared with random masking only. However, there are no empirical results to *directly* support the claim.<BRK>This paper try to improve Masked Language Model pre training by reducing the variance using a new masking scheme. Pros:1.It is very novel and interesting that the authors try to understand the training of MLM by analyzing the relation gradient variance and masking scheme. The performance improvement under continual pretraining and BERT pretraining looks good to me. 2.It would be better to validate the assumption by comparing the gradient variance between MLM training with and w/o the new masking scheme. 3.It is not clear to me how Theorem 1/Assumption 1 motivates the new masking scheme. What does it mean by " The covariance $Cov(g(m1),g(m2))$ is monotone decreasing in terms of the Hamming distance"? Minor:1.The text in Figure 2 can be larger. 2.Last paragraph on page 4: in terms od  > of<BRK>A modified version of MLM is proposed, which has been shown with a smaller gradient variance than the standard MLM. The experimental results show that the new masking strategy does lead to some gains on several benchmarks. This is a very interesting observation and it is nice to see that this can be proved mathematically. This paper is well written and very easy to follow. ### Weak Points  This paper is based on several important assumptions, none of which has been proved mathematically (although there are some empirical evidence)   + Assumption #1: the model quality can be improved by reducing the variance of the gradient. + Assumption #2: the covariance of gradients can be reduced by increasing the Hamming distance between two different masks. The empirical gain of the proposed method seems to be quite small. ### Other Comments  Honestly, I don’t quite see why the proposed method is related to continual pretraining, and why should it be included in the experiment section.
Accept (Poster). rating score: 7. rating score: 7. rating score: 7. rating score: 6. <BRK>By jointly modeling a mapping to continuous latent space, and the likelihood of flows CNF solves some of the bottlenecks in current algorithms. Reasons for the score:I vote for accepting the paper, with minor improvements. This would help with the readability of the paper, and improve understanding. Strengths:+ The CNF framework helps scaling normalizing flow based approaches, and improves the stability and performance on standard benchmarks. Adding some visualizations/samples from the learned models would help with clarity of section5.<BRK>In particular the paper presents a new approach for normalizing flow on categorical data. Then a three step generation approach is presented for graph generation with CNF. The first results on molecule generation are very good when compared to those obtained with other approaches.<BRK>### Summary:This work uses the idea of variational inference to map categorical data to continuous space affording the use of normalizing flows. Several sections are well written and have a nice natural flow. I find the application to graphs an excellent use of the multi scale architectures in coupling based flows and compliment the authors for the superb visualization in Figure 1. The term "overall encoding distribution" is unspecified in the paper,  and I am skeptical of the use of "true decoder likelihood." Is it because we work under the assumption that the KL divergence is negligible?<BRK>(+) Truly permutation invariant NF for graph generation is great. Existing flow models for graphs do not handle the categorical data in proper manners and are permutation dependent. A graph generative flow model is proposed as an application. I have a few questions to confirm my understanding of the paper.
Reject. rating score: 5. rating score: 6. rating score: 6. rating score: 7. <BRK>The first version, named Unbalanced Gromov Wasserstein (UGW), is a direct application of unbalanced optimal transport (UOT) to the setting of Gromov Wassertstein. The second version, named Conic Gromov Wasserstein (CGW), is an extension of the conic formulation of UOT to the setting of Gromov Wasserstein. Finally, the authors also provide some experiments with their proposed divergences. In my opinion, the two proposed versions of Gromov Wasserstein are quite interesting but lack novelty. The theory of CGW also does not appear deep enough for me to appreciate the contribution. (4) The literature of using UOT as a robust version of OT in practical applications of deep generative models and domain adaptation has been considered recently; see for example the paper [2].<BRK>The paper introduces a novel unbalanced Gromov Wasserstein type problem. Following previous works on unbalanced optimal transport (i.e.soft constraints over marginals enforcement of the coupling matrix), and the rationale that disposing of unbalanced versions of transport problems can alleviate in some ways presence of outliers or noise in the distributions, the authors propose two ‘unbalanced’ variants of the Gromov Wasserstein (GW) problem, that allow comparison of metric spaces with arbitrary positive measures up to isometries (I.e.rigid transformations). The paper is fairly well written, original, and the related works is particularly complete. Finally, the weakest part of the paper is the experimental Section. Only two toy examples are presented. While the method could have been used in many settings (graph classification, embedding matching in NLP or  even graph matching, for which many algorithms exist, etc.), it is very hard to conclude about the practical interest of the method. This claim is a bit strong knowing that GW has already been used in several (cited) applications.<BRK>The paper proposes an algorithm for solving the upper bound version, and shows proof of point experiments on very simple 2D settings. Despite some shortcomings in novelty, experimental evaluation, and presentation detailed below, I find the theoretical contribution of this paper to be just enough to carry it, so I m (weakly) recommending acceptance. The flip side of strength (1) is that the novelty of this paper is arguably limited, considering it builds on known techinques, and is addressing a problem that has been tackled in at least two recent works (De Ponti & Mondino 2020, Chapel et al.2020).2.Some of the assumptions and results are not discussed in enough detail3. In particular, none of the motivating applications mentioned in the introduction (NLP, chemistry, graph matching). 2.I understand that Lemma 1 is a tool to draw a connection between the two approaches, but I find its introduction dry and abrupt. There is no comparison to other unbalanced methods (either OT or GW) except for one setting in Fig 3.<BRK>The authors consider the Gromov Wasserstein (GW) problem for metric measure spaces having different masses (i.e., Unbalanced GW). Similar to the ideas of unbalanced optimal transport (UOT), they proposed to use a quadratic divergence to relax the marginal constraints (instead of divergence as in UOT). Additionally, the authors also propose a variant of UGW, namely Conic Gromov Wasserstein (CGW) to address the different masses of metric measure spaces. The authors propose that CGW has nice properties (Theorem 1). + It is easy to follow the paper. + It seems that the experiments are quite simple (with some toy examples). Could the authors give more motivation/explanation about this approach, why not just divergence as in unbalanced OT (Although the GW is a quadratic assignment, the unbalanced problem for GW comes from the marginal constraints, why not just simply use the divergence between the marginal and measures)? + The authors proved nice properties for the proposed CGW and draw its connection to UGW.
Reject. rating score: 3. rating score: 4. rating score: 6. rating score: 7. <BRK>* Comparing first and second order optimisers on a per epoch basis as in Figure 1 does not seem practically relevant to me, a wall clock time comparison would be of much higher interest to most potential users. This issue aside, both the package and the paper appear rushed to me and **not ready for publication**. In general, I think that for a utility library it is best to assume that users have an established workflow of constructing and training their networks (unless the point of the library is to simplify that workflow, but this does not seem to be the case here). I would rather see that space used to go more into depth with the examples.<BRK>### SummaryThe paper presents a library for second order analysis of the optimization of models implemented with PyTorch and potentially having millions of parameters. ### UPDATEThe presentation of the paper is now convincing, with the background, contributions and concepts clearly stated. I hence increased my score. However, I agree with reviewer 2 that the library is not properly tested (I understand it can be hard to test the whole computation, but unit tests could be easily provided) and that it would have a higher impact if it were more modular, so that a user could easily add the loss analysis directly in her workflow.<BRK>I believe that the developed package can be a good contribution to the machine learning community, especially for people working on second order optimization and understanding the training dynamics and generalization performance of deep neural networks. Can you provide more details about this? In the meantime, the authors should highlight more on the difference between your package and the existing implementations. Rating:  This paper did a good job of introducing the package with detailed examples. Also, this package will definitely ease the effort of researchers in related areas to compute the second order information of the neural networks.<BRK>###Summary:This paper proposes a software package to ease and provide a standard way for Hessian related computation, both for loss analysis and second order optimization. How easy is to use it with an arbitrary Pytorch model? Could you elaborate on this point?
Reject. rating score: 2. rating score: 3. rating score: 4. rating score: 5. <BRK>This paper purports to be about Hybrid vehicle fuel optimization using RL. The results seem fine but not enough to justify this paper for ICLR as a deep and original contribution on learning representations. Where is novelty in the rest of this section?<BRK>The organisation of the paper is difficult to follow and I may havemissed some of the arguments the authors are making. This has no impact on technical rating of the paper and it does not directly   contribute to the review score.<BRK>This work proposes a deep reinforcement learning based optimization strategy to the fuel optimization problem for the hybrid electric vehicle. The paper is very convoluted, with lots of different novelties, making it hard to understand the main contributions and how much each of the contributions truly affect the final results.<BRK>This paper proposes a reinforcement learning framework for the fuel optimization problem in hybrid electric vehicles.
Reject. rating score: 5. rating score: 6. rating score: 7. rating score: 7. <BRK>This idea is related to the classical notion of an "affordance" from Gibson. The main problem I have with the paper as it stands is that it s not clear what the overall goal of the work is. A minor problem is that the method used appears to be entirely standard, so it s unclear what the technical contribution is. A further minor problem is that there is a whole related sub field of computational linguistics which has been investigating a similar problem for decades which is ignored in the discussion. The main problem: is the goal to develop a psychologically plausible cognitive model? But if the latter, how would the knowledge be used, and by what sort of AI system? Is the knowledge to be used by a text based system (if so, how) or by a situated agent interacting with an environment (in which case it needs explaining how the knowledge could be grounded in the agent s environment)? The minor problem is that factorisation of the co occurrence matrix appears just as standard as the other methods compared against, eg in sec.4.1.So why are the other techniques any more baselines than yours? The further minor problem is that the sub field of acquiring selectional preferences in computational linguistics looks to be solving the same problem as what you have here. This paper from 2010 is a good one to look at, and has lots of relevant references:Latent variable models of selectional preferenceDiarmuid O SeaghdhaACL 2010More specific comments we show that the dimensions can be used to predict a state of the artmental representation of objects   it s not clear that therepresentation itself is s o t a; I suspect you mean that you obtaineds o t a performance on an existing object representation dataset. when describing the various datasets, eg sec.3.1, some examples wouldhelp. The resulting list has 2541 verbs   not sure whythe number is in bold.<BRK>The authors design a distributional word embedding method inspired by Gibsonian theories of perception. * Gibson (2014) citation should be Gibson (1979). They argue that the learned representations are interpretable, and that this affordance space "underlies the mental representation of objects." ## Post rebuttal responseI have read the other reviews and the authors  extremely thorough responses — much appreciated! 1.The claimed "affordance space" is not falsifiably \*about\* affordances in any deep sense. While the original data matrix linking words and their associated attested verb combinations clearly gets at possible event object interactions, the factorized affordance space doesn t necessarily have this property. Third and possibly most importantly, table 2 confirms that "structural" and "appearance" features are some of the best predicted features from the affordance space.The authors may argue that the set of English verbs used in the raw matrix are not the right basis for affordance knowledge, and that the factorization leads to a better abstract/conceptual affordance knowledge representation less tied to linguistic productions. But this claim about the content of the factorized representation needs to be articulated and substantiated with tests of alternative hypotheses.As a quick analogy in case my point isn t clear: you might learn word embeddings on a Wikipedia dump by factorizing a matrix of word Wikipedia topic co occurrence counts. What do you think about this premise/issue? (I agree that it s nontrivial that a corpus derived representation would suffice here, but I don t find it interesting that it outperforms other more general / less task specific corpus derived representations.) SignificanceThe aim of this paper is not clear to me. It cannot argue for a superior system of word representation, since it does not evaluate these representations on any broad evaluation tests. It also doesn t make a convincing cognitive argument about the content of mental representations, given the conceptual and methodological issues in evaluation 2, discussed above. (A convincing cognitive argument would also need to draw on data from human behavior beyond the sort gathered on AMT, or possibly neural evidence; see Mitchell et al.(2008) as an example.) OriginalityBecause I haven t closely followed the relevant literature, I can t speak to the originality of the embedding method. I would be more motivated to let this slide if the paper were stronger on the experimental / analytic side.<BRK>Summary:This paper attempts to learn embeddings for objects based on their affordances i.e., verbs that could be applied to them to realise their meaning. Here each dimension corresponds to an affordance or an aspect of meaning shared by actions, thus allowing a correspondence between nouns (objects) and verbs (their affordances) based on co occurrences in text corpora in which they exist. Empirical results show that these embeddings allowing prediction of a “mental representation” of objects (i.e., in comparison to human given annotations of dimension “semantics” in embeddings) and a qualitative analysis attempts to show how interpretable the objects are. Reason for score:This paper approaches an interesting problem, but is not well placed in literature and has missed previous work that attempts to do almost the same thing; however from a different angle. I thought the question and problem was interesting enough, but given the missed references and existing embedding learning work, there is limited novelty in this approach. However, I think the results are interesting enough and the authors did a really nice job of qualitatively analysing the representations (and additionally, it would be good to see further discussion of use cases of this e.g., instead of just a verb ranking task), so my score is fairly positive overall. This paper is well written and the methodology is clearly explained. 2.The empirical results show that verb rankings obtained by these embeddings outperform all previous embeddings (however those were not learned with this objective in mind, but just tested on the verb ranking task). It is also further restrained given that novel verbs (unseen during training) may not be accounted for. 4.The correlation results don’t have statistical significance tests/metrics and that would be helpful to see. This seems important given that subword embeddings are now used (and perform better) for most of the best performing models, so if a method that allows better object verb disambiguation could be used to kickstart tasks that require subword embeddings, that would be helpful to see!<BRK>They further show that the novel representations correlate well to a set of interpretable representations that were obtained via human judgements of object similarity. A method of learning an embedding of objects from an unannotated text corpus which is infused with a degree of knowledge of object affordance. The proposed approach is simple and does not require any form of complex annotation. This enables the consideration of a large set of verbs compared to approaches which are based on manually created datasets. 2.The analysis of interpretability is well thought out. What is the significance of the proposed method, beyond its ability to predict a different set of representations? If these representations are meant to achieve a new state of the art, the evaluation is too limited and fails to include common methods in the literature, such as contextual embeddings. [This has since been addressed]2. Given the existence of methods that make use of visual features to predict affordances, I would have liked to see some form of comparison between image  and text based methods. ## Response to commentsI thank the authors for their comments and their revision, which have clarified the aim of this work. Having read the authors  responses to this and other reviews, I realize that in my initial assessment I had misjudged the nature of the manuscript.
Reject. rating score: 5. rating score: 5. rating score: 5. rating score: 6. <BRK>This paper studies federated learning with quantization. The problem setting is very standard, including both iid and non iid cases. The presentation of the paper is generally good. 1.The convergence analysis is based on the assumption that the problem is strongly convex. But from the motivation of this work and numerical results, the problems would be nonconvex. 3.The comparison with double squeeze is definitely not fair, since the aggregation rule of the double squeeze did not consider the \tau step local update. 4.The numerical results are very limited, where the CNN network is very small. There is no need to perform quantization for this neural net.<BRK>In the setting of Federated Learning, the authors propose to quantize both (1) the model send from PS to devices, and (2) the update from device to PS. The authors further show the effectiveness of their proposed algorithm, LFL, by offering a convergence analysis under appropriate conditions, and offering thorough experimental evaluations. Pros:+ The authors show convergence results under the strong convex and smooth condition, making this work more theoretically grounded than previous related work. I believe there are some challenges or tradeoffs to do the PS to device directions, but the authors did not sufficiently address this in the paper. This double quantization will inevitably lead to larger quantization variance, and therefore slower convergence of the model, especially when we are close to the end of the learning. + The contribution is not clearly highlighted in the theory nor in the simulation. I would recommend the authors conduct another set of experiments, maybe in the future, to take random devices join/drop out into consideration. There should be a join/drop out probability thresholding, below which LFL is more efficient than the previous work, and above which LFL is less effective. + What is the architecture the authors used to conduct the experiments? And how the communication cost is evaluated?<BRK>In the paper, authors propose a novel quantization algorithm to reduce the communication cost between server and clients in federated learning, where the communication are limited and unstable. The following are my concerns: 1) In practice, it is not guaranteed that devices don t change in a certain amount of federated rounds. Since the target of the paper is to reduce the communication cost, the authors should perform experiments and investigate the effect of new participated devices. 2) It is better to show the convergence regarding the computational time and communication time. MNIST and CIFAR10 is a little bit weak to prove the effectiveness of the proposed algorithm.<BRK>This approach helps reduce the communication cost of federated learning and is in particular useful when the communication bandwidth is limited. My main concern is about the justification of the assumption and I hope that the authors can address this in the rebuttal. For me, it is not clear how this assumption reflects the practical scenarios. For Figure 1, it would be better if some reasons could be presented that the performances of LGM and LTGM tend to change differently over iteration for non iid and iid data. I think this would help to understand the strength of the proposed method.
Reject. rating score: 5. rating score: 6. rating score: 6. rating score: 6. <BRK>The paper studies membership inference attacks (MIA) in the context of conditional image generation models, i.e., models learned for image to image translation. The problem aims to detect if a data sample is used to train a neural network model. From the context, it seems that the proposed method will fail if the victim model is not trained to be overfitting. The paper designs a difficulty score to augment reconstruction error based method, and shows MIA results on multiple datasets. Eq.(3): The paper considers "difficult" training images and "easy" unseen images, but does not consider "difficult" unseen images. For the unseen images that are difficult to reconstruction, does Eq.(3) still work? Figure 5: How to tell if "difficult score" is better correlated to the reconstrunction error than "supervised difficulty"? post rebuttal I appreciate that authors have provided rebuttal that addresses many of my questions. I ve read the updated paper and other reviewers  comments. However I am still not convinced by the following.<BRK>This paper aims to solve the problem of membership attack, ie detecting if data samples were used to train a neural network for conditional image generation. The paper first proposes a simple but effective approach by using the reconstruction error. Issues:  The novelty of the proposed algorithm is limited: the reconstruction error is quite standard, and the difficulty score is not well explained. While the title of the paper is "conditional generative models", the experiments are only conducted on segmentation to image translation. It will be important to show how it works in other related applications.<BRK>This paper explores the MIA in the scenario of I2I translation and proposed a difficulty scoring function by observing that simply borrowing the MIA techniques from classification task is less effective. Below are some of my concerns and suggestions:(1) The data used for training the regression model is the same with the one used for training the I2I model? It will be better to analyze this partition ratio and see how the MIA accuracy will be affected. An interesting direction is to explore whether it will be more useful in few shot case, not only to detect whether overfitting happens, but also to explore how to use MIA to avoid overfitting and make the model trained with less data more robust. Update:Thanks for the author s feedback that clarifies my concerns. Adding the difficulty score into training looks like a more promising future direction.<BRK>This submission focuses on the problem of membership inference attack for conditional image synthesis. It is straightforward to use reconstruction loss as a measure for membership error. However, the authors pointed out that on top of reconstruction loss, the difficulty for the sample should also be taken into account. The error of the prediction is use as the indicator of difficulty. This is an intuitive method and from the results of the experiment, the proposed method seems to be quite effective. The reviewer would like the author to clarify a few points: 1) is it an assumption that the pre trained network has never seen any data used in the testing? 2) Wouldn’t it be more application/problem specific to train a regressor using the data the victim model is conditioned on (e.g.the segmentation mask) to predict the pixel values of the ground truth image in estimating sample difficulty?
Accept (Poster). rating score: 7. rating score: 6. rating score: 5. rating score: 5. <BRK>Summary: The output of the work is an MDP model that is capable of encoding complex traffic rules including traffic signals, lanes, right of way FIFO etc. The MDP that results from this work is very useful for future research. Therefore, the possibility of new simulators resulting from this MDP is exciting and useful to encourage and promote research in autonomous driving, especially in dense and heterogeneous environments. I am glad that the authors have provided the source code **with extensive documentation and instructions** on how to run the code and reproduce the results. Unless there is some major flaw with this paper (that I may have missed), there is no reason to reject this paper.<BRK>This paper investigate how to design simulation environments so the the agent trained with them can master social rules. Cons:1.The paper is well written and easy to read and understand. The authors seems to only considered the noise of sensors and the number of agents, and these two factors happened to induce social behaviors like following lanes and stopping at traffic signals. In other words, I am not quite convinced that with all vehicles being automated, sensor noise will cause them to formulate rules that what human drivers follow today. Since human driving interactions are complex, I do not think that sensor noise would be enough to induce them. 2.I would be happy to see how this configuration of simulation environment compares with reward guided social behaviors. For example, we can design a reward to encourage agents follow right of way. I think this way might be more direct and powerful. 2.The number of agents seems to be too small and may affect the formulation of road social rules. 4.Figures 2 and 3 needs better explanations for readers to understand. Overall, I think this paper needs better formulation of the logics and also a deep investigation of how the simulation variations lead to those behaviors.<BRK>The paper proposes to learn traffic rules (e.g.traffic lights, speed limits) via multi agent RL (MARL) from observations rather than hardcoding the rules into the algorithms. Conclusion:This works provides an interesting new problem statement and explores the area of using MARL for autonomous driving. My main concerns regarding this paper are the lack of comparison to prior works in the experiments, and the work provides any usefulness and improvements over current autonomous systems, which are mostly based on imitation learning. Experiments show that road rules can be learned. I must admit that I am mainly a computer vision person, and I only have limited experience with RL or MARL. And as the authors stated, the majority of multi agent behavior works have been using imitation learning. The proposed PPO based method seems a good alternative. I don t see any evidence why solving the proposed problem using MARL is better than IL. With other words, if there are no other agents to demonstrate how to behave, the agent will always prefer to run over red. This raises the question of the usefulness of the system. Lack of novelty in the method itself: The paper seems to be using an off the shelf PPO. The bi level extension is a straightforward way to optimize two objectives at the same time, which is quite common even in the ages of convex optimization (https://en.wikipedia.org/wiki/Biconvex_optimization). I think that there __is__ novelty in the method, but I am not sure if it s enough for this venue.<BRK>Summary:This paper proposes a bilevel MARL method that can learn road rules and conventions implicitly without hard coding. It is quite interesting to see a simple and straightforward idea that is effective in this task setting. However, this paper needs to be further polished in terms of its delivery, completeness, and evaluation. In Spline Model, does the trajectory shape only depends on the initial state without considering the afterward interaction? The equations, terms, and the algorithm in Section 4 need sufficient explanations. E.g., what are vf^{target}_t, H, K_1, K_2, N? Experiments:It seems the route is relatively short, and the driving scenarios used for different tasks are distinct. I was wondering whether the generalization of the proposed method and the learned rules could be validated. No baselines have been evaluated or compared. What are the differences between the two models in the results? What do the colors mean in Fig.2?My rating has been updated after the rebuttal.
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 6. <BRK>Murphy can handle unknown interventions as well. To fit to the interventional data, first, the interventional target is estimated by a heuristic approach and the contribution of these variables to the likelihood is ignored since they are set by the experiment. Why not use the existing methods? Note that the objections I (R1), and I believe also R3 and R4, have are not about theoretical vs. experimental research and that the paper lacks proofs or identifiability results. I hope this will help the authors in improving their paper. I am not going to take this work into consideration in my evaluation since it is uploaded on arXiv only very recently.<BRK>The authors propose a method for structure learning from observational and interventional data that uses a continuous optimization method. It is known that in this case, Interventional Markov equivalence class is the extent of identifiability [Hauser and Bulmann, 2012]. In the Appendix, it is mentioned that the method typically requires 500 2000 iterations and 100 interventions per iteration. Unfortunately there are no results in the paper about what the output of the algorithm will actually be.<BRK>This paper aims to extend the continuous optimization approach to causal discovery to handle interventional data as well as observational data. It describes a method for learning the causal structure over a set of categorical variables and reports strong empirical performance. However, no theoretical guarantee or analysis is provided, which is a significant weakness in my view.<BRK>The authors suggest an iterative method, that builds on the widely accepted do formalism. The approach suggested fits the network before interventions, simulates the intervention on the fitted network and then again assigns a likelihood score to the network parametersThe paper concisely describes a novel algorithm used in the notoriously difficult problem of causal structure learning. 1.The definition of interventions is done extremely briefly, (sec.2), however in my opinion the choice of definitions used here would justify some accompanying examples for clarification (this would help especially to understand what is meant with "infinite intervention regimes" (sec.4) 2.The assumption "no control over interventions" is not clear per se, here it would help to understand what the omittance of this assumption would imply. 3.A clarification, why "the interventions can either be known or unknown", provides a relaxation of the formulation used (sec.4.2) would be useful
Accept (Poster). rating score: 7. rating score: 7. rating score: 7. <BRK>Summary:The authors combine several cryptographic techniques to create a federated systems that allows several entities to run classification against all the model held be the participants without revealing information in the process. In particular, the sample to be classified is not revealed to any other party, and differential privacy is used to protect the training data that was used to train the models. This seems to be related to the usage of (unbounded) integer secret sharing. Would it be possible to use secret sharing modulo an integer, in which case the security could be perfect? I find the term collaborative learning somewhat overblown because the proposed protocol only runs classification collaboratively. Overall:Despite the points above, I m in favor of acceptance because the paper seems to improve on previous work, and because it is written very well.<BRK>This work motivated by healthcare and finance where separate parties may wish to collaborate and learn from each other s data but are prevented from doing so due to privacy regulations. This paper propose Confidential and Private Collaborative (CaPC) learning, the first method provably achieving both confidentially and privacy in a collaborative setting. This work also discussed about fairness. I liked this part, since it seems very cool.<BRK>This paper works on the problem of collaborative learning while preserving both confidentiality and privacy of the data points. It combines techniques from secure multi party computation and differential privacy for the same, and improves on confidential inference and PATE in the process. The new technique is called CaPC. So, it is a little hard to judge whether the techniques would generalise or not. 2.The algorithms they provide improve on fairness.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. rating score: 6. <BRK>This is a little outside my area of expertise, but I found the paper interesting, proposing a different approach to dynamic convolutions based on matrix decomposition which requires fewer parameters to achieve similar accuracies as baselines while converging slightly quicker. The key ingredient is dynamic channel fusion which replaces softmax normalized attention as a mechanism used to combine information from different channels. The experiments look convincing and the results are somewhat useful, although additional work may be required to reduce the computational complexity (along with the number of parameters as shown in this work).<BRK># Additional Notes**Abstract:** *"[we] reveal the key issue is that dynamic convolution applies dynamic attention over channel groups after projecting into a higher dimensional intermediate space. I initially had trouble understanding why SVD was used to motivate the proposed method, and initially also struggled to understand what the paper meant by "dynamic channel fusion". This needs to be explained more clearly. It would be helpful to add a citation for this claim, or a forward reference to supporting experiments.<BRK>Authors presented a new perspective of matrix decompoistion to understand dynamic convolution and further proposed dynamic channel fusion which achieves both dimension reduction and good training convergence. Extensive ablation study and experiments give good insight of the proposed method and helps understand its advantage.<BRK>This paper proposes a technique to reduce parameter count and improve training stability for dynamic convolutions using matrix decomposition. The experimental results of the paper can be improved by demonstrating the benefit of this approach on additional and more advanced mobile architectures, such as MobileNetV3. The ablation experiments presented in this paper are relevant and help shed light on the approach and dynamic convolution.
Accept (Poster). rating score: 8. rating score: 7. rating score: 6. rating score: 4. <BRK>This paper presents a new benchmark, CausalWorld, for studying generalization, transfer learning, and causal structure learning in RL and robotics. This is a hugely important problem, and I think this benchmark has some clear advantages over existing benchmarks. More importantly, for each family of tasks, there is controllable procedural generation of goals as well as controllable factors of the environment such as object sizes, masses, frictions, colors, etc. This enables what I think is the key contribution of this paper   a procedural way to define training/evaluation splits where each split samples from different subspaces of the above controllable factors. This provides a systematic way of defining problems which require varying degrees of generalization, measuring the difficulty of such splits, and defining curricula within each split, which is critical to developing learning algorithms which are capable of this sort of generalization. While prior work (Yu et al, James et al) have defined many robotic tasks with some shared structure, one challenge is that it is difficult to say how much generalization one can expect between any two tasks which can be quite different, a problem which this benchmark takes a step towards addressing. Like the paper mentions, prior works have also used procedural generation over similar controllable factors like this paper does. In fact most physics simulators do allow varying these parameters directly. But, a simple API with a standardized interface to define these splits, as well as common splits that are used as benchmarks is still missing, and this paper takes an important step towards that. The main weakness I see of the paper is the experimental section. The authors train a few SOTA RL algorithms on 3 different train configurations of increasing randomization, and test on 12 different eval configurations. I think it would be helpful if for each of the Eval protocols it was clearly described what was changing. Also in terms of performance, it seems like when faced with anything more challenging than push/pick place with limited randomization, all the SOTA algorithms fail even on the train domain (and as a result struggle on Eval domains as well). So one concern is that of the many domains presented in the benchmark, perhaps only a few are actually solvable by current RL algorithms during training. At the same time I think this indicates the challenges in learning generalizable policies, and may inspire better RL algorithms. Overall, I think this is an exciting benchmark, and would be excited to use it.<BRK>This paper proposes a a robotic manipulation benchmark for causal structure and transfer learning in a simulation environment considering 3D shape construction tasks given a set of blocks. Baseline results using model free algorithms are provided for chosen tasks, e.g.pushing, picking, pick&place, stacking. It is also stated that a real version of the robot can be built (as it is open sourced) for sim2real research. The paper is clearly written, nicely structured and, presents interesting and important ideas. It exposes a large set of parameters, e.g.properties of blocks (size, mass, pose), friction, goals for generalisation evaluations. Having a real world counterpart makes it very valuable for sim2real research. Authors provide and discuss the relevant previous work detailing how their work connects to the existing literature. A minor comment: The particular choice of the robot can be motivated, as it  is a special design.<BRK>This paper proposed a new benchmark for studying reinforcement learning and its generalization in the context of the robotic manipulation problem. To study the generalization of a learned policy, the proposed benchmark is equipped with an interface that makes intervention easy. This interface helps to define a training space and an evaluation space so that one can systemically study both in distribution and out of distribution generalization of a learned policy. Strengths:* This paper proposed an RL benchmark with many good properties: systematic intervention of environment distribution and potential application to sim2real transfer experiments* The source code of the benchmark provided with the submission is clean and well documented, so it could benefit future research based on this work. * Proposed evaluation protocol gives an insight on how this benchmark can be used to evaluate generalization of RL agent. Weaknesses:* One concern I have about this benchmark is that the training difficulty may hinder the analysis of generalization. It is expected that a rich training distribution would lead to better generalization, but it seems rich training distribution makes training difficult and results in worse performance on evaluation distribution. * As far as I understand, there are a few predefined tasks, and each task distribution cannot be intervened by modifying some task relevant parameters. However, I can imagine parameterizing the tasks. Questions to authors:* I had the impression that this paper attempts to make a connection with the research about causality. For example, the name of the benchmark is "CausalWorld", and the text mentions "opportunity to investigate causality", and "underlying structural causal model (SCM)". However, it is unclear to me how this benchmark can help to study causality exactly. How these ranges are determined? Is there any motivation behind this split? To the best of my knowledge, no existing open sourced RL environment for robotic manipulation does not support systematic intervention of the environment distribution.<BRK>### SummaryMotivated by the difficulty of evaluating RL’s ability to transfer behaviors across environments, the authors propose the CausalWorld benchmark. Unlike prior benchmarks, CausalWorld exposes well defined casual variables, in the form of task factors, and focuses on robotic manipulation of an open source robot platform. ### Positives  The paper is strongly motivated and tackles a real and practical problem. Evaluating transfer in RL agents has been challenging, especially for robotics, and the authors’ proposed benchmark framework could be useful in addressing this. The authors’ framework is defined in a way that seems easy to extend and supports multiple use cases, including custom “task generators” for defining new tasks or goals, and “intervention actors” to define a learning curriculum. The paper provides relatively strong baseline experiments, with quantitative results across several model free RL algorithms (PPO, SAC, TD3), and multiple potential curriculum techniques. Specifically:  In figure 4, it’s unclear to me what the new experimental result is here, given that the benchmark is meant to test transfer and generalization ability, and the results presented are on training curves. It seems that the main conclusion here is that the choice of learning curriculum is important for performance, which as the authors point out is unsurprising? For instance, automatic domain randomization (ADR) from “Solving rubik’s cube with a robot hand” may be a useful curriculum to compare. It was challenging for me to follow Figure 5, since it was not clear what the training environments agents were being trained on, and which environments they were being evaluated under. Further, do these results for pushing hold across other tasks (picking, pick and place, stacking2)? Figure 5 shows that there is some generalization to tasks in space A and B, but it is unclear how A and B differ, what the variables between both are, which environments in A were trained on, and what P0 P11 are. In addition I think some other experimental results would be helpful:  The authors could investigate a more detailed analysis on different reward structures, other progressive curriculums, and other methods that claim better generalization and transfer performance. Some qualitative results exploring the relationship between the identified and proposed causal variables (potentially through the lens of the agent performance) would be helpful. The authors are motivated by facilitating research in causal structure learning, but this paper focuses almost exclusively on studying transfer learning and generalization ability. I think the benchmark is well motivated, but not backed up with strong experimental results. The motivation for the benchmark is to show that the framework can be used to study transfer performance, but the current experimental results do not convince me that the framework makes it easy to uncover new insights in practice. One reason to potentially accept the benchmark is that it seems easy to extend, but this is also difficult to evaluate from the limited experiments presented. If the authors were to respond to some of my comments above, by providing a better understanding of the figures and experiments (in case I am misinterpreting the current results), and by showing the utility of the benchmark, then some of my concerns would be addressed.
Reject. rating score: 3. rating score: 7. rating score: 7. <BRK>Authors write in the paper that dataset is publicly available in their organization, I don’t understand what do they mean by that. The motivation for the task of predicting formulas given table is not very clear. Figure 1 is not clear, it needs some more intuition and discussion. I found introduction to be a bit disconnected. Question: why authors have not reported results for other related tasks like taskfill using their technique?<BRK>This paper presents an effective way to implement this idea. **ablation study**Ablation studies are comprehensive. **pre trained BERT for headers only**Given the sampled shown in the paper, I am not sure if it is good to employ a pre trained BERT to encode the content of the spreadsheet except for the header. Therefore, I would like to know if the authors have tried to use a pre trained BERT for encoding headers only while using a BERT learning from scratch to encode the rest of the spreadsheet. **dataset availability & more samples**It would be great if the dataset was provided so that the readers can better judge the difficulty of the problem and the performance of the models.<BRK>The spreadsheet formula synthesis is an important domain with a wide audience. * The proposed approach out performs the neural network approaches for programming by examples. It achieves reasonable accuracy on a large scale benchmark to be usable in practice. * I couldn’t find any glaring weakness but here are a few questions/suggestions. Have the authors tried something similar? * It would help to add a few qualitative examples of synthesized formulas in the main paper to get the feel of the results. **Overall Remark**I believe that overall problem formulation and the architecture would be valuable to the community considering that the proposed system supports the full “Google Sheet Language” and performs reasonably well to be used in practice.
Reject. rating score: 3. rating score: 4. rating score: 5. <BRK>This work proposes to improve the generalizability of bAbi models through [entity permutations]. Overall I find the proposed research not very well motivated. Leveraging word type knowledge to improve the generalizability of NLP models has been a popular and effective approach. Commonly used strategy is to replace named entities in sentences with their word type tokens .<BRK>This paper proposes a new type of models that are equivariant to entity permutations, which is an important criterion to build language models that can easily generalize to new entities. The topic is of great interest and it is indeed crutial that neural language models become symbol shift invariant to allow them to better generalize. It is not clear if that also includes the symbolic representation or not?<BRK>The authors propose a network that is equivariant to entity permutations without requiring the pre specification of the set of entities. To this end, the authors propose a hybrid semantic symbolic embedding which they integrate into two QA models. Finally, the authors show significant gains on the bAbi tasks, with especially impressive gains in the 1K setting. The problem is quite interesting and challenging in the setting where entities are not prespecified. However, given the model description it is not clear at all how the model is able to learn a symbol shift equivariant embedding.
Reject. rating score: 4. rating score: 5. rating score: 7. rating score: 8. rating score: 9. <BRK>**It is not clear to what extent short sightedness is a serious issue and how much it affects exploration. For this reason, I think it is important to look to the function approximation setting. However, the paper is supported by other strengths including an appropriate discussion of related work. The authors have made short sightedness a core support for their proposed method. Unfortunately, they have not provided sufficient evidence to convince me that short sightedness is necessarily a problem. The intuition with the corridor example makes sense, and some of the experiments seem to support the idea. In the function approximation setting, shortsightedness isn t clearly a problem. However, I am also of the opinion that for the authors to adequately support claims about these concepts, they must be described in enough detail for the reader to understand. The differential equations are not needed and not even used to make this point. "have proposed to use intrinsic rewards" (p. 1) → "have proposed using intrinsic rewards"? Do you know if it is possible that such environments might give count based methods the edge over BeBold? While testing this hypothesis is beyond the scope of this paper, I think a comment about such a possibility would be appropriate to include in this paper. What does this example have to do with derailment? 3.3 The explanation of detachment on page 4 does not seem to accurately capture the meaning as it was defined by Ecoffet et al.(2019).In particular, an important property of a detachment situation is that the intrinsic reward in an area between two unexplored areas is exhausted, meaning that the exploration of one of those areas is not only delayed, as in your example, but is never induced through intrinsic reward because there isn t enough intrinsic reward left to shape behaviour towards that area. 4.Incorrect or missing logic:4.1 The paper claims that another method relies on good quality generalization because it uses two stages. 2.Weaknesses in the experiments:2.1 Why use a Q network for the tabular setting at all?<BRK>Summary: This paper focuses on exploration with intrinsic rewards and proposes to use the difference of inverse visitation count as the intrinsic rewards. Originality: As far as I know, the proposed formulation of intrinsic reward is novel, though it is closely related to prior works. Significance: The proposed idea itself is interesting, and it has shown SoTA results in some challenging tasks. * In Figure 3, are some baselines methods missing in some tasks. For example, on "Medium: KeyCorridorS5R3", are there curves for the baselines? * In section 4, the authors discuss the weakness of the count based exploration method: detachment. It will be quite interesting if the proposed method could also significantly outperform the count based exploration of the Atari games. * In section 1, it is mentioned that the curiosity driven intrinsic reward suffers from the noisy TV problem. The proposed method will also suffer from this problem or not? In other words, is there any failure case that the proposed method will not work?<BRK>Summary The authors propose a novel intrinsic reward based on the difference of inverse visitation counts for consecutive states. The paper also contains comparisons with a few strong baselines (including SOTA on these benchmarks), analysis of the learned behavior and intrinsic reward, as well as ablations of the proposed approach. Strengths Overall, I really liked this paper. WeaknessesOne thing that wasn’t clear to me after reading the paper was what are the teacher and student networks used to approximate the visitation counts. Could the network phi (used to estimate visitation counts) “forget” previously visited states and thus lead to short sighted behavior in a similar way as count based methods do (i.e.oscillate between two state regions / corridors)? Have you tried scaling the IR reward by the inverse of the episodic state counts (like RIDE does) instead of only using the episodic restriction? It might be interesting to add it as an ablation and give some intuition on which (when) one is preferable. I think it would be valuable to include all the baselines in the analysis section i.e.Tables 1, 2, and Figures 4, 5 (they can be in the appendix if there isn’t enough space). Can you specify how many seeds you used for computing the mean and std in the plots? I could not find information and it is important in order to understand the significance of the results. In Figure 1, you use c(s) to denote visitation counts, while in Section 3, you use N(s). RecommendationThis paper presents a novel and effective method for an important problem, and it also provides insightful analysis to better understand the limitations of different approaches.<BRK>This intrinsic reward combines the ideas behind count based approaches and state diff approaches. They demonstrate the success of BeBold by comparing their algorithm to a set of state of the art exploration methods using intrinsic rewards on a set of tasks from the MiniGrid and NetHack environments. However, I believe that if BeBold were to be applied to such environments, it would also need the downsampling trick (or equivalent) to be able to apply episodic restriction. The idea is simple, the motivations and intuitions are well explained. The paper is also well written. This is definitely not the case in several environments. * The related work is relevant and seems complete. Please consider doing so. **Recommendation and justification:**I think this paper should be accepted for the reasons listed in the Strong Points section. * I believe the paper does not mention which RL algorithm is used. I d be happy to raise this score to an 8 provided that the authors add a discussion section to discuss the points mentioned above. The authors write: “we do not want to give a negative IR to the agent if it transits back from a novel state to a familiar state”, but do not really explain why. * Episodic restriction seems to restrict the use of BeBold to environments with discrete countable states (use of hash table). Is it only the best value? does it assert statistical significance (if yes, which test at which confidence level?) In particular, the authors could discuss the aspects mentioned above: the limitation to discrete states, the noisy TV and derailment problems. This seems like an important detail to provide.<BRK>They propose to compute an intrinsic reward based on the inverse visitation count to reduce the visit imbalance generated by optimizing for the extrinsinc reward. This work present an interesting approach to progressively explore at the boundaries of the most visited states (a phenomenon that occurs when the agent focus on maximizing known rewards). The contribution is clearly stated by the authors. A couple of remarks however:   the context should be clarified: you mention a quite classical RL setting, which assumes is done by interacting with the environment. In that case, one can explore via action selection and potentially discover new states (by trying new actions or experiencing an unexpected outcome). How is this augmented reward information used? I didn t see a clear mention of the learning algorithm implemented in the agent, please make that explicit. It is critical to the method that the action selection process itself moves the agent towards fully unknown parts of the state space. Section 6 should be clarified on how your methods and the related work actually relate ; it is only done for the last paragraph but should be clarified for the other approaches you cite.
Reject. rating score: 5. rating score: 5. rating score: 6. rating score: 6. <BRK>Surprisingly, the authors further show that it is harder to modify knowledge in the partially symbolic  Facts as Experts  model than it is in BERT. However, I was unable to follow some important details, and I think the paper is missing an obvious baseline, so I think it needs some more work before it can be accepted. The proposed method is based around fine tuning the model  on modified facts, with the hard constraint that the norm of the difference from the original model parameters is less than a threshold. I struggled to find any detail on how the authors enforce these constraints during optimization, and this point should be made clearer. I think exploring this question would add to the paper, and might improve results.<BRK>Generally speaking, I like the basic idea of this paper and it might have a broad impact on the whole community. However, there are still a lot of questions about the paper. 1) the paper seems to be written in a rush without refining, there are numerous serious typos and spellings errors, which affect my understanding a lot. Why is the left showing "32 >512" while the right showing "32 >128"? I m not sure if I misunderstand something. 2) The results are also quite messy. Is it possible to aggregate all the main results in one table and demonstrate all the ablation studies using Figures? In lifelong learning or meta learning community, such constrained optimization algorithms have been explored for a few years to prevent the mode from catastrophic forgetting. 4) Overall, I still quite like the scope of this paper.<BRK>The contribution of this paper is two fold: (1) introducing a new benchmark for evaluating such ability, and (2) evaluating a comprehensive list of baselines, including a new model that has a constraint term in the objective during fine tuning. The problem is well motivated and of interest to the wider community. I am not fully convinced by the setup in the paper, where the model is pretrained on unmodified facts and then fine tuned on a modified knowledge. Therefore, an assumption in the paper that the model can only access modified facts during fine tuning seems to be unrealistic. Second, if the research question here is the generalization ability of the model, isn’t a zero shot setting or a setting with small training examples (e.g.1k) more suitable? 2.Although the creation process of the benchmark dataset makes sense, it is still created synthetically. This is important because, when a subset of knowledge was synthetically updated, some knowledge will contradict each other. The conclusion, "the model overfits to modified facts and suffers from catastrophic forgetting" is pretty naive and has been observed in a lot of prior work ([1] is one of recent ones).<BRK>The model has to be described in detail (perhaps with a figure). Show some examples from each dataset. 2.The problem is well motivated and the first half of the paper is well written. Confusing experimental section, and many important details are missing (see comments). 2.The paper felt like it is a last minute submission and written in haste. 3.Important related work on retrofitting literature not cited. 4.The proposed method works at the cost of forgetting unmodified facts as the number of unmodified facts increase. Comments:Although the reviewer likes the problem formulation and the main idea, they find it hard to follow the experimental section. The authors use a lot of acronyms like PT, FT, FTA, FTM, RT which is unnecessary.
Accept (Spotlight). rating score: 7. rating score: 7. rating score: 7. rating score: 7. rating score: 6. <BRK>This paper proposes DeepAveragers: an adaptation of the "averagers" framework to the Deep RL setting. I think that some of the GPU specific discussion is a bit distracting/incidental to the core work of the apper. There are several things to like about this paper:  The problem of "batch RL" is timely as people look to apply RL techniques in real world problems, where learning from tabula rasa may be prohibitive. The paper is overall well written and easy to follow.<BRK>Overall I think the paper makes a good contribution in offline RL. The ideas are intuitive and the empirical results are convincing. I think the paper may benefit from some discussion about the convergence of this hybrid GPU value iteration algorithm. Theoretically, a performance lower bound is derived for the approximate MDP.<BRK>The value of the optimal policy in the approximated MDP can be bounded, under some smoothness assumptions, in the original MDP. The authors should discuss the relation to this work and surrounding literature. In Atari, it appears that the latent representation can be leveraged by the proposed approach to robustly improve the DQN score. Or in general how do other batch RL methods compare? I have updated my score as a result.<BRK>Summary Authors introduced the Deep Averagers with Costs MDP (DAC MDP) as an offline approach for solving MDPsThey addressed the following planning challenges: difference in representation used by model and planner, and 2) planners exploit inaccuracies of modelsTo address (1) authors relied on a simple tabular representation. Currently the paper does not discuss that critical angle. How well this approach works for stochastic transitions? Figures 4 investigates the performance at the final iteration for different values of Ne. Again you should also discuss wall clock time. Details P3: "non core state immediately transitions to the core for any action"  > How do you calculate the corresponding core state?<BRK>The authors present a nearest neighbour method for learning a model offline from the statistics of the given data set. The algorithm is tested in several Atari games over two data set sizes. Either during the rebuttal phase of this conference or as a submission to a future conference. The related work is missing discussion on recent offline RL methods such as [1,2,3,4]. Additionally, although its nice that additional experiments were includes the gym mini world experiments don t add much to the paper without baselines.
Reject. rating score: 3. rating score: 4. rating score: 6. rating score: 8. <BRK>1.I am confused on the motivation part. In my eyes, the authors put the common part and structure specific part together. I am fine with this. But I do not see a deep insight of the problem solving philosophy, either. 4.It is nice to see the performance gain in the experimental part.<BRK>This paper focuses on disentangling embeddings of the structure and the attribute of graph. At last, the authors propose a metric to evaluate the disentanglement. The pros of this paper is as following:1, The motivation/intuition of this paper is good.<BRK>However, this is not convincing since the proposed measure is based on the learned embeddings (i.e., there is no graph structures). The goal is to minimize the change of structure (attribute) part of the embedding when altering the attributes (edges) of the graph. [Pros](1)	This paper is well written and easy to follow. Generally speaking, I think this is a good paper.<BRK>Input SAD is a simple baseline that tries to get structure attribute disentanglements by individually processing graph structures and node attributes. In particular, for Input SAD. Are there any possible explanations on this? Comments:The paper is well written and easy to follow since the intention and corresponding ideas are quite clear.
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 5. <BRK>This paper studies RL with low switching cost under the deep RL setting.<BRK>This is often detrimental for the applications considered, such as medicine, in which robustness is also desirable. I am not completely familiar with the literature on RL with low switching cost, but the proposed approach appears to be novel. 2.The paper is organized well, and the algorithms are clearly explained.<BRK>This study is done in the context of deep reinforcement learning. A few generic baselines solutions are provided as well as a more complex solution that empirically outperforms the baselines. Motivation of the paper:This paper studies an interesting question that is rarely studied in practice. The paper mentions a few applications domains but what would be a very concrete example where the switching cost is important? ExperimentsIt seems that the paper does not mention the number of seeds (runs) that are used for the experiments.<BRK>It shows how stable/unstable the method will be. At the end, I would like to say that, the paper is a good a step, but for publication the analysis/ experiments should be more thorough and possibly give insights about how to "formalize" the problem. (which I believe should be the main focus, developing theoretical grounding for low switching cost problems).
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 5. <BRK>The paper posits some phenomena on neural network training: 1. The intuition is clear but many experimental settings are quite hard to follow. The discussions and results are not very well organized. I also don t understand how the empirical studies verify that with both procedures, they first learn "weakly predictive non robust features". What even is "weakly predictive non robust features" and how is it reflected in plots? The contributions of the paper are not very obvious to me.<BRK>The paper uses experiments based on adversarial training to validate their hypotheses, and also devise a toy model under which their hypotheses hold. Better understanding of the training dynamics of DNNs is an important problem that merits further study, and the authors are taking an important step in this direction. I also appreciate that the authors provide both empirical and theoretical evidence for their claims. They say the point is to establish that “a neural network being unable to learn a generalizing model as evidence that there are no highly predictive non robust features”, but I don’t understand why they need to replicate the results of Nakkiran (2019) to make this claim. Maybe they are replicating to be careful (which is good!), but they never say so. In addition, I also don’t understand this claim very well; e.g., what is the purpose of this connection?<BRK>Summary:This work studies the learning dynamics of neural networks in terms of robust and non robust features. al 2019 and how their work relates to it. Section 5: Isn’t it unlikely that n<<d in deep learning? If so, this should be mentioned as a caveat. al.2019, interesting experiments measuring what features the models is learning, and a digression that presents further results on non robust features in different datasets. The strengths of this paper to me are the discussion in section 2 regarding the robust and non robust features model of Ilyas et. After reading the paper, I have many more questions regarding what the authors did.<BRK>This paper reveals interesting phenomenons of the training dynamics of SGD on convolutional neural networks for image classification. The conclusions are drawn from assumptions for empirical observations, but the scale of the experiments is not large enough, and the conditions for the assumptions are not specified rigorously. Instead of using accuracies on $\mathcal{D}_{shift}$ as a proxy for how much of the model’s performance can be attributed to its learning predictive robust features, showing the accuracy of the model on the shifted dataset under adversarial attacks would make it more convincing to me. With Figure 2, the authors claim that "the network trained on the examples that transfer generalizes well to the true distribution". 2.The definition of robust and non robust features in Section 2 are confusing, not related to the experimental and theoretical results, and might have some minor issues.
Accept (Spotlight). rating score: 8. rating score: 7. rating score: 7. rating score: 7. <BRK>***Summary***The paper uses the idea that a convolution on the Fourier space accounts just to a matrix vector product. Could the authors report the results of the other methods while using Cayley also for them? ***Conclusion***This is a very strong paper, with a very nice application of orthogonalisation in the context of CNNs. I think that the presentation of the content in the paper is very good. "However, it can be extended to all orthogonal convolutions by multiplying by a diagonal matrix with $\pm 1$ entries (Gallier, 2006; Helfrich et al., 2018).".<BRK>The paper provides another parameterization for orthogonal convolutional layers using the Cayley transform, different from BCOP. From the paper, the parameterization is not complete since the eigenvalues are all +1. So I am curious whether the proposed parameterization is a proper superset of BCOP. If the authors can clarify the questions, I will definitely increase my score. The questions above are well addressed in the response, and I would like to increase my score.<BRK>**Comments after rebuttal**: Overall the authors have addressed many concerns in the latest version of the paper. What is the relation with the expression $conv_W   conv_{W^T}$? In the "Architecture considerations" in page 6 what do you mean that “for our Cayley layer… we use the Cayley transform for consistency” what is the alternative? Quality: The empirical evaluation is good at comparing between baselines**, however it could be improved (see Cons). **2.Originality: It seems interesting and novel to do orthogonalization using the Cayley Transform in Fourier domain, as this seems to bypass limitations of other methods that have troubles trying to "orthogonalize" the matrix corresponding to the convolution**. **3.Significance: From experimental evaluation it seems that the proposed method is a strong candidate among other alternatives to orthogonal convolutional layers**.<BRK>### Summary **Objective:** attain orthogonal convolutions. If it is the same, I believe your method can be summarized as done below. To compute the inverse used in the Cayley transform you rewrite the convolution operation to matrix vector multiplication in Fourier space. The paper address this limitation for for circular convolutions. If the authors add a paragraph that explain limitations wrt circular convolution, stride and shape I ll be happy to change to 7. These questions, and their answers, should be visible to all other reviewers, the area chairs and the program committee. I m asking to make sure I understand your method.
Reject. rating score: 5. rating score: 6. rating score: 6. rating score: 6. rating score: 6. <BRK>In general, I think this paper is well written and easy to follow, although the English can befurther improved. 1.I see that the authors conducted two experiments on texture segmentation datasets whereboth are very small datasets. In table I, the authors compare with more general baselines,i.e., Deeplab. However, Deeplab is proposed for large dataset which will experience overfiting onthe small datasets used by the authors. So I feel that Table 1 is not a very fair comparison andindicates less meaning to us in terms of the performance of ST DNN compared to generalsegmentation methods. 3.If we fix the consideration inside texture segmentation, where the authors kindly comparewith a few state of the art in Table 2. Overall, I think the motivation and novelty are good.<BRK>The relationship to Poisson PDE and its formulation as a convolution. Extensive experiments on texture segmentation. If the descriptors indeed are more valuable, this should be demonstrated using simple tasks like using the  average  or  aggregated  descriptor for linear classification tasks. This would be valuable to the representation learning community, but was not addressed in the experiemnts. Also, the authors should clarify the limitations of the approach more clearly. The reason I am still not fully convinced is no experiments indicating the quality of descriptors learned by the method.<BRK>UPDATE I am generally satisfied with the answers provided by the reviewers and I have increased my score accordingly. ST DNNs, in contrast to conv. ST DNNs themselves correspond to solutions to the Poisson PDE. The paper describes how these layers can be trained and used for prediction. Results are reported on a texture dataset. NoveltyThe authors suggest ST DNNs that natively support non rectangular regions. The evaluation of the paper is unnecessarily restricted to texture segmentation. If ST DNNs underperform on mainstream segmentation tasks, this is valuable information to the community. This effectively gives the authors more space for content than competing submissions.<BRK>The paper proposed a new "shape tailored" convolutional layer for improving the accuracy of semantic segmentation. The shape tailored layer is inspired by the Poisson partial differential equation which aggregate features from neighboring pixels through the linear combinations of partial derivatives of the output of PDEs. Negative:The experimental comparisons are quite limited which it has only compared with DeepLab v3 and FCN ResNet101. Both methods were published on or before 2018. The more recent state of the art image segmentation methods (published in 2019&2020) are not compared. The experiments on texture segmentation, especially for the experiments on increasing deformation,  are also not very impressive as these datasets are mostly synthetic.<BRK>ST DNN are motivated by the prior work on shape tailored descriptors (or smoothing) that aggregate image statistics within regions of the interest, and defined as a solutions to the Poisson PDE which balances image fidelity and smoothness. This paper applies this formulation to generalize convolutions from square shared operations to arbitrary regions, and constructs a deep neural networks by stacking this smoothness operator with 1x1 convolutions and ReLU (ST DNN layer), repeatedly. + Proposed outperform other shape tailored variants for texture segmentation as well as earlier works on texture segmentation. The compositional operation (simulated by stacking of multiple layers) should implicitly compute. Comparison with deep segmentation methods: From the texture segmentation, it seems a natural formulation would be use Siamese or triplet networks to facilitate homogeneity of within each region and discriminativeness across regions (as is done in [23], as well as other papers such as https://ieeexplore.ieee.org/document/8545348). Overall the paper presents an interesting formulation which could be useful to segmentation tasks, as well as tracking (as presented in [22]) but there are several concerns which need to be addressed.
Reject. rating score: 3. rating score: 5. rating score: 6. rating score: 6. <BRK># SummaryThis paper works on long tailed classification. I would also suggest that the authors re motivate their paper and modify their approach section. An analysis of the relationship between gradients and the classification performance will make the paper stronger. The paper lacks a detailed description of how the gradient analysis is conducted.<BRK>There s a chance that I didn t understand the paper so I just list all my concerns in questions. There s no detail about the proposed method, e.g., what s the choice of $\lambda$, s, how does the authors actually do the two stage training. Cons:  The presentation of this paper can be improved. "In contrast to the aforementioned strategies, we approach the long tailed recognition problem byanalyzing gradient distortion in long tailed data"  How does the proposed method get connected with this statement and differ from other two stage training algorithms?<BRK>**Strengths:**The observation is interesting and the method is reasonable. 3.The presentation and clarity need to be improved. On the one hand, it provides several interesting observations about the phase transition in long tailed recognition, which would be valuable to the community. The main idea of the method is kind of similar to that of Gidaris et al.[1] as the authors also cited, but in the few shot setting in their paper, the separation of base and novel classes is more natural and reasonable.<BRK>This paper proposes an interesting view to analyze the long tailed problem. 2.Analyzing through the gradient seems to be an interesting view, which could bring insights into the long tailed problem. #### Some questions and concerns:1. So why the grad (a combination of grad1 and grad2 in my opinion) becomes larger? 3.The authors conduct experiments on almost all common long tailed classification datasets, which is great.
Accept (Spotlight). rating score: 8. rating score: 8. rating score: 7. rating score: 6. <BRK>#### General commentsThis paper aims at proving superiority of neural network models to any linear estimators, including kernel methods. For the non parametric regression models within this neural network class, this paper establishes a sharp excess risk error of the least square methods with  noisy gradient descent update, although such optimization may be heavily non convex. This paper is organized well and stated clearly. I argue  that this sentence may be uncorrected, since the mentioned rate is independent of the input dimension, which is not a real curse of dimensionality.<BRK>The paper essentially shows that linear functions have a problem with the non convexity of the neural network class, and approximate the slow rate of 1/(n)^(1/2) for increasing dimension. A neural network trained with noisy stochastic gradient descent on the other hand has a faster rate, depending on several parameters. Setting and results may be interesting for a large audience. Scoring:Overall I think this is a worthwhile contribution in understanding the difference in deep and shallow learning, and as the paper is very sound I will vote for accept. Additional feedback:The result that the minimiax rate of linear functions over a space F is the same as over its convex hull was not known to me.<BRK>This paper shows that the Bayes estimator with Gaussian prior can outperform the linear estimators (including kernel regression and k NN), which I believe is indeed interesting and important. What if using a standard parameterization of a two layer network but performing projected (noisy) gradient descent? 2.It seems that the goal of all estimators is to recover the teacher networks. 4.Does the result in Theorem 2 hold for any f^{\circ}? 7.Moreover, it may not be appropriate to state that “NGD achieves a fast convergence rate”, it seems that the spectral gap \Lambda^* still has an exponential dependency on the parameter beta (shown in Proposition 3), which will be set as beta   \Theta(n) in Theorem 2.<BRK>Summary:The paper aims to demonstrate the superiority of deep learning methods against kernel methods by comparing their excess risk bounds. In particular, the authors first derive the minimax lower bound for linear estimators by assuming that the target function can be represented by a teacher neural network, which implies that the linear estimators suffer from curse of dimensionality. Then the authors further derive a dimension independent upper bound of the noisy gradient descent method for overparametrized two layer neural networks, which theoretically confirms the benefit of deep learning methods in terms of convergence rates. The paper is well written and also interesting to read. Overall, I vote for accepting. In the teacher student setting, what is the minimax rate for any estimator of $f^0$ instead of just linear estimators?
Reject. rating score: 3. rating score: 6. rating score: 6. rating score: 7. <BRK>**Summary of paper**The authors introduce an algorithm called VBSW to re weight a training data set in order to improve generalization. In summary, VBSW sets the weight of each example to be the sample variance of the labels of its k nearest neighbors. The nearest neighbors are chosen in the embedding space from the second to last layer of a pre trained neural network. The last layer of the pre trained model is then trained with these new weights. This approach is quite simple in practice and seems to be theoretically justified. The authors demonstrate that VBSW achieves better test accuracy than not using VBSW on 3 toy datasets and 5 real world datasets. I find this omission inexcusable. The problem of re weighting examples to achieve better accuracy has been studied for decades; there are many other algorithms to compare against. Clarity: The paper is generally well structured and well written, although with a few typos and grammatical errors. Originality: I am not familiar enough with the related work to say whether this idea is novel. However, seems quite simple and potentially very similar to existing published techniques. **Comments**Section 3.1 seems to assume that the labels have no noise. For example, if two examples have the same input features, their labels seem to be generated by the same function f, which would always produce the same label for both examples. Section 2 describes the author s VBSW algorithm as being applied "prior to the training", but the algorithm actually requires a neural network to be pre trained before the reweighting procedure. I felt the beginning of the paper was misleading in this regard.<BRK>A method for computing sample learning weights based on variance is proposed. The method is model independent and a simple k NN based estimator for the weights is derived. The authors justify their work by appealing to a novel generalisation bound. Overall the idea is interesting but the exposition needs to be significantly improved as proofs are difficult to follow as it currently stands. # positives  The idea is interesting and intuitive: essentially concentrate more weight on points that are ambiguous and less on points that are easily learnt  The approach is potentially quite general covering a large range of learning tasks, though this needs to be carefully evaluated# cons  The exposition is very unclear, there are numerous typos and lack of detail in key sections of the proofs  Though the authors make statements that the method is very general, the empirical evaluation does not validate this. There is no attempt to apply their method to anything other than a NN. It s difficult to see how this weighting strategy will improve the noisy label scenario in particular. The benchmark in experiments is an unweighted NN. While this is a good benchmark, it would be good to see some alternative sample weighting methods since according to the authors "Sample weighting has already been explored in many works and for various goals." # some examples of confusing sections  figure 1 lacks axis labels, and panel labels. This makes it difficult to see where bounds have been used. Most of this section is simple algebra and could be shortened. # updateThe authors have addressed a number of issues and strengthened their submission.<BRK>The manuscript follows an intuitively straightforward conclusion: data should focus on the region where the function to learning is steeper. Based on that, a non trivial method is proposed to improve the performance of NN. Empirical results are provided to support the performance of the proposed method. According to my understanding, the performance gain from the proposed sampling method mainly comes from the sample complexity part, or in other words, the variance part. Is this correct? Since provided analysis is mostly on the asymptotic level, it is quite unclear that how much noise/error the proposed sampling method may have, how much these noise will hurt the final NN estimation. So, is there any cases where the proposed sampling method will even hurt the performance of the NN? (For example, what will happen if the weights are poorly approximated?) If not, what are the key conditions to make sure that the sampling method really provides significant performance gains? Also, can we iteratively implement the weight approximation and sampling method many times in Algorithm 1? In all, the method is interesting with improved performance supported by experiments. However, I believe more analysis on the constraints and potential error of the method will benefit the manuscript.<BRK>This paper is well written and very well structured. I think this paper can be interesting for ICLR community. The authors presented experimental results that show marginal improvement using VBSW in both regression and classification applications. The experimental improvement is limited; however, it makes sense since the proposed approach is a preprocessing stage that can not be dynamically tuned during the learning process. I am interested to see experiments (for synthetic and real datasets) wherein the steep region is noisy, demonstrating how well the proposed strategy works in the presence of noise. One can expect that focusing too much on the noisy steep regions can be harmful to the learning process. In my opinion, the investigated problem has been described and motivated properly. It is interesting to formally show (via the presented generalization bound) why NN needs more points in the steep regions and how the steep regions can be formally approximated. The study has proposed reasonable approximations for the cases where the derivations are not available and computing new labels. The theory that backs the statements made in this study seems correct. However, I am concerned about their experimental results that do not seem significant (gain per model is limited). Also, it would be interesting to see a noise robustness investigation in the steep regions.
Accept (Poster). rating score: 8. rating score: 7. rating score: 6. rating score: 6. <BRK>The paper introduces a framework for computationally efficient and exactly rotation equivariant spherical CNNs. Finally, a more efficient sampling theorem is used that reduces the Nyquist rate by a factor of two compared to the ones used in previous works on spherical CNNs. This does not mean the paper will be easy to understand for all readers, but for those familiar with the relevant mathematics, either from textbooks or earlier works in the spherical CNN literature, the paper is very readable. The proposed improvements make a lot of sense to me, and their computational complexity improvements are clearly stated. This makes some sense, but it is not clear to me that this approach is optimal in any meaningful sense or necessary at all. The question then arises whether full mixing actually happens in the considered architecture, given that it is not very deep. It would be interesting to see actual implementation details in some DL framework, as well as wallclock timings.<BRK>Experiment results on multiple benchmark datasets show that the proposed approach outperforms the alternative approaches while having less number of parameters. This paper studies an important problem. The proposed operation has the desirable property of strict rotational invariance, and it is general enough to replace existing spherical convolution operators and may be used as the basic component for CNN on spherical signals. The experiment results also verify the benefit of the proposed method. On the other hand, there are several aspects on which the paper may be improved. Second, the experiments are somehow limited. The authors only test the proposed convolution operations on a single model, and the model size is different from the baselines except for the MNIST experiment. Also, while the main contribution of this work is to reduce the time complexity of the convolution operation, the experiments do not show the comparison in run time. The rebuttal provides valuable information that was missing in the original paper and improves the readability.<BRK>**Reject.It seems the authors have given considerable attention to the problem and produced compelling results; however, for me, the mathematical presentation and discussion are difficult to follow which I expect will make it difficult for readers to understand and build upon what has been done. The mathematical presentation is given with filters and functions in \mathbb{C}, is reflected in the implementation? **Perhaps state that \mathcal{H} is the space of spherical signals and the superscript indicates the layerThe notation is a bit difficult to follow (and read since quite a bit is inline) and often is not explained, for example it could be helpful to say that L^2(S^2) are the square integrable functions on the sphere and show what that means. I think the paper would be easier to read if the language was consistent, for example, in the introduction the language of real and harmonic space is used and in section 2 it seems to change to real and Fourier space. LearningSO(3) equivariant representations with spherical CNNs.<BRK>The gained space should be used to expand and better explain section 3 which is extremely hard to understand. From the results it seems that it does not matter, which is counter intutitive. Group convolution has an adverse effect on performance on standard CNNs. In table 3, we see that it is not state of the art on several metrics. The authors do not compare with the improved Esteves et. al.paper from 2020. This makes me skeptical whether the proposed approach improves efficiency in practice. I would recommend the authors to compare on all benchmarks provided in Esteves et. al.(2020).Overall, the paper is a very hard read which no clear message on the key contributions. I recommend acceptance as two of the reviewers are convinced about the positive impact of the paper.
Accept (Oral). rating score: 8. rating score: 7. rating score: 7. <BRK>These enable to define action values with respect to predefined feature maps, thus providing more "resolution" into the behaviour of the policy. The idea of decomposing the policy into GVFs as a way to force explanations wrt. ### Uncategorised notes  This is more of a meta comment, but I enjoyed reading the paragraph about manually designed features in Section 1. Complex gridworlds such as BabyAI and the NetHack Learning Environment are probably also good options. ### Final commentsOverall, I m extremely happy to strongly recommend this paper towards acceptance. It is well written, it introduces a method that attempts to move forward towards solving an important problem in Reinforcement Learning, and there s a significant amount of details in the paper that would make it fairly straightforward to reproduce.<BRK>This paper proposes a method that offers explanation of action preference in a deep RL agent based on given features by the human. What would happen to the evaluation if some given features are dependent? The authors also proposed a method for evaluation of importance of features in the learned policy. Another question I have, is about the dependence of features.<BRK>Edit: I have read the authors  response as well as the other reviews. Since Q values are based on GVF outputs, these intermediate values can be used as an explanation. Pros: The use of GVFs for explanations in terms of future feature values is a novel line of work. Tug of War uses a bunch of features, including information about feature values when a game ends, and non linearities are applied to the outputs of the GVF features. ESP may not be robust to GVF feature choice, but this is insufficiently addressed in the paper.
Reject. rating score: 4. rating score: 4. rating score: 6. rating score: 7. <BRK>In the manuscript, "Mitigating bias in calibration error estimation", the authors examine the problem of estimating the  calibration error  of a binary classifier; the problem context being that addressed by techniques such as Platt scaling. From the experimental section presented here it is not clear that this is the case. On the other hand, if the value of the  sweep  method is to be the focus then a comparison should be made against a selection of competitive methods for bin smoothing in contemporary use (e.g.moving windows, adaptive bandwidths) rather than simply the equal width and equal mass bins of fixed number.<BRK>**Strengths**   With extensive sensitivity analysis, the paper illustrates the importance of  non biased ${\rm ECE}$  calibration evaluation and model selection**Weakness**The reviewer appreciates the extensive sensitivity analysis. *Clarity*:  The writing could be improved by the following:1) Simulation steps for estimating bias in section 3  can be written in algorithm form2) Computation or approximation of TCE described in section 5 is difficult to follow3) Sections arranged in terms of concepts, e.g., TCE is introduced in section 2 and an approximation approach for TCE described in section 3 and section 54) The proposed ${\rm ECE}_{\rm sweep}$ estimator moved from the appendix to the main section5) What is the motivation for the proposed ${\rm ECE}_{\rm sweep}$*Strong technical assumptions*:  Estimation of TCE relies on parametric formulations for confidence distribution and the true calibration curve;  such parametric assumptions are violated in practice  The paper assumes monotonicity in the true calibration curve, which is ill justified   Provided that the proposed solutions rely on TCE, which is unknown.<BRK>The paper has many empirical experimental and simulation data to support the claim that $ECE_\text{SWEEP}$ is a useful calibration metric. The issue is that I don t think Algorithm 1 is taking the maximum over the quantity in the parentheses of the $\text{ECE}_\text{SWEEP}$ equation. Then for the case $b 1$, $ECE   0.1$. And how do you draw samples such that "the confidence score distribution matches the neural model s best fit Beta distribution and the true calibration curve matches the neural model s best fit GLM"? Why does the "optimal bin count grow with the sample size"? 6.In general, while the experiments are mostly convincing, it would be useful to have some theoretical notions for why/when $ECE_\text{SWEEP}$ is less biased than $ECE_\text{BIN}$. 2.Running experiments on new datasets is understandably time consuming.<BRK>I think the paper is much improved by the comparison to other techniques such as ECE_debiased. Comments:a\) Exact monotonicity in the ECE_sweep proposal   I find the argument stemming from the monotonicity of the true calibration curve, and the idea to use this to nail down a maximum binning size interesting. On the whole, my opinion has shifted to be much more positive. I only realised this now, but I had misentered my confidence   it should have been 3 and not 5! The authors make the case that the biases of the binned estimators vary with the number of bins and the number of samples in a nontrivial manner, which is detrimental to point estimation. Minor issues:a\) Algorithm (1) and the formula for ECE_sweep in section 4 don t compute the same thing. I would much rather that the paper was upfront about the contribution.
Reject. rating score: 5. rating score: 5. rating score: 6. <BRK>However current manuscript fails to point out key difference between Akrout 19 kolen pollack method and DKP (proposed method). As pointed out by other reviewers, paper should highlight key differences and reasoning for such combination. Learning without feedback: Direct random target projection as a feedback alignment algorithm with layerwise feedforward training. ## First ReviewCitation missing for key work on assessing the scalability of bio inspired approaches and highlighting key limitations [Bartunov 18], variants of DFA [ Moskovitz 18, Frenkel 19]  and recently an approach similar to DFA with target projection known as LRA (also has similarity with Direct Kolen Pollack) showing promising performance on deep CNNs [ Ororbia & Mali 2020]. “We also found that the optimal hyperparameters and optimizers for the backward weight matrices in DKP seem to vary greatly from one network to the next”Can you provide more detail about your experimental setup? Deep learning without weight transport.<BRK>This work proposed a possible improvement for this problem. Weakness:(1) My main concern is the novelty of this paper. To my understanding, the DKP and the convergence of weight decaying are first proposed in (Akrout et al., 2019). However, updating the backward matrix suffers from the problem of different dimensions. It is also necessary to comment on how the approach in this paper is different from (Akrout et al., 2019). (2) In the experiments, the authors only compare the DKP with the DFA and BP. For example, how much the performance can be improved by the proposed method compared to the methods introduced in section 1.1. It is difficult for readers to make a judgment about the effectiveness of this work.<BRK>This paper introduces a new method for computing the backward updates of a neural network called Direct Kolen Pollack learning (DKP). It would have been much easier to make a direct comparison with previous works. 8.In related works, author(s) mention prior works that DFA have a hard time with VGG 16 optimization but the experiments are done AlexNet. 7.Despite the fact that KP does not make any assumptions about the structure and inductive biases of the network, DKP is proposed only for CNNs and image base classifications.
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. rating score: 6. <BRK>I agree with the other reviewers that the updates have improved the paper. This paper presents a way of estimating the informativeness of a single training data point wrt a neural networks weights or it s output function. If this is required then it should be noted in the appropriate part of the discussion, otherwise could the authors comment on why it s not required? The notion of unique information is very similar to the notion of strong relevancy in feature selection (in "Wrappers for Feature Subset Selection, Kohavi & John, Artificial Intelligence 1996).<BRK>The paper proposes a way to estimating sample information in thecontext of neural networks. The method is applied to several image classification tasks for illustration. The derivation of the measure is an interesting exploration of therelationship between an individual sample s information content andthe neural network s final trained weights or the network s use ofsuch weights (the values of the decision function). This contributesto a better understanding of how information is leveraged by neural networks. The practical value of the measure itself, on the other hand, isquestionable beyond the use of neural networks. Misc.:Section 2, related works:  should also refer to a recent survey thatincludes many works analyzing the influence of individual sampleson classification difficulty:"How complex is your classification problem? If not, what is the quantity whose distribution this covariance is about?<BRK>The paper proposes a measure to compute the information of each training sample. The paper shows that this measure can be computed for a large DNN without having to train the network. My main concern is that the information measure depends on the initialization, training time, and network architecture. They are easy to read and understand. ***After Rebuttal***I have read the reviews by other reviewers and the responses of the authors to the questions posed by other reviewers.<BRK>For instance, word out in page 1 should be our. Yet in the same section, it says that $A(S)$ is the "output random variable" of the algorithm. 3.2. you would see that $A(S)$ is used as a random variable. The role of smoothing in the paper is not clearly discussed and analyzed in the paper. I understand that it is required to make the KL divergence bounds work by adding continuous noise, but are the authors assume assumptions like this just to get some theoretical bounds? Is such an assumption, a valid assumption?
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 6. <BRK>### SummaryThis paper proposes a zero shot NAS algorithm. Main concern is that as the method relies on only 1 image and the initialization, what is the guarantee that it would generalize. In Figure 4, the ablation study considers networks from different accuracy buckets. The Standard deviation of the score is high for some networks. Even in that case, the performance improvement is not significant.<BRK>** ProsI really appreciate the paper proposes a new direction to benchmark and understand neural networks. The motivation is very impressive. Previous NAS frameworks based on score predictors, e.g.NAO [*1] and ChamNet [*2], have shown that it is possible to directly predict the performance from the architecture embeddings without training, however, the underlaying mechanism is not clear. ** Cons1)	Lack of theoretical evidence to support the intuition of the proposed method. 2)	Some important ablations are missing in the experiments, which makes the method less convincing. Minor:1)	It is interesting if the authors analyze or visualize (just like Fig 1) how the correlation of Jacobian evolves during the training for different architectures.<BRK>However, the accuracy in ImageNet 16 120 seems to be very low. This paper is exploring a novel and interesting direction. This might be an unfair comparison, but will be important for people to know whether the proposed method/metric can generalize to different datasets. 3.In the experiments, all the images in the minibatch are data augmentations of the same image. More insights on this part would be very helpful. How does the proposed method balance them? The writing also needs improvement. 6.I notice that the correlation (tau) value in Figure 3 is not high.<BRK>This estimate is used as signal to construct NAS algorithms that do not require training deep nets and is evaluated on two datasets. To my knowledge the paper is the first to implement training free NAS. 2.The method is simple and easy to implement. The justification for the actual score used is weak (see Questions 2 3 below). 7.How does NASWOT perform on larger search spaces such as DARTS (Liu et al., 2019)? This paper provides a reasonable start for a new potential direction in NAS research and so may be worth presenting at the conference, but the justification and applicability of the method is somewhat limited.
Reject. rating score: 3. rating score: 4. rating score: 6. rating score: 6. <BRK>This paper aims to apply Fuzzy c Means (FCM) clustering to persistence diagrams and prove convergent subsequence of iterates tends to a local minimum or saddle point. The motivation of the work is direct and clear. The contributions in this work are not quite promising. Thus Theorem2 can be not be considered as the contribution of this work. It would be promising if the proposed work valid in other shape datasets such as SHREC2010 or SHREC2014.<BRK>The paper proposes a new clustering algorithm for persistence diagrams. Empirically, the paper did not provide comparison with (Latombe et al.18).Just saying that they did not do it exactly in the PD space is not good enough. This paper is well written. Another issue is the limited experiments. The authors claim that (Lacombe et al.NeurIPS 2018) is hard clustering. So it is unclear why it cannot have some of the benefits of the proposed method. Overall, I feel that the methodology is not very exciting to me, and the experiments are insufficient. Also maybe Lacombe et al should be compared with? I have read the authors  response.<BRK>The authors propose a novel algorithm for the fuzzy clustering of persistence diagrams. However, after the discussion and the update of the manuscript, my score will remain the same. The paper is very well written and clearly presented. •	You say “[…] the vectorization […] required by Lacombe et al.’s algorithm makes it unsuitable for integration into our work”. Could you elaborate on this? Can you not even choose this as a comparison partner? I wonder how susceptible your approach is to increasingly different cardinality (that has to be filled).<BRK>A set of experiments demonstrates the utility of the proposed approach. I am excited to see such a clustering algorithmfinally emerge for persistence diagrams, and I envision that this paperwill be a very useful contribution to the field. In addition,   some details about the empirical behaviour of the method are not   discussed. If these two points were to be rectified in a revision of the paper,it would help the contribution to shine more. ; this is a minor point, but it since  the remainder of the paper is written so neatly, I cannot help but  point out ways to improve it even more. R1 mentioned that the work by Lacombe et al.might also be applicable as a comparison partner. This should be briefly discussed.
Reject. rating score: 4. rating score: 4. rating score: 6. rating score: 7. <BRK>The present work proposes an explanation method returning actionable, proximal, diverse, and not trivial counterexamples as explanation. The proposal is interesting, sound in the formulation, and valuable from the experiments reported. The examples reported are nice and quite convincing. However, the paper lacks some major points that make it not ready for publication. First, even though theoretically the proposed DIVE method can be employed on any type of data it is developed and tested only on image data. Various simple datasets with more simple features can be adopted (mnist, cifar10, fashion mnist) or cifar100 imagenet by considering categories and specific classes for the different features. Second, the paper misses various work on counterfactual explanations (some of them are listed in the following) and consequently also a comparison against them. In particular, it would be interesting to test DIVE against methods using a different logic for finding the counterexamples than against methods using a similar approach. Finally, the trivial/valuable explanations, which are the main motivation for this wor, are not formally defined in Section 4, nor in Section 5. It is not clear (or not easy to find) the dimension of the latent space of the VAE and how it affects the performanceMissing RelatedKarimi, Amir Hossein, et al."Model agnostic counterfactual explanations for consequential decisions." Explanations based on the missing: Towards contrastive explanations with pertinent negatives. Factual and counterfactual explanations for black box decision making.<BRK>I think that it is critical that you improve the experimental section in terms of writing and presentation of the experimental protocol, metrics, results and especially section 4.3. However, although I have a solid understanding of the attribution methods, this paper develops a counterfactual one which is related to but not directly within my area of expertise. The perturbations are obtained by minimizing a loss composed of:  a binary cross entropy loss to generate examples that match the target prediction score,  an L1 loss between the input example and each generated example to force small perturbations in input space,  an L1 loss on each perturbation to force small perturbations in latent space,  a structural mechanism based on the Fisher information matrix and spectral clustering to force diversity of perturbationsClaim:The proposed method generates counterfactuals that are diverse, non trivial (i.e.not just exaggerate or remove an attribute), high quality (i.e.in distribution) and valuable explanations about the model s prediction (i.e.biases can be detected by humans). ## What I liked the most  meta problem of explaining neural networks is critical  mostly well contextualized  mostly easy to read  mostly easy to understand  mostly well illustrated  relevant issues have been identified  novel, simple and interesting method to tackle them  novel experimental benchmark  I really liked the hat section of 4. 1.Abstract and introduction  I find it surprising to assume derivability for a black box in the context of explainability methods. For me, it does not correspond to the commonly admitted definition of a black box (e.g.Wikipedia: "implementation is opaque" "without any knowledge of its internal workings"). I had to write a detailed summary of your paper to better understand it. and the claims that you validate in the experiments. 3) I would write about state of the art generative counterfactual methods and their limitations. I do not agree with "[attribution methods] do not explain how to modify [input features] to change the model outcome". I think that is exactly what they do (by applying perturbations/masks). I would like to see a discussion about the need for this kind of perturbations. Do you use a testing set? Is it standard? I do not understand this: "we train a second order spline on the trajectory of perturbations produced during the gradient descent steps of our method"  I think I understand, but it could be more clearly stated: "even though DiVe is not explicitly trained to produce examples at intermediate target probabilities". I did not clearly understand how your novel experimental protocol can be used to validate "the ability to identify diverse valuable explanations". I would make it clear what "success rate" means (you could make it bold where you define it)  Figure3: Overall, I should be able to mostly understand the Figure by reading the caption. I did not find it clear that you explore different hyperparameters. It is not clear. What does "successful counterfactuals" mean? I did not understand which version of your method works best. In particular, what happens if your encoder decoder is biased? What happens when your encoder decoder is not able to produce disentangled representations (it seems often the case on real and complex datasets)?<BRK>Summary: The authors propose interpreting the decision of a black box (BB) image classifier using diverse counterfactual explanations. The proposed model consists of a pre trained β TCVAE, which learns to extract a disentangled latent representation for the input image. To generate explanations for a given image, the model optimizes to find n latent perturbations. Hence, the disentangled attributes learned by β TCVAE, and discovered by the spectral clustering, may not correspond to discrete human understandable concepts (e.g., sunglasses). The explanations  actionability is defined in terms of sparsity in the number of attributes that are modified in the latent perturbation. The model further performs spectral clustering to partition the latent space into different attributes. It s not clear how experimenting on the counterfactual images provided any more/different information than the same experiment performed on real images. •	The idea of generating multiple images as counterfactual explanations is interesting. The experiments demonstrate the realistic quality of the explanations and their ability to discover bias in the BB classifier. In the introduction, the authors describe a valuable explanation as an explanation that is proximal, i.e., it is much similar to the input image, and actionable i.e., it can be derived by performing feasible changes to the input image. •	Feasible features in an image are hard to define. Also, the authors didn t perform any experiments to show that the explanations generated by their method correspond to feasible changes in the input image, in contrast to other methods like PE or xGEM. •	It is not clear what training data is being used to train the encoder decoder in the proposed model. Also, to compare against the existing methods, the authors can design an experiment where they consider a dataset (explain dataset) different from the dataset used for training the BB classifier (BB dataset). They can then use the explain dataset to train and compare the different explanation models (DiVE, PE, xGEM).<BRK>In this paper, the authors present a method based on counterfactuals that learns a perturbation using constraints to ensure diversity in explanations. The authors argue that explanations produced by their method are more “actionable, diverse, valuable and proximal than the previous literature”. However,it is unclear how they quantitatively measure these attributes, given that FID scores only captures the similarity of generated images to real ones. The author briefly mentioned the gains in terms of image quality, when compared with GANs in PE. However, I would like to see a more deeper discussion. Since interpretability is closely related to users/humans, it is difficult to assess the quality of the generated explanations without human evaluations. An initial setup could be the one used in PE. Overall, assuming the above limitations, the experiments help to understand the contributions of the article.
Reject. rating score: 4. rating score: 5. rating score: 5. rating score: 6. <BRK>Moreover, in practice, we shouldn t be able to leverage the fact that we know a task is in distribution or out of distribution and choose between MIER and MIER wR accordingly (which would also be a bit ugly). This approach alone would work well in regular meta RL, but we aim at robustness under distribution shift, for which we need the second part: experience relabeling. Since most of my concerns pre discussion are still there and we cannot assess whether MIER does well on in distribution (and MIER wR is not better than MQL for OOD tasks) I, unfortunately, have to decrease my score from 5 to 4. This prompted me to take a closer look at the actual numbers of the plots and I got more concerned. The paper is well written and clear and the experiments are well executed. If we don t, wouldn t it make more sense to do so? I am still unconvinced about relabeling being the best we can do for out of distribution state distributions. **I got concerned that a question by AnonReviewer2 "Why for in distribution experiments, Experience Relabeling was removed?"<BRK>This paper proposes a new meta RL algorithm containing two main components: 1. In addition, I don t understand why this method can t have better performance on in distribution tasks. Results on in distribution tasks are comparable with the previous method and it shows good performance on the out of distribution task. That is not entirely true as previous work like MQL does use gradient descent to adapt the context (MQL should be cited there too). experience relabeling should be as useful as for in distribution tasks as for out distribution ones. if that is true, figure 1 is very confusing as it implies the model( \theta) and context will be updated together. or?8.Is it really required to use MAML regression to learn the model? It made me read these two sections multiple times to understand this MIER. 10.Utilizing other benchmarks like meta world [https://meta world.github.io/] will be more useful than the current benchmarks to evaluate this method per MQL findings.<BRK>4.What is the end performance of RL2, MAML and ProMP when trained for longer? The thing I disagree about is that updating $\phi$ only is not a consistent learning algorithm, because $\phi$ is only an input vector, and might not be expressive enough such that a completely new task can eventually be learned. Could the authors comment on this? I think overall the idea is promising but the paper falls short in terms of how the method is evaluated. I feel like too many things are buried in the appendix, and it remains unclear to me if MIER can, under realistic circumstances, really adapt to OoD tasks. I agree with R2 that Meta World might be a suitable benchmark to evaluate MIER on, since  the training and tests tasks are distinct and there s a clear evaluation protocol for ML10 and ML45 (you have to adapt within 10 episodes) which would make it easier to compare to existing methods. c. If you re looking at an out of distribution task, do you update both $\phi$ and $\theta$? If you add this method, then it would help to explain why you compare to it, and what you can take away from this comparison. UPDATEI read the other reviews and the author s responses. Can you explain this a bit more?<BRK>The authors propose a novel meta RL algorithm that can both meta train and adapt to new tasks in an off policy way. Although the paper is well organized and mostly well written, I would like to point out some typos:1. Although a similar off policy idea has been adopted in MQL, the authors use the training data in another way, which is by relabeling them. In the experiments, the authors treat the information whether the task is in distribution or out of distribution as known, which is unrealistic in most cases. In the experiments, the authors conduct experiments that do not change some properties of MDP, more specifically, the state transition remains the same given the desired action. 4.Uncertainty of MIER. Fig.5 shows a strong uncertainty of the training curves and the training process does not seem to have converged for all experiments but Half Cheetah Velocity. Fig.6 raises a question for the necessity of data relabeling in terms of the final performance, since both MIER and MEIR wR converge to similar performance in most OOD cases.
Reject. rating score: 5. rating score: 5. rating score: 6. <BRK>This paper is well written and easy to follow. However, the overall technical contribution and novelty of this work remains to be a concern. After reading the response and the comments of peer reviewers, the rating is maintained as follows. The issue considered in this paper is interesting, and the proposed method is a good attempt to address this issue.<BRK>This paper proposes an interesting image processing approach to deal with the issue that the processed images cannot be recognized by machines. To this end, the contribution of this paper maybe not enough. The authors evaluate their design on three different image processing scenarios, i. e., super resolution, denoising, deblocking, and the improvements in all scenarios are impressive. Weakness:  The novelty is somewhat limited.<BRK>(2) The paper simply adding a transformer in between Process module and Recogition module, to guarantee the image processing quality not affected. This seem to be a trivial approach and need more experiment to justify. The problem is well formulated and experiments is comparably extensive.
Reject. rating score: 3. rating score: 3. rating score: 3. rating score: 4. <BRK>The experiments in Table 1 and Table show that the workflow do improve the final performance. Personally, I m not very comfortable with the authors not presenting formally what is Hyperband, what is Dijkstra s algorithm, and also how is the problem of finding the best ensemble modeled as a knapsack problem. It looks like for some experiments, a fixed time horizon is given. Could the authors highlight a bit more the technical difficulties if I have missed anything? Minor comments and grammar issues (non exhaustive):  In general, I would suggest the authors to review a bit the writing style of the paper.<BRK>This paper is proposing to build ensembles of deep models, components of which have different hyperparameter (HP) configurations. The correct reference for this is [1], and this is just what people do when they create ensembles. Batch ensemble: an alternative approach to efficient ensemble and lifelong learning. This algorithm is termed Dykstra s algorithm on a certain graph, but it is of course simply just the default greedy algorithm, which is almost by default used to create an ensemble from a pool.<BRK>not Schwenk & Bengio. The choice of the Dijkstra algorithm is poorly justified and might be incorrect  More baselines for comparison are requiredRecommendation:I strongly recommend that this paper be rejected. Furthermore, the paper is riddled with mistakes, unneeded details and bad explanations. For example, no need to mention work on multi objective optimization.<BRK>The authors contribute the idea of selecting a subset of models for building ensembles using the Dijkstra algorithm. Given that the latter is just an application of the algorithm, the former will have to be the main contribution of the paper. The application alone on HPO technique is a fairly straightforward one, even if effective, and does alone not warrant a paper, with the decent but limited results presented. * The results although limiting (only 2 datasets are used, ensemble baselines are missing) are promising. In some sense the proposed algorithm can be considered the obvious extension of this idea if presented with a cost constraint. * The paper would be stronger if results were presented on more datasets.
Reject. rating score: 10. rating score: 5. rating score: 5. rating score: 6. <BRK>The authors come up with a constructive method for deriving an estimator for this gradient for any distribution $p(z)$ based on Fourier analysis. Itis not clear why the difference between $f(z)$ and $f(z\*)$ is necessaryor why it should be interpreted as a discrete derivative as the $z$ vectoris not being perturbed. What is meant by the pathwise derivativein the experiments? For the toy problems. Rezende et al (2014) also mention the reparameterization of the variableunder stochastic backpropagation, and this gives a different gradientfor the covariance parameters of a Gaussian compared to the stochasticbackpropagation rule derived in the present paper. "What is the link between the discrete random variable case and thecontinuous case? **Questions**In the experiments, what is the performance for truncation depth 1, 2, 3?<BRK>This paper presents a general framework for deriving stochastic back propagation rules for both discrete and continuous distributions. The main contribution of this paper is to derive two general formula of gradient computation with respect to continuous and discrete random variables. The technique used in this paper is standard, and the applications on different distributions can conclude similar results as previous research works. It also verifies the correctness of the proposed generalized stochastic back propagation. In addition, using Fourier transformation (https://arxiv.org/pdf/1808.03953.pdf) in such case is not new. This paper should compare with some baselines.<BRK>The paper derives a unified view for stochastic back propagation for both continuous and discrete distributions. It is nice that the paper exposes several interesting connections between stochastic back propagation in both continuous and discrete cases as well as deterministic back propagation. However, it seems the approach is quite limited in its usage and it is not so clear what the advantage is.<BRK>In the present work, the authors present a general method for deriving stochastic back propagation rules, using the link between Fourier transforms and the characteristic function associated to the random variable probability distribution and transferring the derivative directly to the random variable. The presented numerical experiments show how this method can be used to match state of art performance in simple models. Finally, the authors highlight the fact that deterministic neural networks and usual back propagation can also be framed by the same method, by simply considering a Dirac s delta probability distribution for the parameters. I think the paper is well written and that the presented framework nicely connects many ideas and methods developed in the literature in the past decades. It seems clear that methods based on the reparametrization trick will always be more viable for deep models, but they are based on ad hoc rules. The presented method is instead general and might be more effective in special cases where an early truncation of the series is justified.
Reject. rating score: 5. rating score: 5. rating score: 7. rating score: 8. <BRK>The use of PAC Bayes theory for NLP tasks is rare. This makes me wonder if PABI would not better fit in the purely Bayesian framework (see other comments below). **Is PABI really backed by PAC Bayes theory? **As far as I understand, the procedure PABI is only remotely inspired by the PAC Bayes bound,  but is not truly justified by it. No PAC Bayes bounds are fully optimized; PABI borrows from PAC Bayes the sole idea of relying on the KL between distribution. For this reason, I think that the introduction sentence "Previous attempts are either not practical or too heuristic" is harsh, because the proposed method turns out to be a heuristic too. **Is PABI a more Bayesian method than a PAC Bayes one? **I wonder if one could not do the same analysis in a fully Bayesian setting, maximizing a Bayesian information criterion. Note that there is a direct link between the Bayesian Marginal Likelihood and the PAC Bayes generalization bound (e.g., Germain, et al., 2016: "PAC Bayesian Theory Meets Bayesian Inference.") Overall, I think that the paper explores a new and exciting territory, but needs a deeper analysis to support the connection with the PAC Bayes theory.<BRK>##########################################################################Summary: This paper proposes a unified PAC Bayesian based informativeness measure (PABI) to quantify the value of incidental signals. ##########################################################################Reasons for score:  Overall, my score is marginally below than acceptance threshold. Pros:1.I enjoyed reading the paper, and I like the idea of covering various types of supervision signals at one unified measure. In the introduction, I do understand how conceptually PABI is different from others, but do not know what it is. Does the strong correlation with relative improvement mean that it can be used as an alternative measure of mutual information and further applied to other applications using such information measures in their optimization?<BRK>#### SummaryThis paper proposes a unified measure for the informativeness of incidental signals (ie, not standard ground truth supervised labels) derived from the PAC Bayesian theoretical framework. Instantiations of the score are derived for a variety of these signals, and experiments show good agreement between the measure and true performance improvements. Besides the directions identified in the paper, one could easily imagine using this kind of a measure in ML applications as a tool to help guide economic decisions about what kinds of datasets or annotations to pursue. The supplemental appendix was comprehensive with respect to theoretical derivations and experimental details. Is there anything we can say about how good/accurate this approximation is? Is it possible to frame the PABI measures in terms of testable hypotheses about true generalization error, or are the bounds too loose in practice to say anything meaningful here?<BRK>This paper proposes PABI (PAC Bayesian Informativeness?), a way of measuring and predicting the usefulness of “incidental supervision signal” for a downstream classification task. In particular, when labeled data is only available in noisy or partial form, or over a different domain than the target test domain, this data may still be used to improve a classifier, but it’s unclear how to tell which forms of incidental supervision will be most useful. PABI is proposed as a very general framework. The most general form of the measure, dealing with updates to the concept class prior, seems that it could capture any kind of incidental supervision. Why not use more? In the case of transductive learning, it seems that a model needs to be trained on the incidental signal, although this is better than the combinatorial explosion of jointly trained models that would be required to test relative improvements directly. As proposed, the PABI framework seems very general—which is good. * It seems to me that the combination of inductive and transductive learning may be possible using something close to the paper s proposed methods , but this isn’t addressed by the paper except a glancing mention in Footnote 6. In particular, it seems that in this case the approximation method proposed for transductive learning would indeed have to reduce to training a combined model. This is fine.
Accept (Poster). rating score: 8. rating score: 7. rating score: 7. rating score: 5. <BRK>### Summary ###The paper presents an approach for predicting edits in programs, by modeling the programs as trees. The approach is mainly an extension of Yin et al.(2019), with the main difference that the model is required to predict only the output **actions**, instead of generating the entire output tree as in Yin et al.(2019).This difference of predicting only output actions is shared with other previous work though. Although the technical contribution is limited, the paper presents strong empirical results and a combination of interesting ideas. I feel like maybe this should have been the main focus of the paper. Limited novelty   the encoder, as far as I understand, is identical to the edit encoder of Graph2Tree (Yin et al.2019).The decoder ("editor") is better, empirically and conceptually, than the decoder of Graph2Tree, but its main novelty is the prediction of the edit action itself, rather than generating the entire output tree. First, the work of Tarlow et al.(2019) is not cited at all (although their application is different, the approach is very similar). These previous works are language agnostic as well, they just use a different AST "format". This argument would have been valid if it was demonstrated empirically that Hoppity s accuracy decreases as the length of the sequence increases. In that case, the imitation learning part might be a very natural fix (which was good!but not shown). In the one shot dataset (Fixers one shot)   Graph2Tree performs better than the proposed Graph2Edit model. ### Questions for Authors ###1. As far as I understand, when trained on these gold datasets: $f_{\Delta}$ depend on $C_{+}$, and then $f_{\Delta}$ is *used* in the prediction of $C_{+}$. I saw the footnote that says that  $f_{\Delta}$ does not *directly* expose $C_{+}$. Section 3.3 explicitly says that "given an input tree $C_{ }$ and an edit representation  $f_{\Delta}$ (calculated either from $<C_{ }, C_{+}>$ or another edit pair $<C _{ }, C _{+}>$), we generate one tree edit at a time step...". So, since in the gold dataset  $<C_{ }, C_{+}>$ $<C _{ }, C _{+}>$ , the authors model the "actions leading to $C_{+}$" given "an encoding of $C_{+}$"? If so, Graph2Tree (Yin et al., 2019) performs best on the Fixers one shot dataset (which is the "important" dataset). If not, and the gold datasets are meaningful on their own, then why there is no comparison to the seq2seq editor+decoder that Yin et al., 2019 found to perform best on the gold datasets? A conceptual discussion of the differences from previous work (Tarlow, Dinella, Brody). ### Minor questions and comments ###5. What is "incremental" about it?<BRK>## SummaryThe paper proposes a general model for incremental editing of tree structureddata such as abstract syntax trees. ## Pros  The work has several interesting and valuable contributions:  + Compared to previous work, the model is much more general: it supports    general tree edits, is language agnostic, and can handle much longer edit    sequences. + The novel edit encoder which directly encodes the edit actions is more    intuitively correct and also performs better than previous approaches. The source code will be released which   given the general nature of the  model   could enable further interesting research. + I don t think the results support the claim that Seq Edit Encoder memorizes    specific patterns with the baselines as the micro average of Graph2Tree for    Fixers one shot is very close to Graph2Edit. + Even if we accept the claim, that would not explain the CopySpan >    Graph2Tree > Graph2Edit results on GHE gold and Fixers gold. The authors    state that Seq Edit memorizes specific patterns, TreeDiff Edit learns more    generalizable information, and Graph2Edit makes Seq Edit learn more    generalizable information. So why does increasing    generalization by switching Seq Edit to TreeDiff Edit improve performance of    Graph2Edit on GHE gold and Fixers gold (which doesn t need generalization),    and decrease performance on Fixers one shot (which needs generalization)? As the Seq Edit encoder makes more mistakes and so it s    easier to improve, we don t know whether imitation learning helps in the    relevant case of the TreeDiff encoder. In my opinion this makes imitation    learning more of a digression and a less of an organic part of the paper. For example, the authors state  that they are adding subtrees as an edit operation, but as far as I  understand, they are adding individual nodes. ## Reasons for rankingI believe that the model is an important step in learning to represent edits. ## Minor comments  I found Figure 1 confusing at first, because there is essentially no caption  and the description of the figure comes much later in parts. It would be good  to either have a more substantial caption or to move the figure closer to the  explanations.<BRK>The authors focus specifically on abstract syntax tree representation of programs (e.g., C#). The model has two main parts:(1) Neural editor models p(a|) that iteratively performs tree edit actions such as sub tree deleting or adding;(2) Edit encoder learns edit representations f_Delta by encoding the sequence of ground truth tree edit actions. The authors also propose an imitation learning algorithm to train the editor and evaluate the model on source code edit datasets. The idea of incremental tree transformation pretty much follows that of Hoppity by Dinella et al, ICLR 2020 for bug fixing of Javascript programs. The difference is that to ensure the syntactic validity of the tree at any point, the authors use a grammar specified a priori. This mechanism was proposed in semantic parsing by Yin et al., ACL 2017. Compared to Hoppity, this model has another SubTreeCopy operation, but it is a somewhat straightforward extension of the copy mechanism from Yin et al.Although the whole idea is not new, I think the paper presents a valued extension to existing work. However, there are a number of parts that are unclear and need more clarity. 1.The authors should be clear (e.g., before Equation 1 and in Section 3) about where the sequence actions {a_t} comes from and how sub tree actions are represented (e.g., decomposed into single node actions). In Figure 1 and Equation 1, f_Delta does not depend on t and seems to be fixed. Similarly, for an *optional* cardinality field, what does the model do on the attached dummy node if the field is indeed optional? Equation 2 does the other way. 7.To what extent this framework is language agnostic? Despite the ASDL, even for the same language, different parsers can have different grammar specifications, so how easy is it to apply this framework for other languages? But it does not look like the source code for the baselines are available. Releasing the source code with that of the baselines would be helpful.<BRK>## SummaryThis paper presents an approach to learn a model over incremental structural tree edits, that takes as input a partially formed tree and applies a sequence of transformations that edit the tree into a final form. They focus on abstract syntax trees as used to represent expressions in programming languages, where the grammar is specified using the ASDL formalism. ## OverviewThe motivation for this work is weakly specified. Analogies are made to the fact that humans seem to edit objects in sequence, but not much more than that is provided. Writing wise, it is hard to tell what this paper actually contributes from the abstract or introduction. The claimed advantages over existing approaches are:  Supports general tree edits, whereas previous approaches are somehow more restricted  Language agnostic due to use of ASDL  Supports longer sequences of edits in practiceA major problem is that these advantages are only weakly demonstrated, if at all:   What is a general tree edit? The paper focuses on a very particular set of tree edits, so it is very unclear what is being claimed here. Language agnosticism through ASDL is a valid claim, and useful. It s not clear that generalizing any of the existing work to work with a general grammar would require much work though. Moreover, the work closest to this work (Dinella et al) is not compared against, neither experimentally, nor are the differences in the approaches detailed. Why?Overall while I think a useful software package could be made based on this work (which the authors suggest is forthcoming and which itself could be presented as a publication of a much different kind), the delta over existing work has not been demonstrated enough for me to recommend publication. ## Questions  In the LSTM encoding of an edit sequence, you have these four transformations to produce a_stop, a_Delete, a_Add, and a_CopySubTree.
Accept (Poster). rating score: 8. rating score: 6. rating score: 4. rating score: 4. <BRK>This paper describes a nearest neighbor enhancement to NMT, where internal token level context representations are used to index into a large data store to find relevant (source, target prefix) pairs. Since the index representation is taken from a pre softmax representation in the decoder network, no additional training of the NMT model is required. The authors show a diverse range of strong results, from improvements using a data store over the model’s own training data, to improvement from using a collection of domain specific corpora not present during training used for domain adaptation, to language specific collections to improve capacity of multilingual models. This is a very strong paper. It s well written and easy to read, the method is very novel to MT, and the results are great. The only complaint that I could imagine raising against this paper is that the method is not particularly novel in light of recent work on nearest neighbor language modeling, but in this day and age, with so many papers available, I think it’s actually very important to make these incremental stops in neighboring fields to make the connections explicitly clear. It looks like statistical significance, but if so, please be clear about what test was used.<BRK>An extensive evaluation is performed along with some detailed analysis on the important parameters. Strengths:  the idea is very simple, very easy to understand, and intuitive  can be added to existing pre trained NMT model  many interesting applications (domain adaptation, multilingual model specialization for instance) are presented and are mainly the reason why I think paper can be accepted for publication. the paper is easy to read and well writtenWeaknesses:   exploiting a translation memory at test time is not novel (exploitation of billions of tokens is rather impressive but in my opinion making this possible is more an engineering problem)  the approach is described within one page, the remainder of the paper is about evaluation and analysis. For ICLR, the paper lacks of substance. the improvements over SOTA English German are very small considering that billions of tokens are exploited and the high decoding cost. the experiments presented in this paper are not reproducible since unpublishable data are exploited to train the system (eg.CCMatrix)  computational cost at test time is extremely high, as expected. This is probably why nobody tried it before. Since the major issue of the proposed approach is its computational cost, adding the decoding time would probably encourage future work to try to improve it.<BRK>The authors conduct experiments are different settings, the single language pair translation, the multi lingual machine translation, and the domain adaption translation. Results show that kNN MT can easily improve translation performances by searching out related test sentences with non trivial scores. Comments:Generally speaking, the submission is okay and the proposed approach has no big flaws, however, I feel hard to make this submission to be accepted. It is clear that this submission is a direct and straightforward extension of the previously published ICLR 2020 paper: kNN LM. As the authors also clearly stated in the abstraction. Therefore, in terms of the contributions and differences, they are quite limited. However, the computation cost is also high. Though the authors mentioned there is a trade off and I also acknowledge this, but it is still not clear what is a good trade off. 3.Also, this method highly depends on the scale of the dataset, also the similarity between training and test dataset, if I understand correctly. This is another drawback of these search based algorithms. Therefore, shortly speaking, I feel this paper is straightforward to extend from the previous paper (indeed this is the future work and the answer from the review comments of previous work). This concerns me a lot for another one in ICLR 2021. Update:I thank the authors to give responses to my points, especially the discussion about novelty. But I still feel the success of KNN for NMT is similar for LM, that s why a lot of works study on NMT are also work on LM. Since this KNN method only targets at the decoder side, same as LM model.<BRK>The paper is an extension of [1]. The task in [1] is Language Modeling, while this paper is doing machine translation with the similar idea. The authors propose a non parametric method for machine translation via a k nearest neighbor (KNN) classifier. Specifically, it predicts tokens with a KNN classifier over examples cached in a so called datastore and this method can be applied to any pre trained neural machine translation model without further training. The experiments show that it improves results across a range of settings (in domain, out of domain, and multi lingual evaluations). + The experimental results across a range of settings are effective. Weaknesses:  Although the method is simple and does not add trainable parameters, it add the computational cost. The authors mentioned the computational cost briefly but there are no detailed experiments. It would be good to see the authors add more analysis on the computational cost, for example, how it varies with k.  Technical novelty over [1] seems to be incremental, where a large portion of the work is essentially regarding machine translation as a language modeling and applying the method in [1] to machine translation.
Reject. rating score: 4. rating score: 4. rating score: 6. rating score: 8. <BRK>To improve the understanding of CNNs, this paper proposes a method to constrain the behavior of AlexNet by replacing its first layer with a module based on wavelet packet decompositions. Three variants of wavelet decompositions are evaluated, including the separable wavelet packet transform and the 2D dual tree real and complex wavelet packet transforms. Pros:+ It is interesting to see the combined convolutional kernels, as shown in figure 3, resembles that of AlexNet. + The paper presents some intuitive explanations on some aspects of the results, including (1) why and how the proposed DT CWPT module can reduce the number of trainable parameters, with the accuracy rate maintained compared with standard AlexNet, and (2) why the three variants differ in accuracy. Cons:  The insight provided by this paper is vague, and it is not so clear how this can improve our understanding of CNNs (which was claimed as one of the contributions). Furthermore, what is the benefit of replacing the first layer of AlexNet with pre designed non trainable convolutions? (2) In the proposed networks, only the first layer of AlexNet is replaced, but most of the parameters are in the deeper layers, especially the FC layers. It is hard to see the advantage of such a reduction of trainable parameters. Lack of experiments. (1) Only one dataset is used, and we do not know how the filters would be affected when applied to a different dataset. (3) In the introduction, the paper refers to some previous work on replacing freely trained CNN layers with more constrained structures. But readers could also be interested in $W[i,\cdot]$ for $i 1,2$.<BRK>Summary:This paper proposes a modification to the prevalent CNN architecture that leverages filter banks based on wavelets with the motivation to reduce trainable parameters and improve interpretability. More specifically, the first CNN layer of the AlexNet architecture is replaced with a wavelet packet transform (WPT). The authors show the wavelet packet transform can be written as a series of convolution operation and visually compare the filters of the trained AlexNet to the WPT filters. Experiments on ImageNet show the proposed method can match the performance of AlexNet on ImageNet with fewer parameters. Pros:This work tackles in a focused way the interpretability and formalism of deep neural networks, specifically CNN, by grounding the first layers of the network in the frame work of the wavelet transform. The similarities shown in Figure 1 between trained AlexNet kernels and kernels from the proposed method are interestingThe reduction in learned parameters for the network under the proposed approach is a nice feature, and shows that stronger priors can guide learning. Cons:A crucial limitation of the proposed approach seems to be its application only to the first layer of the CNN. It would be interesting to apply the method to multiple layers of the network or in the extreme case, a network based solely on the WPT. Results on one CNN architecture on one dataset does not fully demonstrate the generalizability of the method. The authors show the proposed method reduces the number of learned parameters, however does the method reduce the total number of parameters?<BRK>This paper describes a variation of the popular AlexNet architecture, where the first convolutional layer is replaced with a wavelet packet decomposition. This is motivated by the fact that the first layer convolutional kernels look very similar to wavelet filters in that they mostly extract oriented edges and smooth gradients. The wavelet packet coefficients are then weighted using a single mixing layer implemented as a 1×1 convolution. The resulting module (wavelet packet decomposition plus 1×1 convolution) has a smaller number of learnable parameters, but achieves close to the same performance as the standard AlexNet on the ImageNet ILSVRC2012 dataset. The paper is well laid out and the important technical concepts are explained in a clear and concise manner. The various wavelet packet modules used to replace the first layer of AlexNet are well described and their differences clear. – p. 8, “does not restricts” should be “does not restrict”. While the experimental results are impressive, more could also be made out of the analysis. I also do not see any evidence that the authors intend to publish the code for this experiment. As discussed in the paper, there is a great need for theory explaining the performance of deep neural networks. This work is a step in that direction, reducing the number of learnable components and replacing them with fixed representations (here: wavelet packet decompositions) and achieving the same performance. Do these filters have certain properties that make them easier to analyze? Is the resulting reduction in number of learnable parameters greater? It is mostly speculation about how the number of parameters could be reduced further. Similarly, the authors speculate that the dual tree real wavelet packets perform worse than the complex variant due to higher sensitivity to image shifts. Whether this is the case can be easily tested experimentally by shifting the images in the test set. There are also a few small problems in the main text:– p. 3, in Definition 1, it is not clear how the operator is defined.<BRK>Summary:The authors propose a scheme for combining the trusted mathematical properties of Dual Tree Wavelet Packets with CNN style feature extraction. Specifically, they learn simple functions of wavelet kernel outputs, rather than learning kernels themselves from scratch. The fundamental gains are a significant drop in the number of parameters, while retaining feature expressiveness and intuition. Clarity:The paper clarity is significantly above average. Quality:The paper is very clear and concise, but it might be better if it compared across other nets besides AlexNet. For example, how does it compare to nets with feature extractors in the same order of magnitude (3k parameters), vs much bigger (alexnet: 25k). Originality/Significance:I am not extremely familiar with literature related to this idea. However, I think constraining CNN filters in this way is an important area of research.
Reject. rating score: 3. rating score: 5. rating score: 6. rating score: 6. <BRK>The idea is to generate OOD data, close to the training data, where the model is overconfident, and force a higher entropy for their corresponding predictions. This topic is very relevant to the ICLR community, the paper is clear, and I was excited with the goal in a first place. However, the paper as it is has major drawbacks. Up to how many dimensions would this approach be useful? Yet, one might think that the amount of data needed to robustify uncertainty would depend on the manifold geometry. In particular, PAD* Could the proposed approach suffer from the opposite issue, i.e., deliver too high uncertainty in the augmented OOD data? * How does the proposed approach compare to a DNN whose last layer is GP or Bayesian RBF network?<BRK>Overview:The authors propose a data augmentation scheme that generates samples out of distribution and helps with uncertainty estimates. The major concern is that the gains seem relatively small, and the objective is ad hoc. It would be nice to see either more substantial, uniform gains (so that the authors can justify the procedure on the results alone) or more solid conceptual motivation of the method, especially from the Bayesian side. It seems like the motivation and intro is clear, and section 3 onwards becomes very ad hoc and loses much of this. It would be nice to be convinced that there are a set of assumptions and conditions under which this is the right way to do uncertainty quantification. Uncertainty estimation out of distribution is an important and timely problem. The fact that non bayesian methods have similar issues with uncertainty quantification would suggest that the latter is certainly an issue. Is it really not possible to post process the model distribution to achieve the same thing? The experiments are extensive, but a bit mixed. The corruptions in MNIST / CIFAR must also be pretty aggressive, as the accuracy numbers are quite low for both. Does PAD do similarly well on milder or no distribution shift settings?<BRK>I think the empirical results are strong, and while I am not as troubled by the motivation and framing of the work as reviewers 3 and 4, I think their more conceptual and methodological critiques have merit, dampening my enthusiasm for the submission. This is a solid paper: the proposed method seems sensible (if pretty complex) and appears to be modestly effective in the included experimental results. It proposes a model driven data augmentation technique aimed at improving calibration and reducing over confidence for OOD samples. Maybe also some counts for how often a PAD variant has the best performance. The proposed technique seems sensible, if complicated: add a generator network to produce OOD pseudo samples during training and penalize the prediction network for making high confidence (low entropy) predictions on these pseudo samples. The intuition for the OOD samples resonates with me: they should be close enough to real data to be plausible but far enough away that the predictor would be unjustified in assigning a high confidence or departing from the prior. The regularization term in Equation (7) is a bit more arcane at first glance, but it s intuitive: the conditional prediction distribution should be close to the prior for pseudo data points far from the real training distribution. The experimental results are promising.<BRK>I think the paper is interesting and well written. Addressing OOD data is an important direction, and I think the author proposed a reasonable approach to prevent models from overfitting on data points that are rarely observed during training. However, I believe there are some limitation of the method at the current stage, and the experiments did not fully convince me. The paper addresses an important question of models being over confident on out of distribution data. The method is practical for applications where uncertainty estimation is needed. 3.The authors included a good selection of datasets and experiments. The PAD based methods are also compared to a good variety of baselines. I would like the authors to give more details on how it is chosen. In figure 5, it looks like the OOD data are mostly in the convex hull of observed data (at least in this low dimensional embedding).
Reject. rating score: 3. rating score: 5. rating score: 5. rating score: 8. <BRK>However, I see Sunrise as combining two ideas: weighting and UCB exploration. The first issue is the justification for the approach. The terms inconsistency and unstable convergence should be explained, since they seem like technical terms. There are natural questions as to the interaction between the ensemble uncertainty estimates and the ensemble estimates. 4.What is meant by the signal to noise in Q updates? What is the final point of convergence? Then the question arises how much it is helping, and why this small reduction in weight helps. This is particularly important to ask, considering the algorithm requires an ensemble to be learned, with subsets of data used for each action value. Unfortunately, I remain concerned about the significance of experiments. But, as part of the reply, the authors state: "Figure 3(a) shows the learning curves of all methods on the SlimHumanoid ET environment over 10 random seeds. But, the ablations themselves are not sufficiently in depth to provide insight into the idea and algorithm. The results in Figure 2 are key, since that figure examines Sunrise with and without the weighting. This implies that the proposed weighted Bellman backups can handle the error propagation effectively even though there is a large noise in reward function." The results in Figure 3, which motivate the exploration utility, are more clear in Cartpole. The main novelty in this work is the weighting. But, of course, there will be higher variance due to differences in the environments, so it is not obvious this would be true.<BRK>The only new idea here is perhaps a specific way of reweighting the Bellman backups though the idea of reweighting the Bellman backups to stabilize the learning is already known e.g., Kumar et al.2020.Significance: In addition, at the present form I find it hard to be convinced both empirically and theoretically (or at least more elaborate explanation or intuition) why the proposed weighted Bellman backups using empirical std of Q functions improve the signal to noise in Q updates as claimed in the paper (see Questions for the authors). ###  Questions for the authors  	In the last sentence of Section 4.1, the paper claims that “the proposed objective … has a better signal to noise ratio”. I would like the authors to elaborate in this claim. Why down weighting the sample transitions with high variance across target Q functions result in a better signal to noise ratio? For simplicity for the moment let’s call by “reward to noise ratio” the ratio of the magnitude of the original reward signal r(s,a) to the magnitude of the added noise. Then, how the performance of the proposed weighted Bellman updates when the “reward to noise ratio” varies? ### My final recommendation The authors did not fully address my points.<BRK>The authors finally tested the proposed method on both continuous and discrete reinforcement learning tasks, and showed the improved or competitive performance, compared with baselines. The proposed ensemble based approach is interesting and the authors conducted an extensive experiments to verify its empirical performance, which I really appreciate. On the other hand, I am a bit concerned about whether the improvement is indeed because of the weighted backups. For example, Figure 3(a) showed that if removing UCB, the performance for SUNRISE dropped a lot. Therefore, it s a bit questionable whether UCB or the proposed weighted backups is the main factor for performance improvement. I hope there could be more rigor here. What exactly is the definition for this term? Furthermore, I also doubt about the fairness in Table 3: The results there are only for 100K interactions; however, when comparing with Figure 8, Rainbow has not become stable at 100K and the scores for some games are just too low (e.g., Breakout), compared with results in the Rainbow paper. There are a few recent papers on the weighted Q updates as well, e.g.,Song, Z., Parr, R. and Carin, L., 2019, May.<BRK>  Overview   The paper proposes SUNRISE, an approach to reinforcement learning that leverages ensembles of agents to build more robust RL updates. Sample transitions for which there is larger variability (across the ensemble) in the estimates of the next step Q values are down weighted in the computation of the loss, thus potentially rendering the learned Q function more robust to noise. Additionally, the proposed approach is sensible and the empirical evaluation is, in my perspective, quite comprehensive: SUNRISE is evaluated in a broad collection of domains in the RL literature. Negative points  The paper would benefit, in my opinion, from additional discussion regarding: (a) the impact of the use of bootstrap with random initialization; and (b) the computational complexity of SUNRISE (even if the paper does briefly discuss the latter in Section 5.2)  Comments   I quite enjoyed reading the paper. The problem addressed is a relevant problem in RL, and the approach proposed in the paper is, in my opinion, simultaneously simple and sensible. The results show that SUNRISE compares favorably   in terms of performance   with several of these other methods in multiple domains. While the paper introduces both bootstrapping and UCB exploration as a "useful complement", it seems to me that this is quite central to the performance of the algorithm.
Reject. rating score: 5. rating score: 5. rating score: 6. rating score: 7. <BRK>SummaryThis paper proposes an actor critic algorithm based on distributional RL. Review SummaryThere is a solid algorithmic contribution in this paper, although at present the comparison against baselines considered feels a little incomplete. SignificanceWhile several aspects of the proposed algorithm have been explored before (multi step returns in distributional RL, Cramer distance in training loss), these components are combined to yield a novel algorithm, and the treatment of multi step returns differs from previous work. Below Equation (12), the authors discuss pdfs of Z^{(n)}_t etc., but presumably these random variables may not have pdfs? Minor comments on formatting etc. selected for the methods considered in the paper? I appreciate the effort the authors have put in during the rebuttal phase, and would say the paper is now clearer. Figure 2 experiment. However, the main drawbacks that remain are empirical; the smaller scale comparisons between methods need to be updated to give a like for like comparison in terms of numbers of parameters etc., as the authors acknowledge, and the paper still lacks baseline distributional agents in the large scale experiments. This is important, as it means it is difficult to assess the impact that, for example, SR(lambda) may be having on the experimental results.<BRK>This paper proposes to learn a Gaussian Mixture Model of the distribution of returns and use it as the critic in an actor critic RL agent. However, this work has several problems that make it unpublishable at the moment. Approximated how well? Existing work has considered multi step returns in distributional RL (Rainbow, Reactor, as well as almost all methods that use AC with Dist.RL).However, the Sample Replacement method is an interesting contribution that is novel compared with this existing work. While this is an interesting topic, the authors do not actually address it or contribute towards its understanding or solution in any way. "The actor critic method is a specific case of temporal difference (TD) learning method in w hich the value function, the critic, is learned through the TD error defined by the difference..."Actor critic uses TD to learn the critic, but it is not a specific case of TD. Huber quantiles are not quantiles. The authors learn Huber quantiles and then treat them as quantiles and observe they look wrong.<BRK>This paper proposes a distributional Actor critic framework (GMAC) based on GMM, Actor critic and Cramer distance. Authors introduce SR(λ) a distributional version of the λ return algorithm and to minimize the Cramer distance   as opposed to minimizing the Wasserstein distance using Huber quantile regression  between the value distribution, this helps in obtaining unbiased sampled gradients, this is shown to be more effective in preserving modality that can provide extra information in sparse reward exploration tasks as well as more stability during training. Clarity: The paper is easy to follow and well written. The motivations are quite clear from the beginning. Experiments and significance of the empirical results: Authors evaluate GMAC using a two state MDP, a set of discrete and continuous action space tasks. the majority of the results presented show convincing improvements of GMAC over IQAC and the PPO baselines. Questions:q1: in Figure 7, the PyBullet learning curves, In 3/5 of the learning curves IQN + Huber quantile (IQAC) seems to be performing on par or better than GMAC. this makes me wonder what conceptually makes GMAC specifically suitable for both Discrete and continuous action spaces. q2: Since there are no space limitations in the appendix.<BRK>Using GMMs for distRL: it appears explored before in ref 1, but not cited. The distribution learned by DistRL is prevoulsy shown to be asymmetirc (Fig 5 of Mavrin et.al.2019).one question: since the three problems also exist for distRL alg s like QRDQN, why don t you improve the original value function approximation distRL alg s, but instead on AC algorithms? DRL: deep reinforcement learning. Morimura et al.(2010a;b) designed a risk sensitive algorithm using a distributional perspective: this paper is perhaps the earliest concept of distRL. We believe that the findings from this paper can easily generalizeto other actor critic frameworks as well: are you sure the other alg s all have the same kind of the (three) issues? Previously experiments by Mavrin et. Discrete and Continuous Action Spaces section:Do you use the same algorithm for both cases? Why PPO, IQAC IQAC E GMAC are selected? How these alg s compare to distRL alg s like DQN, C51, QRDQN?
Accept (Poster). rating score: 7. rating score: 7. rating score: 7. rating score: 6. <BRK>This article tackles the analysis of irregular samples time series. The approach is mainly based on interpolation. The architecture is made of a sinusoid attention layer, a VAE layer that lead to a fixed size set of landmark in the latent space and a RNN decoder. They obtain impressive results on the interpolation task and interesting results on the classification task. * In an interpolation problem, we would like to consider a robust baseline as a linear interpolation or an AR like modeling. * Results are impressive but I don t get which part of the architecture lead to such a performance<BRK>One query I had is regarding the application of the proposed framework for extrapolation or forecasting tasks. The paper is well written and easy to follow. The multi time attention mechanism takes a query time t and a multivariate sparse and irregularly sampled time series, and returns a fixed dimensional embedding for the query time t. This mechanism is used twice in an encoder decoder VAE framework with varying reference (input) and query (output) time points. The idea of the paper is novel, impactful, and well explained.<BRK>This paper proposed a new model (mTANs) for sparse and irregularly sampled multivariate time series. It incorporates the time attention mechanism to learn embedding for continuous time series based on a kernel smoothing method. I have the following comments that I think is worthwhile to consider to improve the paper:1. I didn t see much on the main method sections that specifically address/discuss sparsity and irregular sample problems, it seems like the proposed method also works for general time series data. 3.How does an extra module of mTAND in encoding and decoding procedure help intuitively?<BRK>In particular, it proposes an mTAN network to leverage the mTAN module in an encoder decoder framework for both unsupervised and supervised Learning. Empirical studies are performed to show the superiority of the proposed model mTANs over several baseline approaches on the tasks unsupervised and supervised learning. 2.The proposed mTAN is novel for capturing the time dependencies time series, sparse, irregularly sampled, and multivariate data. 3.This paper provides comprehensive experiments, including both unsupervised and supervised learning results, to show the effectiveness of the proposed framework. 3.As the model is attention based, it has the ability to find the relationships among sequential events.
Accept (Poster). rating score: 8. rating score: 8. rating score: 6. rating score: 6. <BRK>Specifically, the first use the concept of convolution support to unite the ideas of spatial based methods and spectral based methods. In general, the paper brings an interesting perspective in addition to the WL test to reveal the expressive power of GNNs, and both the theory and evaluation sound solid. I also suggest the authors to revise Definition 2 to further explain why each convolution support has the same frequency response over different graphs in a spectral designed case, as there might be some training parameters that can be affected by different graph structures. The analysis in Sec.5 is interesting, but it would be better if the authors can expand the discussion on how we can further utilize the obtained frequency profile to analyze the expressive power of different GNNs. In summary, this work provides a new perspective in analyzing the expressive power of GNNs and I suggest the authors to further address the above issues.<BRK>In particular, it shows the kernel for all kinds of proposed GNN models can be expressed in a general form with a specific frequency response definition, which indicates the spectral property (spectrum) of the kernel. + The experimental result shows that it is important to have different kinds of filters   Cons  I do not have too much criticism about this work. Another question is that, the expressive power analyzed by WL test involves the depth of the network, while in this work it appears that only one layer is considered, so I am wondering *what is the relation between the depth and the expressive power, from a spectral perspective? * To me it seems to be difficult to analyze, but I believe it is worth to address, as we have seen the importance of depth in CNNs. Reason for score  This paper is clear written, the spectral perspective looks very interesting to me, the theoretical analysis appears to be correct and solid, and the experimental result verifies that the analysis from such perspective is important indeed.<BRK>The connection between spatial and spectral GNNs is remarked upon in Bruna s original 2013 paper and is discussed in later papers (e.g., Kipf&Welling GCN, Wu+2019a_ICML). However, this paper makes the connection explicit. On the flip side, the technical novelty in the paper might not be sufficient but I would still argue that the paper merits publication. The MNIST superpixel dataset gives a highly biased view for need of high pass filter (which is provided by spectrally designed GNNs). ## Questions to the authors   Since the theoretical frequency response of CayleyNet, ChebNet, GCN, GIN and GAT,  is one of the main contributions of this paper,  I think the paper would benefit from presenting this in a tabular form in the main text e.g.,  Method, Classification (design(spatial/spectral), support (fixed/trainable), frequency response dependent on graph structure, etc.)<BRK>1.Summary: The authors study the expressive power of GNNs from the spectral view and bridge the gap between spectral and spatial designs of graph convolutions by casting several popular GNN models into a common framework. 3.Clearly state your recommendation (accept or reject) with one or two key reasons for this choice:I am slightly leaning towards recommending a rejection to this paper, with the main reason being that I am not sure if the contributions are sufficiently significant, as I will elaborate below. They could be correct in the end, but it will be better to support them with either theoretical arguments or experimental evidence. b) As I mentioned above, it would be nice if some of the claims can be further supported. Revisiting graph neural networks: All we have is low pass filters.
Reject. rating score: 4. rating score: 4. rating score: 5. rating score: 5. <BRK>1.It is not convincing to me why the proposed model should be better than existing energy based model. It is the nature of all EBMs to assign high density to training data and lower down the energy of the sampled data. The authors should shorten the descriptions of known results on EBMs and focus more on why the defined energy is better than existing  on OOD. There are other AE based works on OOD/Anomaly detection are not discussed, such as * Rate Distortion Optimization Guided Autoencoder for Isometric Embedding in Euclidean Latent Space5.<BRK>The authors address an important problem of autoencoders having low reconstruction error for OOD instances. For anomaly detection in particular it is not sufficient just to report AUC and other metrics like AUPR or F 1 score should also be reported. Empirical analysis reveals that the proposed method outperforms existing autoencoder baselines.<BRK>A generative autoencoder outlier detection called EBAE is proposed by introducing fake samples which produce small  reconstruction error, yet being outliers, during training to enhance the AE outlier detectability. The paper approaches an interesting topic that why AE  may fail to detect OOD samples. and do you have any results showing the proposed method could outperform overfitting. Could we improve OOD detection by other augmentation like those artificial done in Figure 1?<BRK>### SummaryThe paper describes a new method for detecting outliers with deep autoencoders by suppressing the reconstruction of out of distribution data. The main novel contribution is the Energy based Autoencoder (EBAE), a variant of an autoencoder in which the reconstruction loss is directly used as an energy function, and therefore outliers should have high energy. A.(2018).Waic, but why? In the section on outlier reconstruction it is not clear which of the proposed reasons for outlier reconstruction by AEs are novel insights, and which are known facts from the literature. The paper shows a new method for outlier detection that improves existing AE based techniques.
Reject. rating score: 4. rating score: 5. rating score: 6. rating score: 6. <BRK>The method in the paper looks like a combination of a number of well known techniques, which might limit the novelty claim in this paper. The writing quality of this paper is worrying. However, the writing quality of this paper is worrying. 2.To me, the novelty of this paper is limited, it seems like an extension to Once for all, and the authors also cited this work.<BRK>This paper proposed a method to train quantized supernets which can be directly deployed without retraining. At this point, the contribution in terms of the novelty is limited. It s not clear what is the main factor in this comparison. Are all the methods using the same experiment setup?<BRK>This paper presents a new method to search for quantized neural networks. This method is different from others that it results in quantized weights which can be deployed without post process such as fine tuning. However, the knowledge distillation method is not specified after the statement. However, there is no analysis on the search cost under such scenarios. I believe that additional analysis on the benefit of deploying the quantized weights without retraining in the mean of search cost must be given in the paper as one of the main contribution of the paper is that the proposed method allows the deployment without retraining.<BRK>This paper presents One Quantize for all framework. The framework claims to search for the network and the quantization without the need for retraining. Results are promising although it is not clear to me if the comparisons are fair (different bit size). It is not clear to me why the number of FLOPS is so low compared to related methods.
Reject. rating score: 5. rating score: 6. rating score: 6. rating score: 6. <BRK>This paper presents a "remastered" version of the Deep Mind Control suite that allows for testing of visual generalization to a number of environmental changes (e.g., pattern/texture of the floor, background, and lighting). While this paper seems positioned as a more systematic baselining and data set paper and the novelty from an methodological perspective is somewhat low. I think these are helpful in increasing how challenging the baseline is and providing more sight about how well the current methods perform. The link to the anonymous page wasn t working for me, I tried several PDF viewers but couldn t access it. Also the image assets did not seem to be included in the supplementary material. I understand that these augmentations might be novel in the domain of RL, however, I think it is worth noting how adding conceptually this is something that has been done in past in several computer vision domains/tasks. Tables 1 and 2 don t have clearly labeled units. This might seem minor but is a constant frustration for readers. To summarize, I think that this work is a helpful contribution, albeit with somewhat limited innovation.<BRK>The purpose of the dataset is to measure the generalization and transfer abilities of pixel based continuous control agents across different visual variations. The paper presents a comparison between several different representation learning method for CC models and concludes that augmentation plays a big role in making such models generalize well. Demonstrating the ability of methods to be robust to more severe changes in the viewpoint would be a harder and more convincing test case (as it affects, directly, some task relevant properties which can be extracted from the scene). Finally, in terms of the baselines used and the results shown   I think it would have been good to show another RL method other than SAC   just to make sure results (in terms of augmentation and generalizablity) to not depend greatly on the specific choice of underlying RL algorithm. To conclude   I think this is a nice contribution with a potential to be even nicer. *Post Rebuttal*The authors have mostly addressed my concerns   I still think SAC should not only be the only RL method in the paper, and though I m still not convinced more drastic camera variations wouldn t make this more interesting I think all in all this is a decent contribution and probably should be accepted.<BRK>### **Summary and Contributions of Paper** This paper proposes a new RL Generalization benchmark based on the DM Control Suite, where there are multiple changing backgrounds but fixed dynamics. Paper is written well and is easily understandable. Nearly identical DeepMind Control/background benchmarks have been proposed in (Zhang et al 2020). One unfortunate trap that many RL generalization benchmark papers fall into, is the pattern of "Propose benchmark, test algorithms/hyperparameters", without providing revelations/ablations as to why such methods work conceptually, or why certain phenomena exist. Properties of the policy/SAC algorithm, such as how different data augmentations affect its optimization process. I assume from Fig.8 that the background moves along with the agent, and thus forward progress (via reward function) can be spuriously correlated with the background, but could you please clarify this point? From the authors  responses to Q 3.2 and Q 3.3, I believe that the main visual overfitting is occurring with the floor tile, as it is the only spurious object that is correlated with progress.<BRK>This paper extends the DeepMind Control Suite benchmark by adding a series of visual variations across different tasks (e.g.lighting, color, background, textures, camera angles etc.). They also contrast a few recent self supervised learning and data augmentation RL methods and measure these agents’ ability to generalize and transfer across a variety of visual variations provided by their benchmark. They also investigate different aspects of the variation in the scene that these agents seem to be most affected by. Overall, this paper is clearly written and the analysis is very thorough and well motivated. However the results in my view are not that surprising: the observation that agents that have been trained only on a  single  visual variation of an environment overfit to the visual features and fail to generalize outside of this distribution is not particularly novel. While I appreciate the amount of work that has been done here and the helpful analysis, contrasting different state of the art methods on self supervised learning, I have some questions/concerns:1. Could you comment on that?
Reject. rating score: 5. rating score: 5. rating score: 5. rating score: 7. <BRK>The authors explain the merits of second order graph convolution from the perspective of representation ability. The resulted second order graph convolutional networks are compared with several graph convolutional networks on three benchmarks. +: The proposed method is simple and easy to implement. Besides, second order or higher order information have also been used for global pooling for convolution networks [r3, r4, r5], which also show better representation ability. This paper lacks discussions on above these works, which will bring a side effect on contributions of this paper. Besides, why higher order  GCN are not compared on real world benchmarks. (4) Which method does MoNet indicate in Table 2 ?<BRK>This is yet another paper on graph convolutional networks (GCNs). The investigated SoGCN is a second order GCN, thus a special case of high order GCNs (namely with multi hop graph kernels), which have has been proposed earlier by many researchers, such as by Defferrard et al.(2016), by Kipf & Welling (2017) and by Abu El Haija et al.(2019).The main interest is that a second order GC is a universal approximator, because any univariate polynomial can be factorized into sub polynomials of degree two, which is not the case of first order GCs. For example, two versions of the nonlinear activation are considered in experiments on CIFAR10 (with and without GRU); however, they were not considered in other experiments. Moreover, it is not clear where the combined RELU and GRU is considered.<BRK>The submission identifies the importance of second order filter by showing that two is the minimally necessary order to achieve full representation power. Without using GRU, the proposed method in fact does not achieve state of the art performance on CIFAR10 and MNIST, which is concerning. I encourage the authors to provide more in depth analysis of GRU and connects it to the rest of the paper. As Figure 2 showed, GRU also changes the signal of a vanilla GCN significantly. Also, the theory predicts that the linear Second Order GCN should outperform linear Vanilla GCN (this is like SGC?). As the authors acknowledge in the introduction, Abu El Haija et al.(2019), MixHop, makes similar observations about higher order GCN.<BRK>The authors argue that second order graph convolutions (SoGC) should be the building blocks for future graph networks. According to the [homepage of MNIST](http://yann.lecun.com/exdb/mnist/), none of the MNIST results in Table 2 is better than an SVM with degree 4 polynomial kernels, a 2 layer MLP with 800d, or a LeNet 1 which has only 3k parameters instead of 100k. In general, the theory is sound and the results on the synthetic data and ZINC are strong and I don t see many flaws, but I would like to see more results on realistic datasets.
Reject. rating score: 4. rating score: 4. rating score: 6. rating score: 6. <BRK>I m also surprised that the paper did not provide a comparison to stronger lifelong baselines, like those based on experience replay, which have been shown to vastly outperform regularization based methods in recent work (e.g., Lopez Paz & Ranzato). Intro  Some paragraphs are spaced and some aren t. The rest of the paper has un spaced paragraphs only. for decimals. What s N in the summation? This should be stated in text.<BRK>The authors benchmark HRNs against several baselines in a number of tasks. Some relevant existing work has not been cited and compared to: the authors did not cite the ANML algorithm (https://arxiv.org/pdf/2002.09571.pdf), which has achieved state of the art performance on tasks similar to the one that the papers of the paper reviewed here evaluate on.<BRK>The 10 groups and corresponding labels serve as 10 distinct tasks for evaluating continual learning. It will be good if the paper can provide some explanations. It will be perfect if the authors can show real applications of the proposed continual learning with decreased accuracy scores. The experiments in Figure 2 verify that the proposed HRN outperforms a number of baselines on incremental Cifar100 dataset.<BRK>New convolution filters can be added to the network without increasing the computational cost of the network. 3) Couldn t you train a single model on the old and new datasets such that it performs well on both?
Accept (Poster). rating score: 8. rating score: 7. rating score: 6. rating score: 5. <BRK>The paper considers stochastic gradient descent convergence in a distributed setting with m workers, where up to α workers can be Byzantine, i.e.perform in an arbitrarily adversarial way. Can this work use this assumption? I believe that footnote 3 on page 4 talks about this assumption and argues that it may be too strong for practical applications, but I don’t see a reason to not get a result with this assumption. Can this paper handle this kind of assumption? The reason why α 1/sqrt(m) is a threshold is also not clear. Minor issues:While assuming that smoothness constants are 1 slightly simplifies the presentation, I believe that it makes some transitions harder to understand.<BRK>I am also satisfied with the authors  response to my comments and to the comments of the other reviewers. This paper studies distributed non convex learning that is Byzantine resilient. The paper has a nice blend of algorithmic development, theoretical analysis, and detailed experiments. It would be useful to see how does the proposed approach work in the presence of non i.i.d.datasets and how does it compare to works such as the one referenced earlier. This adds one more parameter to the problem and it is not clear how would one tune this parameter. How does one fix these parameters and how were these parameters set for the experiments?<BRK>I appreciate the formal work and it clearly aligns with the results they have shown in the paper and in the supplementary part. The results are in favor of the authors  method. This should be presented in a clear way. The formal analysis is though rigorous but it requires a lot of time to understand as some of these notations are not defined and clearly mentioned and one has to assume some of the arguments presented to follow on.<BRK>In this paper, the authors propose a new algorithm called SafeguardSGD, which solves the Byzantine detection problem, and tolerate less than half Byzantine workers with theoretical guarantees. However, there are some issues to be resolved:1. Such assumption is not required by most of the previous works (Krum, median, Zeno), although it may not be emphasized in the previous work.
Accept (Poster). rating score: 7. rating score: 7. rating score: 5. rating score: 5. <BRK>The authors build upon prior work (FineGAN) in intra domain disentanglement to extend to inter domain transfer of separate attributes. Since no ground truth data exists for inter domain transfer, they use contrastive losses to enforce similar statistics of low level filter activations (averaged over the image) as a proxy for appearance similarity. Quantitative metrics support this point. That said, the paper could be significantly improved by spending less space motivating and defining the problem, and more space describing the actual method used.<BRK>### SummaryThis paper proposes a generative model as an extension of FineGAN that aims to learn a disentangled representation for image shape and appearance across different domains rather than "intra domain" disentanglement. To this end, the authors adopt the prior that features that correspond to an object s appearance should preserve frequency histograms. How is sim in eq.1 defined? I have read the other reviews and responses and still believe that the paper is a good contribution. Therefore, I am keeping my score.<BRK> Summary:The paper proposed a method to learn disentangled representation of shape and appearance for cross domain (different object categories) data. The motivation is still unclear. I still don t get the point for the usefulness of appearance transfer across two different types of objects (e.g.car and animal) which they claim as their contribution. For example, I don t see the application for applying car appearance to animals. Recommendation:Although the authors demonstrate the effectiveness of the proposed method, there are some concerns to be addressed: 1) Motivation is not intuitive. 2) There are many more recent papers for transferring appearance to another shape, e.g.StarGANv2[1], which is not included in the experiment.<BRK>As it is I feel that the paper would need significant revision for acceptance at ICLR. ### Strengths**[S1]** The paper is written well and it seems that one could reproduce the method reasonably. **[S3]** Based on the given motivation, retaining the low level statistics of the image, the authors derive how to model a solution, optimize and evaluate it with respect to this motivation in a structured manner. This indeed could be a strong point, see W2. **[W6]** I read the submission as more of an empirical paper than theoretical paper.
Accept (Poster). rating score: 8. rating score: 7. rating score: 6. rating score: 4. <BRK>The contributions of this paper are the following:   it extends previous work on binary neural networks to the case of deep generative models which perform density estimation (VAEs and Flows)   the results show that the proposed approach works well, with the expected trade off but closely matching the much larger real valued networks   in order to do so, it introduces a novel technique for binarizing weight normalized layers, which are used in these generative models   the results show the advantage of this technique, and they illustrate it is particularly important for ResNet layers. Originality is clear but not very high, as this contribution may be seen as a low hanging fruit, albeit a useful and well executed one.<BRK>However, the largest models we see in the world today are knowledge representation and language models (transformers)). The authors call this a “framework” to go to binary weights and/or activations, but this is really a set of methods shown to work on a particular NN. A major contribution of the paper is Binary Weight Normalization (BWN) and the binarizing method for residual layers. There is something deeper there. However, binarization is still seen as a method to try and reduce the computational load of something that is already being done.<BRK>The paper introduces the first way (to the best of authors knowledge) of building generative models with binary weights. 4.My major concern is the visual quality of the images obtained by binary models. Do I understand right that there is a clear visual difference between objects generated by real valued and binarized networks of similar size? I have several questions on the proposed methodology:1.<BRK>The authors propose to binarize weights and activations of generative VAE and Flow++ models. Also, as generative models are often evaluated qualitatively, the paper would benefit from including several samples from binarized models, to show that quality does not degrade. Overall, motivation for binarizing generative models is unclear. An experiment ablating an architecture with/without the proposed binary weight normalization is missing.
Reject. rating score: 5. rating score: 5. rating score: 6. rating score: 8. <BRK>The authors propose to extract two types of explanations: abductive and contrastive explanations to address a gap in the literature of explainable AI. Indeed, that s a great point and often explainable models address the "why" and rarely the "why not" that can help identify the features guiding the change in the class. Comparison to Shap (using correlation) is not discussed. provides some statistics on the time, number of abductive and contrastive explanations. Overall, there is a need for some baseline to validate the explanations (both types); 6  The methodology should be made clearer, notations introduced or re introduced, many readers might not be familar with some notations like entailments; Overall, I feel there are good ideas in there, the authors should consider enlarging the spectrum of the applicability of their approach, may be rework the definitions and methodology section and design more solid experiments.<BRK>I thank the authors for their submission. High level comments:* generally, the paper does a good review of existing literature and aims to relate two important subfields (abductive vs contrastive explanations) using rules of logic, particularly using the minimal hitting set relationship * beyond showing that such a duality holds between abductors and contrastive explanations, I believe the experimental section should further explore comparisons with related work such as Dhurandhar et al.(as cited in earlier sections) and Rebeiro et al.* furthermore, the idea of using FOL for generative contrastive explanations (also sometimes called counterfactual explanations) has been explored before (e.g., [Karimi et al.]);* on the presentation of material, there seemed to be an underwritten requirement to be familiar and have a background in logic and verification, which makes me wonder whether ICLR is the right venue here (I also apologize for not being to provide much feedback on the technical front)Minor comments and nits:  the footnotes seemed to contain important details, but the number of footnotes seemed overwhelming and hurt the flow of reading  [footnote 9] seems incorrect; e.g., non linearities in MLPs or RBF kernels in SVMs cannot be encoded as first order logic  perhaps figure 2 can be redone to more visually demonstrate the benefit of using the proposed method; if the provided explanations aren’t visually appealing (relatively), then perhaps consider a non image based dataset?<BRK>OverviewThis paper develops, what it calls, contrastive explanations using first order logic. Contrastive explanations answer the why not question, while standard explanations (abductive in this paper s language), answer why. One issue is with the citations: there is a missing bracket with the citations, which then makes them part of the sentence and ultimately distracting. Contrastive explanations could be useful for a variety of tasks and importantly provide actionable insights about how to change a sample to satisfy positive rating. In that regard, the goal of this work is a worthy one. What are the authors referring to?<BRK>Summary: This work presents first of a kind logic based framework that relates contrastive (minimally absent) and abductive (minimally present) explanations and shows that abductive explanations are essentially minimal hitting sets of contrastive explanations. Also the relationship between types of explanations may helps us enumerate/compute other types of explanations based on the computation of one type. before applying the proposed ideas for local or global explanations.
Accept (Poster). rating score: 8. rating score: 7. rating score: 7. rating score: 4. <BRK>This work analyses the interaction between data augmentation strategies such as MixUp and model ensembles with regards to calibration performance. The authors note how strategies such as mixup and label smoothing, which reduce a single model s over confidence, lead to degradation in calibration performance when such models are combined as an ensemble.<BRK>##########################################################################Summary: The paper identifies the negative effects on calibration and the robustness of the deep models when data augmentation and the ensembles are combined. The calibration pathology is observed for ensembles with mixup, is it true for other data augmentations such as rotation, cropping, etc? + In section 3.2 the label smoothing experiment is interesting. “Ensemble methods are a simple approach to improve a model’s calibration and robustness.” Who found this?<BRK>The paper explores the interesting relations of Mix Up and Uncertainty, which is useful and will be the right fit for the conference. **Summary:**The work studies how a better calibration of individual members of an ensemble affects the calibration of an ensemble. It is demonstrated that i) better calibration of individual members of the ensemble may lead to the worse calibration of the ensemble predictions ii) this is the case when mix up / label smoothing are used during training. The CAMixup is an adaptive mixup data augmentation based on per class calibration criteria. The confidence criteria are computed once in an epoch.<BRK>Summary:  This paper found that combining ensembles and data augmentation can harm model calibration. Inspired by this finding, it proposes a simple correction by only applying mixup to certain classes. The vanilla deep neural networks are often in the over confident regime, so either ensemble or mixup itself seems very effective in improving model calibration. How s the performance on metrics other than ECE?
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. <BRK>This should be clarified in the introduction. The authors introduce a regularization term to the loss that controls the amount of selectivity in the units of the network. * The question of necessity of selectivity is similarly topical for both ML and neuroscience.<BRK>[Update after authors  reply]In light of the authors  reply, I have updated my review to favor acceptance. I appreciate the additional experiments. The authors attempt to ascertain whether single neuron class selectivity is beneficial or harmful to overall network performance. It is not obvious how to control for such a possibility. Perhaps only turning on the regularizer when switches become rare (if they ever do!) Otherwise, the problem needs to be at the very least discussed, and the authors should find some way to estimate it and possibly control for it, for the paper to be accepted.<BRK>The authors have addressed some but not all of the issues raised, as noted above. Pros:The authors address a basic/important question – whether class selectivity in individual units of a deep network is related to task performance on a classification task. This paper does not examine this type of selectivity for sub classes. I found the motivation, experiments, and results easy to understand.
Reject. rating score: 3. rating score: 3. rating score: 3. rating score: 5. <BRK>Summary: The paper proposes a method to avoid the overestimation bias. I have three concerns due to which I am currently recommending rejection: First, the smaller concern is that the paper is currently difficult to understand, second, my major concern is that I am not sure about it s correctness, due to equation (9).<BRK>The main claim is that it reduces overestimation issues in a more effective way. At least one of these aspects need to be improved significantly before the paper is ready for acceptance.<BRK>I did not see exactly the same work before. Please see the citation part below. The authors should also search for average Q learning, ensemble Q learning, etc. The cited paper is about multi objective and constraint MDP; the credit of the Bellman equation should not go to this work.<BRK>So, a comparison of UAD3 with DDPG and TD3 is not fair. The authors claim that applying the clip variant of DDQN to the update procedure of the actor is more reasonable, but the experimental results did not support the authors’ claim.
Reject. rating score: 3. rating score: 4. rating score: 5. rating score: 7. <BRK>Several methods have been proposed that in one way or another perform a low pass filtering of the image to reduce the perturbation noise and thus improve robustness to AEs. The experiments are also limited insofar as a comparison is made with adversarial training, without consideration for any of the dozens other defense methods available. that sounds too categorical, it has to be rephrased. That perturbations must be mainly impinging on high frequency content is an obvious conclusion.<BRK>This paper analyzes the frequency spectrum of adversarial perturbations during normal training. The authors used theory and experiments to demonstrate this point. The authors indeed provide an iterative equation showing how the frequency pattern changes across training, but it is only for a very specific case: the network is two layer, trained with gradient descent algorithm, and the adversarial perturbation is FGM. As we know, the naturally trained models are very non robust, which means that there are potentially many different ways to attack the model. The first point says the adversarial perturbation concentrates on the low frequency domain and the second point says it concentrates on the high frequency domain. This experiment was done by first attack the natural images on normal models, without knowing that there will be a low pass filter, and then pass the attacked images to the low pass filter. The authors agreed that my third point was correct, i.e., the current results do not give enough insights on how to improve robustness against adversarial examples, in the real world white box setting.<BRK>This submission deals with understanding the gradient based adversarial examples. For this means, it analyzes the adversarial examples in the frequency domain, where it identifies that the ratio of high frequency and low frequency parts is quite large in adversarial examples compared with the natural ones. As a result, it proposes to apply a low pass filtering to the data that can significantly improve the model robustness. Weak pointsSeveral assumptions are made. It is not clear how much the accuracy can deteriorate because of low pass filtering. The theoretical results and analysis relies on several assumptions.<BRK>The paper proposes that applying a low pass filter on the input data improves the robustness of the model. •	Filtering out the high frequency component of the signal can be very application dependent. In many applications, e.g.Time frequency image of the signals such as radar signals or vibration signals, the high frequency component contains the information that the modeler of the DNN is seeking to model. Please elaborate more in what application this technique can be useful. Image processing is a very general term that may not be necessarily descriptive about the domain where the proposed technique is applicable. Is there recommendations for modelers? •	Can the authors provide more details on the design of the low pass filter? Is it FIR or IIR?
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. rating score: 5. <BRK>They are then used to train Transformers with tree positional encoding. Most importantly, the LTL model generalizes to examples that lead to timeout when using the imitated solver directly. Deep learning for LTL is interesting and I have not seen it done before. What happens if you use satisfiable examples where the generator times out after 1s as a test set? The distribution of LTLUnsolved is not discussed in detail. How exactly were those formulas obtained? The paper does not show generalization between LTLRandom and LTLPattern datasets, even though this would be an obvious experiment to try if the goal is to demonstrate that the model learns LTL semantics in both cases instead of overfitting to the dataset generation procedure and the generator. Detailed comments/questions:Page 4:Termination condition 4 requires solving a satisfiability instance after each new conjunct is added. Maybe you could analyze the sensitivity of the generated traces to random noise. In the text, you say that you trained on LTLPattern126, which makes more sense.<BRK>The paper explores the application of modern learning techniques (transformers and tree positional encodings) to the task of producing valid traces for a given LTL specification. The work follows a recent trend of the application of deep learning techniques to logic based settings, and the authors present (to the best of my knowledge) the first attempt of applying deep learning techniques to this particular task. In particular, the following claim from 5.1 is extremely exciting: "Our best model predicted correct solutions in 83% of the cases, taking on average 15s on a single CPU". There are countless ways to solve many LTL formulae, and very few for any given formula will be syntactically close. To show that level of generalization, I would expect to see a model trained using random LTL or benchmark LTL problems w/ spot, and testing done in a different (out of distribution) setting (like SAT or traces generated in an entirely different way than spot). I am leaning towards accepting the paper. E.g., the setting of "Bayesian Inference of Linear Temporal Logic Specifications for Contrastive Explanations" Kim et al.A final point of recommendation (not affecting my decision on the paper).<BRK>This paper presents a dataset of linear time temporal logic (LTL) formulas, which are generated by conjoining popular LTL specification patterns, and then investigates the learning capability of the Transformer over these LTL formulas. The experimental evaluation shows that the Transformer predicts solution with high accuracy and sometimes even outperforms the classic solver used for providing training data. Quality: Though Transformers are fairly standard models, this paper shows an interesting application, i.e.solving LTL formulas, and the experimental evaluations are convincing and promising. Originality: There is no technical innovation, but the presented dataset is new. Have you tried to train Transformer on LTLPattern126 and tested it on LTLRandom35? Q3: Boolean satisfiability in the DNF form is trivial to solve.<BRK>The results show that, when trained on large datasets of random formulas, transformer models can perform quite well on within distribution held out test tasks, and when equipped with tree positional encodings, they exhibit generalization to longer formulas. Novelty of the approach:  The approach is not novel, using a transformer model and a previously proposed tree positional encoding scheme. Novelty in the approach is not required, as long as the paper also contains experimental analysis which provides insight into either the technique or the problem studied, and the evaluation is thorough. If the claim is instead that high capacity models in general can perform well on important LTL tasks, then I think that the use of only synthetic test data is a weakness (see below). However, I would be willing to raise my score if concerns about baselines, analysis, or synthetic data were addressed.
Reject. rating score: 5. rating score: 5. rating score: 6. <BRK>Pros:+ This paper proposes a novel solution for learning odometry by using an information bottleneck constraint + This paper is well written with clear derivation. Concerns: The main issue of this paper is the insufficient experiment to validate the advantages of the method. 2019. The comparing methods, especially visual odometry methods are few. The experiment of visual odometry only compares with DeepVO [1]. However, to  the best of my knowledge, the visual odometry methods including non learning methods (e.g.ORB SLAM2 [2]), unsupervised methods (e.g.Bian et al.[3], Li et al.[4]), and the more recent supervised methods (e.g.Xue et al.[5], Xue et al.[6]) are not compared with the proposed method. The main weakness is the lack of the comparison with the state of the art methods. The ground truth pose \xi_t serves as the input of the deterministic function f^p in the training phase. But the estimated pose is used in the test phase instead. However, the RMSE of the entire trajectory is insufficient to examine the drift. I am curious about the difference between the original results and the results of re implementation. Besides, I would like to see the quantitative results of both RMSE and absolute error, which is provided by Chen et al.[7].The absolute error could be a reference to the original results of Chen et al.[7].Minor: typos:  \xi   g(X, \Theta) is "an" one to one function instead of "a" on page 5. IEEE, 2017.<BRK>In practice one might argue that there s some modeling regarding the connection between inertia and accelerations. It certainly makes sense, and it s interesting. It s very interesting research. By approaching the problem as one of pose prediction in general, it might be possible to go even further. The authors seem perfectly capable of producing this with some more discussion and work put in the research. Being able to perform tracking and obtain better pose estimates may be a good thing in an application, and why would any engineer stick to pure odometry if it were possible to employ a better solution? The occurrence of high z axis acceleration may serve as a clue for especially high height values to be predicted. For example, is it that most sensors have peculiar noise distributions now well modeled by Gaussians, and yet oversimple models are often used? Apart from these issues regarding the nature of the research, and its motivation, there is another related concern with what was achieved. These are all important questions that should be discussed in the experiments, although in the end the authors seem only to care more about how they compare to other learning based methods in different benchmarks, and then with the issue of detecting failures. Just focus on the more fundamental issues first. This would maybe replace the geometry processing core from alternative methods, with rotation encoded somehow in the latent state, and then different sensors would require just training part of the complete model. How does the proposed method differ from that? Another important detail not mentioned in the paper is how the proposal follows a strict filter based approach, while in general odometry might be performed with regression applied to a longer sequence of observation, as done in OKVIS. Would it be fair to say thatthe latent state learned by the proposed technique can somehow encode some of the information that is retained in the alternative method by not following a strict filtering scheme. This is the kind of question that would be interesting to see investigated here, and the authors do not seem very aware of that. If this is the main point of the research, though, it should be given much more attention, from the start, and then more comparisons with alternative methods should be made with attention given to that specific issue, etc.<BRK>The authors propose an information theoretic model for visual and visual inertial odometry. The method is based on the hypothesis that features contain pose irrelevant information that leads to overfitting which is alleviated through the using of an information bottleneck (IB) objective. The information theoretic formulation allows them to use existing results to provide guarantees related to generalization. The observation that the features learned by a typical VO model might contain pose irrelevant information that hurts generalization is sensible and does happen in practice and thus the proposed approach is very well motivated. The generalization bounds for the problem are theoretically interesting as overfitting is quite a significant issue with learning based VO models. Specifically, the results support the effectiveness of the proposed IB based loss with respect to the generalization ability of the trained model and the proposed method outperforms all the existing methods in terms of accuracy. As an example, how is Equation 13 obtained? According to my derivation the bound for $I(o_{1:T} || s_{1:T}|\xi_{1:T})$ should be $E_{o^m_{1:T},\xi_{1:T}} \left[D_{KL}\left[p(s_{1:t} | o^m_{1:T}, \xi) || q(s_{1:t} | o^m_{1:T}, \xi_{1:T}) \right]\right]$. Also, how does Corollary 1 follow from Theorem 3? A lot of emphasis is put on the theoretical guarantee of the generalization ability, however, it is not mentioned how tight this bound is or what practical implications it has. It would be good if the authors could demonstrate how this bound can be used to in practice. A lot of the contributions in the paper seem to be based on (Zhang, 2018) and (Xu & Raginsky, 2017). Although I recognize that applying these to the VO domain is not trivial, it would be good if the authors could better highlight what their contributions are. The existing results can be put in the appendix.
Reject. rating score: 5. rating score: 6. rating score: 7. <BRK>In another work, I wish the submission could answer some of these questions. The proposed model also have many parameters and neural network components. I don t how easy it is for others to tune the model. In a summary, the experiment results of this submission is strong, but I feel the motivation of the model design is not clear. 2. what is p_z? 3.The minimization problem in 2 is invalid since the true label z is unknown. The proposed method still outperform baseline methods by a good margin. Is this an evidence that the model is still better without much contribution from the label generator?<BRK>This paper presents a multi level generative model for partial label learning. The noise label generator and the data feature generator are learned in an adversarial manner. My concerns are mainly as following. Such kinds of approaches do not mean that they are not good methods. Therefore, such motivation is not so convincing, and leads to an important new contribution. The proposed method involves a conditional probability to model the correlation. However, this might be sensitive and restrict. For frequent patterns, this could be trivial to hold.<BRK>Overall, I like the idea of this paper and it is well written. With the proposed minmax adversarial loss, the proposed framework achieved state of the art performance for partial label learning.\\I think this paper has the following advantages:1. 3.The proposed model achieved the state of art results. Despite the above advantages, I still have the following questions:1. 3.In equation 3, it is not clear what the “$n$” in $\mathbf{y}_n$ stands for?
Reject. rating score: 3. rating score: 4. rating score: 4. rating score: 6. <BRK>In this submission, the authors propose a modification to the PBT (population based training) method for HPO. The novelty of the proposed method ROMUL is not high. But more important, it is unclear why such modifications are necessary. In other words, what new challenges in HPO can be addressed by conducting these modifications to PBT. Many paragraphs and sentences are not logically organized, and it is difficult to understand the main points of the submission. For example, based on the Introduction section, it seems that the main part of this submission is to "empirically study the different training dynamics of ..." (second paragraph). And in introduction, the authors didn t well motivate the proposal of their method. Personally I feel that "fixed step" issue in PBT is important, which should be mentioned early. Several interesting findings are provided in the experiments. The authors can make them clear and highlight them by improving the writing of current version.<BRK>** Summary **This paper focuses on issues in the popular PBT algorithm for hyperparameter optimization. The proposed approach is to use Differential Evolution which the authors claim makes the hyperparameter selection more robust. However, as someone who frequently uses variants of the PBT algorithm, the evidence provided in this work is not sufficient for me to adopt their recommendations. The method is based on heuristics and the experiments are unfortunately not rigorous: the gains are small and it is a single seed. To increase my score, I would need to see more robust results that make these heuristics convincing, for example multiple seeds with clear outperformance (ideally statistically significant). 2) The topic of the paper (PBT) is one that I think has not been sufficiently addressed by the community. ** Weaknesses **1) The main contribution of the work is not convincing. While the results show an improvement, it is not clear. If the TransformerXL is too expensive, then a smaller experiment which can be repeated multiple times would be a stronger piece of evidence for the method’s efficacy. 4) The library is presented as a second major contribution, but it is not clear why the reader would choose to use it over existing libraries such as ray tune, which are popular and widely used. I also couldn’t find the library anywhere, the supplementary material is just a two page pdf, and there is no anonymized link. Please correct me if I missed this.<BRK>It makes two contributions: (1) a novel PBT algorithm, ROMUL, and (2) a library for PBT based training, hoptim. While the authors highlight the hoptim library as one of the main contributions of the paper, they do not describe what are their advantages over existing hyperparameter optimization frameworks or existing PBT implementations (e.g.the one in Ray). As far as I can tell, there is no source code or link to an anonymous repository so that we can evaluate this contribution. Commands for replicating experiments using hoptim are scattered throughout the manuscript, but please note that this is not enough to evaluate the quality or impact of the software. This is an important issue because the paper justifies weaker empirical results based on implementation differences that are never discussed (e.g.“The differences in the job and population management in hoptim may explain the difference between our implementation and theirs, which is particularly marked on the training set reduced CIFAR 10: 12.8% for their vs. 13.9% for our implementation.”, or how the number of workers has a strong impact in the final result for PTB experiments.). The benefits of the proposed strategy are showcased by optimizing a 2D Rosenbrock function where the optimal values for the two parameters differ in magnitude (a 1, b 100). ROMUL seems to outperform other PBT methods when tuning TransformerXL, but the benefits on PBA when applied to CIFAR 10 are not so clear. It is difficult to evaluate the significance of these figures, as no standard deviation across seeds is reported. While this submission discusses important research topics, I do not believe it is ready for publication yet. The authors highlighted two main contributions, but I believe there are three potential ones: (1) a PBT method that does not need extensive tuning, (2) a software library for PBT training, and (3) an empirical evaluation of different design choices for PBT methods. However, these need to be developed further (and potentially in separate papers) before they can be published at ICLR.<BRK>#### SummaryThe paper provides a new variant of PBT which utilizes ideas from differential evolution and cross over. The investigation of better cross over in PBT is itself an interesting research direction and the authors demonstrated its effectiveness in standard benchmarks and data augmentation tasks. The improvements of ROMUL PBT are also helpful to the community since PBT has been applied in a variety of real world applications. The organization is also clear. 3.Originality: I think that adapting ideas from differential evolution to PBT is new, even though differential evolution itself is not something new. 4.The paper provides some benchmarking of PBT related algorithms in image classification, language modeling and data augmentation which is good for the community to understand these approaches. Significance: the improvements over existing methods seem slight. The experiments do not provide sensitivity analysis so it is a bit hard to conclude whether the results are statistically significant. But at the same time, the proposed method does show promise. 2.As a thorough evaluation purpose, it would be interesting to see how the proposed methods work in large set of hyperparameters (magnitude of 10 100). So it would be nice to have results on a held out test set.