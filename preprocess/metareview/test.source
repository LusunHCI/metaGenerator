Reject. rating score: 5. rating score: 6. rating score: 7. <BRK>This paper introduces a number of different techniques for improving exploration in deep Q learning. The main technique is to use UCB (upper confidence bound) to speedup exploration. The techniques introduced are a small permutation of previous results. The baselines are not particularly strong either. The paper appeared to have be rushed. The presentation is not always clear. All that was proposed was: (1) Majority voting, (2) UCB exploration. 4.Why not comparing to Bootstrapped DQN since the proposed method is based on it?<BRK>There are several things to like about this paper:  It is a clear paper, with a simple message and experiments that back up the claims. On the other hand:  The novelty/scope of this work is somewhat limited... this is more likely (valuable) incremental work than a game changer. I think this paper might miss the point of the "bigger" problem of efficient exploration in RL... or even how to get "deep" exploration with deep RL. Yes this algorithm sees improvements across Atari, but it s not clear why/if this is a step change versus simply increasing the amount of replay or tuning the learning rate. Overall I do think this is a pretty good short paper/evaluation of UCB ensembles on Atari.<BRK>The authors propose a new exploration algorithm for Deep RL. But to me it feels a bit like shoehorning the probabilistic interpretation into an already existing update   I’m not sure this is justified and necessary here. Some questions about the results: How does it perform compared to epsilon greedy added on top of Alg1, or is there evidence that this produces any meaningful exploration versus noise? Was epsilon greedy used in addition to UCB exploration? Question for both Alg 1 and Alg 2. Maybe mention that the leftarrows are not hard updates.
Reject. rating score: 3. rating score: 3. rating score: 4. <BRK>However, this works both ways, meaning that wrong past predictions can persist because of the long term modelling. However, the novelty is insufficient for a publication at this stage.<BRK>To sum it up, the positive aspect of nicely executed experiments is contrasted by low novelty of the method.<BRK>The novelty of this paper is very limited. Another concern is that the number of layers parameter  K .
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. <BRK>The paper is dense but well written. The authors provide a few regret theoretical results (that I did not check deeply) obtained by reduction to "value aware" contextual bandits. An interesting synthetic experiment (Figure 4) is also proposed to study the ability of the algorithm to work on both decomposable and non decomposable structured prediction tasks. Question 1: The credit assignment approach you propose seems way more sophisticated than eligibility traces in TD learning. But sometimes old and simple methods are not that bad.<BRK>I also appreciate the reviewers  efforts to run more experiments and flesh out the discussion in the revised version of the submission. This paper uses too many examples, from part of speech tagging to credit assignment in determining paths. However, I have some reservations, a significant portion of which stem from not understanding aspects of the proposed approach and theoretical results, as outlined below. The ideas presented are interesting and the results are potentially interesting as well. 2) is the remainder of that paragraph a description of a "standard learning to search step"?<BRK>Revision: I thank the authors for addressing some of my concerns. This, and also a bigger discussion on prior bandit learning methods like LOLS will help under the context for why we’re performing the reduction stated in the paper. Pros1.The results on bandit structured prediction problems are pretty good2. The idea of a learnt credit assignment function, and using that to separate credit assignment from the exploration/exploitation tradeoff is good.
Reject. rating score: 4. rating score: 4. rating score: 5. <BRK>The major contribution lies in the producing of the data. There are several concerns. 1.Since the major contribution lies in the production of the data, it is required for the authors to justify the quality of data. 4.This paper is not very well written.<BRK>The data set is built from open source data to comprise pollutants measured at a number of stations and meteorological data. Most of the first part s work is in the extraction of the public data from the above mentioned sources, aligning of the two source data and sampling considerations. It also lacks definition of certain application domain area terms and acronyms (PM2:5).<BRK>The work is original and significant from an applications point of view. It looks like the dataset is useful but the model development and experimental sections are weak. Figure 3 is not clear.
Accept (Oral). rating score: 8. rating score: 8. rating score: 7. <BRK>The relevance of the method to achieve a deeper sense of learning and performing more complex tasks is however unclear to me. A couple more specific comments:  I think that dealing with multimodal distributions of actions with the forward consistency loss is effective for achieving the goal, but not necessarily good for modeling multimodality. From the navigation task, it seems like the system mainly learns a discover behavior that is better than random motion. Conclusion:I think the paper presents an interesting idea which should be exposed to the community.<BRK>The authors propose an approach for zero shot visual learning. I am very happy to see experimental evaluations on real robots, and even in two different application domains. The proposed method was evaluated on a mobile indoor navigation task and a knot tying task. The proposed approach is well founded and the experimental evaluations are promising.<BRK>Comments:  In the visual navigation task no numbers are presented on the comparison to slam based techniques used as baselines although it is mentioned that it will be revisited. 2.Robotic knot tying with a loose rope where visual input of the initial and final rope states are given as input. The proposed method has at its core a method for learning a parametric skill function (PSF) that takes as input a description of the initial state, goal state, parameters of the skill and outputs a sequence of actions (could be of varying length) which take the agent from initial state to goal state. This will be an interesting paper to have at the conference and will spur more ideas and follow on work.
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. <BRK>Would be good to know if the authors have any intuition why is that the case. It’s a simple method that can be applied post training and seems to be effective. I would be interested to know more about the intuition behind the proposed method. The analyses are interesting and done well.<BRK>The paper could be strengthened by addressing the issues above as well as including more empirical results (if nothing else). Empirically the authors demonstrate, on two different task domains, that one can trade off some accuracy for a little robustness   qualitatively speaking. On the other hand, I find it lacking in terms of theoretical support, other than the fact that the added stochasticity induces a certain amount of robustness. This adds stochasticity as well so why and why not this work?<BRK>The most important contribution is that the proposed algorithm can be applied post hoc to already trained networks. In section 4, I do not understand why the adversary uses only the sign and not also the value of the estimated gradient. If it is the case, you should explain that the optimal policy of the adversary is approximated by “fast gradient sign method”. SAP does not perform as well as adversarial training, but SAP could be used with a trained network.
Reject. rating score: 4. rating score: 5. rating score: 5. <BRK>The problem considered in the paper is of compressing large networks (GRUs) for faster inference at test time. What are the values of lamdas that were used to train (the l2 and trace norm regularization) the Stage 1 of models shown in Fig 4. The authors point it out, but a further investigation might be interesting. Could the authors confirm that the reported CERS are on validation/test dataset and not on train/dev data?<BRK>The technique consists of first training a model by constraining its trace norm, which allows it to be well approximated by a truncated SVD in a second fine tuning stage. Also, particularly given that the focus is on embedded speech recognition, of which the acoustic model is one part, I would like a few more details on how decoding was done, etc. The details in appendix B are interesting, and I think they should really be a part of the main paper. The paper focuses fairly heavily on speech recognition tasks, and I wonder if it would be more suited to a conference on speech recognition. I think these experiments would strengthen the paper. Could the authors also indicate the CER of the model used for initialization in addition to the final CER after stage 2 training in Figure 5.<BRK>Paper is well written and clearly explained. The experimental section is strong and it has evaluated across different datasets and various scenarios. However, I feel the contribution of the paper toward the topic is incremental and not significant enough to be accepted in this venue. It only considers a slight modification into the loss function by adding a trace norm regularization.
Reject. rating score: 4. rating score: 6. rating score: 7. <BRK>*Quality*The paper is easy to parse, with clear diagrams and derivations at the start. The problem context is clearly stated, as is the proposed model. Hence, I have assigned a score of "4" for the following reasons: the quality of the generated models is unclear; the paper does not clearly distinguish itself from the closely related Z Forcing concept (published at NIPS 2017); and the reasons for the improvements shown in average log likelihood are not explored sufficiently, that is, the ablation studies don t eliminate key parts of the model that could provide this information. I also find the motivations for the proposed model itself a little unclear. In the introduction, improved regularization for LSTM models is cited as a primary motivation for introducing and learning two approximate distributions for latent variables between the forward and backward paths of a bi LSTM. This weakens a possible theoretical contribution of the paper. Both appear to employ the same core idea of regularizing an LSTM using a learned variational distributions. The differences *seem* to be in the small details, and these details appear to provide better performance in terms of average log likelihood on all tasks compared to Z Forcing but, crucially, not compared to other models in all cases.<BRK>This paper builds a sequential deep generative model with (1) an inference network parameterized by an RNN running from the future to the past and (2) an explicit representation of the hidden state of the backward RNN in the generative model. The model is validated on held out likelihood via the ELBO on text, handwriting, speech and images. It presents good emprical results and works at par with or better than many other baselines considered. I found the presentation of both the model and learning objective to be confusing and had a hard time following it. Under this view, setting beta to 0 simply corresponds to not observing \tilde{h_t}. alpha can be annealed but should never be set to anything less than 1 without breaking the semantics of the learned generative model. It seems that the core difference between this work and [Chung et. al] and [Krishnan et. Incorporating a discussion around this idea would provide useful context for where this work stands amongst the many sequential deep generative models in theliterature. Questions for the authors:* How important is modeling \tilde{h_t} in TIMIT, Blizzard and IMDB? Based on the KL divergence you report it seems the latent variable is not necessary. Overall, I find the model to be interesting and it performs well empirically. However, the text of the paper lacks a bit of context and clarity that makes understanding it challenging to understand in its current form.<BRK>This paper proposes a particular form of variational RNN that uses a forward likelihood and a backwards posterior. Additional regularization terms are also added to encourage the model to encode longer term dependencies in its latent distributions. My first concern with this paper is that the derivation in Eq.1 does not seem to be correct. It is not clear to me why h_t should depend on \tilde{b}_t. It may add capacity to the decoder in the form of extra weights, but the same could be achieved by making z_t larger. In the no reconstruction loss experiments do you still sample \tilde{b}_t in the generative part? It seems the Blizzard results in Figure 2 are missing no reconstruction loss + full backprop. I don t understand the description of the "Skip Gradient" trick. Do you have any intuition for why it is sometimes necessary to set beta 0?
Accept (Poster). rating score: 7. rating score: 7. rating score: 7. <BRK>This paper studies the problem of one shot and few shot learning using the Graph Neural Network (GNN) architecture that has been proposed and simplified by several authors.<BRK>Strengths  Use of graph neural nets for few shot learning is novel. EDIT: I have read the author s response. The writing is improved and my concerns have largely been addressed. For active learning, the proposed method seems to be specific to the case of obtaining a single label. Was the same procedure done for the experiments in the paper?<BRK>The proposed method appears to have a modest improvement for few shot learning. The reason is that the label already appears in the loss of the nodes  in 5.1.
Reject. rating score: 3. rating score: 3. rating score: 4. <BRK>In particular, the paper introduces a benchmark domain to model fleet coordination problems as might be encountered in taxi companies. The paper does not really introduce new methods, and as such, this paper should be seen more as an application paper. As such, I do not really see any real grounds for acceptance. The paper is quite poorly written in places, has poor formatting (citations are incorrect and half a bibtex entry is inlined), and is highly inadequate in its treatment of related work.<BRK>In this paper, the authors define a simulated, multi agent “taxi pickup” task in a GridWorld environment. The battery can be “recharged” by moving to a “charge” tile. Cooperative multi agent problem solving is an important problem in machine learning, artificial intelligence, and cognitive science. Second, given its contribution, the manuscript is better suited for a conference specific to multi agent decision making.<BRK>In spirit, these simulations are similar to those in the original paper by M. Egorov. For instance, since the reward has been designed arbitrarily, it could have been defined as giving a penalty for those missing customers that are at some distance of an agent. In particular, how is this sentence related to partial observability? The paper is clear and well written.
Reject. rating score: 3. rating score: 6. rating score: 7. <BRK>The paper proposes an adaptation of existing Graph ConvNets and evaluates this formulation on a several existing benchmarks of the graph neural network community. The authors describe this as adapting it to general graphs, stacking, followed by adding edge gates and residuality. This is a minor modification. What are the inputs, what are the outputs, what kind of problems should be solved? A couple of details :  the length of a graph is not defined.<BRK>The paper proposes a new neural network model for learning graphs with arbitrary length, by extending previous models such as graph LSTM (Liang 2016), and graph ConvNets. I would expect the paper elaborate more (at least in a more explicit way) about the relationship between the two models (the proposed graph LSTM and the proposed Gated Graph ConvNets). The authors claim that the innovative of the graph Residual ConvNets architecture, but experiments and the model section do not clearly explain the merits of Gated Graph ConvNets over Graph LSTM. The presentation may raise some misunderstanding. A thorough analysis or explanation of the reasons why the ConvNet like architecture is better than the RNN like architecture would be interesting. These two proposed neural network models seem performing well empirically. In my opinion, the two different graph neural network models are both suitable for learning graphs with arbitrary length, and both models worth future stuies for speicific problems.<BRK>Summary: this works proposes to employ recurrent gated convnets to solve graph node labeling problems on arbitrary graphs. The authors extend the tree LSTMs formulation to perform graph labeling on arbitrary graphs, merge convnets with residual connections and edge gating mechanisms. They apply the 2 proposed models to 3 baselines also based on graph neural networks on two problems: sub graph matching (expressing the problem of sub graph matching as a node classification problem), and semi supervised clustering. Main comments:It would strengthen the paper to also compare all these network learning based approaches to variational ones. The abstract should be self contained and should not contain citations. The authors should clarify which problem they are dealing with.
Reject. rating score: 5. rating score: 5. rating score: 5. <BRK>The paper proposes a feature learning technique for molecular prediction using reinforcement learning. The predictive model is an interesting two step approach where important atoms of the molecule are added one by one with a reward given by a second Q network that learns how well we can solve the prediction problem with the given set of atoms. It s somewhat odd that the test performance in table 2 is often better than CV performance. Overall the method is interesting and has a clear impact for molecular prediction, however the paper has limited appeal to the broader audience.<BRK>This paper presents an interesting approach to identify substructural features of molecular graphs contributing to the target task (e.g.predicting toxicity). These two phases are iterated in a reinforcement learning manner as policy iterations. Both parts are based on conv nets for molecular graphs, and this framework is a kind of  self supervised  scheme compared to the standard situations that the environment provides rewards. Technically speaking, the proposed self supervised scheme with two conv nets is very interesting. This demonstrates how we can perform progressive substructure selections over molecular graphs to highlight relevant substructures as well as maximizing the prediction performance. It would be unconvincing that the proposed neural nets approach fits to this hard combinatorial task rather than these existing (mostly exact) methods. Can we guarantee in some sense this would not happen? should be presented for discussing the results.<BRK>In this manuscript, the authors propose an interesting deep reinforcement learning approach via CNNs to learn the rationales associated to target chemical properties. Moreover, the fact that test performances are sometimes (much) better than training results are quite suspicious in methodological terms. Finally, the experimental part is quite limited (two small datasets), making it hard to evaluate the scalability (in all sense) of the proposed solution to much larger data.
Reject. rating score: 4. rating score: 5. rating score: 5. <BRK>I think it will eventually become a good paper, but it is not ready yet.<BRK>The paper studies a combination of model based and model free RL. Pros:  The research direction in combining model based and model free RL is interesting. The paper needs more discussion and comparison to relevant baseline methods.<BRK>The main idea of the paper is to improve off policy policy gradient estimates using control variates based on multi step rollouts, and reduce the variance of those control variates using the reparameterization trick. This is laid out primarily in Equations 1 5, and seems like a nice idea, although I must admit I had some trouble following the maths in Equation 5.
Reject. rating score: 3. rating score: 3. rating score: 4. <BRK>The interesting part here is that the linear projection is a function of the support points. If S is diagonal then the S generation methods a) b) c) in the end of section 3.1 will make sure that S is PSD, I do not think that this is the case with d) though. The present paper extends the above work to include the learning of a Mahalanobis matrix, S, for each instance, in addition to learning its projection.<BRK>Why isn t the covariance matrix estimated in the usual way as the empirical covariance in the embedding space? The idea of using a Gaussian model and its associated Mahalanobis metric is certainly interesting, but also a time honored concept. EVALUATION:CLARITY: I found the paper difficult to read. In principle, the idea seems to be clear, but then the description and motivation of the model remains very vague.<BRK>Uncertainty may be particularly important in the few shot learning case this paper examines, when it is helpful to extract more information from limited number of input samples. However, several important concepts in the paper are not well explained or motivated. For example, it is a bit misleading to use the word "covariance" throughout the paper, when the best model only employs a scalar estimate of the variance. Pros: Interesting problem and interesting direction.
Reject. rating score: 5. rating score: 5. rating score: 7. <BRK>Pros:  Using insights from information geometry  opens up a very interesting and (to my knowledge) new approach for analysing the generalisation ability of ML models. Therefore, it is not clear how much of insights the theoretical analysis gives for practitioners (it could be nice to analyse the tightness of the bound for toy models). explaining in which sense the formula on page 4 is equivalent to “the learning equation of Boltzmann machines”. explaining what is the MLE of the true distribution (I assume the closest distribution in the set of distributions that can be modelled by the BM). (Hinton et al., 2006) : The paper describes deep belief networks (DBNs) not DBMs   \theta is used to describe the function in eq.(2) as well as the BM parameters in Section 2.2   page 5: “nodes H is”  > “nodes H are” REVISION:Thanks to the reviewers for replying to my comments and making the changes. I think they improved the paper.<BRK>This paper uses an information geometric view on hierarchical models to discuss a bias   variance decomposition in Boltzmann machines, presenting interesting conclusions, whereby some more care appears to be needed for making these claims. The paper arrives at the main conclusion that it is possible to reduce both the bias and the variance in a hierarchical model. The discussion is not specific to deep learning nor to Boltzmann machines, but actually addresses hierarchical exponential family models. The methods pertaining hierarchical models are interesting and presented in a clear way. This interferes with the claims and derivations made in the paper in the case of models with hidden variables. The problem seems to lie in the fact that the presented derivations assume that an optimal distribution in the data manifold is given (see Theorem 1 and proof), effectively making this a discussion about a fully observed hierarchical model.<BRK>Summary: The goal of this paper is to analyze the effectiveness and generalizability of deep learning. This authors present a theoretical analysis of bias variance decomposition for hierarchical graphical models, specifically Boltzmann Machines (BM). The authors first define the bias variance decomposition of KL divergence using Pythagorean theorem followed by applying Cramer Rao bound and show that the variance decreases when adding more parameters in the model.
Reject. rating score: 5. rating score: 5. rating score: 6. <BRK>This paper proposes a model of "structured alignments" between sentences as a means of comparing two sentences by matching their latent structures. In the answer selection and NLI experiments, the proposed model does not beat the SOTA, and is only marginally better than unstructured decomposable attention. The plots in Fig 2 with the marginals on CKY charts are not very enlightening. How do this marginals help solving the NLI task?<BRK>* I m skeptical of the type of qualitative analysis in section 4.3, unfortunately. This is an intriguing idea. I had a couple of reservations however:* The empirical improvements from the method seem pretty marginal, to thepoint that it s difficult to know what is really helping the model.<BRK>Summary:This paper introduces a structured attention mechanisms to compute alignment scores among all possible spans in two given sentences. The paper claimed “the model is able to recover tree structures that very closely mimic syntax”, but it’s hard to draw this conclusion from the two examples in Figure 2. Strengths:The idea of using latent syntactic structure, and computing cross sentence alignment over spans is very interesting. It would be nice to show, quantitatively, the agreement between the latent trees and gold/supervised syntax.
Accept (Poster). rating score: 8. rating score: 7. rating score: 4. <BRK>The paper presents an extensive framework for complex valued neural networks. The contribution of the current work does not lie in presenting significantly superior results, compared to the traditional real valued neural networks, but rather in developing an extensive framework for applying and conducting research with complex valued neural networks. In this work, the complex equivalent of many of these basics tools are developed, such as a number of complex activation functions, complex batch normalization, complex convolution, discussion of complex differentiability, strategies for complex weight initialization, complex equivalent of a residual neural network. Empirical results show that the new complex flavored neural networks achieve generally comparable performance to their real valued counterparts, on a variety of different tasks.<BRK>It definitely does not preserve phase, like modReLU would. The improved performance on the audio tasks seems significant, but how the complex nature of the networks helps achieve this is not really demonstrated. page 3: "(cite a couple of them)" should be replaced by some actual references :)  Although care is taken to ensure that the complex and real valued networks that are compared in the experiments have roughly the same number of parameters, doesn t the complex version always require more computation on account of there being more filters in each layer? It would be nice to discuss computational cost as well. REVISION: I have decided to raise my rating from 5 to 7 as I feel that the authors have adequately addressed many of my comments.<BRK>However, cases the authors address, which are training batch norm ReLU networks on standard datasets, are already formulated in terms of real valued arithmetic. Formulate two complex valued alternatives to ReLU and compare them3. Formulate complex batch normalization as a "whitening" operation on complex domain4. Formulate complex analogue of Glorot weight normalization schemeSince any complex valued computation can be done with a real valued arithmetic, switching to complex arithmetic needs a compelling use case.
Reject. rating score: 3. rating score: 4. rating score: 5. <BRK>The authors generalize this idea in a nice  way and present results on 1 experiment. On the positive side, the paper is clearly written and while the fast weights are not new, the details of the presented method are original. The results are good but the improvements are not too large, and they are measured over weak baselines implemented by the authors.<BRK>Overall, the only contribution of the paper seems to be the modification to Ba et al.is the Eq.(8).The authors have only evaluated the method on a synthetic associative retrieval task. Without additional experiments on other datasets, it is hard for the reader to draw any meaningful conclusion about the proposed method in general.<BRK>While this task is artificial, it does make sense in the context of what the authors want to show. I’m not saying those differences aren’t there, but the paper simply didn’t emphasize them very well and I had to reread the paper from Ba et al.(2016) to get the full picture. Originality/SignificanceWhile the architecture is new, it is based on a combination of previous ideas about fast weights, hypernetworks and activation gating and I’d say that the novelty of the approach is average. The architecture does seem to work well on the associative retrieval task, but it is not clear yet if this will also be true for other types of tasks. Good results.
Reject. rating score: 3. rating score: 4. rating score: 6. <BRK>Data involves multiple subjects (4 selected from a larger pool). While limited novelty is found in the methodology/engineering   novelty being mainly related to the affine transfer mechanism, results are disappointing. The decoding performance of the LSTMs does not convincingly exceed that of the simple baselines. When analyzing the transfer mechanism only the LSTMs are investigated and it remains unclear how well trans works. In the discussion we find the claim: "In this work, we have shown that LSTMs can model the variation within a neural sequence and are a good alternative to state of the art decoders."<BRK>From the presented results, the LSTM model is not an improvement over a basic linear model. The transfer learning models performs better than subject specific models on a subset of the subjects. Therefore this statement should not be in the paper. It is unclear to me how they are used exactly. This is common for brain data and makes evaluation much more difficult. I think that it would be interesting how linear model transfer learning would fare in this task.<BRK>Data of the type analysed is highly dependend, so it is not unclear whether this validation procedure will not provide overoptimistic results. Currently, I do not see evidence for a stable training procedure in the ms. If it were a neuroscience contribution, then it would be important to analyse and understand the LSTM representation and to put it into a biological context fig 5B is a first step in this direction. There is also some initial experiments in fig 3A. Currently, I find the paper somewhat unsatisfactory and thus preliminary.
Accept (Oral). rating score: 8. rating score: 8. rating score: 8. <BRK>This paper provides a reasonably comprehensive generalization to VAEs and Adversarial Auto encoders through the lens of the Wasserstein metric. While the existing properties of auto encoders are preserved, stability characteristics of W GANs are also observed in the proposed architecture. The results from MNIST and CelebA datasets look convincing, though could include additional evaluation to compare the adversarial loss with the straightforward MMD metric and potentially discuss their pros and cons. The closest work to this paper is the adversarial variational bayes framework by Mescheder et.al.<BRK>This very well written paper covers the span between W GAN and VAE. The authors claim that their use in the latent space makes it more practivalThe experiments are very convincing, both numerically and visually. This work contains plenty of novel material, which is clearly compared to previous work:  The main consequence of the use of Wasserstein distance is the surprisingly simple and useful Theorem 1.<BRK>This paper satisfies the following necessary conditions foracceptance. The problem addressed is one worth solving   building agenerative model of observed data. The authors are careful to relate the presented method with existingones, most notably VAE and AAE. WAE is a bit oversold. There is no proof that it is always better, and I can tsee how there could be.
Reject. rating score: 3. rating score: 4. rating score: 6. <BRK>This paper discusses using neural networks for super resolution. I m also not sure how this figure adds to the information already in the text. Given that much of the main result seems to already be known, I feel that this work is not novel enough at this time.<BRK>The method proposes a new architecture for solving image super resolution task. They provide an analysis that connects aims to establish a connection between how CNNs for solving super resolution and solving sparse regularized inverse problems. The writing of the paper needs improvement. When measuring PSNR, is this taken into account? This should be discussed. The network is used in the same way at training and testing. Please comment on this.<BRK>The paper proposes an understanding of the relation between inverse problems, CNNs and sparse representations. Using the ground work for each proposes a new competitive super resolution technique using CNNs. Could this be modeled in the network? Why to keep the quantization at binary?
Reject. rating score: 4. rating score: 5. rating score: 6. <BRK>For this to pan out, we d need to see that the GAN samples are a) useful for a range of supervised tasks, and b) do not leak private information. This paper touches on many interesting issues   deep/recurrent models of time series, privacy respecting ML, adaptation from simulated to real world domains. But it is somewhat unfocused and does not seem make a clear contribution to any of these. That said I agree this is an interesting avenue for future work.<BRK>The authors demonstrate novel approaches for generating real valued sequences using adversarial training, a train on synthetic, test of real and vice versa method for evaluating GANS, generating synthetic medical time series data, and an empirical privacy analysis. the changes in performance of TSTR are large enough that I would have difficulty trusting any experiments using the synthetic data. The authors certainly make a convincing statement about the internal validity of the method. I m not quite sure how the authors could externally validate the synthetic data as this would also require generating synthetic outcome measures. I think it would be possible for the synthetic sequence to also generate an outcome measure (i.e.death) based on the first 4 hours of stay.<BRK>Overall, I thought the paper was clearly written and extremely easy to follow. Furthermore, the story of generating medical training data for public release is an interesting use case for a model like this, particularly since training on synthetic data appears to achieve not competitive but quite reasonable accuracy, even when the model is trained in a differentially private fashion. My most important piece of feedback is that I think it would be useful to include a few examples of the eICU time series data, both real and synthetic.
Reject. rating score: 3. rating score: 3. rating score: 5. <BRK>The paper proposes knowledge distillation on two very specific non classification tasks. I find the scope of the paper is quite limited and the approach seems hard to generalize to other tasks. How are they actually selected in the experiments? 3.The paper works on a very limited scope of face alignment. How does the proposed method generalize to other tasks?<BRK>Summary:The manuscript presents experiments on distilling knowledge from a face classification model to student models for face alignment and verification. It is very hard to follow! Two reasons are that it has too many grammatical mistakes and that very often a “simple trick” or a “common trick” is mentioned instead of using a descriptive name for the method used.<BRK>This paper proposed to transfer the classifier from the model for face classification to the task of alignment and verification. Specifically, it proposed to utilize the teacher model from classification to other tasks, and proposed a unified objective function to model the transferability as shown in Equation (5). The two terms in (5), (7) and (9) are used to transfer the knowledge from the teacher model. The author mentioned that it is due to the weak teacher model.
Reject. rating score: 4. rating score: 5. rating score: 5. <BRK>For the base line Encoder+HC, was the encoder trained independently? Or it s trained jointly with PCN and OCN? Some minor comments:When applied to the rejected examples, wouldn t the ground truth # of clusters no longer be 4 or 10 because there are some known class examples mixed in?<BRK>So, I d really urge the authors to extend this evaluation. Further, I miss some baselines and ablation study.<BRK>Thirdly, the experiments are only on the MNIST and EMNIST; still not quite sure any real world problems/datasets can be used to validate this approach.
Reject. rating score: 4. rating score: 5. rating score: 5. <BRK>This work introduces a new semantic parsing dataset, which focuses on generating SQL from natural language. First of all, I d like to emphasize that the creation of a large scale semantic parsing dataset is fantastic, and it is a much appreciated contribution. However, I find its presentation problematic. For example, how well does the proposed model work when evaluated on an existing dataset containing full SQL queries, such as ATIS? On the modeling side, the role of reinforcement learning seems oddly central in the paper, even though though the added complexity is not well motivated. There are far simpler solutions that would achieve the same result, such as optimizing the marginal likelihood or even simply including all orderings as training examples. These should be included as baselines.<BRK>This paper presents a new approach to support the conversion from natural language to database queries. One of the major contributions of the work is the introduction of a new real world benchmark dataset based on questions over Wikipedia. 1) Limitation of the dataset: While the authors claim this is a general approach to support seq2sql, their dataset only covers simple queries in form of aggregate where select structure. 3) Comparisons to existing approaches: Since it is a template based approach in nature, the author should shrink the problem scope in their abstract/introduction and compare against existing template approaches. It thus makes sense when the performance of semantic parsing approaches on a constrained domain, such as WikiSQL, is not comparable to the proposal in this submission. However, that only proves their method is fully optimized for their own template. The authors must carefully consider how their proposed approach could be generalized to handle wider workload beyond their own WikiSQL dataset.<BRK>The authors have addressed the problem of translating natural language queries to SQL queries. They also released a new dataset WikiSQL for the problem. The proposed method outperforms the existing semantic parsing baselines on WikiSQL dataset. Cons:1.It would have been better to see performance of the proposed method in other datasets (wherever possible). This is my main concern about the paper. 3.More details about training procedure (specifically for the RL part) would have been better.
Reject. rating score: 4. rating score: 5. rating score: 6. <BRK>This has previously been referred to as a special caseof "multi task" Bayesian optimization, in which the tasks can beconstructed to reflect different fidelities. Why can t any EI or entropy searchmethod also use gradient observations? This doesn t usually come upin hyperparameter optimization, but it seems like a grandiose claim. Similarly, although I don t know of a paper that explicitly does "A +B" for multi fidelity BO and parallel BO, it is an incrementalcontribution to combine them, not least because no other parallel BOmethods get evaluated as baselines. How can the batched algorithmoutperform the sequential algorithm on total cost? The sequentialcfKG algorithm should always be able to make better decisions with itsremaining budget than 8 cfKG.<BRK>This paper studies hyperparameter optimization by Bayesian optimization, using the Knowledge Gradient framework and allowing the Bayesian optimizer to tune fideltiy against cost. There’s nothing majorly wrong with this paper, but there’s also not much that is exciting about it. The empirical results look good in comparison to the competing methods, but I suspsect an author of those competitors could find a way to make their own method look better in those plots, too.<BRK>“Then, observe that the same reasoning we used to develop the cfKG acquistion functionin (3.2) can be used when when we observe gradients to motivate the acquisition function…”   some misprints, e.g.double “when”  The paper lacks theoretical analysis of convergence of the proposed modification of the knowledge gradient criterion. Other sections of the paper are sufficiently well written, except   the section 3.3.2,   section with results of experiments: I was not able to understand how the authors defined cost function in sections 4.2 and 4.3 for their neural network and large scale kernel learning. The paper contains a some new algorithm to perform Bayesian optimisation of a function with continuous fidelity.
Reject. rating score: 5. rating score: 5. rating score: 7. <BRK>It is more like a dependency based version skip thought on the sentence level. The idea is interesting to me, but I think this paper still needs some improvements. The introduction and related work part are clear with strong motivations to me. What if I only have pure text document without these HTML structure information?<BRK>This paper extends the idea of forming an unsupervised representation of sentences used in the SkipThought approach by using a broader set of evidence for forming the representation of a sentence. It s a shame they don t let you see the usefulness of the OOV model. p.8.For various reasons, the coreference results seem less useful than they could have been, but they do show some value for the technique in the area of domain specific coreference. It seems like there s quite a bit of related work.<BRK>This paper presents simple but useful ideas for improving sentence embedding by drawing from more context. The authors build on the skip thought model where a sentence is predicted conditioned on the previous sentence; they posit that one can obtain more information about a sentence from other "governing" sentences in the document such as the title of the document, sentences based on HTML, sentences from table of contents, etc. Here are the pros of this paper:1) Useful contribution in terms of using broader context for embedding a sentence. 3) Outperforms SkipThought in evals. Also, why have the authors not used this embedding for eval on standard coreference datasets like OntoNotes. Clarifications:1) In section 6.1, what is the performance of skip thought with the same OOV trick as this paper?
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. <BRK>This paper considers the problem of private learning and uses the PATE framework to achieve differential privacy. The dataset is partitioned and multiple learning algorithms produce so called teacher classifiers. The labels produced by the teachers are aggregated in a differentially private manner and the aggregated labels are then used to train a student classifier, which forms the final output. The novelty of this work is a refined aggregation process, which is improved in three ways:a) Gaussian instead of Laplace noise is used to achieve differential privacy. c) A data dependent privacy analysis is used to attain sharper bounds on the privacy loss with each query. However, I think some clarification is needed with regard to item c above:Theorem 2 gives a data dependent privacy guarantee. These works also involve a "student" being trained using sensitive data with queries being answered in a differentially private manner. It would be helpful to add a comparison.<BRK>Summary:In this work, PATE, an approach for learning with privacy,  is modified to scale its application to real world data sets. This is done by leveraging the synergy between privacy and utility, to make better use of the privacy budget spent when transferring knowledge from teachers to the student. on the positive side:Having scalable models is important, especially models that can be applied to data with privacy concerns. The paper is well written, and the idea of the model is clear. However, in the following paper, the model is applied no neither medical nor healthcare data. The authors mention that the original model PATE was applied to medical record and census data with the UCI diabetes and adult data set.<BRK>The paper proposes novel techniques for private learning with PATE framework. Two key ideas in the paper include the use of Gaussian noise for the aggregation mechanism in PATE instead of Laplace noise and selective answering strategy by teacher ensemble. I am not familiar with privacy learning but it is interesting to see that more concentrated distribution (Gaussian) and clever aggregators provide better utility privacy tradeoff. It would be great to discuss and show experimental results for utility privacy tradeoff with different variances of Laplace and Gaussian noise.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>In this paper, the authors propose a method of compressing network by means of weight ternarization. While the proposed method achieved promising results compared to the competing methods, it is still necessary to compare their computational complexity, which is one of the main concerns in network compression.<BRK>Experiments demonstrate the proposed scheme outperforms the state of the art methods. The experiments are complete and the writing is good.<BRK>Consequently, there is not a great degree of novelty in terms of the proposed method, and the results are only slightly better than those of previous methods. This may not be relevant for the practical results, but to be accurate, it can t be simply stated that the algorithm converges, without a more careful analysis.
Accept (Poster). rating score: 9. rating score: 6. rating score: 6. <BRK>The authors notice that in distribution examples are also examples where it s easy to drive the confidence up with a small step. This is also the gradient used to determine influence of predictors, and it s the gradient term used for adversarial training "fast gradient sign" method.<BRK>The paper proposes a new method for detecting out of distribution samples. Could the authors comment on how sensitive the method is to this parameter? This paper is well written, easy to understand and presents a simple and apparently effective method of detecting out of distribution samples. My only concern is that the parameter delta (threshold used to determine in/out distribution) is not discussed much.<BRK>Given this and the other reviews I have bumped up my score from a 5 to a 6. (This is in part, addressed in the CIFAR80 20 experiments in the appendices). This appears to be a borderline paper, as I am concerned that the method isn t sufficiently novel (although it is a novel use of existing methods). The paper is quite well written aside from some grammatical issues.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. <BRK>The authors then propose an efficient parallel algorithm for this class of RNNs, which produces speedups over the existing implements of Quasi RNN, SRU, and LSTM. Apart from efficiency results, the paper also contributes a comparison of model convergence on a long term dependency task due to (Hochreiter and Schmidhuber, 1997). The paper provides argument and experimental evidence against the rotation used typically in RNNs.<BRK>The authors now make a crucial observation, namely that a certain class of RNNs allows evaluation in a non linear fashion through a so called SCAN operator. Here, if certain conditions are satisfied, the calculation of the output   can be parallelised massively. The paper is certainly relevant, as it can pave the way towards the application of recurrent architectures to problems that have extremely long term dependencies.<BRK>The application is straightforward and thus technical novelty of this paper is limited. One concern is the proposed technique is only applied for few types of RNNs which may limit its applications in practice. Could the authors comment on this potential limitation?
Reject. rating score: 3. rating score: 5. rating score: 6. <BRK>Exploring the use of syntax in neural translation is interesting but I am not convinced that this approach actually works based on the experimental results. The paper distinguishes between syntactic and semantic objectives (4th paragraph in section 1), attention, and heads. Please explain this a bit more. The results show hardly any improvement over the flat attention baseline (at most 0.2 BLEU which is well within the variation of different random initializations). It looks as if the improvement comes from adding additional capacity to the model.<BRK>This paper induces latent dependency syntax in the source side for NMT. Experiments are made in En De and En Ru. The idea of imposing a non projective dependency tree structure was proposed previously by Liu and Lapata (2017) and the structured attention model by Kim and Rush (2017). In light of this, I see very little novelty in this paper. Expressions (12) to (15) are essentially the same as in Liu and Lapata (2017), not original contributions of this paper. Why is hard attention (sec 3.3) necessary? Experimentally, the gains are quite small compared to flat attention, which is disappiointing.<BRK>This paper describes a method to induce source side dependency structures in service to neural machine translation. Unfortunately, the results of the NMT experiments are not particularly compelling, with overall gains over baseline NMT being between 0.6 and 0.8 BLEU. In general, I found this region of the paper, including these two equations and the text between them, very difficult to follow. Section 4.4: It’s very very good that you compared to “flat attention”, but it’s too bad for everyone cheering for linguistically informed syntax that the results weren’t better.
Reject. rating score: 4. rating score: 4. rating score: 5. <BRK>To conclude, the authors propose a new approach to learning convolutional networks with dynamic input conditioned filters. Yet, there is no comparison to other methods for dynamic weight generation.<BRK>This paper explores learning dynamic filters for CNNs. There is a lot of prior work in this area that should be cited in the area of dynamic filters and steerable filters. There are also parallels to ladder networks that should be highlighted. The results indicate improvement over baselines, however baselines are not strong baselines.<BRK>This paper proposes a two pathway neural network architecture. For MTFL, I am not sure how significant the final results are. The proposed method is an interesting way of combining an unsupervised learning objective and a supervised one.
Accept (Poster). rating score: 9. rating score: 8. rating score: 5. <BRK>The student model is a deep learning model (MLP, CNN, and RNN were used in the paper). The teacher model learns via reinforcement learning which items to include in each minibatch of the data set. In both circumstances, they demonstrate the efficacy of their technique and that it performs better than other reasonable baseline techniques: self paced learning, no teaching, and a filter created by randomly reordering the data items filtered out from a teaching model. One other paper of note given that the authors train a MLP is an optimal teaching analysis of a perceptron: (Zhang, Ohannessian, Sen, Alfeld, & Zhu, 2016; NIPS).<BRK>Does it mean that you have not run enough iterations for the baseline methods? The proposed approach leverages reinforcement learning by defining the reward as how fast the learner learns, and use policy gradient to update the teacher parameters. The problem formulation is mostly reasonable, and the evaluation seems quite convincing. The paper is well written: I enjoyed the mathematical formulation (Section 3). 2.The authors should do a better job at explaining the details of the state definition, especially the student model features and the combination of data and current learner model.<BRK>This paper suggests a "learning to teach" framework. The problem is framed as RL problem, where the state space corresponds to learning configurations, and teacher actions change the state. I found it very difficult to understand the evaluation. It would be helpful if there are comparisons to these models, and use similar datasets. I would also like to see some analysis of what s actually being learned by the teacher. Maas et al.
Reject. rating score: 2. rating score: 3. rating score: 7. <BRK>There may be some interesting ideas here, but I think in many places the mathematicaldescription is very confusing and/or flawed. To give some examples:* Just before section 2.1.1, P(T)   \prod_{p \in Path(T)} ... : it s not clear at all clear that this defines a valid distribution over trees. There is animplicit order over the paths in Path(T) that is simply not defined (otherwisehow for x^p could we decide which symbols x^1 ... x^{p 1} to conditionupon?) * "We can write S  > O | v | \epsilon..." with S, O and v defined as sets. This is certainly non standard notation, more explanation is needed. * "The observation is generated by the sequence of left most production rules".<BRK>To perform tree to tree transduction the input tree is encoded as a vector with a Tree LSTM; correspondences between input and output subtrees are not modelled directly (using e.g.attention) as is done in traditional tree transducers. The model in this paper is not more expressive than RNNG, it just encodes somewhat different structural biases, which might or might not be suited for real tasks. While neural approches to tree to tree transduction is an understudied problem, the contributions of this paper are very narrow and it is not shown that the proposed approach will generalize to more expressive models or real world applications of tree to tree transduction.<BRK>The authors propose to tackle the tree transduction learning problem using recursive NN architectures: the prediction of a node label is conditioned on the ancestors sequence and the nodes in the left sibling subtree  (in a serialized order)Pros:  they identify the issue of locality as important (sequential serialization distorts locality) and they move the architecture closer to the tree structure of the problem  the architecture proposed moves the bar forward in the tree processing fieldCons:   there is still a serialization step (depth first) that can potentially create sharp dips to null probabilities for marginal changes in the conditioning sequence (the issue is not addressed or commented by the authors)   the experimental setup lacks a perturbation test: rather than a copy task, it would be of greater interest to assess the capacity to recover from noise in the labels (as the noise magnitude increases)  a clearer and more articulated comparison of the pros/cons w.r.t.competitive architectures would improve the quality of the work: what are the properties (depth, vocabulary size, complexity of the underlying generative process, etc) that are best dealt with by the proposed approach?
Invite to Workshop Track. rating score: 6. rating score: 4. rating score: 3. <BRK>The paper proposes a new learning algorithm for learning neural networks that may be biologically plausible. As a non expert in this field, I found this result of this paper pretty interesting, given experimentally the algorithm does work well for MNIST (which is already interesting to me, given the limited progress in this area).<BRK>to test the robustness of the proposed algorithm? The main issues are:1) The theoretical result is incomplete since it fails to show that the algorithm converges to a meaningful learning result. Both these methods are arguably as simple and biologically plausible as the proposed algorithm. Since no complete theoretical guarantees are provided, a much broader experimental study would be necessary to justify the claims made in the paper. It seems to me that the used learning rate heuristic may hinder scalability of equilibrium propagation.<BRK>tl;dr: The paper extends equilibrium propagation to recurrent networks, but doesn t test the algorithm on a dataset requiring a recurrent architecture. What about in more difficult cases? The authors should investigate datasets with sequential structure.
Invite to Workshop Track. rating score: 6. rating score: 6. rating score: 4. <BRK>The paper proposes an interesting usage of Bloomier filters in lossy compression of neural net weights. I think its contribution is novel and original. Is it because the network is deeper? 4.The experimental part can be improved by reporting the compression results for the whole network instead of a single layer. It would be nice to have a separate comparison on the time consumption of  different methods. The comparison should be conducted on the same accuracy level instead of the ratio of nonzero weights.<BRK>Summary: The paper addresses the actual problem of compression of deep neural networks. Moreover, authors propose elegant and efficient trick for mitigating errors of Bloomier filter. Clarity and Quality: The paper is well structured and easy to follow. Significance of the results is hard to estimate because of several reasons:Values of compression and improvement are presented only for two layers, not for the whole network. Perhaps, “...$r$ must be greater than $\lceil \log_2 k\rceil$” would be better for understanding. Perhaps, authors have meant top 1 error.<BRK>That is, the benefit is mainly for storing and transmission. 6) I would like to see the sensibility analysis with respect to t and the number of clusters. Those components are not detailed to the level of being reproducible. Results:  Current results are interesting. At the beginning it is claimed that it takes about one hour for VGG 16 to compute the Bloomier filters.
Reject. rating score: 3. rating score: 4. rating score: 4. <BRK>The methods used in Frey & Jojic are different from what is proposed in the paper, but there needs to be comparisons. 1) The related work section is outrageous, containing no references before 2016. This is the bad side of the recent deep nets hype, and ICLR is particularly susceptible to this.<BRK>Also, experimental results are very preliminary and not properly analyzed.<BRK>ProsThe paper presents interesting ideas regarding unsupervised object discoveryCons:The paper shows no results. Each object is described by a position, appearance feature and confidence of existence (presence).
Reject. rating score: 4. rating score: 6. rating score: 6. <BRK>The paper proposes a block diagonal hessian free method for training deep networks. The block diagonal approximation has been used in [1]. Is the computational time (per iteration) of the proposed method similar to SGD/Adam? All the figures are showing the comparison in terms of number of updates, but it is not clear whether this speedup can be reflected in the training time.<BRK>Presentation/Clarity: The paper is well structured and well written. This results into a block diagonal approximation to the curvature matrix, in order to improve Hessian free convergence properties: in the latter, a single step might require many CG steps, so the benefit from using second order information is not apparent. It is not clear why the deficiency of first order methods on training NNs with big batches motivates us to turn into second order methods. Or is it just because second order methods are kind of the only other alternative we have?<BRK>In this paper, authors discuss the use of block diagonal hessian when computing the updates. The paper is nicely written and all was clear to me. Indeed, the paper is clearly not a theoretical paper, is proposing a new algorithm, hence there should be evidence that it works. For example, I would like to see how the choice of hyper parameters influences the speed of the algorithm. Was "CG" cost included in the "x" axis? i.e.if we put "passes" over the data as x axis, then 1 update \approx 30 CG + some more   32 batch evaluation.
Invite to Workshop Track. rating score: 5. rating score: 5. rating score: 4. <BRK>What data was used? Of course there would be a few conditions needed to make this into a precise statement, but no need for assuming the second term is negligible. Major comments:While the paper has some interesting tentative experimental insights, the relationship between theory and experiment is complicated. A large amount of the paper hinges on being able to ignore the second term in (6), and this fact is referred to many times, but the theoretical and experimental justification for this claim is very thin. This distinction is particularly important in the theoretical discussion. It would be helpful to be clearer about the differences between this work and that presented in Sagun et al.(2016).Minor comments:The assumption that the target y is real is at odds with many regression problems and practically all classification. It might be worth generalizing the discussion to multidimensional targets. In section 5, "we see that even large batch methods are able to get to the level where small batch methods go" seems strange. Hopefully it is in the sense that there are more parameters than needed for good performance at the true global minimum (the additional parameters helping with the process of *finding* a good minimum rather than its existence) or in the sense that M  > infinity for N "equal to" infinity. The claim that the Hessian is ill conditioned depends on the condition number, which is impossible to estimate from the plot. In the caption for Figure 6, "scaled by their ratio" is not clear.<BRK>This is a potentially important observation, and the experiments were well worth performing, but I don t find them fully convincing (partly because I was confused by the presentation). They perform four sets of experiments:1) In section 3.1, they show on simulated data that for data drawn from k clusters, there are roughly k significant eigenvalues in the Hessian of the solution. 3) In section 3.3, they show (again on MNIST) that at their respective solutions, large batch and small batch methods find solutions with similar numbers of large eigenvalues, but that for the large batch method the magnitudes are larger. Section 2.1 is said to contain an argument that the second term of equation 5 can be ignored, but only says that if \ell  and \nabla^2 of f are uncorrelated, then it can be ignored. In section 3.2, it sounds as if the exact Hessian is used, and at the end of this section the authors say that figure 6 demonstrates that the effect of this second term is small, but I don t see why this is, and it isn t explained. It s "principal components", not "principle components".<BRK>More experimental details need to be included, such as the parameters used in training and generating the synthetic dataset. It also studies the effects on the spectrum from the model size, input data distribution and the algorithm empirically. 3.The author needs to provide an explanation for the disagreement between Figure (10) and the result of Keskar et. What s the key difference in experimental settings? 2.A decomposition of the Hessian is introduced to explain the degeneracy of the Hessian. The authors failed to show the significance of their results. For example, what further insights do the results in Sec.3 provide to the community compared with Sagun et. How does this lead to the vanishing of the second term in the decomposition? al.(2016).However, this conclusion is not convincing. However, it is not well organized. In the introduction, the authors spent several paragraphs for line search and expensive computation of GD and the Hessian, which I don t think are very related to the main purpose of this paper.
Invite to Workshop Track. rating score: 7. rating score: 6. rating score: 3. <BRK>The presented MIST architecture certainly has got its merits, but in my opinion is not very novel, given the fact that NARX RNNs have been described 20 years ago, and Clockwork RNNs (which, as the authors point out in section 2, have a similar structure) have also been in use for several years. Regarding the concrete results, I would have wished for a more detailed analysis of the more surprising results, in particular, for the copy task (section 5.2): Is it really true that Clockwork RNNs fail because they make it "difficult to learn long term behavior that must be detected at high frequency" [section 2]? How relevant are the results in figure 2 (yes, the gradient properties are very different, but is this an issue for accuracy)? In summary, for me this paper is solid, and although the architecture is not that new, it is worth bringing it again into the focus of attention. On p2 they write: "Many other approaches have also been proposed to capture long term dependencies." First, Clockwork RNNs sever high frequency to low frequency paths, thus making it difficult to learn long term behavior that must be detected at high frequency (for example, learning to depend on quick motions from the past for activity recognition). NARX RNNs suffer from neither of these drawbacks." Perhaps this trick could further improve the system of the authors, as well as the Clockwork RNNs, at least for certain tasks?<BRK>Summary: The authors introduce a variant of NARX RNNs, which has an additional attention mechanism and a reset mechanism. The attention is only applied on subsets of hidden states, referred as delays. The delays are aggregated into a vector using the attention coefficients as weights, and then this vector is multiplied by the reset gates. The model sounds a bit incremental, however, the performance improvements over pMNIST, copy and MobiAct tasks are interesting.<BRK>The followings are my main critics of the paper: 1. 3.The experimental results are not convincing. This includes 1. the choices of tasks are limited   very small in size, 2. the performance in pMNIST is worse than [1], under the same settings. Hence I think the novelty of the paper is very little, and the experiments are not convincing.
Reject. rating score: 2. rating score: 4. rating score: 5. <BRK>The paper is sloppily written where math issues and undefined symbols make it hard to understand. It seems to be a different and unspecified function from the one introduced in 2)4.1: a substitution cipher has an exact model, and there is no reason why a neural networks would do well here. I also do not understand how this is adversarial, as these are just computed through forward propagation. You have to either reproduce some of the previous results, or run your own experiment in matching settings.<BRK>This paper proposes a generative model called matching auto encoder to carry out the learning from unaligned data. If the title is called  text decipherment , there should be no parallel data at all, otherwise it is a huge overclaim on the decipherment tasks. I would prefer to see some results of baseline models for comparison instead of a pure qualitative analysis. The claim on "FMAEs are state of the art for neural machine translation with limited supervision on EN DE and EN FR" is not exciting to me. Semi supervised learning is interesting, but in the scenario of MT we do have enough parallel data for many language pairs. Possibly it is because the introduction of stochastic variables that prevent the models from overfitting on small datasets.<BRK>This work propose a generative model for unsupervised learning of translation model using a variant of auto encoder which reconstruct internal layer representation in two directions. One of the problems of this paper is the clarity. It is not immediately clear how the feature mapping explained in section 2 is related to section 3. It would be helpful if the authors could provide what is reconstructed using the transformer model as an example. The improved noisy attention in section 3.3 sounds orthogonal to the proposed model. I d recommend the authors to provide empirical results. MT experiments are unclear to me.
Reject. rating score: 3. rating score: 4. rating score: 6. <BRK>There are several issues with the paper: First, it is hard to relate the presented model to its machine learning counterpart. Separating pairs of CIFAR 10 classes is relatively easy and can be done with reasonable accuracy without much nonlinearity. Similarly, an error rate of 5% on MNIST is already achievable by basic machine learning classifiers. The concept of bond and bond dimensions, which are central in this paper due to their relation to model complexity, could be better explained.<BRK>Full disclosure: the authors  submission is not anonymous. Thus, this review is not double blind. This is an interesting application of tensor networks to machine learning. The work proposes using a tree tensor network for image classification. Each image is first mapped into a higher dimensional space. * Consider redoing the experiments with a different cost function: least squares is an unnatural cost function to use for classification. In its current form, reading the paper requires a physics background. I would guess that the ideas you propose are equivalent to existing work in information theory. That would make it less confusing.<BRK>Authors of this paper derived an efficient quantum inspired learning algorithm based on a hierarchical representation that is known as tree tensor network, which is inspired by the multipartite entanglement renormalization ansatz approach where the tensors in the TN are kept to be unitary during training. For example, the scaling of the complexity O(dN_T(b_v^5 + b_i^4)) is not easy to understand. How about the complexity of eigen decomposition for one tensor at each iterates. However, from Fig 3 only, it is hard to make this conclusion. Second, there is no visualization result reported from deep learning on the same data for comparison.
Reject. rating score: 5. rating score: 6. rating score: 6. <BRK>This paper propose a simple extension of the adversarial auto encoders for (conditional) image generation. The general idea is that instead of using Gaussian prior, the propose algorithm uses a "code generator" network  to warp the gaussian distribution, such that the internal prior of the latent encoding space is more expressive and complicated. Pros:  The proposed idea is simple and easy to implement  The results show improvement in terms of visual qualityCons:  I agree that the proposed prior should better capture the data distribution. This makes the prior and posterior learnable, which makes it easier to fool the regularisation discriminator (think about the latent code and prior code collapsed to two different points). As shown in Fig.5.I believe this is a result due to the fact that the adversarial loss in the regularisation phase does not a significant influence there. I have some doubts over why AAE works so poorly when the latent dimension is 2000. How to make sure it s not a problem of implementation or the model wasn t trapped into a bad local optima / saddle points. However, neither the idea/insights it brought can be applied onto other generative models, nor the improvement bring a significant improvement over the state of the arts. I am wondering what the community will learn from this paper, or what the author would like to claim as significant contributions.<BRK>This paper proposes an interesting idea to learn a flexible prior from data by maximizing data likelihood. It seems that in the prior improvement stage, what you do is training a GAN with CG+dec as the generator while D_I as the discriminator (since you also update dec at the prior improvement stage). So it can also be regarded as GAN trained with an additional enc and D_c, and additional objective. In my opinion, this may explain why your model can generate sharper images. The experiments do demonstrate the power of their model compared to AAE. However, only the qualitative analysis may not persuade me and more thorough analysis is needed. 1.About the latent space for z. I m curious how the geometry of the latent space will be, when the code generator is introduced. Doing a likelihood analysis like that in the AAE paper will be very informative.<BRK>Recently some interesting work on a role of prior in deep generative models has been presented. A few existing work presents methods for learning priors from data for variational autoencoders [Goyal et al., 2017][Tomczak and Welling, 2017]. The current work focuses on adversarial autoencoder (AAE) and introduces a code generator network to transform a simple prior into one that together with the generator can better fit the data distribution. Adversarial loss is used to train the code generator network, allowing the output of the network could be any distribution. I think the method is quite simple but interesting approach to improve AAEs without hurting the reconstruction. However, what is missing in this paper is an analysis of learned priors, which help us to better understand its behavior. The model is evaluated qualitatively only.
Reject. rating score: 4. rating score: 6. rating score: 6. <BRK>Pros:The paper is well written, the analysis interesting and the application of the Tucker2 framework sound. Cons:I find the novelty of the paper limited: The authors extend the work by (Onken et al.2016) to subtract baseline (a rather marginal innovation) of this approach.<BRK>The BC method often performs similarly to or is outperformed by non BC SbT NMF. The authors provide a possible mechanism to explain these results, by analyzing classification performance as a function of baseline firing rate.<BRK>A possible solution is to add a regularization term to the objective function to ensure the sparsity of the factorization.
Reject. rating score: 4. rating score: 5. rating score: 6. <BRK>In particular it targetsGraph Convolutional Networks. This is a very important point that should be madeclearer. I would put it at the front. The experiments compare with the recent relevant literature. I think the separability of the filters in this case brings the right level ofsimplification to the learning task, however as it also holds for the planar caseit is not clear whether this is necessarily the best way forward. Overall I found the paper interesting but not ground breaking.<BRK>Instead of using a fixed or Gaussian parametric filters, this work proposes to predict filter weights using a multi layer perception. that predicts filter weights. But, this is clearly missing in the paper. If one needs to run an MLP for each edge in a graph, for each channel and for each layer, the computation complexity seems quite high for the proposed network. How does the proposed technique compare to existing methods in terms of runtime? Minor Weaknesses:  Since this paper is closely related to Monti et al., it would be good if authors used one or two same benchmarks as in Monti et al.for the comparisons. The technical novelty seems incremental (but interesting) with respect to existing methods. It would be better if authors move the important details of the technique and also some important experimental details to the main paper.<BRK>The paper presents an extension of the Xception network of (Chollet et al.2016) 2D grids to generic graphs. Cons:i) The architecture of the 2 layer MLP used to learn weights for a particular depth channel is not provided. The proposed filter relaxes this requirement by forming the weights as the output of a two layer perception. Pros:i) Detailed review of the existing work and comparison with the proposed work.
Reject. rating score: 4. rating score: 7. rating score: 8. <BRK>The authors propose to drop the recurrent state to gates connections from RNNs to speed up the model. The recurrent connections however are core to an RNN. This results in a somewhat unfortunate naming (simple *recurrent* unit), but most importantly makes a comparison with autoregressive sequence CNNs [ Bytenet (Kalchbrenner et al 2016), Conv Seq2Seq (Dauphin et al, 2017) ] crucial in order to show that gated incremental pooling is beneficial over a simple CNN architecture baseline. In essence, the paper shows that autoregressive CNNs with gated incremental pooling perform comparably to RNNs on a number of tasks while being faster to compute. Since it is already extensively known that autoregressive CNNs and attentional models can achieve this, the *CNN* part of the paper cannot be counted as a novel contribution. Slightly unfortunate naming that does not account for autoregressive CNNs  Lack of comparison with autoregressive CNN baselines, which signals a major conceptual error in the paper.<BRK>This work presents the Simple Recurrent Unit architecture which allows more parallelism than the LSTM architecture while maintaining high performance. Significance, Quality and clarity:The idea is well motivated: Faster training is important for rapid experimentation, and altering the RNN cell so it can be paralleled makes sense. The idea is well explained and the experiments convince that the new architecture is indeed much faster yet performs very well. A few constructive comments:  The experiment’s tables alternate between “time” and “speed”, It will be good to just have one of them. Table 4 has time/epoch yet only time is stated<BRK>The authors introduce SRU, the Simple Recurrent Unit that can be used as a substitute for LSTM or GRU cells in RNNs. Authors perform experiments on numerous tasks showing that SRU performs on par with LSTMs, but the baselines for these tasks are a little problematic (see below). Some of this has been pointed out in the comments below already. While the latest are non RNN architectures, a table like Table 5 should include them too, for a fair presentation. That s bad presentation of related work and should be improved in the next versions (at which point this reviewer is willing to revise the score).
Accept (Poster). rating score: 8. rating score: 8. rating score: 8. <BRK>SummaryThis applications paper proposes using a deep neural architecture to do unsupervised anomaly detection by learning the parameters of a GMM end to end with reconstruction in a low dimensional latent space. Since this is so important to the results, more analysis would be helpful. QualityThis paper does not set out to produce a novel network architecture.<BRK>The idea to constraint the dimension reduction to fit a certain model, here a GMM, is relevant, and the paper provides a thorough comparison with recent state of the art methods. Also, the anomaly detection in the evaluation step is based on a threshold which depends on the percentage of known anomalies, i.e., a priori information. 2.Is there a theoretical justification for computing the mixture memberships for the GMM using a neural network? 6.In the newly constructed space that consists of both the extracted features and the representation error, is a Gaussian model truly relevant? Does it well describe the new space? If there is a clear separation from a different view, show that one instead.<BRK>1.This is a good paper, makes an interesting algorithmic contribution in the sense of joint clustering dimension reduction for unsupervised anomaly detection2. It demonstrates clear performance improvement via comprehensive comparison with state of the art methods3. can it be a trainable parameter?
Accept (Poster). rating score: 7. rating score: 6. rating score: 5. <BRK>To my knowledge, the explanation of universal perturbations in terms of positive curvature is novel. The paper works out a probabilistic analysis arguing that when either of these conditions obtains, there exists a fooling perturbation which affects most of the data.<BRK>The paper is written well and clear.<BRK>Why is universal perturbation an important topic (as opposed to adversarial perturbation). And how to achieve that?
Reject. rating score: 4. rating score: 4. rating score: 5. <BRK>The results are preliminary and should be extended to CIFAR 100 and ImageNet to be convincing. 6.Baseline numbers for training on datasets without incomplete dot products should be provided. Summary:——In summary, I think the paper proposes an interesting approach but more work is necessary to demonstrate the effectiveness of the discussed method.<BRK>It is not clear to me what the advantage of this approach is, as opposed to alternative ways of compressing the network (e.g.via group lasso regularization), or training an emulator on the full model for each task. Positive points:  The application seems relevant, and the task wise procedure seems like an improvement over the original IDP proposal.<BRK>This paper presents a modification of a numeric solution: Incomplete Dot Product (IDP), that allows a trained network to be used under different hardware constraints. Additionally, there were several terms that were unexplained in this paper such as  harmonic  method highlighted in Figure  3. The original IDP method (cited in the paper) is based on iteratively training for higher hardware capacities. However the writing is not very clear and the paper is not self contained at all.
Accept (Oral). rating score: 8. rating score: 7. rating score: 7. <BRK>The paper is largely well written and well motivated, the overall setup is interesting (I find the authors  practical use cases convincing where one only has access to imperfect data in the first place), and the empirical results are convincing.<BRK>The theoretical analysis is satisfactory. However, it would be great if the theoretical results in the paper were able to associate the difficulty of the inversion process with the difficulty of AmbientGAN training.<BRK>The method is demonstrated to the generate better results than the baseline on a variety of datasets and noise processes. Quality:I found this to be a nice paper   it has an important setting to begin with and the proposed method is clean and elegant albeit a bit simple.
Reject. rating score: 2. rating score: 5. rating score: 5. <BRK>These reward schemes are evaluated empirically in a packet routing problem. The approach taken by this paper is very ad hoc. It claims to study rewards for multi agent reinforcement learning, but never properly details the learning setting that is considered or how this affects the choice of rewards.<BRK>The rest of the paper has similar issues, with key intuition and concepts either missing entirely or under represented. In game theory, cooperative games are those in which agents share rewards. This statement is too vague, and the authors could do more to identify which application areas might benefit. • [p3, first para] "However, the reward design studies for MARL is so limited." Also, I would argue that there have been quite a few (non deep) discussions about reward design in MARL, cooperative, non cooperative and competitive domains.<BRK>The authors advocate to use multi agent reinforcement learning. is it the ratio between the mean reward of the learnt policy and that of the optimal ? Furthermore, the authors do not provide a baseline to which the outcome of the learning algorithms they propose: for instance how does their approach compare to simple policies (those are commonplace in networking) such as MaxWeight, Backpressure and so on ?
Reject. rating score: 2. rating score: 3. rating score: 4. <BRK>The method is data efficient compared to what? "our results on data efficiency hint that it may soon be feasible to train successful stacking policies by collecting interactions on real robots": Prior work already shows successful stacking policies on real robots, as well as successful pick and place policies and a variety of other skills. "To our knowledge our results provide the first demonstration of end to end learning for a complex manipulation problem involving multiple freely moving objects": This was demonstrated by Finn et al.in "Deep Spatial Autoencoders for Visuomotor Learning," with training times that are a tiny fraction of those reported in this paper, and using raw images and real hardware.<BRK>Reinforcement learning methods are generally aiming to be data efficient, and the method does not seem designed specifically for dexterous manipulation (which is actually a positive point, as it is more general). The paper presents two extensions for DDPG: multiple network updates per physical interactions, and asynchronous updates from multiple robots. The method relies on a predefined task structure (reach grasp stack) and is very similar to reward shaping already used in many other reinforcement learning for manipulation papers. A comparison of different methods for defining the rewards and a more formal description of the reward generation procedure would improve the impact of this section. The fourth and final listed contribution is learning from demonstrated states. It is not clear though how applicable this approach is for a real robot system.<BRK>Pros and Cons (from the RSS AC which sums up my thoughts nicely) + The paper presents and evaluates a collection of approaches to speed learning of policies for manipulation tasks. + Improving the data efficiency of learning algorithms and enabling learning across multiple robots is important for practical use in robot manipulation. + The multi stage structure of manipulation is nicely exploited in reward shaping and distribution of starting states for training. The techniques of asynchronous update and multiple replay steps may have limited novelty, building closely on previous work and applying it to this new problem. The contribution on reward shaping would benefit from a more detailed description and investigation. There is concern that results may be specific to the chosen task. Experiments using real robots are needed for practical evaluation.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>The paper trains wide ResNets for 1 bit per weight deployment. +the paper reads well+the reported performance is compelling Perhaps the authors should make it clear in the abstract by replacing:"Here, we report methodological innovations that result in large reductions in error rates across multiple datasets for deep convolutional neural networks deployed using a single bit for each weight"with"Here, we report methodological innovations that result in large reductions in error rates across multiple datasets for wide ResNets deployed using a single bit for each weight"I am curious how the proposed approach compares with SqueezeNet (Iandola et al.,2016) in performance and memory savings.<BRK>Since right now more and more neural networks are deployed to end users, the authors make an interesting contribution to a very relevant question. The authors include a few other methods for comparision, but I think it would be very helpful to include also some methods that use a completely different approach to reduce the memory footprint. For example, weight pruning methods sometimes can give compression rates of around 100 while the 1bit methods by definition are limited to a compression rate of 32.<BRK>Question for Table 3: 1 bit WRN 20 10 (this paper) outperforms WRN 22 10 with the same #parameters on C100. I would like to see more explanations.
Reject. rating score: 2. rating score: 4. rating score: 4. <BRK>First of all, I don t think I fully understand this paper, because it is difficult for me to find answers from this paper to the following questions:1) what is the hypothesis in this paper? But it misses the most important thing: what is THIS paper (not some other deep learning/representation problems)2) about section 2, regardless whether this is right place to talk about datasets, I don t understand why these two datasets. Since this paper is about generating reviews and discovering sentiment (as indicated in the paper)3) I got completely confused about the content in section 3 and lost my courage to read the following sections.<BRK>The authors propose to use a byte level RNN to classify reviews. They apply this architecture on the same task as the original article: document classification; they use a logistic regression on the extracted representation. The authors obtain interesting results on several datasets. Exploiting the generative capacity of the network, they play with the "sentiment neuron" to deform a review. Qualitative results are interesting. In fact, we do not know what is given as input and what is expected at the output  some clues are given in the experimental setup, but not in the model description . This article is very interesting and well documented. However, according to me, the fact that it provides no model description, no model analysis, no modification of the model to improve the sentiment discovery, prevents this article from being publicized at ICLR.<BRK>This paper shows that an LSTM language model trained on a large corpus of Amazon product reviews can learn representations that are useful for sentiment analysis. The results are mixed, and they understandably are better for test datasets from similar domains to the Amazon product reviews dataset used to train the language model. I think the main result of the paper is not surprising and does not show much beyond we can do pretraining on unlabeled datasets from a similar domain to the domain of interest. I assume that the reason to use byte LSTM is because it is cheaper than a word level LSTM. The paper is also poorly written. There are many typos (e.g., "This advantage is also its difficulty", "Much previous work on language modeling has evaluated ", "We focus in on the task", and others) so the writing needs to be significantly improved for it to be a conference paper, preferably with some help from a native English speaker.
Reject. rating score: 4. rating score: 4. rating score: 6. <BRK>Given that imitation learning is often used to initialize reinforcement learning, the authors should consider using a more descriptive title for this paper. Unfortunately the results are not great. If you give the robot images with one set of objects, but the actual task is performed  using objects of different shapes and sizes, how much does the performance decrease?<BRK>+ Each part of the method is not particularly novel. However, this paper actually addresses these problems by training in a simulator, and only transferring 2 of the 6 tasks to the real world. > You are literally hand engineering a shaping reward. + Because the method needs simulation to learn a policy, it is limited to tasks that can be simulated somewhat accurately (e.g.ones with simple dynamics).<BRK>While it s true that there is a particular combination of factors that doesn t exactly appear in prior work, the statement the authors make is way too strong. Is the implication that prior work is not diverse? Maybe a more honest statement is that this paper proposes some tasks that prior methods don t show, and some prior methods show tasks that the proposed method can t solve. The current paper does use object state information during training, which some prior works manage to avoid. The comments about Cartesian control are a bit peculiar... the proposed method controls fingers, but the hand is simple.
Reject. rating score: 4. rating score: 5. rating score: 5. <BRK>Summary: This paper proposes to use deep Q learning to learn how to reconstruct a given tower of blocks, where DQN is also parameterized by the desired goal state in addition to the current observed state. Pros:  Impressive results on a difficult block stacking task. Cons:  The idea of parameterizing an RL algorithm by goals is not particularly novel. I think it is a useful contribution to introduce this task and the GDQN agent as a baseline.<BRK>They use end to end deep reinforcement learning   the DQN model   including the task goal as an input in order to to improve generalization over several tasks, and shaping the reward depending on the visual differences between the goal state and the current state. Despite Arxiv definitely being an important tool for paper availability, it is not peer reviewed and there are also work that are non finished or erroneous. The authors initially claim that "In this paper, [they] study how an artificial agent can autonomously acquire this intuition through interaction with the environment", however the proposed tasks present little to no realistic physical interaction: the navigation task is a toy problem where no physics is simulated. In the stacking task, only part of the simulation actually use the physical simulation result.<BRK>The authors use a variant of deep RL to solve a  simplified 2d physical stacking task. Overall it feels as if this is an interesting project but that it is not yet ready for publication. The input to the network is the current state of the environment as represented by the 2d projection of the objects in the simulated grid world and a representation of the goal state in the same projection space. Or are separate DQNs trained for multiple tasks?
Accept (Poster). rating score: 8. rating score: 7. rating score: 7. <BRK>The paper provides an interesting data collection scheme that improves upon standard collection of static databases that have multiple shortcomings   End of Section 3 clearly summarizes the advantages of the proposed algorithm. The paper is easy to follow and the evaluation is meaningful. In MTD, both data collection and training the model are intertwined and so, the quality of the data can be limited by the learning capacity of the model.<BRK>This idea of HITL dataset creation is interesting, because the competitive aspect incentivizes turkers to produce high quality data. Judging by the feedback given by turkers in the appendix, the workers seem to enjoy the competitive aspect, which would hopefully lead to better data. The results seem to suggest that MTD provides an improvement over non HITL methods. MTD is mostly competitive, and the authors should reduce the emphasis on a stretched definition of collaboration. While the turkers are provided immediate feedback when the model already correctly classifies the proposed training example, it seems difficult for turkers to anticipate when an example is too hard, because they have no idea about the learning process. My biggest criticism is that MTD seems more like an NLP paper rather than an ICLR paper.<BRK>Over multiple iterations, Turkers provide training examples for a language grounding task, and they are incentivized to provide new training examples that quickly improve generalization. The framework is straightforward and makes few assumptions about the task, making it applicable to potentially more than grounded language. Result show that the interactive learning outperforms the static learning baseline, but there are potential problems with the way the test set is collected. Additionally, there is potentially a different distribution of language for gamified and non gamified settings. I would like to see the results over the different test subsets, allowing us to verify whether MTD outperforms the baseline for the baseline s test data.
Accept (Poster). rating score: 8. rating score: 7. rating score: 6. <BRK>However, related to the above non intuitive claim, here is a question on a related Gaussianization transform missed by the authors that (I feel) fulfils the conditions defined in the paper but it is not obviously related to wavelets. Writing is suggestive and experimental results are interesting, so I clearly recommend acceptation. J. Comp.Vis.2000] in which after wavelet transform, local division is performed to obtain Gaussian variables, and these can be used to synthesize the learned textures.<BRK>After a first manuscript that needed majors edits, the revised versionoffers an interesting GAN approach based the scattering transform. Approach is well motivated with proper references to the recent literature. Experiments are not state of the art but clearly demonstrate that theproposed approach does provide meaningful results.<BRK>It seems that it would be known from unknown images. The paper is well written and clear. The authors should show more clearly the generalization capabilities to test samples. Would it make sense to combine the two? The samples produced by the model are of poorer quality than those obtained with GAN’s. The title is a bit misleading in my view. However, I do find very interesting the analysis provided in Section 3.2. The idea of using meaningful intermediate (and stable) targets for the first two layers seems like a very good idea. In Figure 3, it would be good to show some interpolation results for test images as well, to have a visual reference.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. <BRK>The authors proposed a supervised learning algorithm for modeling label and worker quality. Overall the paper was well written.<BRK>"To re (label), or not to re (label)." Pros:+ The paper is generally very clearly written. The authors missed an important related work which studies the same problem and comes up with a similar conclusion: Lin, Mausam, and Weld.<BRK>However, I like the motivation of this paper and the discussion about the relationship between training efficiency and label redundancy.
Reject. rating score: 3. rating score: 4. rating score: 4. <BRK>This paper considers distributed synchronous SGD, and proposes to use "partial pulling" to alleviate the problem with slow servers. The authors suggested one possibility, namely that the server and some workers are located on the same machine and the workers take most of the computational resource. However, if this is the case, a simple solution would be to move the server to a different node. A more convincing argument for a slow server should be provided.<BRK>This paper introduces a parameter server architecture to improve distributed training of CNNs in the presence of stragglers. This technique is combined with existing methods such as partial pushing (Pan et.al.2017) for a partial synchronous SGD method. Unfortunately, in your Figure 2, this is not as obvious and not real since it is using simulated delays. The idea is to send partial parameter blocks and when  b  blocks are received, compute the gradients. 3) The evaluation is on fairly small workloads (CIFAR 10). Furthermore, the proposed technique despite the simplicity appears as a rather incremental contribution.<BRK>Paper proposes a weak synchronization approach to synchronous SGD with the goal of improving even with slow parameter servers. This is an improvement on earlier proposals (e.g.Revisiting Synchronous SGD) that allow for slow workers. The choice of simulation constants (% delayed, and delay time) seems somewhat arbitrary as well. For the simulated results, the comparisons seem unfair since the validation error is different. Overall, the paper proposes an interesting improvement to this area of synchronous training, however it is unable to validate the impact of this proposal.
Reject. rating score: 5. rating score: 6. rating score: 6. <BRK>This very much relates to the method used to generalize over subgoals in the paper. The main claimed advantage is that it doesn t require the knowledge of the actions taken by the expert, only observations of states. Finally, I also think that using expert data generated by a pre trained network makes the experimental section very weak.<BRK>This seems like a key claim to establish. Essentially the expert defines a new Q value problem at every state for the learner? The resultant policy is a function of the expert traces on which it depends.<BRK>The authors propose to speed up RL techniques, such as DQN, by utilizing expert demonstrations. The paper is overall well written, and the proposed idea seems interesting. There is also the issue of keeping tracking of a large number of demonstration states in memory. The empirical evaluation seems rather mixed.
Reject. rating score: 3. rating score: 4. rating score: 4. <BRK>The rotation matrix is a block diagonal one where each block is a 2x2 rotations and those rotations are parametrized by another neural network that predicts the angle of the rotations.<BRK>This is not clear at all after reading the paper. Besides, the idea of using a rotation operation in recurrent networks has been explored before [3]. Firstly, the title and abstract discuss "modifying memories", but the content is only about a rotation operation.<BRK>The transform allows for explicit rotations and swaps of the hidden cell dimensions. The idea is illustrated for LSTM units, where the transform is applied after the cell values are computed via the typical LSTM updates. Have you considered training jointly (across the tasks) as well?
Reject. rating score: 4. rating score: 4. rating score: 5. <BRK>Decomposing the semantic part from the context part in an image based on a generative model is an interesting problem. It generates images in a layer wise manner. [Weaknesses]This paper proposed an interesting and intuitive image generation model. However, there are several weaknesses existed:1. In the experiments, the authors showed qualitative results on three datasets, MNIST, SVHN and CelebA. The authors should present some quantitative evaluations in the paper, which are more persuasive than a number of examples. Recently, CIFAR 10 has become a popular dataset as a testbed for evaluating various GANs.<BRK>In additional, there is no ablation study analyzing impacts of each design choices. The paper shows results on the MNIST, SVHN, and Celebrity Faces datasets. Poor experimental validationWhile it is interesting to know that a foreground background decomposed generative model can be learned in an unsupervised manner, it is clear how this capability can help practical applications, especially no such examples are shown in the paper. For example, the paper will be more interesting if inception scores were shown for various challenging datasets.<BRK>Summary: This paper studied the conditional image generation with two stream generative adversarial networks. Experiments on MNIST, SVHN, and CelebA datasets demonstrated promising generation results with the unsupervised two stream generation pipeline. For example, layered generation (Section 2.2.1) has been explored in Yan et al 2016 (VAEs) and Vondrick et al 2016 (GANs). For example, I am not convinced if the two stream generation pipeline can work well on more challenging datasets such as MS COCO, LSUN, and ImageNet. Overall, I believe the paper is interesting but not ready for publication. Presentation  The paper is readable but not well polished.
Reject. rating score: 5. rating score: 6. rating score: 7. <BRK>This paper presents an analysis of LSTMS showing that they have a from where the memory cell contents at each step is a weighted combination of the “content update” values computed at each time step. The second problem of what tasks to evaluate on is a general problem with comparing RNNs. Second, the paper offers a simplification of LSTMs that compute the value by which the memory cell at each time step in terms of a deterministic function of the input rather than a function of the input and the current context. This reduced form of the LSTM is shown to perform comparably to “full” LSTMs.<BRK>On the experimental side, to draw the conclusion, "weighted sum" is enough for LSTM. Both of the two paper don t have output gate and non linearity of "Wx_t" and results on PTB also stronger than this paper.<BRK>The paper then argues that LSTM is redundant by keeping only input and forget gates to compute the weights.
Accept (Poster). rating score: 7. rating score: 7. rating score: 7. <BRK>The paper is a step forward for image deep compression, at least when departing from the (Balle et al., 2017) scheme. I find the description of the maths too laconic and hard to follow. operator in (5)? What about reproducibility of the results?<BRK>Authors propose a transform coding solution by extending the work in Balle 2016. The paper is well written, although I had trouble following some parts. *** MAIN ISSUESI have two main concerns about motivation that are related. REFERENCES  Balle 2016 and Theis 2017 seem to be published in the same conference the same year. Another thing is that the symbol ψ appears in this figure and is not used in section 2.<BRK>Summary:This paper extends the work of Balle et al.(2016, 2017) on using certain types of variational autoencoders for image compression. Both the coefficients and the representation of the scales are quantized and encoded in the binary image representation. I like the approach of using a hierarchical entropy model, which may inspire further work in this direction. It is nice to see that the variational approach may be able to outperform the more complicated state of the art approach of Rippel and Bourdev (2017). It would have been great if the authors included a comparison based on human judgments or at least a side by side comparison of reconstructions generated by the two approaches. I did not quite follow the motivation for convolving the prior distributions with a uniform distribution. The paper is mostly well written and clear. Minor suggestions:– On page 3 the paper talks about “the true posterior” of a model which hasn’t been defined yet.
Reject. rating score: 2. rating score: 2. rating score: 4. <BRK>This writeup describes an application of recurrent autoencoder to analysis of multidimensional time series. The method is explained in a very unclear way, there is no mention of any related work. I would encourage the authors to take a look at other ICLR submissions and see how rigorously written they are, how they position the reported research among comparable works.<BRK>The authors show that for their application, better performance is obtained when the network is only trained to reconstruct a subset of the data measurements. The paper doesn’t frame the work in prior research at all and the six papers it cites are only referred to in the context of describing the architecture. I found it very hard to distil what the main contribution of this work was according to the paper. The paper describes how existing methods are applied to a specific data set. Cons:* It is not clear what the main contribution is.<BRK>This paper proposes a strategy that is inspired by the recurrent auto encoder model, such that clustering of multidimensional time series data can be performed based on the context vectors generated by the encoding process. In short, the paper in its current form does not provide sufficient details for the reviewer to judge its merits and contributions. I would like the authors to explain it in more details or empirically demonstrate that, since a LSTM based model could be computationally expensive.
Accept (Poster). rating score: 8. rating score: 7. rating score: 6. rating score: 6. <BRK>This paper explores a new approach to optimal transport. I should mention that I m not sufficiently familiar with the optimal transport literature to verify the detailed claims about where the proposed dual based algorithm stands in relation to existing algorithms. In the comparison to previous work, please explicitly mention the EMD algorithm, since it s used in the experiments. It would be great to mention very briefly any helpful intuition as to why F_\epsilon and H_\epsilon have the forms they do. Is their any helpful intuition about what goes wrong? What cost is used for generative modeling on MNIST?<BRK>ClarityThe paper is mostly clear, even though some parts deserve more discussion/clarification (algorithm, experimental evaluation). Could the authors discuss this aspect? If this subject is important, it would have been interesting to compare the approaches on other large scale problems and possibly with other implementations. Hyperparameter tuning is another aspect that is not sufficiently precise in the experimental setup: it seems that the parameters are tuned on test (for all methods), which is not fair since target label information will not be available from a practical standpoint.<BRK>This paper proposes a new method for estimating optimal transport plans and maps among continuous distributions, or discrete distributions with large support size. The consistency properties are nice, though they don t provide much insight into the rate at which epsilon should be decreased with n or similar properties. The proofs are clear, and seem correct on a superficial readthrough; I have not carefully verified them. Though it makes sense that your regularization might lead to a better estimator, you don t seem to have shown so either in theory or empirically. Do you have any guesses as to why this might be?<BRK>I do not see that from the paper. A better result, hinting on how "optimal" this can be, would have been to guarantee that the solution to regularised OT is within f(epsilon) from the optimal one, or from within f(epsilon) from the one with a smaller epsilon (more possibilities exist).
Reject. rating score: 4. rating score: 5. rating score: 5. <BRK>My main concern iswith lack of sufficient depth in empirical evaluation and analysis of the method. 2.The proposed method is simple and intuitive.<BRK>The paper is overly long and could be improved by a more compact presentation of background, algorithms, and results.<BRK>Minor:  Paper is significantly over the page limit; in many places, writing could be improved, many typos in paper(in the first page: "project of design" > "project of designing"; "farmework" >"framework"; "we consider the scenario" "problems that are once" are clumsy).
Reject. rating score: 4. rating score: 4. rating score: 4. <BRK>There are a number of attempts to add episodic memory to RL agents. A common approach is to use some sort of recurrent model with a model free agent. The primary weakness of this work its lack of novelty and lack of evidence of generalization of the approach, which limits its significance. Simply showing that a customized model can outperform on a single custom, synthetic task is insufficient to demonstrate that these changes are of wider interest. Why not just  blind ?<BRK>The paper addresses an important problem of how ML systems can learn episodic memory. 3) While the game of concentration clearly requires episodic memory to some extent, this only task is not enough for testing EM approaches, because there is always a risk that one of the evaluated systems somehow overfitted to this task by design. Thus it is impossible to make a human baseline for this task and decide on how far are we below the human level. Detailed comments:1) When a new architecture is proposed, it is good to describe in detail, at least in the appendix.<BRK># SummaryThis paper proposes an external memory architecture for dealing with partial observability. The results on "Concentration" task show that the proposed method outperforms DNC and LSTM. [Pros]  Presents a new memory related task. Comparison to DNC does not show the effect of the proposed idea (masked Euclidean distance). The description of concentration task is a bit lengthy.
Reject. rating score: 3. rating score: 5. rating score: 7. <BRK>The novelty of the paper does not appear to be significant, considering that most of the key techniques used in the paper had already appeared in several related papers, such as Nalisnick & Smyth (2017), Srivastava & Sutton (2017), and Miao et al.(2016 & 2017). To make the paper theoretically sound as a Bayesian nonparametric topic model that uses the stick breaking construction, please refer to Teh et al.(2006, 2008) and Wang et al.(2011) for the correct construction that ties the document specific pi vectors with a globally shared stick breaking process. While experiments show the proposed models outperform the others quantitatively (perplexity and coherence), the paper does not provide sufficient justifications on why ITM VAE is better.<BRK>The paper proposes a VAE inference network for a non parametric topic model. The model on page 4 is confusing to me since this is a topic model, so document specific topic distributions are required, but what is shown is only stick breaking for a mixture model. This would be best shown by comparing with the corresponding non deep version of the model rather than LDA and other deep models.<BRK>Hughes, Kim and Sudderth (2015) have avoided stick breaking and CRPs altogether, as have others in earlier work. In Related Work, you seem to only mention HDP for non parametric topic models. Good to see a prior is placed on the concentration parameter. Very important and not well done in the community, usually. Others stress the importance of this. The comparison with LDA makes me suspicious.
Reject. rating score: 3. rating score: 4. rating score: 7. <BRK>Comparisons to other imitation learning approaches are needed. Pros:  The paper concentrates on an interesting special case of imitation learningCons:  The paper is written very confusingly and hard to understand. It is unclear why the heuristic reward function makes sense. Also the results are not convincing.<BRK>My main issues with the paper are:  It does not cite or discuss a very important piece of related work: "Imitation from Observation: Learning to Imitate Behaviors from Raw Video via Context Translation" (Liu et al., 2017)  The empirical results are unconvincing   it seems like in all problems they use there is a straightforward mapping from state feature differences to actions, as pointed out in an anonymous comment.<BRK>Model Based Imitation Learning from State TrajectoriesSIGNIFICANCE AND ORIGINALITY:The authors propose a model based method for accelerating the learning of a policyby observing only the state transitions of an expert trace. Not clear that method converges on all problems. The model free algorithm is trained to try to duplicate the expert state at each trajectory. Interestingly, DQN + heuristic reward approaches expert performancewhile behavioral cloning never achieves expert performance level even though it has actions. Does it not converge to expert level?? If so, this would be useful to know.
Accept (Poster). rating score: 7. rating score: 7. rating score: 7. <BRK>This is a well written paper that proposes regularization and optimization strategies for word based language modeling tasks. The  focus of this work is on the prevention of overfitting on the recurrent connections of the LSTM. Overall, it would be beneficial to the MLP community to see this paper accepted in the conference.<BRK>Clearly presented paper, including a number of reasonable techniques to improve LSTM LMs. re."ASGD" for Averaged SGD: ASGD usually stands for Asynchronous SGD, have the authors considered an alternative acronym?<BRK>at the expense of very common words. All in all, the paper is a solid contribution which deserves to be accepted. The paper is well written, easy to follow and the results speak for themselves. A variant on the Averaged SGD method is proposed.
Accept (Oral). rating score: 8. rating score: 7. rating score: 7. <BRK>In general, the paper was written in good quality and in detail, I would recommend a clear accept. One caveat is that there seem to be some conflictions in the results shown in Table 1, especially ImageNet.<BRK>This will give the hardware community a clear vision of how such methods may be implemented both in data centers as well as on end portable devices. Afterward, the authors conduct experiments on MNIST, SVHN, CIFAR10, and ILSVRC12 datasets, where they show promising results compared to the errors provided by previous works.<BRK>This paper proposes a method to train neural networks with low precision. Taking all the above into account, it hard to be sure whether the proposed methods meaningfully improve existing methods.
Reject. rating score: 4. rating score: 4. rating score: 4. <BRK>The paper treats the interesting problem of long term video prediction in complex video streams. I find some of the claims not clearly backed by a thorough evaluation and analysis. Claiming to be able to produce encodings of scenes that work well at predicting many steps into the future is a very strong claim. The main lack of clarity source I think is about what the contribution is.<BRK>The paper presents a method for hierarchical future frame prediction in monocular videos. The conclusions from the paper are uncertain, partly  due to the difficulty of evaluating the video prediction results.<BRK>The paper presents a method for predicting future video frames. The novelty of the method is limited.
Accept (Poster). rating score: 8. rating score: 8. rating score: 8. <BRK>The authors also point out the connection between the gate biases and the range of time dependencies captured in the network. From that, they develop a simple yet effective initialization method which performs well on different datasets. Writing: The paper is well written and easy to read.<BRK>The experiments do not directly test whether the theoretical insight holds in practice, but instead a derivate method is tested on various benchmarks. Such a result would in my opinion be of much more use than the tiny increment in performance that is the main output of the paper as of now, and which will be stomped by some other trick in the months to come.<BRK>Summary:This paper shows that incorporating invariance to time transformations in recurrent networks naturally results in a gating mechanism used by LSTMs and their variants. This is then used to develop a simple bias initialization scheme for the gates when the range of temporal dependencies relevant for a problem can be estimated or are known.
Invite to Workshop Track. rating score: 6. rating score: 6. rating score: 4. <BRK>Pros  The proposed model is a nice way of multiplicatively combining two features :  one which determines which classes to pay attention to, and other thatprovides useful features for discrimination. : This doesnot seem to be true. This would notresult in excluding the unit. QualityThe paper makes relevant comparisons and is overall well motivated. However,some aspects of the paper can be improved by adding more explanations. OriginalityThe main contribution of the paper is similar to multiplicative gating. However, experiments are insufficient to determine whether it is this noveltythat contributes to improved performance or just the gating.<BRK>This paper propose an adaptive dropout strategy for class logits. They learn the dropout distribution by variational inference with concrete relaxation. Overall I think this is a good paper. The technique sounds, the presentation is clear and I have not seen similar paper elsewhere (not 100% sure about the originality of the work though). I would like to see the results on more datasets.<BRK>In the spirit of the latter series of papers on variational dropout there is a derivation of this algorithm using ideas from variational inference. A fairly small, but consistent improvement on the base model and other similar ideas is reported in Table 1. I would have liked to have seen results on ImageNet. The test loss in question looks like a noisy version of the base test loss with a slightly lower mean. There are grammatical errors throughout the paper at a higher rate than would normally be found in a successful submission at this stage. Figure 3 illustrates the idea nicely.
Reject. rating score: 3. rating score: 4. rating score: 4. <BRK>This suggests that the paper fails to see the connection and blindly put the two things together.<BRK>This paper proposed an X shaped GAN for the so called semantic style transfer task, in which the goal is to transfer the style of an image from one domain to another without altering the semantic content of the image. Here, a domain is collectively defined by the images of the same style, e.g., cartoon faces.<BRK>This paper proposes a new GAN based model for unpaired image to image translation. First, the baselines are insufficient. I was a bit confused by the “finetuned DTN” in Section 7.2.
Accept (Poster). rating score: 8. rating score: 7. rating score: 4. <BRK>Four adversarial attacks strategies are considered to attack a Resnet50 model for classification of Imagenet images. Experiments are conducted in a black box setting (when the model to attack is unknown by the adversary) or white box setting (the model and defense strategy are known by the adversary). The previous best approach for this task consists in ensemble training and is attack specific. It is therefore pretty robust to the attack it was trained on but is largely outperformed by the authors methods that manage to reduce the classifier error drop below 25%. Comments: The paper is well written, the proposed methods are well adapted to the task and lead to satisfying results. Minor: the bibliography should be uniformed.<BRK> The paper investigates using input transformation techniques as a defence against adversarial examples. The authors have evaluated their defences against four main kinds of adversarial attacks. The main takeaways of the paper are to incorporate transformations that are non differentiable and randomised. Would this observation then be vulnerable to such attacks? The evaluation is carried out on ImageNet dataset with large number of examples.<BRK>* The writing is reasonably clear (up to the terminology issues discussed among the weak points), and introduces properly the adversarial attacks considered in the work. Weak points:* The black box versus white box terminology is not appropriate, and confusing. * The paper does not discuss the impact of the denfense strategy on the classification performance in absence of adversity. Designing an attack in case of a non differentiable transformation is obviously not trivial since back propagation can not be used. Overall, the works investigates an interesting idea, but lacks maturity to be accepted. * p1:  too simple to remove adversarial perturbations from input images sufficiently
Accept (Poster). rating score: 8. rating score: 8. rating score: 4. <BRK>This limitation is an empirical fact that the paper has done a reasonable job of revealing, and it does not take away the paper s reason for existence, since many of the results are still quite strong, and the trends do support the merit of the proposed approach. The authors mostly addressed my main concern, which was the relatively weak ablation. This paper isn t especially novel. Your ablation does not offer enough evidence to one to infer this among other things, NLI and MT are never presented in isolation, and parsing is never presented without those two. If task batches are sampled *uniformly*, how is NLI be sampled less often than the other tasks?<BRK>I think this paper is impressive in how it scales up training to use so many tasks and such large training sets for each task. I understand that sometimes it s tempting to minimize one s weaknesses in order to get a paper accepted because the reviewers may not understand the area very well and may get hung up on the wrong things. I would suggest adding some motivation for the focus on fixed length representations. It would be nice if the authors could discuss this. For all tasks for which there is additional training, there s a confound due to the dimensionality of the sentence embeddings across papers.<BRK>This paper shows that learning sentence representations from a diverse set of tasks (skip thought objective, MT, constituency parsing, and natural language inference) produces . The main contribution of the paper is to show learning from multiple tasks improves the quality of the learned representations. Experiments on various text classification and sentiment analysis datasets show that the proposed method is competitive with existing approaches. There is an impressive number of experiments presented in the paper, but the results are a bit mixed, and it is not always clear that adding more tasks help. I think this paper addresses an important problem of learning general purpose sentence representations. Could it be that datasets such as MRPC, SICK, and STSB require more understanding of syntax? The results for transfer learning and low resource settings are more positive.
Reject. rating score: 3. rating score: 4. rating score: 5. <BRK>The authors propose a neural network architecture which takes the characters of a word as input along with their positions, and output a word embedding. While the idea has merit, the experimental protocol is too flawed to draw any reliable conclusions.<BRK>This paper presents a new model for composing representations of characters into word embeddings. The starting point of their argument is to include position specific embeddings of characters rather than just position independent characters. 1) It is a bit hard to assess since it is not evaluated on a standard datasets. There are a number standard datasets for open vocabulary language modeling. 2) There are many existing models for composing characters into words.<BRK>The paper uses both position agnostic and position aware embeddings for tokens in a language modeling task. While their technique is interesting, they do not compare it to the baseline of using convolutions over characters.
Reject. rating score: 2. rating score: 4. rating score: 4. <BRK>I now see you have a similar statement in Discussion, but if this is what you try to do and has to be explained at the beginning. It is very hard to follow this work, it feels like it tries to get several messages across while none of them properly. Sec 3. you use IFO of Agarwal and Bottou which is known not to include this kind of algorithm   see large red box above abstract in the last version of the cited paper.<BRK>Moreover, there is no guarantee for sparsity by using L1 regularization on nonconvex problems. al (2016) is not the leading result. There are (at least) two more results which are better than Han et. Therefore, you should provide more experiments to show the efficiency.<BRK>Hence, it is unclear how the use of SVRG over SGD improves things. Unfortunately, the authors do not compare with some key literature. For example there has been several techniques that use sparsity, and group sparsity [1,2,3], that lead to the same conclusion as the paper here: models can be significantly sparsified while not affecting the test accuracy of the trained model.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. <BRK>The paper presents an implementation strategy (with code link anonymized for review) for fast computations of binary forward inference. and there has been lots of work on fast inference of quantized, low bit width neural networks, but if indeed the implementation is significantly faster than commercial alternatives (e.g.from Intel) then I expect the authors have made a novel and useful contribution.<BRK>This paper builds on Binary NET [Hubara et al.2016] and expands it to CNN architectures. I think it is a good fit for a poster. The main contribution of this paper is an optimized code for Binary CNN. The authors provide the code with permissive licensing.<BRK>The paper presents a library written in C/CUDA that features all the functionalities required for the forward propagation of BCNNs. The library is significantly faster than existing implementations of optimized binary neural networks (≈ 2 orders of magnitude), and will be released on github. I increase my rating to 6.
Invite to Workshop Track. rating score: 6. rating score: 6. rating score: 6. <BRK>Using ideas based on the Maximum Mean Discrepancy (MMD) to compare distributions of mini batches, the authors generalize the idea of mini batch discrimination. The key insight is that the training procedure usually used to train GANs does not allow the discriminator to share information across the samples of the mini batch. Some minor points:  How sensitive is the method to various neural network architectures, initializations, learning rates, etc? I think it s important to discuss this since it s one of the main challenges of training GANs in general. Figure 1 is interesting but it could use better labelling (words instead of letters)Overall:Pros: Well written, good empirical results, well motivated and intuitively explainedCons: Not particularly novel, a modification of an existing idea, more sensitivity results would be nice<BRK>One of the best ways to evaluate GAN algorithms is not domain adaptation but semi supervised learning, and this is completely lacking in this paper. I think it s fair to say that the whole paper is approximately minibatch discrimination + MMD. While this is a very useful and a  much more principled combination, supported by good experimental results, I m not 100% sure if it is original enough.<BRK>Overall this paper seems borderline   a nice theoretical story, grounding out into a simple architecture that does seem to work in practice (the domain adaptation results are promising), but with somewhat sloppy writing and experimentation that doesn t clearly demonstrate the value of the proposed approach. I hope the authors continue to improve the paper by comparing to other minibatch discrimination techniques. This is an interesting approach, although empirically it does not appear to have any advantage over the simpler DAN S   do the authors agree with this interpretation? If so it is still a worthwhile negative result, but the paper should make this conclusion explicit.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>Summary:This paper empirically studies adversarial perturbations dx and what the effects are of adversarial training (AT) with respect to shared (dx fools for many x) and singular (only for a single x) perturbations. The authors conclude that in this experimental setting:  AT seems to defend models against shared dx s.  This is visible on universal perturbations, which become less effective as more AT is applied.<BRK>This paper analyses adversarial training and its effect on universal adversarial examples as well as standard (basic iteration) adversarial examples. It also analyses how adversarial training affects detection. Finally, the paper spends significant time on describing MaxMin and MinMax and the graphical visualizations but the paper fails to show these graphical profiles for real models. There is also no analysis of what happens for adversarial examples for the detector.<BRK>This paper investigates the effect of adversarial training. Based on experiments using CIFAR10, the authors show that adversarial training is effective in protecting against "shared" adversarial perturbation, in particular against universal perturbation. In contrast, it is less effective to protect against singular perturbations. I like the message conveyed in this paper.
Reject. rating score: 3. rating score: 6. rating score: 7. <BRK>Is there some thermodynamic limit argument required here? How do we know what phase these experiments were in? How do we know these experiments were in the thermodynamic limit? For Observation 2, the authors point out that in VSDL, "the only way to prevent overfitting is to decrease the number of iterations." The argument needs to be sharpened here. This seems to be in direct contradiction to the predictions made by the theories presented here. Footnotes 3 and 4. As written, I simply do not see which actual observations they think they explain. Check the appendix for consistency here too. I have questions. The "proof" is a reference to SM papers.<BRK>I agree with the authors that this line of work, that is not very well known in the current machine learning community, includes a number of ideas that should be able to shed light on some of the currently open theoretical questions. Why in Fig.3(a) the training and generalization error is the same while in Fig.3(c) they are different?<BRK>The authors are making a strong case for the use of these models to understand overfitting and generalization in deep leaning. The problem is however that, except from advocating the use of these "spin glass" models studied back in the days by Seung, Sompolinksy, Opper and others, there are little new results presented in the paper. This might very well be, but this is precisly the point: is it ? This is all nice, interesting, and well written, but at the end of the day, the paper is not doing too much beyond being a nice review of all ideas. While this has indeed some values, and might trigger a renewal of interested for these approaches, I will let the comity decide if this is the material they want in ICLR.
Reject. rating score: 2. rating score: 3. rating score: 3. <BRK>This reframing does point out a different and perhaps better path for AI, but it is not entirely new and this paper does not present a method for getting from sensed data to higher level concepts.<BRK>The paper, therefore,  does not set their approach in context and is not able to acknowledge related work in this area. This is very suspicious.<BRK>In its current state, it therefore does not feel like an appropriate paper for this particular conference.
Accept (Poster). rating score: 6. rating score: 6. rating score: 4. <BRK>This paper focuses on imitation learning with intentions sampled from a multi modal distribution. The unimodal claim for distribution without randomness is weak. The use of a latent variable in this setting makes intuitive sense, but I don t think multimodality motivates it. I can see how it adds value over sampling from the prior, but it s unclear if it has value over a modern approximate inference scheme like a black box variational inference algorithm or stochastic gradient MCMC. Finally, I d also be curious about how much added value you get from having access to extra rollouts.<BRK>The authors propose a new sampling based approach for inference in latent variable models. They apply this approach to multi modal (several "intentions") imitation learning and demonstrate for a real visual robotics task that the proposed framework works better than deterministic neural networks and stochastic neural networks. This reviewer is a bit sceptical to the methodology. Con:1.Not entirely convincing that it should work better than already existing methods. 2.Missing some investigation of the properties of the estimator on simple problem to be compared to standard methods.<BRK>The authors provide a method for learning from demonstrations where several modalities of the same task are given. They put the this specific work in the right context of imitation learning and IRL. Even the control task is very similar to the current proposed task in this paper. I went over the math. It seems right and valid. I must say that I was impressed with the authors making the robot succeed in the tasks in hand (although reaching to an object is fairly simple task). Why not adding (non Bayesian) context (not label) to the task will not work as well? 3) the robot task is impressive. But I think some more work is needed in this work: comparing to the right current state of the art, and show that in principal (by demonstrating on other simpler simulations domains) that this method is better than other methods.
Accept (Poster). rating score: 8. rating score: 7. rating score: 6. <BRK>This paper introduces a smooth surrogate loss function for the top k SVM, for the purpose of plugging the SVM to the deep neural networks. The paper is well organized and clearly written. On the other hand, there might be better and more direct solutions to reduce the combinatorial complexity.<BRK>This paper made some efforts in smoothing the top k losses proposed in Lapin et al.(2015).A family of smooth surrogate loss es was proposed, with the help of which the top k error may be minimized directly. Pros:1, The paper is well presented and is easy to follow. 2, The contribution made in this paper is sound, and the mathematical analysis seems to be correct. 3, The experimental results look convincing. Cons:Some statements in this paper are not clear to me.<BRK>The paper is clear and well written. The proposed approach seems to be of interest and to produce interesting results. The paper proposes to use a top k loss such as what has been explored with SVMs in the past, but with deep models. Those claims are not substantiated, however, and the method proposed by the paper seems to add substantial complexity without really proving that it is useful. I believe the paper could justify this approach better by providing a bit more insights as to why it is required.
Accept (Poster). rating score: 8. rating score: 7. rating score: 7. <BRK>It is claimed that the transformer decoder makes optimization easier but no complete explanation or justification of this is given. In the task setup the information retrieval based extractive stage is crucial to performance, but this contribution might be less important to the ICLR community. The training data is significantly larger than the CNN/DailyMail single document summarization dataset. The paper presents strong quantitative results and qualitative examples. In some of the examples the system output seems to be significantly shorter than the reference, so it would be helpful to quantify this, as well how much the quality degrades when the model is forced to generate outputs of a given minimum length. The additional experiments and clarifications in the updated version give substantially more evidence in support of the claims made by the paper, and I would like to see the paper accepted.<BRK>The main significance of this paper is to propose the task of generating the lead section of Wikipedia articles by viewing it as a multi document summarization problem. The main strength is in the task setup with the dataset and the proposed input sources for generating Wikipedia articles. A further analysis which would be nice to do (though I have less clear ideas how to do it), would be to have some way to figure out which article types or which section types are amenable to this setup, and which are not. After reading the authors  response and the updated submission, I am satisfied that my concerns above have been adequately addressed in the new version of the paper. This is a very nice contribution.<BRK>This paper considers the task of generating Wikipedia articles as a combination of extractive and abstractive multi document summarization task where input is the content of reference articles listed in a Wikipedia page along with the content collected from Web search and output is the generated content for a target Wikipedia page. In general, the paper is well written and the main ideas are clear. However, my main concern is the evaluation. More importantly, it was not clear from the paper if there was a constraint on the output length when each model generated the Wikipedia content. The human evaluation only compares two alternative models for preference, which is not enough to support this claim. I have updated my scores as authors clarified most of my concerns.
Accept (Poster). rating score: 7. rating score: 7. rating score: 7. <BRK>This paper introduces a method for learning new tasks, without interfering previous tasks, using conceptors. This method originates from linear algebra, where a the network tries to algebraically infer the main subspace where previous tasks were learned, and make the network learn the new task in a new sub space which is "unused" until the present task in hand. They compare the method to EWC with the same architecture.<BRK>After a brief and clear introduction to conceptors and their application to ridge regression, the authors explain how to inject conceptors into Stochastic Gradient Descent and finally, the real innovation of the paper, into Backpropagation. Follows a section of experiments on variants of MNIST commonly used for continual learning. For example, the main method this article is compared to (EWC) had a very strong section on Reinforcement learning examples in the Atari framework, not only as an illustration but also as a motivation. The numeric examples, although quite toy, provide a clear illustration.<BRK>The paper leaves me guessing which part is a new contribution, and which one is already possible with conceptors as described in the Jaeger 2014 report. Figure (1) in the paper is identical to the one in the (short version of) the Jaeger report but is missing an explicit reference. What I am missing here is a clear indication what is an original contribution of the paper, and what is already possible using the original approach.
Invite to Workshop Track. rating score: 6. rating score: 6. rating score: 6. <BRK>This paper studies the amortization gap in VAEs. Inference networks, in general, have two sources of approximation errors. They consider learning VAEs using two different choices of inference networks with (1) fully factorized Gaussian and (2) normalizing flows. The inference gap is log p(x)   L[q], the approximation gap is log p(x)   L[q^* ] and the amortization gap is L[q^* ]   L[q]. There are several different observations made via experiments in this work but one of the more interesting ones is quantifying that a deep generative model, when trained with a fully factorized gaussian posterior, realizes a true posterior distribution that is (more) approximately Gaussian. Questions:* How did you optimize the variational parameters for q^* and the flow parameters in terms of learning rate, stopping criteria etc. This is not defined previously. FashionMNIST and MNIST are similar in many ways. Overall, I think this paper is interesting and presents a quantitative analysis of where the errors accrue due to learning with inference networks.<BRK>The existence of amortization error is often ignored in the literature, but (as the authors point out) it is not negligible. It has been pointed out before in various ways, however:* Hjelm et al.(2015; https://arxiv.org/pdf/1511.06382.pdf) observe it for directed belief networks (admittedly a different model class). * The ladder VAE paper by Sonderby et al.(2016, https://arxiv.org/pdf/1602.02282.pdf) uses an architecture that reduces the work that the encoder network needs to do, without increasing the expressiveness of the variational approximation. Since these earlier results existed, and approximation amortization decomposition is fairly simple (although important!), the main contributions of this paper are the empirical studies. This idea has been around for a long time (although I’m having a hard time coming up with a reference). If you trust the AIS estimate, then the result will be the actual KL divergence between the FFG and the true posterior.<BRK>* EDIT: Increased score from 5 to 6 to reflect improvements made in the revision. 2. the "approximation gap": the part of the slack due to using a restricted parametric form for the posterior approximation. I enjoyed reading the paper, but I think its contribution is on the small side for a conference paper. The main limitation of the proposed method of analysis I think is that the two parts of the inference gap are not really separable: Because the VAE encoder is trained jointly with the decoder, the different limitations of the encoder and decoder all interact. I think these experiments should be elaborated on.
Reject. rating score: 6. rating score: 6. rating score: 6. <BRK>Though the results on ODP dataset is very strong, the experiments still leave something to be desired. The results of MACH would be more significant if comparison to these or some of these baselines can be available. The idea is novel as far as I know. One unique advantage of the proposed method is that, during inference, the likelihood of a given class can be computed very efficiently without computing the expensive partition function as in traditional softmax and many other softmax variants.<BRK>It would be important to clarify if the method can be used on multi label datasets or not, if so, it needs to be evaluated on the XML datasets [3]. For a fair comparison, the proposed method must be compared against these datasets. This is related to the theme of extreme classification but the setting is restricted to that of multi class classification instead of multi label classification.<BRK>Results are provided on the Imagenet and ODP datasets with comparisons to regular one vs all classifiers and tree based methods for speeding up classification. A better graph to include would be a time vs accuracy trade off for all methods. Is there any setting where the proposed approach reaches 95% of the baseline accuracy? Negatives  Hierarchical softmax is one of more standard techniques that has been very effective at large scale classification.
Reject. rating score: 2. rating score: 3. rating score: 3. <BRK>The experiments are somewhat interesting but they appear rather preliminary. Also formally the paper is not in good shape.<BRK>The presentation of the paper could be significantly improved. The motivation is difficult to grasp and the contributions do not seem compelling. Could the authors clarify that? However, experiments are performed on MNIST, CIFAR100, a curve fitting problem and a presumably synthetic 2D classification problem. Performing the analysis on computer vision datasets such as ImageNet would be more compelling to back the statement in section 4.<BRK>The paper contains ONLY 4 references. From the paper, it is difficult to understand the contributions. From the ones listed in Section 1, it seems that most of the contributions were shown in the original ResNet and DenseNet papers. Could the authors provide more details on this? In order to claim this, I would encourage the authors to run tests on a CV benchmark dataset (e. g. ImageNet)
Reject. rating score: 4. rating score: 4. rating score: 7. <BRK>This paper collects a cloze style fill in the missing word dataset constructed manually by English teachers to test English proficiency. Experiments are given which are claimed to show that  this dataset is difficult for machines relative to human performance. The dataset seems interesting but I find the empirical evaluations unconvincing.<BRK>The authors claim that this cloze dataset is a more challenging dataset since CLOTH requires a deeper language understanding and wider attention span. I don t think the language model is a robust baseline for this paper. Are these improvements mostly in grammar?<BRK>This paper presents a new dataset for cloze style question answering. 2) The authors then show that human performance on this dataset is much higher than the performance of LSTM based and language model based baselines; this is in contrast to existing cloze style datasets where neural models achieve close to human performance. 3) The authors hypothesize that this is partially explained by the fact that neural models do not make use of long distance information. 3) The paper is clear, well written, and is easy to read. Cons:1) Overall, some of the claims made by the paper are not fully supported by the experiments.
Reject. rating score: 2. rating score: 2. rating score: 6. <BRK>* PAPER SUMMARY *This paper proposes a siamese net architecture to compare text in different languages. Proceedings of the Learning to Rank Challenge. * REVIEW SUMMARY * This paper is hard to read and need proof reading by a person proficient in English. The experiments are extremely limited, on a toy task. No other baseline than (Mueller and Thyagarajan, 2016) is considered. It is hard to find positive points that would advocate for a presentation at ICLR. For instance, this book will be a good read.<BRK>The motivation of the problem and applications are presented well, especially for news recommender systems. How does your approach compare to these other approaches besides the Siamese LSTM baseline? The technical contributions are also not novel or strong  to make the paper convincing. Comparison against other relevant baselines (including other cross lingual retrieval approaches) is missing.<BRK>In the Following, pros and cons of the paper are presented. Pros 1.Many real world applications. 2.Simple architecture and can be reproduced (if given enough details.) 2.Baseline is not strong. 6.How are the similarity assessments made in the gold standard dataset. 2.In Section 2.2, it denote that  as the figure demonstrates . No reference to the figure. The paper requires more experimental analysis to judge the significance of the approach presented.
Reject. rating score: 3. rating score: 4. rating score: 5. <BRK>This function is learned from expert demonstrations. The cost of visiting a state is then defined as the distance between that state and the predicted state according to the learned function. This reward is then used in standard RL algorithms to learn to stick close to the expert s demonstrations. While the experiments clearly show the advantage of this method, this is hardly surprising or novel. This paper uses a three layered fully connected auto encoder (which is not that deep of a model, btw) for the same purpose. The expert may choose to go to terrible states with the hope of getting to a highly rewarding state in the future.<BRK>The authors propose to solve the inverse reinforcement learning problem of inferring the reward function from observations of a behaving agent, i.e.trajectories, albeit without observing state action pairs as is common in IRL but only with the state sequences. But, apparently, this is not the problem the authors actually solve, according to eq.1 5.Particularly eq.1 is rather peculiar. This is not learning the underlying reward function. One could also argue that the manuscript would profit from a better theoretical analysis of the IRL problem, say:C. A. Rothkopf, C. Dimitrakakis. Preference elicitation and inverse reinforcement learning.<BRK>This paper uses inverse reinforcement learning to infer additional shaping rewards from demonstrated expert trajectories. The key distinction from many previous works in this area is that the expert’s actions are assumed to not be available, and the inferred reward on a transition is assumed to be a function of the previous and subsequent state. I am also uncertain of the robustness of the proposed approach when the learning agent goes beyond the distribution of states provided by the expert (where the inferred reward model has support). One way to address this would be to use the expert trajectories to infer not only a reward function, but also an initial state value function (trained on the expert trajectories with the inferred reward).
Accept (Poster). rating score: 7. rating score: 6. rating score: 5. <BRK>This paper suggests a simple yet effective approach for learning with weak supervision. Overall, I liked the paper. Can this approach be applied to semi supervised learning? Is there a reason to assume the fidelity scores computed by the teacher would not improve the student in a self training framework? Is it clear that this step in needed? Can you add an additional variant of your framework when the fidelity score are  computed by the teacher when trained from scratch? using different architecture than the student? I went over the authors comments and I appreciate their efforts to help clarify the issues raised.<BRK>This algorithm can be useful because correct annotation of enough cases to train a deep model in many domains is not affordable. The authors propose to combine a huge number of weakly annotated data with a small set of strongly annotated cases to train a model in a student teacher framework. The paper is well written, easy to follow, and have good experimental study. To me, it seems that the algorithm first tries to learn a good representation for which lots of data is needed and the weak training data can be useful but why not combing with the strong data? Why not learning the representation using an unsupervised learning method (unsupervised pre training)? This should be at least one of the baselines. (4) the idea of using surrogate labels to learn representation is also not new.<BRK>The student (deep neural network) model will learn from both labelled and unlabelled training data with the labels provided by the teacher (Gaussian process) model. The teacher also supplies an uncertainty estimate to each predicted label. How about the heuristic function? This is used for learning initial feature representation of the student model. On a related remark, the nice side effect is not right as it was emphasized that data points with a high quality label will be limited.
Reject. rating score: 4. rating score: 5. rating score: 7. <BRK>Gaps are only in between forward and backward, and between iterations. The main idea of this paper is to optimize the parallelization scheme of CNN, which is independent of the framework used.<BRK>Although parallelism across each of the individual dimensions has been explored (batch parallel is most common and best supported, height and width is discussed at least in the DistBelief paper), automatically exploring this to find the most efficient approach is new. While the approach is interesting, its impact also depends on the speedup on the common hardware used today.<BRK>Whereas the majority of work on parallel or distributed deep learning partitions training over bootstrap samples of training data (called image parallelism in the paper), DeePa is able to additionally partition the operations over image height, width and channel.
Invite to Workshop Track. rating score: 6. rating score: 5. rating score: 5. <BRK>* A very recent paper by Krishnan et al.(https://arxiv.org/pdf/1710.06085.pdf, posted to arXiv days before the ICLR deadline) is probably closest; it also examines using iterative optimization (but no learning to learn) to improve training of VAEs. I think this is good and potentially important work, although I do have some questions/concerns about the results in Table 1 (see below). Some more specific comments:Figure 2: I think this might be clearer if you unrolled a couple of iterations in (a) and (c). Why not have mu_{q,t+1} depend on sigma_{q,t} as well as mu_{q,t}? Table 1: These results are strange in a few ways:* The gap between the standard and iterative inference network seems very small (0.3 nats at most).<BRK>The resulting iterative inference framework is applied to a couple of small datasets and shown to produce both faster convergence and a better likelihood estimate. From a novelty standpoint though, the paper is not especially strong given that it represents a fairly straightforward application of (Andrychowicz et al., 2016). Likewise for Fig.6, where faster convergence over traditional first order methods is demonstrated; but again, these results are entirely expected as this phenomena has already been well documented in (Andrychowicz et al., 2016).<BRK>This paper proposes an iterative inference scheme for latent variable models that use inference networks. Instead of using a fixed form inference network, the paper proposes to use the learning to learn approach of Andrychowicz et. al.The parameter of the inference network is still a fixed quantity but the function mapping is based on a deep network (e.g.it could be RNN but the experiments uses a feed forward network). My main issue with the paper is that it does not do a good job justifying the main advantages of the proposed approach. I am supposing this is at the test time. It is not clear exactly when this will be useful. In summary, the paper needs to do a better job in justifying the advantages obtained by the proposed method.
Reject. rating score: 3. rating score: 4. rating score: 5. <BRK>The paper is not anonymized.<BRK>(!)The (ensemble) white box attack is effective but the results are not compared to anything else, e.g.it could be compared to (vanilla) FGSM nor C&W.<BRK>Overall, the results are interesting but the technique seems relatively incremental. Confusing as to what is being referred to where it currently is written.
Accept (Poster). rating score: 7. rating score: 7. rating score: 5. <BRK>In this paper, the authors present a second order method that is specifically designed for RNNs. The paper overall is well written and I enjoyed reading the paper. The main idea of the paper is to extend the existing kronecker factored algorithms to RNNs. Even though the gain in the convergence speed is not very impressive and the algorithm is quite complicated and possibly not very accessible by deep learning practitioners, I still believe this is a novel and valuable contribution and will be of interest to the community.<BRK>Summary of the paper The authors extend the K FAC method to RNNs. Due to the nature of BPTT, the approximation that the activations  a  are independent from the gradients  Ds  doesn t hold anymore and thus other approximations have to be made. They present 3 ways of approximating F, and show optimization results on 3 datasets, outperforming ADAM in both number of updates and computation time. Significance: This paper aims at helping with the optimization of RNNs and is thus and important contribution for our community. In figure 1, how does it compare to Adam instead of SGD? 3.How does it compare to different reparametrization techniques, such as Layer Normalization or Batch Normalization?<BRK>This paper extends the Kronecker factor Approximate Curvature (K FAC) optimization method to the setting of recurrent neural networks. What is a good finite sample size in which the assumption that the training sequences are infinitely long is reasonable in practice? The authors compare their method to SGD on two language modeling tasks and against Adam for learning differentiable neural computers. The main issue that I have with this paper is the lack of theoretical justification or even intuition for the many approximations carried out in the course of approximating the Fisher information matrix. This quality of this paper would be greatly  strengthened if it had some bounds on approximation error or even empirical results testing the validity of the assumptions in the paper.
Reject. rating score: 3. rating score: 4. rating score: 6. <BRK>The ambition of this paper is to address multi view object recognition and the associated navigation as a unified reinforcement learning problem using a deep CNN to represent the policy. Multi view recognition and active viewpoint selection have been studied for more than 30 years, but this paper ignores most of this history. This is strictly weaker than active viewpoint selection. It is not clear what objective function the system is intended to optimize.<BRK>Paper Summary: The paper proposes an approach to perform object classification and changing the viewpoint simultaneously. Paper Strength: The idea of combining active vision with object classification is interesting. It is not clear how the hierarchical soft max layers have been implemented. This should be clarified in the rebuttal.<BRK> The paper proposes LSD NET, an active vision method for object classification. The main contribution of the paper is a hierarchical action space that distinguishes between camera movement actions and classification actions. This hierarchical action space results in reduced bias towards classification actions.
Reject. rating score: 4. rating score: 5. rating score: 7. <BRK>In this paper authors are summarizing their work on building a framework for automated neural network (NN) construction across multiple tasks simultaneously. This is especially the case for the transfer learning task. Authors cite the Neural Architecture Search (NAS) framework as an example of such a framework that yields better results compared to NN architectures configured by humans. In its current state and format the major issue with this work is the lack of more in depth performance analysis which would help the reader draw more solid conclusions about the generalization of the approach.<BRK>The paper proposes an extension of the Neural Architecture Search approach, in which a single RNN controller is trained with RL to select hyperparameters for child networks that must perform different tasks. The paper is very well written, and based on a simple but interesting idea. It also deals with core issues in current machine learning. It would be good to see other experiments where there is less of a trivial structure distinguishing tasks, to check if transfer helps. Finally, it s not clear to me why the multitask architecture was used in the experiment even when no multi task pre training was conducted: shouldn t the simple neural architecture search method be used in this case?<BRK>Pros1.The problem of neural architecture design is important and interesting. It is reasonable to introduce task embeddings into NAS to obtain a generalization model for multiple tasks. 2.The experiments are not sufficient. 3.In order to demonstrate the effectiveness of the idea of multi task learning and task conditioning in MNMS, some architecture search methods for single task should be conducted for comparison. For instance, NAS on SST or the Spanish language identification task should be compared. The most important contribution of this paper is to search neural models for multiple tasks simultaneously using task conditioning.
Reject. rating score: 4. rating score: 5. rating score: 6. <BRK>This paper considers the problem of generating differentially private datasets using GANs. I didn t find a formal proof of the privacy guarantee in the paper. The authors say that the privacy guarantee is based on the moments accountant method, but I couldn t find the proof anywhere. Thus the paper seems to be incomplete.<BRK>About the presentation:  As a paper proposing a differentially private algorithm, detailed and formal analysis of the privacy guarantees is essential to convince the readers. The idea of building a differentially private GAN and generating differentially private synthetic data is very interesting. There is also room for improvement in the presentation and clarity of the paper.<BRK>1.The technical novelty of the paper is not that high. I may be missing something. The information (in the form of gradients) is passed from the discriminator on to the generator via a differentially private channel (using Gaussian mechanism).
Accept (Poster). rating score: 7. rating score: 7. rating score: 7. <BRK>The goal of this work is to infer weights of a neural network, constrained to a discrete set, where each weight can be represented by a few bits. This is a quite important and hot topic in deep learning. The paper presents ternary quantization for LeNet 5 (MNIST) and DenseNet 121 (CIFAR 10).<BRK>This paper presents Variational Network Quantization; a variational Bayesian approach for quantising neural network weights to ternary values post training in a principled way.<BRK>The paper is of good quality, clearly written with an ok level of originality and significance. Pros:1.Demonstrates a sparse Bayesian approach that scales.
Reject. rating score: 4. rating score: 4. rating score: 4. <BRK>The manuscript advocates to study the weight sharing in a more systematic way by proposing ArbNets which defines the weight sharing function as a hash function. In the experimental section, it is interesting to see how different hash function with different level of entropy can affect the performance of neural nets.<BRK>This paper proposes a general framework for studying weight sharing in neural networks. Otherwise, the significance of the results is not clear.<BRK>The experimental section is week, with only mnist and cifar results it s not convincing to the community whether this method is general.
Accept (Poster). rating score: 8. rating score: 6. rating score: 5. <BRK>SUMMARY The model evaluates symbolic algebraic/trigonometric equalities for validity, with an output unit for validity level at the root of a tree of LSTM nodes feeding up to the root; the structure of the tree matches the parse tree of the input equation and the type of LSTM cell at each node matches the symbol at that node in the equation: there is a different cell type for each symbol. I believe continuous values like "0.29" in the preceding expressions are encoded as the literal value of a single unit (feeding into an embedding unit of type W_{num}), whereas the symbols proper (including digit numerals) are encoded as 1 hot vectors (feeding into an embedding unit of type W_{symb}). Performance was also tested on a fill in the blank test, where a symbol from a correct equation was removed and all possible replacements for that symbol with expressions of depth up to 2 were tested, then ranked by the resulting validity score from the model. WEAKNESSES* The title is misleading; "blackbox function evaluation" does not suggest what is intended, which is training on function evaluation equations. The actual work is more interesting than what the title suggests. * The biggest performance boost (roughly 15%) arises from use of the tree structure, which is given by an oracle (implemented in a symbolic expression parser, presumably): the network does not design its own example dependent structure. If the solver’s performance is that weak, why is it used during generation of training data to determine the validity of possible equations? * Given that this is a conference on "learning representations" it would have been nice to see at least a *little* examination of the learned representations. It would be easy to do some interesting tests. How do the embeddings of different integers provided by W_{sym} relate to one another? * We are told only that the "hidden dimension … varies"; it would be nice if the text or results tables gave at least some idea of what magnitude of embedding dimension we’re talking about. * It is good to see the power of training the same system to learn the semantics of functions from the equations they satisfy AND from the values they produce. * The inclusion of decimal expansion equations for relating numeral embeddings to number embeddings is clever.<BRK>Two digits? p3: "division because that they can"  > "division because they can"p4 Fig.1: Is there a reason 1 is represented as 10^0 here? In my opinion, the main contribution of this paper is this potentially useful dataset, as well as an interesting way of representing fixed precision floats. StrengthsThe authors present a new datasets for mathematical identities. p5: I don t understand why function evaluation results in identities of depth 2 and 3. Is it both or one of them? p6: The modules "symbol" and "number" are not shown in the figure. For instance, the authors use the TreeNN model from that paper as a baseline but the EqNet model is not mentioned at all. The obvious question is whether EqNets can be applied to the two tasks (verifying and completing mathematical equations) and if so why this has not been done. On page 6, it is unclear to me what "handles […] function evaluation expressions". p8: Do you have an intuition why prediction function evaluations for "cos" seem to plateau certain points? Furthermore, it would be interesting to see what effect the choice of non linearity on the output of the TreeLSTM has on how accurately it can learn to evaluate functions. What are the limitations of the architecture? TreeLSTMs have been shown to outperform Tree NN s in various prior work. Minor CommentsAbstract: "Our framework generalizes significantly better" I think it would be good to already mention in comparison to what this statement is. p3: Could you expand on "mathematical equation verification and completion […] has broader applicability" by maybe giving some concrete examples. p3 Eq.5: What precision do you consider?<BRK>This paper proposes a model that predicts the validity of a mathematical expression (containing trigonometric or elementary algebraic expressions) using a recursive neural network (TreeLSTM). The idea is to take the parse tree of the expression, which is converted to the recursive neural network architecture, where weights are tied to the function or symbol used at that node. The overall approach described in this paper is technically sound and there are probably some applications (for example in online education). Another strange thing is that the accuracies reported do not seem to divide the reported test set sizes (see, e.g., the depth 1 row in Table 2). It would also be good to discuss the Sympy baseline a bit — being symbolic, my original impression was that it would be perfect all the time (if slow), but that doesn’t seem to be the case, so some explanation about what exactly was done here would help. For the extrapolation evaluation — evaluating on deeper expressions than were in the training set — I would have liked the authors to be more ambitious and see how deep they could go (given, say, up to depth 3 training equations).
Reject. rating score: 3. rating score: 3. rating score: 4. <BRK>What does 45% accuracy actually mean? See any of the numerous good systems described in literature. Section 4.1: "During training the output from the VI module is fed to an action selection function to compare those results against actions chosen in the training data. ": What is the action selection function? Section 2: "Imitation learning for navigation has been studied by other groups as well (Silver et al.2010)": That particular paper is about using inverse optimal control (aka inverse reinforcement learning) and not imitation learning for first learning a good terrain cost function and then using it in a receding horizon fashion. 2.Why are the authors choosing to do essentially behavior cloning as opposed to imitation learning? It is not obvious where it is from the field arrows.<BRK>I think at least inverse RL should be mentioned and the relationship to it should be discussed in the paper (which it is currently not). Furthermore, one input layer corresponds to a one hot encoding of the goal, which is also a correct output of the reward function. 1.I have a difficult time identifying the (large enough) novel contribution. The second experiment doesn t have a baseline to compare the results against so it is hard to judge how well the algorithm performs.<BRK>"Learning to search: Functional gradient techniques for imitation learning." Unfortunately, I believe the original VIN paper also failed to articulate the precise advantages of VIN over this prior work—which is not to say there are none, but it is clear that VINs applied to problems as simple as the one considered here have real competitors in prior work. Again, this raises the question of how the proposed method compares to MaxEnt IOC, both theoretically and experimentally. The experiments are also a bit lacking in a few ways.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. <BRK>This paper provides an interesting analysis of the importance sampled estimate of the LL bound and proposes to use Jackknife to correct for the bias. The experiments show that the proposed method works for model evaluation and that computing the correction is archivable at a reasonable computational cost. It also contains an insightful analysis.<BRK>[After author feedback]I think this is an interesting paper and recommend acceptance. Starting by studying the bias of the IWAE bound for approximating log marginal likelihood, the authors propose to make use of debiasing techniques to improve the approximation. * It could be worth mentioning that the JVI objective function is now no longer (I think?) a lower bound to the log evidence.<BRK>The authors analyze the bias and variance of the IWAE bound from Burda et al.(2015), and with explicit formulas up to vanishing polynomial terms and intractable moments. The paper is well written and offers an interesting combination of ideas motivated from statistical analysis. They apply it for training and also as an evaluation method to assess the marginal likelihood at test time. It would be useful if the authors could clarify these details.
Invite to Workshop Track. rating score: 7. rating score: 5. rating score: 3. <BRK>The paper presents an off policy actor critic method for learning a stochastic policy with entropy regularization. It is a direct extension of maximum entropy reinforcement learning for Q learning (recently called soft Q learning), and named soft actor critic (SAC). Or, is the instability from elsewhere?<BRK>I think the paper could be organized in a more balanced way  by providing a more detailed description and analysis of the numerical results, especially given the fact that in my opinion this is the main strength of the paper. For instance "Prior deep RL methods based on this framework have been formulated as either off policy Q learning, or on policy policy gradient methods" not true, e.g., look at  Deepmind AI recent work:  https://arxiv.org/abs/1704.04651. Originality and novelty:I think much of the ideas considered in this paper is already explored in previous work as it is acknowledged  in the paper. However some of the techniques such as the way the policy is  represented  and the way the policy gradient formulation is approximated  seems to be novel in the context of Deep RL though again these ideas have been explored in the literature of control and RL extensively.<BRK>However, the current paper has some correctness issues, is missing some related work and lacks a clear statement of innovation. In particular, the connection to the work by Haarnoja is unclear. There is this statement: “Although the soft Q learning algorithm proposed by Haarnoja et al.(2017) has a value function and actor network, it is not a true actor critic algorithm: the Q  function is estimating the optimal Q function, and the actor does not directly affect the Q function except through the data distribution. Further, there is a missing connection to the paper “Guided policy search”, Levine and Koltun. That work is different, but a discussion should nonetheless be included about connections. The experimental results also appear to have some correctness issues. 1.For the claim that the algorithm does better, this is also difficult to gauge because the graphs are unclear.
Reject. rating score: 1. rating score: 2. rating score: 3. <BRK>The paper presents a method for feature projection which uses a two level neural network like structure to generate new features from the input features. The weights of the NN like structure are optimised using a genetic search algorithm which optimises the cross validation error of a nearest neighbor classifier. There is nothing interesting or novel about the paper. The poor language and presentation does not help in clearing that, as it does not help in general.<BRK>The main issue is the scientific quality. What the authors call "intelligent mapping and combining system" for the proposed system is simply a fully connected neural network. Such systems have been largely investigated in the literature. The use of genetic algorithms has also been considered. Moreover, mapping features to some appropriate feature space has been widely investigated, including the choice of appropriate mapping. There are many spelling and grammatical errors.<BRK>This paper proposes using a feedforward neural network (FFNN) to extract intermediate features which are input to a 1NN classifier. The parameters of the FFNN are updated via a genetic algorithm with a fitness function defined as the error on the downstream classification, on a held out set. – The paper’s main contribution seems to be a neural network with a GA optimization for classification that can learn “intelligent combinations of features”, which can be easily classified by a simple 1NN classifier. There also exists prior work on optimizing neural nets via GA (Leung, Frank Hung Fat et al., IEEE Transactions on Neural networks 2003). – The use for a genetic algorithm for optimization is not motivated, and no comparison is made to the performance and efficiency of other approaches (like standard backpropagation).
Reject. rating score: 4. rating score: 5. rating score: 5. <BRK>The paper proposes a generalization of an algorithm by Yin et al.(2017), which performs SGD with adaptive batch sizes. The present paper generalizes the algorithm to SGD with momentum. The identification of the "batch size boom" is interesting. Given the incremental process, I find the presentation unnecessarily involved, and experiments not convincing enough. Page 5 provides pseudocode for the proposed algorithm. Do the authors understand this behavior?<BRK>The authors propose extending the recently proposed adaptive batch size approach of Yin et al.to an update that includes momentum, and perform more comprehensive experiments than in the Yin et al.paper validating their approach. The extension to the momentum case (section 3) seems to be more or less straightforward, but I do have a question about equation 15: am I misreading this, or is it saying that the variance of the momentum update \mathcal{P} is the same as the variance of the most recent minibatch?<BRK>Overall, the manuscript is well organized and written with solid background knowledge and results to support the claim of the paper. All the compared methods adopt a fixed batch size, but the proposed method uses an adaptive batch size. The paper can compare the proposed method with adaptive batch size in intuitive settings, e.g., small batch size in the beginning of training and larger batch size later. However, the test accuracy is not shown.
Accept (Poster). rating score: 8. rating score: 7. rating score: 7. <BRK>In this paper, the authors propose a novel method for generating adversarial examples when the model is a black box and we only have access to its decisions (and a positive example). 3.2 attempts this slightly by using an image in the class, but is less clear for something like FaceID. The paper is clearly written. Would like to see more analysis of this.<BRK>What this paper does well:  Suggests a type of attack that hasn t been applied to image classifiers  Proposes a simple heuristic method for performing this attack  Evaluates the attack on both benchmark neural networks and a commercial system Problems and limitations:1. Thus, there s an implicit claim of generality that is not supported. I suggest rewording some of the mentions of adversarial. 3.Ignorance of prior work. Thus, "decision based attacks" are not new, although the algorithm and experiments in this paper are.<BRK>The authors propose one specific attack instance out of this class of attacks. The paper is rather well written and structured. The text was easy to follow. I suggest that a self contained description of the problem setting (assumptions on attacker and defender; aim?) As in many DL papers these days, there really isn t any math in it worth a mention; so no reason here to say anything about mathematical soundness. Apart from some minor weaknesses in the presentation that can be easily fixed for the camera ready, this is a nice, fresh paper, that might spur more attacks (and of course new defenses) from the new class of decision based attacks.
Accept (Poster). rating score: 7. rating score: 6. rating score: 4. <BRK>Where the paper could perhaps be slightly improved is writing clarity. The paper under review overcomes this drawback by estimating the continuity on perturbations of the real samples. Together with various technical improvements, this leads to state of the art practical performance both in terms of generated images and in semi supervised learning. Wasserstein gan.<BRK>This would strengthen the paper quite a bit. The results are very good, as noticed by the comments, the fact that the method is also less susceptible to overfitting is also an important result, though this might be purely due to dropout. If the authors fix the theoretical analysis and add evidence in a larger dataset I will raise the score. Figure 4 is thus relevant, but the semi supervised results of MNIST or the sample quality experiments give hardly any evidence to support the method.<BRK>The author can submit it to the workshop and prepare for next conference. Firstly, although the SSL results are very good, it is guaranteed the proposed GAN is good [Dai & Almahairi, et al.2017].Secondly, the paper missed several details, such as settings, model configuration, hyper parameters, making it is difficult to justify which part of the model works. Original review: This paper presented an improved approach for training WGANs, by applying some Lipschitz constraint close to the real manifold in the pixel level. Updates: thanks for the authors  hard rebuttal work, which addressed some of my problems/concerns.
Reject. rating score: 2. rating score: 3. rating score: 4. <BRK>This paper proposes a new character encoding scheme for use with character convolutional language models. This is a poor quality paper, is unclear in the results (what metric is even reported in Table 6), and has little significance (though this may highlight the opportunity to revisit the encoding scheme for characters).<BRK>The manuscript proposed to use prefix codes to compress the input to a neural network for text classification. There are several issues with the paper and I cannot recommend acceptance of the paper in the current state. It looks like it is not finished. As a reviewer my impression (which is subjective) is that the authors used difficult language to make the manuscript look more impressive.<BRK>The paper proposed to encode text into a binary matrix by using a compressing code for each word in each matrix row. The idea is interesting, and overall introduction is clear. The results using this particular encoding are not better than any previous work. The depth of the network is only 5, even with many layers listed in table 5. It uses 1 D convolution across the word dimension (inferred from the feature size in table 5), which means the convolutional layers learn intra word features for the entire text but not any character level features.
Reject. rating score: 6. rating score: 6. rating score: 6. <BRK>the paper is clearly written; it works on a popular idea of combining graphical models and neural nets. the authors claim that the previous art directly integrate neural networks into the graphical models as components, which renders the models uninterpretable. however, it is unclear, following the same logic, why the proposed method has interpretability. the other idea is to go context specific. but it could be helpful for the readers to understand if the idea in this work is fundamentally different from these previous ideas from amortized inference.<BRK>The article "Contextual Explanation Networks" introduces the class of models which learn the intermediate explanations in order to make final predictions. The experimental part of the paper considers variety of experiments, including classification on MNIST, CIFAR 10, IMDB and also some experiments on survival analysis. I should note, that the quality of the algorithm is in general similar to other methods considered (as expected). It would be interesting to know the explanation. Also, it would be interesting to have more examples of qualitative analysis to see, that the learned explanations are really useful.<BRK>The paper is clearly written and might inspire follow up work in other applications. The description of related work is sparse (beyond a derivation of an equivalence with LIME in some settings, explained in the appendix).
Reject. rating score: 4. rating score: 5. rating score: 6. <BRK>The authors discuss this in the end of Section 3, but a more careful comparison is needed. The experimental results are pretty limited and lack detailed quantitative evaluation, which makes it harder to compare the performance of the proposed variant to existing algorithms. Overall, I think that the idea is interesting, but the paper needs more work and does not meet the ICLR acceptance bar. It would be useful to write down the actual loss function so that it s easier to compare with other GAN variants.<BRK>Can the authors comment on this? The approach suggested in this paper models the output of the discriminator using a mixture of two Gaussians (one for “fake” and the other for “not fake”). Relation to instance noise and regularization techniques: Instance noise is a common trick being used to train GANs, see e.g.http://www.inference.vc/instance noise a trick for stabilising gan training/This also relates to some regularization techniques, e.g.Roth et al., 2017 that provides a regularizer that amounts to convolving the densities with white Gaussian noise. Comparison to existing baselines: Given that the paper addresses the stability problem, I would expect some empirical comparison to at least one or two of the stability methods cited in the introduction, e.g.Gulrajani et al., 2017 or Roth et al., 2017.<BRK>Could the authors provide more details on choosing the generator loss function and why Eq.(12) provides satisfying results in practice? Why would a bi modal distribution be meaningful? The performance of variance regularization scheme was evaluated on the CIFAR 10 and CelebA data.
Reject. rating score: 4. rating score: 5. rating score: 7. <BRK>This paper baffles me. To strike the right balance between pretension and accuracy, I would suggest substituting the word "stochastic"  everywhere "variational" is used. In this sense the architecture should really be seen as a single model with different noise levels at alternating steps. The authors make a comparison to AlphaGo Zero s use of self play, but here the weak and strong generators are on the same side of the game, and because there are no game rules provided beyond "reproduce the training set", there is no possibility of discovery beyond what is human provided, contrary to the authors  claim. Third, the total absence of mathematical notation made it hard in places to follow exactly what the models were doing. As it was the only example shown, it s difficult to evaluate their claim that this is a general method for improving variety without sacrificing quality.<BRK>The paper proposed a method that tries to generate both accurate and diverse samples from RNNs. I like the basic intuition of this paper, i.e., using mistakes for creativity and refining on top of it. I think my biggest concern is that the method was only tested on a single dataset hence it is not convincing enough.<BRK>Overall the paper is good: good motivation, insight, the model makes sense, and the experiments / results are convincing. I would like to see some evidence though that the strong generator is doing exactly what is advertised: that it’s learning to clean up the mistakes from variation. The writing grammar quality fluctuates. Because people can do it, ML should be able to? Could this be a simultaneous variety + quality reward signal? P7:I like the score scheme introduced here. If so, did you account for this in your experiments?
Reject. rating score: 3. rating score: 5. rating score: 6. <BRK>This paper presents a comparative study on second order optimization methods for CNNs. However, I think there are important issues about the paper:1) The paper is not very well written. 2) For such a comparative study, the number of algorithms and the number of datasets are quite little.<BRK>A good experimentation of second order methods for training large DNNs in comparison with the popular SGD method has been lacking in the literature. This paper tries to fill that gap. Though there are some good experiments, I feel it could have been much better and more complete. The second order methods are much slower (in time) than SGD. One obvious question I have is: could it be that, methods such as SHG which have much less noise in them, have poor generalization properties? Overall, I like the attempt of exploring second order methods, but it could have come out a lot better.<BRK>The paper presents several interesting empirical findings, which will no doubt lead to follow up work. 1.There is no complexity comparison, e.g.what is the complexity for a single step of different method. 2.Relatedly, the paper reports the performance over epochs, but it is not clear what "per epoch" means for 2nd order methods. Details on implementations of 2nd order methods are important here. Assuming using the batch loss, I suspect the training curve will be very noisy (depending on how large the batch size is). Here are other points. The choices made were reasonable, but 2nd order methods are not as trivial to implement as SGD, and it isn t clear whether they have really "spanned the space" of second order methods3.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. <BRK>In this paper, the authors show how a Deep Learning model for sea surface temperature prediction can be designed to incorporate the classical advection diffusion model. This seems to be inconsistent. minor comments:  on page five in the last paragraph there is a left parenthesis missing in the inline formula nabla dot w_t(x))^2. between 2 [!]<BRK>The paper ‘Deep learning for Physical Process: incorporating prior physical knowledge’ proposesto question the use of data intensive strategies such as deep learning in solving physical inverse problems that are traditionally solved through assimilation strategies. It is not clear how the modellearnt on one particular type of data transpose to other data sequences. All in all the paper is very clear and interesting.<BRK>The authors use deep learning to learn a surrogate model for the motion vector in the advection diffusion equation that they use to forecast sea surface temperature.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>**Paper Summary**    This paper proposes a self supervised method, RotNet, to learn effective image feature from images by predicting the rotation, discretized into 4 rotations of 0, 90, 180, and 270 degrees. They achieve an ImageNet and PASCAL classification score as well as an object detection score higher than other baseline methods. The proposed self supervised task is simple and intuitive. In particular, evaluating the learned representations on the task of image semantic segmentation is essential in my opinion.<BRK>Strengths:* Very simple strategy for unsupervised learning of deep image features. * The representation learned from unlabeled data is shown to yield strong results on image categorization (albeit mostly in scenarios where the unsupervised features have been learned from the *same* dataset where classification is performed   more on this below). * The image rotations are implemented in terms of flipping and transposition, which do not create visual artifacts easily recognizable by deep models. This is a useless application scenario.<BRK>The paper proposes a simple classification task for learning feature extractors without requiring manual annotations: predicting one of four rotations that the image has been subjected to: by 0, 90, 180 or 270º. It would be important to come up with tasks for which there is not one ImageNet, then techniques such as that proposed in the paper would be necessary.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>This paper investigates an expressive power of the tensor train decomposition relative to the CP decomposition. The result of this paper is interesting and also important from a viewpoint on analysis for the tensor train decomposition. However, I think there is some room for improvement on this paper. Comments are as follow. C2.I wonder that the experiment for comparing TT decomposition and CP decomposition is fair, since CP decomposition does not have the universal approximation property. Such experiments will improve persuasiveness of the main result presented in this paper.<BRK>In this paper, the expressive power of neural networks characterized by tensor train (TT) decomposition, a chain type tensor decomposition, is investigated. It is proved that the space of TT type networks with rank O(r)  can be complex as the same as the space of CP type networks with rank poly(r). The contribution is clear and it is distinguished from previous studies. Though I enjoyed reading this paper, I have several concerns. It seems the comparison with Tucker type representation makes much more sense because it has universality. Due to the gaps, the analysis used in this paper seems not applicable to RNNs. If this is true, the story of this paper is somewhat misleading.<BRK>The authors of this paper first present a class of networks inspired by various tensor decomposition models. * For both TT networks and CP networks, there are multilinear interaction of the inputs/previous hidden states. I also did not find the experiments illuminating. In addition, I would like to see the performance of RNNs and MLPs with the same number of units/rank in order to validate the analogy between these networks. Minor comments: * In p7 it would help readers to point out that B^{(s,t)} is an algebraic subset because it is an intersection of M_r and the set of matrices of rank at most q^{d/2}   1, which is known to be algebraic.
Reject. rating score: 2. rating score: 4. rating score: 9. <BRK>This paper proposes a variation to the familiar AdaGrad/Adam/etc family of optimization algorithms based a gradient magnitude normalization. I feel this paper would be much stronger focusing extensively on one or two small problems and models, providing insight into how normalization affects optimization, rather than chasing state of the art numbers on a variety of datasets and models. ## Pros ##The paper is easy to follow. I appreciate the variety in experimental setups. The authors provide a proof of convergence for the AdaGrad variant on convex functions. From the empirical side, the authors compare the proposed optimizers on many datasets and models, but concerningly only using the baselines  default hyperparameters. In addition, different tasks use different optimizers, which strikes me as odd, and no error bars are added to any plots. From the theoretical side, the authors show a convergence bound that is minimized when the number of blocks is one. This, however, is not what the authors use in experiments, and no reasoning about the choice of blocks   network layers is given. I suggest keeping only the vanilla method analyzed in this paper, or that the second method be better motivated.<BRK>This paper proposes a family of first order stochastic optimization schemes based on (1)  normalizing (batches of) stochastic gradient descents and (2) choosing from a step size updating scheme. The authors argue that iterative first order optimization algorithms can be interpreted as a choice of an update direction and a step size, so they suggest that one should always normalize the gradient when computing the direction and then choose a step size using the normalized gradient. The authors also test their proposed method on many datasets, which is appreciated. The proposed technique is reasonable on its own, but the empirical results do not come with any measure of statistical significance. Moreover, some algorithms were used as benchmarks on some datasets but not others. For a primarily empirical paper, every state of the art algorithm should be used as a point of comparison on every dataset considered. The theoretical result in the convex setting is also not data dependent, despite the fact that it is the normalized gradient version of AdaGrad, which does come with a data dependent convergence guarantee. Because of these points, I do not feel the quality, originality, and significance of the work to be high enough to merit acceptance. p. 2: "we hope the resulting methods can benefit from both techniques". What reason do you have to hope for this? Arbitrarily mixing the two doesn t seem to be theoretically well motivated. It would be great to provide some intuition for this. p. 3: There should be a reference for RMSProp. Why is layer parametrization (and later on normalization) a good way idea? p. 4: "For all the algorithms, we use their default settings." This seems insufficient for an empirical paper, since most problems often involve some amount of hyperparameter tuning. How sensitive is each method to the choice of hyperparameters? What about the impact of initialization? Apart from the typos, are these parameters chosen from the training set or the test set? However, I still do not feel that the paper is up to the standards of the conference.<BRK>Beyond exploring the "vanilla" normalized gradient algorithm they also consider adaptive versions, i.e., methods that employ per block (adaptive) learning rates using ideas from AdaGrad and Adam. Finally, the authors provide a theoretical analysis of NG with adaptive step size, showing convergence guarantees in the stochastic convex optimization setting. I find this paper both very interesting and important. The normalized gradient method was previously shown to overcome some non convex phenomena which are hurdles to SGD, yet there was still the gap of  combining NG with methods which automatically tune the learning rate. In light of their experiments it seems like AdamNG and NG should be adopted as the new state of the art methods in deep learning applications. Additional comments: In the experiments the authors use the same parameters as is used by Adam/AdaGrad, etc..Did the authors also try to fine tune the parameters of their NG versions? It will be useful if the authors can provide some intuition about why is the learning rate  chosen per block for NG? If so, what is the behaviour that they see. 1 and compare to AdaGrad.
Accept (Poster). rating score: 8. rating score: 7. rating score: 5. <BRK> I think title is misleading, as the more concise results in this paper is about linear networks I recommend adding linear in the title i.e.changing the title to … deep LINEAR networks  Theorems 2.1, 2.2 and the observation (2) are nice! I’m a bit puzzled by Theorems 4.1 and 4.2 and why they are useful.<BRK>In particular:  in the case of deep linear networks, they characterize whether a critical point is a global optimum or a saddle point by a simple criterion. The technical proofs of the paper are in appendices, making the main text very smooth.<BRK>The paper gives sufficient and necessary conditions for the global optimality of the loss function of deep linear neural networks. The paper is an extension of Kawaguchi 16. I think the main technical concerns with the paper is that the technique only applies to a linear model, and it doesn t sound the techniques are much beyond Kawaguchi 16.
Reject. rating score: 4. rating score: 4. rating score: 5. <BRK>UPDATED REVIEW:I have checked all the reviews, also checked the most recent version. I like the new experiments, but I am not impressed much with them to increase my score. The assumption about the variance is fixing my concern, but as you have pointed out, it is a bit more tricky :) I would really suggest you work on the paper a bit more and re submit it. In this paper, authors provided a convergence analysis of Sign SGD algorithm for non covex case. Then define the function f(x)   E [ f_i(x)  ]. where B is a random variable which has value "a" with probability 0.5 and value "0" with probability 0.5. Hence, even in this simple example, one can show that this assumption is violated unless $\sigma   \infty$. In terms of experiments, I like the discussion about escaping saddle points, it is indeed a good discussion. However, it would be nicer to have more numerical experiments.<BRK>The stated Theorem 1 is incorrect. Even if the stated result was correct, it presents much worse rate for a weaker notion of convergence. As far as I can see, Theorem 1 should depend on 4th root of N_K, the last (omitted) step from the proof is done incorrectly. This makes it much worse than presented. Also, it is lot more worse than just d times:3. In particular, the one for signSGD is the weaker notion   squared L1 norm can be d times bigger again. If this is not the case for some reason, more detailed explanation is needed. Other than that, the paper contains several attempts at intuitive explanation, which I don t find correct. Experiments are also inconclusive, as the plots show convergence to significantly worse accuracy than what the models converged to in original contributions.<BRK>Dear Authors,After reading the revised version I still believe that the assumption about the gradients + their variances to be distributed equivalently among all direction is very non realistic, also for the case of deep learning applications. I think that the direction you are taking is very interesting, yet the theoretical work is still too preliminary and I believe that further investigation should be made in order to make a more complete manuscript. $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ The paper explores SignGD   an algorithm that uses the sign of the gradients instead of actual gradients for training deep models. Yet, as the authors themselves mention, the dependence on the dimension is much worse compared to SGD. Moreover, the authors do not mention that if the noise variance does not scale with the dimension (as is often the case), then the convergence of SGD will not depend on the dimension, while it seems that the convergence of signGD will still depend on the dimension. In order to do so, the authors should make a more extensive experimental study.
Reject. rating score: 5. rating score: 5. rating score: 5. <BRK>This paper describes techniques for training semantic segmentation networks. The GAN and the semi supervised training scheme appear to be largely independent. If the authors cannot demonstrate an improvement with these components, their ideas are unlikely to be adopted in state of the art semantic systems, which do use these components and are doing fine. That is, add a discriminator network that decides whether each pixel in the label map belongs to a real label map or not.<BRK>This paper proposed an approach for semi supervised semantic segmentation based on adversarial training. Built upon a popular segmentation network, the paper integrated adversarial loss to incorporate unlabeled examples in training. The proposed method achieved consistent improvement over existing state of the art on two challenging segmentation datasets. However, the outputs from the discriminator indicate whether its inputs are from ground truth labels or model predictions, and may not be directly related to ‘correctness’ of the label prediction. For instance, the proposed semi supervised learning strategy based on Eq.(5) may be suffered by noise outputs from the discriminator in early training stages.<BRK>The paper presents an alternative adversarial loss function for image segmentation, and an additional loss for unlabeled images. The experimental section is extensive, and shows a significant improvement over prior state of the art in semi supervised learning. Unfortunately, it is unclear what exactly lead to this performance increase. Is it a better baseline model?
Accept (Poster). rating score: 8. rating score: 7. rating score: 7. <BRK>The proposed model achieves SOTA on a char level language modeling task and is demonstrated to yield reasonable tree structures. Comment: I like the paper a lot.<BRK>The model reaches state of the art level performance in language modeling and the performance on unsupervised parsing task (which is a by product of the model) is also quite promising.<BRK>The results reported on the language modeling experiments are strong. The model is evaluated on three language modeling benchmarks: character level PTB, word level PTB and word level text8.
Invite to Workshop Track. rating score: 7. rating score: 6. rating score: 4. <BRK>19 benchmarks are proposed, small data sets are expanded to a large, standardized data set and it is explored how to apply new RL techniques effectively for molecular design. on the positive side:The paper is well written, quality and clarity of the work are good. on the negative side:There is no new novel contribution on the methods side.<BRK>Originality and significance: The conclusion from the experiments could be valuable to the broader sequence generation/synthesis field, showing that many current RL techniques can fail dramatically. The paper does not provide any theoretical contribution but nevertheless is a good application paper combining and comparing different techniques.<BRK>The paper proposes a set of benchmarks for molecular design, and compares different deep models against them. Variances should be added, and preferably more than 3 initialisations used. The paper s title also does not seem to fit: this feels like a survey paper, which is not reflected in the title.
Reject. rating score: 4. rating score: 4. rating score: 5. <BRK>This paper proposes a new method for reverse curriculum generation by gradually reseting the environment in phases and classifying states that tend to lead to success. The introduction should be more clear with regard to the assumptions. Second, the paper states that the assumption "when resetting, the agent can be reset to any state" can be satisfied in problems such as real world robotic manipulation. This is not correct. It would be preferable to use the standard terminology of "keyframe". 2012In summary, I think this paper has a number of promising ideas and experimental results, but given the significant issues in clarity and significance to real world problems, I don t think that the current version of this paper is suitable for publication in ICLR. More minor feedback on clarity and correctness:  Abstract: "Deep RL algorithms have proven successful in a vast variety of domains"   This is an overstatement.<BRK>It is nice to see that the authors compare their method with alternative approaches. The approach of this paper seems severely severely limited by the assumptions made by the authors, mainly assuming a deterministic environment, known goal states and the ability to sample anywhere in the state space. Results are pure performance results.<BRK>The authors present a new method for doing reverse curriculum training for reinforcement learning tasks with deterministic dynamics, a desired goal state at which reward is received, and the ability to teleport to any state. This covers a number of important cases of interest, including all simulated domains, and a number of robotics applications. The initial set of states used is close to the desired state goal. During the training in a single phase, the algorithm uses a shaping reward (the tendency) which is based on a binary classifier that predicts if it will be possible to reach the goal from this state. I’m not yet convinced about this method for the desired setting in terms of significance and quality.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>This paper introduces an iterative method to build hierarchical policies. The experimental results are a bit confusing. One of the limitation of the method is that appropriate subgoals and curriculum must be hand designed.<BRK>For example, Figure 2 contains V(s,g), but that is only defined much later on. Review:Overall, I found the paper to be generally well written and the core idea to be interesting. Can you clarify this sentence? I think the paper could also benefit from at least one more experiment in a different, harder domain.<BRK>The method is well ablated; Figures 4 and 5 answered most questions I had while reading. Providing this reward requires knowing the full state of the world. There are no comparisons to other multitask or hierarchical methods. The stages are ordered in a semantically meaningful order (find is the first stage), but the authors claim that the order is arbitrary. Clarity:Although the method is complicated, the paper was understandable.
Accept (Poster). rating score: 7. rating score: 7. rating score: 5. <BRK>The paper takes an interesting approach to solve the existing problems of GAN training, using Coulomb potential for addressing the learning problem. My understanding and validity of the proof is still an educated guess. Overall, I think this is a good paper that provides a novel way of looking at and solving problems in GANs.<BRK>Nonetheless, I think this is an important step forward in improving GANs, and should be accepted for publication. This is a good, well written paper. Overall, it presents an interesting approach to overcome the mode collapse problem with GANs. The image samples presented   although of high variability   are not of very high quality, though, and I somewhat disagree with the claim that "Coulomb GAN was able to efficiently learn the whole distribution" (Sec 3.1).<BRK>In this paper, the authors interpret the training of GAN by potential field and inspired from which to provide new training procedure for GAN. The model collapsing is not just because loss function in training GAN. 1, I agree that the "model collapsing" is due to converging to a local Nash Equilibrium. In sum, this paper provides an interesting perspective modeling GAN from the potential field, however, there are several issues need to be addressed.
Reject. rating score: 6. rating score: 6. rating score: 6. <BRK>In particular, the use of LSTMs helps take into account interdependencies between pattern labels. Strengths:  The paper is very well written. Contextualization with respect to previous work is adequate. Novelties are clearly identified by the authors. Quantitative improvement with respect to the state the art. Weaknesses:  The paper does not introduce strong technical novelties   mostly, it seems to apply previous techniques to the medical domain. It could have been interesting to know if there are more insights / lessons learned in this process. This could be of interest for a broader audience. The impact of the proposed approach on medical diagnostics is unclear. Also, it could be interesting also to discuss how the results in Table 2 and 3 compare to human classification capabilities, and if that performance would be already enough for building a computer aided diagnosis system.<BRK>This paper presents an impressive set of results on predicting lung pathologies from chest x ray images. Authors present two architectures: one based on denseNet, and one based on denseNet + LSTM on output dimensions (i.e.similar to NADE model), and compare it to state of the art on the chest x ray classification. The only issue with this paper is, that their proposed method, in practice is not tractable for inference on estimating probability of a single output, a task which would be critical in medical domain. Considering that their paper is titled as a work to use "dependencies" among labels, not being able to evaluate their network s, and lack of interpretable evaluation results on this model in the experiment section is a major limitation. On the other hand, there are many alternative models where one could simply use multi task learning and shared parameter, to predict multiple outcomes extremely efficiently.<BRK>Well written and appropriately structured. This study is (unfortunately) typical in that it focuses on and provides detail of the technical modeling issues, but ignores the medical applicability of the model and results. This is exemplified by the fact that the data set is hardly described at all and the 14 abnormalities/pathologies, the rationale behind their choice and the possible interrelations and dependencies are never described from a medical viewpoint. If I were a medical expert, I would not have a clue about how these results and models could be applied in practice, or about what medical insight I could achieve. The bottom line seems to be: "my model and approach works better than the other guys  model and approach", but one is left with the impression that these experiments could have been made with other data, other problems, other fields of application and they would not have not changed much
Accept (Poster). rating score: 8. rating score: 8. rating score: 6. <BRK>Both of these cases lead to singularities in the Hessian matrix, and this work includes a number of experiments showing the effect of skip connections on the Hessian during training. This is a significant and timely topic.<BRK>They then demonstrate that skip connections can reduce the prevalence of these singularities, and thus speed up learning. The analysis is thorough: the authors explore alternative methods of reducing the singularities, and explore the skip connection properties that more strongly reduce the singularities, and make observations consistent with their overarching claims. I have no major criticisms. One suggestion for future work would be to provide a procedure for users to tailor their skip connection matrices to maximize learning speed and efficacy.<BRK>This paper proposes to explain the benefits of skip connections in terms of eliminating the singularities of the loss function. I would love to see more solid theoretical discussion to justify the hypothesis proposed in this paper.
Accept (Poster). rating score: 7. rating score: 7. rating score: 3. <BRK>The novelty of the approach in context of prior visual navigation and landmark based robotics research is the hybrid algorithmic and learned approach that builds a graph purely from observations without ego motion or direct state estimation. The results while not thorough do support the ability of the method effectively plan on novel and unseen environments. This method’s memory architecture can be considered to be nonparametric, and, while different from the proposed method, this similarity merits additional discussion and consideration for empirical comparison. Some of the the details for the baseline methods are unclear. The reviewer wonders whether the baselines may be disadvantaged compared to the proposed method. The authors should consider bootstrapping the baseline methods with similar experience.<BRK>The paper is not without merit: the idea of storing experiences in a graph and in using landmark similarity rather than metric embeddings is interesting. This paper presents a hybrid architecture that mixes parametric (neural) and non parametric (Dijkstra s path planning on a graph of image embeddings) elements and applies it to navigation in unseen 3D environments (Doom). This is NOT a proper navigation agent.<BRK>The agent uses Dijkstra s algorithm to plan a a path through the graph in order to solve the navigation task. There are several major problems with this paper. My overall impression is that the the proposed agent is a nearly hard coded solution (which I think might be the correct approach to such problems), but a poorly implemented one. Specific points: 1 There are only 5 test mazes, and the proposed agent doesn t even solve all of them.
Accept (Poster). rating score: 6. rating score: 6. rating score: 3. <BRK>A predictor is trained on simulated images created with a manually initialized distribution. The paper is well written. The novelty is incremental in most parts, but the overall system can be seen as novel. If the real world data does not cover certain ranges, not because those values are infeasible or infrequent, but just because it so happens that this range was not covered in the data acquisition, the simulation could be used to fill in those ranges. It might be possible in the case of the task at hand, but for more challenging domain adaptation problem it might not be feasible. This would be necessary to prove the benefit of using the back generator + sim trained predictor.<BRK>To trace back, in fact it is helpful to have at least a simple intro/def. * Somehow there is a feeling that the notations in sec.2.1 and sec.2.2 are not well aligned. It is helpful to start providing the math notations as early as sec.2.1, so labels, pseudo labels, the algorithm illustrated in Fig.2 etc. can be consistently integrated with the rest notations. The difference of 0.07/0.20 are not so significant.<BRK>The authors show that the proposed method is able to fully leverage the flexibility of simulators by presenting an improved performance on the gaze estimation task. The proposed method seems to be a direct combination of the CycleGAN and the S+U learning. Here the author apply it by "translating" the the simulated data to real data. Without deeper insights of the proposed method, the novelty of this paper is not sufficient. 3.This work seems closely related to S+U learning. It would be nice to conduct more experiments to show the effect of adding the feature consistent loss.
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. <BRK>1   While data augmentation literature is well acknowledged in the paper, I would also like to see a comment on domain adaptation, which is a very closely related topic and of particular interest to the ICLR community. I therefore am quite confused about the fact that the authors present experiments on classification tasks, with a method that writes for regression.<BRK>* Baseline in which the labels are not mixed, in order to ensure that the gains are not coming from the data augmentation only. Practical contributions: The paper introduces a new technique for training DNNs by forming a convex combination between two training data instances, as well as changing the associated label to the corresponding convex combination of the original 2 labels. The authors show mixup provides improvement over baselines in the following settings:  * Image Classification on Imagenet.<BRK>However, the lack of sufficient theoretical justification is now well complemented by extensive experiments, and it will motivate more theoretical work. The authors cite recent work by DeVries & Taylor (2017) and Pereyra et al.(2017), but the technique of combining multiple samples for data augmentation have been a popular approach.
Reject. rating score: 2. rating score: 5. rating score: 6. <BRK>While the motivation is that classes have different complexities to learn and hence you might want each base model to focus on different classes, it is not clear why this methods should be better than normal boosting: if a class is more difficult, it s expected that their samples will have higher weights and hence the next base model will focus more on them. Experimentally, paper would benefit with better comparisons and studies: 1) state of the art methods haven t been compared against (e.g.ImageNet experiment compares to 2 years old method) 2) comparisons to using normal AdaBoost on more complex methods haven t been studied (other than the MNIST) 3) comparison to simply ensembling with random initialisations.<BRK>This paper applies the boosting trick to deep learning. The proposed algorithm is validated on several image classification datasets. The proposed algorithm is essentially an ensemble algorithm, there exist several works on deep model ensemble (e.g., Boosted convolutional neural networks, and Snapshot Ensemble) should be compared against. 3.In Eq.(3), \tilde{D} is not defined. Typo: In Session 3 Line 7, there is a missing reference.<BRK>In conventional boosting methods, one puts a weight on each sample. The wrongly classified samples get large weights such that in the next round those samples will be more likely to get right. This idea however is difficult to be applied to deep learning with a large amount of data. This paper instead designed a new boosting method which puts large weights on the category with large error in this round.
Accept (Poster). rating score: 7. rating score: 6. rating score: 5. <BRK>That could be a make or break feature of this work. What kind of tuning? Was it  manual, and hence not reproducible? It is refreshing to see an article that does not boast to offer the new "bestest ever" algorithm in town, overcrowding a landscape, but instead tries to prune the tree of possibilities and wading through other people s inflated claims.<BRK>The paper "DEEP BAYESIAN BANDITS SHOWDOWN" proposes a comparative study about bandit approaches using deep neural networks. Uncertainty does not consider the neural representation of inputs ? Also, what does not help is that it is very hard to conect the names in the result table with the corresponding approaches (some abbreviations are not defined at all   BBBN or RMS for instances).<BRK>This paper presents the comparison of a list of algorithms for contextual bandit with Thompson sampling subroutine. The main paper + appendix are clearly written and easy to understand. There is a lack of novelty of this study.
Invite to Workshop Track. rating score: 5. rating score: 4. rating score: 3. <BRK>I suggest to conduct transfer learning studies in the similar settings.<BRK>What kind of ensembling did the authors chose for those experiments?<BRK>Nothing is novel in the deep models (CNN and TreeLSTM).
Reject. rating score: 4. rating score: 4. rating score: 4. <BRK>The paper presents a combination of evolutionary computation (EC) and variational EM for models with binary latent variables represented via a particle based approximation. Genomes have a linear order but in the case of 2D images you use it is not obvious how that should be mapped to 1D. There are no empirical comparisons with state of the art, only between different variants of the proposed method.<BRK>I guess this istechnically different, but it is already well known that any E step methodwhich monotonically improves the free energy is a valid algorithm. ## Review summaryOverall, the paper makes an interesting effort to tightly integrateexpectation maximization (EM) training algorithms with evolutionary algorithms(EA). Itsplain text definition is: "the logarithm of the joint probability wheresummands that do not depend on the state s have been elided". This EA is the core contribution,since the work on Trucated Posteriors has appeared before in the literature.<BRK>This paper proposes an evolutionary algorithm for solving the variational E step in expectation maximization algorithm for probabilistic models with binary latent variables. The applicability of the method is quite limited. There is no comparison with other methods such as Monte carlo sampling. It is not clear how computationally Evolutionary EM performs comparing to Variational EM algorithm and there is neither experimental results nor analysis for the computational complexity of the proposed model.
Accept (Poster). rating score: 7. rating score: 6. rating score: 6. <BRK>originality: this paper is originalsignificance: this paper is significantPROS  Using ECC theory for reducing the memory footprint of a neural network seems both intuitive and innovative, while being grounded in well understood theory. The authors address a consequence of current approaches to neural network pruning, i.e., the high cost of sparse matrix index storage. How difficult is it to tune the pruning algorithm hyper parameters?<BRK>There was a time about 2 or 3 years ago when sparse matrix approaches seemed to have a lot of promise, but I get the impression that a lot of people have moved on. Towards the end of the paper I see mention of a 38.1% reduction in matrix size.<BRK>The paper proposes VCM, a novel way to store sparse matrices that is based on the Viterbi Decompressor. Only a subset of sparse matrices can be represented in the VCM format, however, unlike CSR format, it allows for faster parallel decoding and requires much less index space. Therefore the reported 35 50% compression of the index storage is not very significant.
Reject. rating score: 2. rating score: 3. rating score: 4. <BRK>This appears to be a very straightforward application of existing techniques and networks. Quality: Given the task that the authors are trying to solve, the approach seems reasonable. Clarity: The paper appears quite clearly written for the most part. Originality & Significance: Unless I am missing something important, or misunderstanding something, I do not really understand what is significant about this work, and I don t see it as having originality. It would have only added a few characters to the paper to specify the notation here, e.g."Addition(A), Max (X), Min (N), Multiply (M)". The story from the figures seems to be that the authors  system works beats a CNN when there are very few examples. But significance of this is not really discussed in any depth other than being mentioned in corresponding places in the text, i.e.it s not really the focal story of the text. Seems like a reasonable application of pre trained nets to allow solving a different visual problem for which less data might be available. Cons: Unless I am missing an important point, the results are unsurprising, and I am not clear what is novel or significant about them.<BRK>The paper presents an interesting model to reuse specialized models trained for perceptual tasks in order to solve more complex reasoning tasks. However, the paper evaluates the proposed model in artificial tasks with limited reasoning difficulty: the tasks can be solved with simpler baseline models. The paper argues that the advantage of the proposed approach is data efficiency, which seems to be a side effect of having pre trained modules rather than a clear superior reasoning capability. The paper discusses other advantages of the model, but these are not tested or evaluated either. A more convincing experimental setup would include complex reasoning tasks, and the evaluation of all the aspects mentioned as benefits: computational time, flexibility of computation, better accuracy, etc.<BRK>The quality of the experimental evaluation is not great. The contribution section is not giving any credit to Zaremba et al.(2016) whereas this work is at best a variant of that approach. Pros  It is confirmed that noisy operators (in the form of neural networks) can be used on the visual arithmetic taskCons Not very novel Experimental evaluation is wantingThe focus of this paper is on integrating perception and reasoning in a single system. This interface terminology for POMDPs was actually introduced in:J.  Schmidhuber. Another notable difference is that the proposed system is trained with Actor Critic as opposed to Q learning, but this is not further elaborated on by the authors. p 4: authors write: "One obvious point of comparison to the current work is recent research on deep neural networks designed to learn to carry out algorithms on sequences of discrete symbols. I presume that the LSTM uses this operator to evaluate whether the current entry contains a digit or an operator. In all cases the proposed method requires fewer samples to achieve the final performance, although given enough samples all of the CNNs will solve the tasks. The proposed system incorporates pre trained modules, whose training samples are not taken into account. Although the visual arithmetics on a 2x2 grid is a toy task it would at least be nice to evaluate some of the policies that are learned by the LSTM (as done by Zaremba) to see if some intuition can be recovered from there. Proper evaluation on a more complex environment (or at least on that does not assume discrete grids) is much desired.
Reject. rating score: 4. rating score: 4. rating score: 7. <BRK>Detecting and exploiting "critical structures" in graphs for graph classification is indeed something that is missing in previous work. It is very difficult to understand what it is that you want to express with the above sentence. Unfortunately, I find it difficult to understand what this means. This is at the moment also the crucial shortcoming of the paper. Also, in the learning for graph structured data, the variance can be quite high and providing the stddev would at least indicate how significant the improvements are.<BRK>Learning graph representations is an important task and fits well into ICLR. The paper pursues interesting ideas and shows promising experimental results. Unfortunately, this connection is neither made clear in the discussion of related work, nor does the experimental evaluation include a comparison. In particular, the paper mentions that Ego CNN is similar to the Weißfeiler Lehman (WL) algorithm. Detecting critical substructures is an explicit focus of the paper. For instance, precisely why can t Neural Fingerprint detect critical structures? [1] https://en.wikipedia.org/wiki/Neighbourhood_(graph_theory)[2] Kipf et al."Semi supervised classification with graph convolutional", 2017.<BRK>3.There seems to be a mistake in Figure 5 with the top neighborhood in white4. 5.The visualization of critical structures are very helpful. However, it might be better to look into structures in high level layers for truly global signatures. This is especially the case for the reddit dataset, where visualizations at the node and edge level creates hairballs.
Reject. rating score: 4. rating score: 4. rating score: 5. <BRK>Much of the paper remains unchanged from the time of my previous review. ], one could refine the base segmentation CNN as well.<BRK>The experimental evidence is insufficient.<BRK>Hence the main focus of the paper (image segmentation or DAE conditioning) remains vague.
Reject. rating score: 4. rating score: 4. rating score: 4. <BRK>Positive:  Interesting approach  Hardware validation (the RL field needs more of this!) Why did you pick this task? It s fine to only validate on a single task in hardware, but why not include additional simulation results (e.g.double pendulum)? The one from Section 5.1?<BRK>The proposed technique is of modest contribution and the experimental results do not provide sufficient validation of the approach. There are a few notational issues in the paper that should be addressed. The authors mislabel the value function V as the  action value, or Q function. The action value function is action dependent where the value function is not.<BRK>Clarity The paper is clear in general. OriginalityThe novelty of the method is limited. The simulated results are very limited. Cons:  Limited simulation results.
Reject. rating score: 5. rating score: 5. rating score: 6. <BRK>SUMMARYThe major contribution of the paper is a generalization of lambda returns called Confidence based Autodidactic Returns (CAR), wherein the RL agent learns the weighting of the n step returns in an end to end manner. These CARs are used in the A3C algorithm.<BRK>This paper is below the threshold because there are issues with the : 1) motivation, 2) the technical details, and (3) the empirical results.<BRK>Nonetheless, I believe that the paper represents an interesting and worthy submission to the conference. But the exact method is difficult to piece together from what is written.
Reject. rating score: 3. rating score: 4. rating score: 7. <BRK>This paper proposes a new training method for graph convolutional networks. The experimental results look interesting. However, this paper has some issues. There are some undefined or multi used notations. For instance, sigma is used for two different meanings: an activation function and variance. Some details that need to be explained are omitted. Why should we make the variance from dropout sigma^2? Proposition 1 is wrong. First, \|A\|_\infty should be max_{ij} |A_ij| not A_{ij}. When A [1 1] and B is the transpose matrix of A, \|AB\|_\infty  2 and \|A\|_\infty \|B\|_\infty   1. I cannot believe the proof of Theorem 2.<BRK>The paper proposes a method to speed up the training of graph convolutional networks, which are quite slow for large graphs. I was hoping the method would also include importance sampling, but it doesn’t. There are some odd assumptions (independent Gaussian activations in a graph convolution embedding?!?) Clarity: It is well written and the reader is able to follow most of the details. Significance: Not very significant. The problem of computing better averages for a specific problem (neighbor embedding average) seems a bit too narrow. Theorem 2 is not too useful, unfortunately: Showing that the estimated gradient is asymptotically unbiased with learning rates approaching zero over Lipchitz functions does not seem like an useful statement.<BRK>Existing training algorithms for graph convolutional nets are slow. This paper proposes two key ideas   preprocessing and better sampling based on historical activations. The value of these ideas is demonstrated very well via theoretical and experimental analysis. The role of preprocessing to add efficiency is important here. It would be useful to know how much the training speed will suffer if we use three or more layers, say, via one more experiment on a couple of key datasets. This will help see the limitations of the ideas proposed in this paper. While I can see that this is done to make the analysis simple, how well does this analysis correlate with what is seen in practice?
Accept (Poster). rating score: 6. rating score: 6. rating score: 5. <BRK>This paper proposes an end to end trainable attention module, which takes as input the 2D feature vector map and outputs a 2D matrix of scores for each map.<BRK>This paper proposed an end to end trainable hierarchical attention mechanism for CNN. Overall, the idea presented in the paper is simple yet solid, and showed good empirical performance.<BRK>Moreover, [G] introduces a method of using an attention model for segmentation, while the paper does not contain any discussion about it. Strength:  It is interesting idea to use the global feature as a query in the attention mechanism while classification tasks do not naturally involve a query unlike other tasks such as visual question answering and image captioning. Image captioning with semantic attention.
Reject. rating score: 4. rating score: 4. rating score: 6. <BRK>In this paper, new layer architectures of neural networks using a low rank representation of tensors are proposed. The main idea is assuming Tucker type low rank assumption for both a weight and an input. [Clarity]The paper is well written and easy to follow. How is the proposed method different from them? Also, the "end to end" feature is repeatedly emphasized in the paper, but I don t understand its benefit. [1] Tai, Cheng, et al."Convolutional neural networks with low rank regularization."<BRK>This paper is well written and easy to read. However, I cannot find a strong or unique contribution from this paper. Main questionWhy authors focus on the combination of the methods? Both of the two methods can perform independently. Minor questionThe performance of the tensor contraction method depends on a size of tensors.<BRK>This paper incorporates tensor decomposition and tensor regression into CNN by replacing its flattening operations and fully connected layers with a new tensor regression layer. Overall, this paper is easy to follow. Cons: Q1: Can the authors discuss the computational time of the proposed tensor regression layers and compare it to that of the baseline CNN? The tensor regression layer is computationally more expensive than the flattening operations in original CNN. Q3: There are a few typos in the current paper. For example,(1) In the “Related work“ paragraph on page 2, “Lebedev et al.(2014) proposes…” should be “Lebedev et al.(2014) propose…”. Many other references have the same issue.
Reject. rating score: 3. rating score: 4. rating score: 6. <BRK>(Summary)This paper is about learning a representation with curriculum learning style minibatch selection in an end to end framework. 2.The experiments show almost no discernable practical gains over  random  baseline which is the baseline for random minibatch selection. (Cons)1.The method lacks algorithmic novelty and the exposition of the method severely inhibits the reader from understand the proposed idea.<BRK>While the idea is novel and I do agree that I have not seen other works along these lines there are a few things that are missing and hinder this paper significantly. 1.There are no quantitative numbers in terms of accuracy improvements, overhead in computation in having two networks. Authors should be motivated to run the large scale experiments.<BRK>The authors purpose a method for creating mini batches for a student network by using a second learned representation space to dynamically selecting  examples by their  easiness and true diverseness . The work presented is novel but there are some notable omissions:    there are no specific numbers presented to back up the improvement claims; graphs are presented but not specific numeric results  there is limited discussion of the computational cost of the framework presented   there is no comparison to a baseline in which the additional learning cycles used for learning the embedding are used for training the student model.
Reject. rating score: 3. rating score: 6. rating score: 7. <BRK>Finally, the authors have admirably attempted a thorough comparison with existing work, in the related work section, but this section takes up a large chunk of the paper at the end, and again I would have preferred this section to be much shorter and more concise.<BRK>As R1 says, a *ACL short paper would be more appropriate. It seems misleading to claim that your CNN is modeled after AdaSent, as that model uses a number of layers that varies with the length of the sentence (and differs from yours in a few other less important ways). Please clarify this or remove it.<BRK>Sec.3:Section 3 does not add much to the paper. So all the words can be predicted all at once with a fixed maximum sentence length. The authors  method is better on SUBJ by 0.7 and better on MPQA by 0.5.
Reject. rating score: 3. rating score: 5. rating score: 6. <BRK>The focus of the paper is independent component analysis (ICA) and its nonlinear variants such as the post non linear (PNL) ICA model. The primary idea of the paper is to use the Wasserstein distance as an independence measure of the estimated source coordinates, and optimize it in a neural network (NN) framework. Although finding novel GAN applications is an exciting topic, I am not really convinced that ICA with the proposed Wasserstein GAN based technique fulfills this goal. In other words, estimating the joint dependence of the source coordinates is not necessary; it is worthwhile to avoid it. 5)Section 3.1: This section is devoted to generating samples from the product of the marginals, even using separate generator networks. ii) The proposed method gives pretty comparable results to the chosen baselines (fastICA, PNLMISEP) on the selected small dimensional tasks. Nonparametric divergence: Estimation with applications to machine learning on distributions.<BRK>The paper proposes a GAN variant for solving the nonlinear independent component analysis (ICA) problem. The method seems interesting, but the presentation has a severe lack of focus. First, the authors should focus their discussion instead of trying to address a broad range of ICA problems from linear to post nonlinear (PNL) to nonlinear. Fully general nonlinear ICA is ill posed, as shown already by Darmois (1953, doi:10.2307/1401511). There are an infinite number of nonlinear ICA solutions   which one is the proposed method going to return and why is that relevant? One idea for evaluation: comparison with ground truth makes sense for PNL, but not so much for general nonlinear because of unidentifiability.<BRK>The key idea of adversarial training is adapted in this context as comparing samples from the joint distribution and the product of the marginals. Two methods are proposed for drawing samples from the products of marginals. The approach is demonstrated in the solution of both linear and non linear ICA problems. There is no analysis and the paper is somewhat anecdotal. The sampling from product distribution method is somewhat obvious. Is this due to nonlinear mixing? Figure 1 may be misleading as h are not defined
Accept (Oral). rating score: 8. rating score: 7. rating score: 6. <BRK>The paper considers a problem of adversarial examples applied to the deep neural networks. It turns out that there is a well studied concept in the literature capturing the desired intrinsic dimensionality: it is called the local intrinsic dimensionality (LID, Definition 1) .<BRK>The authors clearly describe the problem being addressed in the manuscript and motivate their solution very clearly. Is this assuming that the "initial training set" which is used to obtain the "pre trained DNN" free of adversarial examples?<BRK>This paper tried to analyze the subspaces of the adversarial examples neighborhood. More specifically, the authors used Local Intrinsic Dimensionality to analyze the intrinsic dimensional property of the subspaces. The characteristics and theoretical analysis of the proposed method are discussed and explained. This paper helps others to better understand the vulnerabilities of DNNs.
Accept (Poster). rating score: 8. rating score: 8. rating score: 6. <BRK>The problem is an interesting one, the overall approach makes sense, it is clear the authors have done a very substantial  amount of work, and very diligently so (well done!), some of the ideas are interesting and seem creative, but I am not sure I understand the glue of the details, and that might be very important here in order to assess it effectively. In principle, this kind of example is great, and more of these would be very useful in this paper.<BRK>The paper comprises several ideas to study the continual learning problem. It would have been interesting to evaluate the algorithm on more complex tasks, and how these parameters affect the learning. Third, the authors introduce another module to learn how to switch from task to task in a dynamical way. The main concern with this paper is about its length.<BRK>The authors propose a kind of framework for learning to solve elemental tasks and then learning task switching in a multitask scenario. This necessarily introduces a number of Overall, I am not sure what I have learned with this paper. Is the integral in eq.1 appropriate or should it be a finite sum?
Accept (Poster). rating score: 8. rating score: 6. rating score: 3. <BRK>Ideally, a more reasonable form of parameter crossover (see references) could be compared to   the naive one is too much of a straw man in my opinion. To clarify: I think the proposed method is genuinely novel, but a bit of context would help the reader understand which aspects are and which aspects aren’t. A neuroevolution approach to general atari game playing. What is the total computation time of the different variants and baselines? The loss on \pi_S should be made explicit. for Figure 2a it would be clearer to normalize such that 1 is the best and 0 is the random policy, instead of 0 being score 0.  the language at the end of section 3 is very vague and noncommittal   maybe just state what you did, and separately give future work suggestions? I suspect that the results will look different when plotted in different ways, and would enjoy some extra plots in the appendix.<BRK>The authors present an algorithm for training ensembles of policy networks that regularly mixes different policies in the ensemble together by distilling a mixture of two policies into a single policy network, adding it to the ensemble and selecting the strongest networks to remain (under certain definitions of a "strong" network). It seems that for much of the paper, the authors could dispense with the genetic terminology altogether   and I mean that as a compliment. I would perhaps even call this a distillation network rather than a crossover network.<BRK>This paper proposes a genetic algorithm inspired policy optimization method, which mimics the mutation and the crossover operators over policy networks. The title and the motivation about the genetic algorithm are missing leading and improper. The mutation is a method to sample individual independence of the objective function, which is very different with the gradient step. It is straightforward if two policies are to be mixed. Although the mixing method is more reasonable than the genetic crossover operator, it is strange to compare with that operator in a method far away from the genetic algorithm. Another drawback, perhaps resulted from the "genetic algorithm" motivation is that the proposed method has not been well explained. It is problemistic that if the baselines have bad parameters.
Accept (Oral). rating score: 8. rating score: 8. rating score: 1. <BRK>This paper proposes a number of ideas for improving GANs for image generation, highlighting in particular a curriculum learning strategy to progressively increase the resolution of the generated images, resulting in GAN generators capable of producing samples with unprecedented resolution and visual fidelity. Pros:The paper is well written and the results speak for themselves! (Though I think this issue could be addressed a bit better   see below.) The training code and data are released. On a related note, it would be nice if there were more details on the “revised training hyperparameters” improvement ((d) in the ablation study)   which training hyperparameters are adjusted, and how? Overall, this is a well written paper with striking results and a solid effort to analyze, ablate, and quantify the effect of each of the many new techniques proposed. It’s likely that the paper will have a lot of impact on future GAN work.<BRK>The paper describes a number of modifications of GAN training that enable synthesis of high resolution images. The modifications also support more automated longer term training, and increasing variability in the results. Then a layer that refines the resolution is progressively faded in. (More accurately, a corresponding pair of layers, one in the generation and one in the discriminator.) Finally, the paper describes simple schemes for initialization and feature normalization that are reported to be more effective than commonly used initializers and batchnorm. The paper is also very well written. StackGAN: Text to photo realistic image synthesis with stacked generative adversarial networks. I couldn t find a discussion of [Huang et al., CVPR 2017] at all, although it s in the bibliography. These papers don t diminish the submission, but they should be clearly acknowledged and the contribution of the submission relative to these prior works should be discussed.<BRK>This is a violation of double blindness, and in any established double blind conference this would be a clear reason for automatic rejection. In case of ICLR, double blindness is new and not very well described in the call for papers, so I guess it’s up to ACs/PCs to decide. The key contribution is a principled multi scale approach, where in the process of training both the generator and the discriminator are made progressively deeper and operate on progressively larger images. The proposed version of GANs allows generating images of high resolution (up to 1024x1024) and high visual quality. 3) The authors perform an ablation study illustrating the value of each of the proposed modifications. Cons:1) The paper only shows results on image generation from random noise. (This conclusion does not take the anonymity violation into account.Because of the violation I believe the paper should be rejected. The experimental evaluation is thorough, to the degree allowed by the poorly defined task of generating images from random noise. Still, the paper should definitely be accepted for publication. Normally, I would give the paper a rating of 8.
Reject. rating score: 4. rating score: 5. rating score: 7. <BRK>In summary, the paper is based on a recent work Balestriero & Baraniuk 2017 to do semi supervised learning. However, I think there are several main drawbacks, detailed as follows:1. The paper lacks a coherent and complete review of the semi supervised deep learning. As stated in the introduction, the authors think there are several drawbacks of existing methods including "training instability, lack of topology generalization and computational complexity." 3.The experimental results are not so convincing.<BRK>The main contribution of this paper is supposed to be the reconstruction mapping (6) and its effect in semi supervised learning. In experiments, results with beta 1.0 need to be presented to assess the importance of network inversion and the reconstruction loss. It appears sometimes the entropy loss (which is not the main contribution of the paper) is essential to improve performance; this obscures the main contribution.<BRK>This paper proposed a new optimization framework for semi supervised learning based on derived inversion scheme for deep neural networks. The numerical experiments show a significant improvement in accuracy of the approach.
Accept (Poster). rating score: 9. rating score: 6. rating score: 6. <BRK>In the entirely unstructured case, there are strong lower bounds with an exponential dependence on the number of hyperparameters. Based on the sparse and low degree assumption, the paper introduces a new algorithm (called Harmonica) for hyperparameter optimization. The main idea is to leverage results from compressed sensing in order to recover the sparse and low degree function from a small number of measurements (i.e., function evaluations).<BRK>  algorithm 1 has a lot of problem specific hyperparametes that may be difficult to get right. Not clear how important they are  they analyze the simpler (analytically and likely computationally) Boolean hyperparameter case (each hyperparameter is binary). interesting idea but I think it s more theoretical than practical. Feels like a hammer in need of a nail.<BRK>In the presented experiments, the new spectral method outperforms the tool based on the Bayesian optimization, technique based on MAB and random search. However, I find this result to be out of the context with the main theme of the paper. Also the theoretical results are developed for Harmonica 1 while Harmonica q is the main method used in the experiments. One weakness of Harmonica is that it has 6 hyperparameters itself to be tuned. It would be great to see how Harmonica compares with some of the High dimensional Bayesian optimization methods.
Reject. rating score: 4. rating score: 4. rating score: 5. <BRK>The paper is written as a survey paper on literatures related to regularization in deep learning. However, it is not clear from reading the paper where these insights came from. Also there is a mix of trainability and regularization.<BRK>Thus, I think that  the paper is well written in general,  it can be improved (by taking into account several important comments from the Reviewer 2) and served as a review paper in some appropriate journal,  the paper is not suited for ICLR proceedings due to reasons, mentioned above.<BRK>This paper is unusual in that it is more of a review than contributing novel knowledge. It considers a taxonomy of all the ways that machine learning (mostly deep learning) methods can achieve a form of regularization. That does not sound right to me. This is not good for a review and when making recommendations.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. <BRK>Overall this is a good paper and I have little to add to it. Minor: In Fig.1, consider to make “(d)” bold to be consistent with other terms. One of the major conclusions is GANs and VAEs minimize the KL Divergence in opposite directions, thus are exposed to different issues, overspreading or missing modes. Is it possible to revise the title of the paper to specifically reflect the proposed idea?<BRK>Update 1/11/18:I m happy with the comments from the authors. Original review:The paper is overall a good contribution. The motivation / insights are interesting, the theory is correct, and the experiments support their claims. I’m not sure I agree that this is “unifying” GANs and VAEs, rather it places them within the same graphical model perspective. It seems like there should be some mention of this.<BRK>I know this is a kind of open ended question but i think it would greatly aid the reader in understanding the paper if more ‘guidance’ is provided instead of just writing “..by definition this is the posterior.’Q4) In a similar vein to the above. This JSD term acts in a somewhat opposite direction of the KL divergence that we are interested in minimizing. Q5) The authors state that there is ‘strong connections’ between VAEs and GANs.
Reject. rating score: 4. rating score: 5. rating score: 6. <BRK>This paper proposed a procedure for assessing the performance of GANs by re considering the key of observation. It is not easy to follow the main idea of the paper. I suggested that the author should reform the structure, ignore some unrelated content and make the clear claims about the contributions on the introduction part. Regarding the experimental part, it can not make strong support for all the claims. Meanwhile, the results are performed on some specific model configurations (like ResNet) and settings. Therefore, I think the current version is not ready to be published.<BRK>As GANs are minimizing some f divergence measure, the papers remarks that computing a  Wasserstein distance between two distributions made of a sum of Diracs is not a degenerate case and is tractable. A first remark is that the papers does not clearly develop the interest of puting things a trying to reach a treshold of performance in W distance rather than just trying to minimize the desired f divergence. This would be very interesting to have arguments on why being better than the "Dirac estimation" in terms of W2 distance would lead to better performance for others tasks (as other f divergences or image generation). In my opinion the contribution is more about exhibiting a baseline which has to be defeated for any algorithm interesting is learning the distribution in terms of W2 distance. Nevertheless, there is interesting observations in the paper about the sensitivity of this metric to the bluring of pictures. I would enjoyed more digging in this direction. The authors proposes to solve this issue by relying to an embedded space where the L2 distance makes more sense for pictures (DenseNet).<BRK>This would cut down the text a bit to make space for more experiments. why is your definition of generalization that the test set distance is strictly less than training set ? I would think this should be less than or equal   there is a sentence that doesn t end at the top of p.3: "... the original GAN paper showed that [ends here]"   should state in the abstract what your "notion of generalization" for gans is, instead of being vague about it   more experiments showing a comparison of the proposed metric to others (e.g.inception score, Mturk assessments of sample quality, etc.) would be necessary to find the metric convincing   what is a "pushforward measure"? (p.2)   the related work section is well written and interesting, but it s a bit odd to have it at the end.
Accept (Poster). rating score: 7. rating score: 7. rating score: 7. <BRK># Paper overview:This paper presents an analysis of a basket of approaches which together enable one to sample conditionally from a class of generative models which have been trained to match a joint distribution. * The regularisation term L_dist, why this and not log(1 + exp(z    z)) (or many arbitrary others)? Identity preserving  transformations are then introduced within the latent space, which allow the retrospective minimal modification of sample points such that they lie in the conditional set of interest (or not).<BRK>This paper considers the problem of generating conditional samples from unconditional models, such that one can query the learned model with a particular set of attributes to receive conditional samples. The qualitative results presented are compelling and the approaches taken seem reasonable.<BRK>UPDATE: I think the authors  rebuttal and updated draft address my points sufficiently well for me to update my score and align myself with the other reviewers. The paper is also rather sparse in terms of comparison with existing work.
Accept (Poster). rating score: 7. rating score: 7. rating score: 6. <BRK>This paper introduces a new exploration policy for Reinforcement Learning for agents on the web called "Workflow Guided Exploration". The paper is clear, very well written, and well motivated. Exploration is still a challenging problem for RL. The workflows remind me of options though in this paper they appear to be hand crafted. The results suggest that WGE sometimes helps but not consistently.<BRK>This lattice encodes actions which are in some sense similar to those in the demonstration. Comments:  The paper is well written and relevant literature is cited and discussed.<BRK>Specifically, it is applied to the Mini world of Bids benchmark (http://alpha.openai.com/miniwob/). In the results of table 1 and Figure 3.
Reject. rating score: 2. rating score: 3. rating score: 5. <BRK>The authors of the paper advocate injecting noise into the activations of recurrent networks for regularisation. The paper has several issues with respect to the method and related work. More specifically, the reader is left alone with the problem of estimating the gradients in the Bernoulli case, which is an active area of research by itself. The desiderate for noise seem completely arbitrary to me and are not justified. "Practical variational inference for neural networks."<BRK>In order to regularize RNNs, the paper suggests to inject noise into hidden units. Fam.: During all experiments, only Gaussians are used? The described approach seems to be simple. What is missing here are some details on how to compute the gradient for U and Wl.<BRK>The work is written clearly and easy to follow. Overall, the core idea in this work is interesting but underexplored. The authors responded by stating that this was done to achieve a relative comparison. A more interesting comparison, in addition to the ones presented, would be to see how well each method performs while not controlling for hidden layer size. * The regularization is motivated from the point of view of sampling the hidden states to be from the exponential family, but all the experiments provided seem to use a Gaussian distribution. This paper would be strengthened by a discussion and experimentation with other kinds of distributions in the exponential family.
Reject. rating score: 2. rating score: 3. rating score: 5. <BRK>But above all, this paper incredibly lacks of context in both RL and dialogue systems. These are very engineered and cannot easily transfer to other tasks. I think the authors should first read the state of the art in the domain before they suggest new solutions.<BRK>There seems to be some confusion in the notion of state. The RL techniques consist of A3C and DQN. The digital search application is interesting, however a detailed description with comprehensive experiments are needed for the publication of an application paper.<BRK>My concern with this paper is about the experiments that are only based on simulated agents, as it is the case for learning. While it can be questionable for learning (but we understand why it is difficult to overcome), it is very problematic for the experiments to not have anything that demonstrates the usability of the approach in a real world scenario. I have serious doubts about the performances of such an artificially learned approach for achieving real world search tasks.
Reject. rating score: 3. rating score: 3. rating score: 5. <BRK>In the current state, I can t recommend the paper for acceptance. More importantly, the main issue is that this paper might need to highlight the fundamental difference between their proposed method and Inverse Autoregressive Flow (Kingma et al., 2016).<BRK>The difference is that Kingma et al.used 2d convolution (as well a fully connected architectures) where the authors of this paper propose to use 1d convolution. The current version of the paper does not present convincing experimental results.<BRK>The paper proposes to increase the expressivity of the variational approximation in VAEs using a new convolutional parameterization of normalizing flows. Especifically a) is it correct that convolutional normalizing flow trades global connectivity for more expressivity locally?
Reject. rating score: 4. rating score: 4. rating score: 6. <BRK>Summary: The paper is trying to improve Adam based on variance adaption with momentum. Also, to compute \gamma_{t,i}, it requires to compute \nabla f_{t,i}, which is full gradient. According to your rate O(1/t), the complexity is worse than that of gradient descent and SGD as well. Also, theoretical results are not strong enough. I like the idea of the paper but I would love if the author(s) could improve more theoretical results to convince people. Otherwise, the results in this paper could not be considered as good enough. At this moment, I think the paper is still not ready for the publication.<BRK>The paper presents some analysis of the scale invariance and the particular shape of the learning rate used in Adam. Some analysis is provided on these two aspects. The result is mildly interesting, but I fail to see how this would give us a hint of what is happening during the minimization of the non convex objectives for training deep networks. Regarding the experiments, the parameters are chosen to have the best test accuracy, mixing the machine learning problem with the optimization one: it is well known and easy to prove that a worst optimizer can give rise to better test errors. To summarize, I do not think the contributions of this paper are enough to be published in ICLR.<BRK>Stochastic Sign Descent (SSD) and Stochastic Variance Adapted Gradient (SVAG) are inspired by ADAM and studied in this paper, together with momentum terms. Analysis showed that SSD should work better than usual SGD when the Hessian of training loss is highly diagonal dominant. It is intrigued to observe that for MNIST and CIFAR10, SSD with momentum champions with better efficiency than ADAM, SGD and SVAG, while on the other hand, in CIFAR100, momentum SVAG and SGD beat SSD and ADAM. Does it suggest the Hessians associated with MNIST and CIFAR10 training loss more diagonally dominant?
Reject. rating score: 4. rating score: 4. rating score: 5. <BRK>The paper presents a new CNN architecture: CrescendoNet. It does not have skip connections yet performs quite well. The architecture is competitive on SVHN and CIFAR 10 but not on CIFAR 100. To be accepted to ICLR, either outstanding performance or truly novel design principles are required. This is misleading. In fact, the number of layers is linear in the depth of the network.<BRK>In this paper, the authors propose  a new network architecture, CrescendoNet, which is a simple stack of building blocks without residual connections. The experimental results on CIFAR 10, CIFAR 100 and SVHN show that CrescendoNet outperforms most of the networks without residual connections. 6 The model size of CrescendoNet is larger than residual networks with similar performance. Negative points:1 The motivation of the paper is not clear.<BRK>This paper proposes a new convolutional network architecture, which is tested on three image classification tasks. The results seem to be worse than existing networks, e.g., DenseNet (Note that SVHN is no longer a good benchmark dataset for evaluating state of the art CNNs). Why not adopt it in CrescendoNet?
Reject. rating score: 4. rating score: 5. rating score: 5. <BRK>This work proposes a multi task learning framework for the modeling of clinical data in neurodegenerative diseases. Differently from previous applications of machine learning in neurodegeneration modeling, the proposed approach models the clinical data accounting for the bounded nature of cognitive tests scores. The idea of explicitly accounting for the boundedness of clinical scores is interesting, although the assumption of the proposed model is still incorrect: clinical scores are defined on discrete scales. For this reason the Gaussian assumption for the cost function used in the method is still not appropriate for the proposed application. Furthermore, while being the main methodological drive of this work, the paper does not show evidence about improved predictive performance and generalisation when accounting for the boundedness of the regression targets. The loss function of Figure 2.b also does not show a strong improvement across iterations, while indicating a rather large instability of the optimisation procedure. These aspects may be a sign of convergence issues. In particular, due to the nonlinear nature of (1), all the competing linear models are expected to perform poorly in this kind of setting.<BRK>The authors propose a DNN, called subspace network, for nonlinear multi task censored regression problem. Experiments on real data show improvements compared to several traditional approaches. My major concerns are as follows. 1.The paper is not self contained. However, for some key steps in the proof, they refer to other references. If this is due to space limitation in the main text, they may want to provide a complete proof in the appendix. They compare the proposed SN with other traditional approaches on a very small data  set with 670 samples and 138 features. A major merit of DNN is that it can automatically extract useful features. Thus, I would like to see a comparison between SN with vanilla DNN.<BRK>This paper presents a new multi task network architecture within which low rank parameter spaces were found using matrix factorization. The assumption that a low rank parameter space exists among tasks rather than original feature spaces is not new and widely used in literature. 2.The proof part(Section 2.2) can be extended with more details in Appendix. In Section 4.2, the real dataset is rather small thus the results on this small dataset were not convincing enough. SN model outperforms the state of the art with only small margin. 8.The performance on One Layer Subspace Network (with only the input features) could be added. Conclusion:Though with a quite novel idea on solving multi task censored regression problem, the experiments conducted on synthetic data and real data are not convincing enough to ensure the contribution of the Subspace Network.
Reject. rating score: 4. rating score: 8. rating score: 8. <BRK>This paper looks at a specific aspect of the learning to teach problem, where the learner is assumed to have a teacher that selects training examples for the student according to a strategy. In this case the authors look at finding interpretable teaching strategies. The suggested method follow an iterative process in which the student and teacher are interchangeably used.<BRK>This is a well written paper on a compelling topic: how to train "an automated teacher" to use intuitive strategies  that would also apply to humans. The paper appears to be original, and the related work section is quite extensive.<BRK>The authors define a novel method for creating a pair of models, a student and a teacher model, that are co trained in a manner such that the teacher provides useful examples to the student to communicate a concept that is interpretable to people. They do this by adapting a technique from computational cognitive science called rational pedagogy. It is an interesting approach that builds on computational cognitive science research and the authors provide strong evidence their method creates interpretable examples.
Reject. rating score: 4. rating score: 5. rating score: 5. <BRK>In this paper, the authors consider the problem of generating a training data set for the neural programmer interpreter from an executable oracle. Typically, we are given a set of data, not an oracle that can generate such data, and our task is to learn something from the data.<BRK>ClarityThe paper is clearly written. OriginalityTo my knowledge the method proposed in this work is novel. Training and verification sets are automatically generated by the proposed method.<BRK>But these are also the same set of experiments performed by Cai et al.Given the original number of traces generated is huge, I do not understand, why this method is at all practical. So, I am hesitant accepting the paper.
Reject. rating score: 4. rating score: 5. rating score: 6. <BRK>I believe the primary difference (other using an LSTM instead of a convnet) is to replace max pooling with softmax pooling. The experiments offer no empirical comparison. Note that exposition in Le and Zuidema (2015) discusses the pruned case as well, i.e., a compete parse forest.<BRK>This paper proposes to jointly learning a semantic objective and inducing a binary tree structure for word composition, which is similar to (Yogatama et al, 2017). Overall, I think it is really an interesting direction and the proposed method sounds reasonable. However, I am concerned about the following points:    The improvements are really limited on both the SNLI and the Reverse Dictionary tasks. Also, it would be much better to have a direct comparison to (Yogatama et al, 2017), including the performance and also the induced tree structures. I am not sure if the attention overt chart is a highlight of the paper or not.<BRK>Summary: The paper proposes to use the CYK chart based mechanism to compute vector representations for sentences in a bottom up manner as in recursive NNs. The paper is very well written. My only concern about the novelty of the paper is that the idea of using CYK chart based mechanism is already explored in Le and Zuidema (2015).
Accept (Poster). rating score: 7. rating score: 7. rating score: 7. <BRK>G CNNs were introduced by Cohen and Welling in ICML, 2016. They showed that group equivariant networks can lead to more effective weight sharing and hence more efficient networks as evinced by better performance on CIFAR10 & CIFAR10+ for the same parameter budget. This paper shows G equivariance implemented on hexagonal lattices can lead to even more efficient networks. The benefits of using hexagonal lattices over rectangular lattices is well known in the signal processing as well as in computer vision. Group equivariant DNNs could lead to more robust, efficient and (arguably) better performing neural networks. Pros  A good paper that systematically pushes the state of the art towards the design of invariant, efficient and better performing  DNNs with G equivariant representations. Cons  The authors should relate the paper better to existing works in the signal processing and vision literature. The results are on simple benchmarks like CIFAR 10. Clarity could be improved in a few places: Since * is used for a standard convolution operator, it might be useful to use *_g as a G convolution operator.<BRK>The paper proposes G HexaConv, a framework extending planar and group convolutions for hexagonal lattices. Original Group CNNs (G CNNs) implemented on squared lattices were shown to be invariant to translations and rotations by multiples of 90 degrees. With the hexagonal lattices defined in this paper, this invariance can be extended to rotations by multiples of 60 degrees. This shows small improvements in the CIFAR 10 performances, but larger margins in an Aerial Image Dataset. All these steps are very well explained in the paper, combining mathematical rigor and clarifications. All this makes me believe the paper is worth being accepted at ICLR conference. Authors claim to have an efficient implementation but the paper lacks a proper quantitative evaluation.<BRK>The authors could also integrate their discussion about their results on CIFAR in the paper, I think it would help readers understand better the advantage of the contribution. This paper is based on the theory of group equivariant CNNs (G CNNs), proposed by Cohen and Welling ICML 16. Regular convolutions are translation equivariant, meaning that if an image is translated, its convolution by any filter is also translated. G CNN introduces G convolutions, which are equivariant to a given transformation group G.This paper proposes an efficient implementation of G convolutions for 6 fold rotations (rotations of multiple of 60 degrees), using a hexagonal lattice. Using a hexagonal lattice is elegant, even if it is not new in computer vision (as written in the paper).
Reject. rating score: 3. rating score: 4. rating score: 6. <BRK>I find this almost a bit circular in the line of argumentation, but ok.<BRK>I am not sure of the relevance of this work as written.<BRK>We have that normal classification is linear in the numberof classes. I would like moreevidence for this, including some examples of this problem includingin the paper. Why not just use this   and dropthe vague, wordy definition? My criticism of the paper is that I don t think there is enoughmotivation.
Reject. rating score: 5. rating score: 6. rating score: 6. <BRK>I find this idea potentially interesting but am more concerned with the poorly explained motivation as well as some technical issues in how this idea is implemented, as detailed below. 1.Actually I find the entire notion of an "ideal" prior under the GAN setting a bit strange. But I feel this sounds like a new angle and not the one that is adopted by the authors in this paper. It is **not** however to match Q(x,z) with P(x,z). And btw, don t you need to put E_z[ ... ] around the 2nd term on the r.h.s. E.g.in the beginning of the 2nd paragraph in Introduction, the authors write "Generative models like GANs, VAEs and others typically define a generative model via a deterministic generative mechanism or generator ...". I guess my point is, a seemingly well partitioned latent space doesn t bear an obvious correlation with a multi modal distribution in it. 6.The generator reversal procedure needs to be carried out once for each data point separately, and also when the generator has been updated, which seems to be introducing a potentially significant bottleneck into the training process.<BRK>Summary:The paper proposes to learn new priors for latent codes z  for GAN training. To fix this the paper proposes to learn a second GAN to learn the prior distributions of "real latent code" of the first GAN. The first GAN then uses the second GAN as prior to generate the z codes. The solution presented is not end to end (learning a prior generator on learned models have been done in many previous works on encoder/decoder)General Review:More experimentation with the latent codes will be interesting:  Have you looked at the decay of the singular values of the latent codes obtained from reversing the generator? ****** I read the authors reply.<BRK>The paper demonstrates the need and usage for flexible priors in the latent space alongside current priors used for the generator network. It will be informative to see how the model holds in high dimensional settings. The experimental results show the benefits of this approach. 2.The results are depicted with a latent space of 20 dimensions.
Invite to Workshop Track. rating score: 6. rating score: 6. rating score: 4. <BRK>This paper describes the application of a neural network architecture, called Share, Specialize, and Compete, to the problem of automatically generating big fixes when the bugs fall into 4 specific categories. This paper is well written and nicely organized. The technical approach is described in sufficient detail, and supported with illustrative examples. To me the major shortcoming of the model is that the analysis focuses only on 4 specific types of semantic bugs. And while the high performance achieved on these 4 bugs is noteworthy, the fact that the baseline compared against is more generic weakens the contribution. Overall this is a nice paper with very promising results, but I believe addressing some of the above weaknesses (with experimental results, where possible) would make it an excellent paper.<BRK>Pro:Interesting application Impressive results on a difficult taskNice discussion of results and informative examplesClear presentation, easy to read. Con: The comparison to baseline seq 2 seq does not seem quite fairThe method appears to be highly specialized to the four bug types. It is not clear how generalizable it will be to more complex bugs, and to the real application scenarios where we are dealing with open world classification and there is not fixed set of possible bugs.<BRK>The paper is well written and easy to follow. It leads to a natural question that how many other cases besides the four? It seems that even if the proposed method works pretty well in practice, it would not be very useful since it is effective to only 4 out of a huge number of cases that a program could be wrong. * Many technical details have not been well explained. * The experiments are weak. 2) the comparsion between SSC with and Seq to Seq is not fair, since the baseline is more general and not specially crafted for these 4 cases.
Reject. rating score: 5. rating score: 5. rating score: 6. <BRK>Images are tiled and tiles are sampled and encoded into a feature vector via a ResNET 50 pretrained on ImageNET. The min max layer selects the R min and max values, which then enter the FC layers. A multi instance (MIL) approach is used to train the model by backpropagating only instances that generate min and max values at the min max layer. The paper is well written and easy to understand. Patch based convolutional neural network for whole slide tissue image classification. Weldon: Weakly supervised learning of deep convolutional neural networks.<BRK>As such I feel that this would be interesting to present if there is interest in the overall application (and results of the 2016 CVPR paper), but not necessarily as a novel contribution to MIL and histology image classification. Comments to the authors:* The intro starts from a very high clinical level. Can you detail about the ranking method in Durand 2016, for example? Results in table 1 suggest that this leads to some 2 5% performance increase which is a nice result. I would assume that experimental conditions (training data, preprocessing, optimization, size of ensemble) are kept constant in between those two comparisons?<BRK>This paper proposes a deep learning (DL) approach (pre trained CNNs) to the analysis of histopathological images for disease localization. It correctly identifies the problem that DL usually requires large image databases to provide competitive results, while annotated histopathological data repositories are costly to produce and not on that size scale. The study seems sound from a technical viewpoint to me and its contribution is incremental, as it builds on existing research, which is correctly identified. Results are not always too impressive, but authors seem intent on making them useful for pathogists in practice (an intention that is always worth the effort).
Reject. rating score: 3. rating score: 5. rating score: 5. <BRK>This paper proposes using a set of orthogonal basis and their combination to represent convolutional kernels. The naming for state of the art methods is not consistent. Figures 2 and 3. I have not been able to match these numbers with those in table 2.<BRK>The paper presents a binary neural network architecture that operated on predefined orthogonal binary basis. Few mistakes and questions: Is Equation 2 used to measure the quality of the kernel approximation?<BRK>The paper proposes a neural net architecture that uses a predefined orthogonal binary basis to construct the filter weights of the different convolutional layers. The citation to binary weight networks is missing. The authors propose to compute the filter weights on the fly in order to tradeoff memory for computation time. Positives  The idea of using a predefined basis to estimate filter weights in a neural network is novel and leads to significant reduction in memory usage.
Reject. rating score: 3. rating score: 5. rating score: 6. <BRK>I’m not entirely sure the authors understand the material particularly well, as I found some of the arguments and narrative confusing or just incorrect. We often see the model collapse on several different values: why couldn’t each of your generators do this? Arjovsky et al addresses the mode collapse problem, which is just another word for a type of instability in GANs. You should also probably cite Che et al 2016 as another model that addressed missing modes. This needs to be explicitly stated. The real world experiments are fairly unconvincing, as you only show MNIST and CIFAR 10 (and MNIST doesn’t look very good).<BRK>The paper proposes to use multiple generators to fix mode collapse issue. The multiple generators are trained to be diverse. One disadvantage is that it increases the number of networks (and hence the number of parameters). The paper needs some additional experiments to convincingly demonstrate the usefulness of the proposed method.<BRK>Strengths:Mode collapse in GANs is a timely and unsolved problem. While most work aims to construct auxiliary loss function to prevent this collapse, this paper instead chooses to accept the collapse and instead encourage multiple models which collapse to unique modes. Weaknesses:Organization   The paper is quite difficult to read. Some concepts are presented out of order. Experiments   Comparison is limited to single generator models. Figure 4: why does the inception score for the single generator models vary with the #generators?
Accept (Poster). rating score: 7. rating score: 7. rating score: 5. <BRK>This paper describes PLAID, a method for sequential learning and consolidation of behaviours via policy distillation; the proposed method is evaluated in the context of bipedal motor control across several terrain types, which follow a natural curriculum. Although the main focus of this paper is on continual learning of “related” tasks, the authors acknowledge this limitation and convincingly argue for the chosen task domain. Due to the high amount of variance in single RL experiments it is recommended to perform several re runs and argue about mean behaviour. How were the network architecture and network size chosen, especially for the multitasker? Is performance maintained only on the last 2 tasks, or all previously seen tasks?<BRK>The results show that this PLAID algorithm outperforms a network trained on all tasks simultaneously. What data do you use for the distillation? I do not understand the purpose of "input injection" nor where it is used in the paper. The paper cites many previous approaches to this but does not compare against any of them. In conclusion, the paper s approach to multitask learning is a clever combination of prior work.<BRK>I think overall it is a good idea. But I find the paper lacking a lot of details and to some extend confusing. The plot does not explicitly account for the distillation phase. What do you do when you go back to the task that doesn t have the input, feed 0? Please say in the main text that details in terms of architecture and so on are given in the appendix. Wouldn t the fact of having data from all the 100 tasks at the end contradict the traditional formulation of continual learning?
Reject. rating score: 2. rating score: 2. rating score: 3. <BRK>In particular, the effect of the ReLUs seems tobe limited in this regime. I have some other concerns about correctness, but I do not thinkthat the paper can be accepted even if they are unfounded. The exposition is uneven.<BRK>Given the above, at this point I cannot recommend the paper for acceptance. 2.The maximum norm of the noise is O(1/k). The notation section should be brought forward (or referred the fist time the notation is actually used). Definition 3: C_j is not defined in the main text.<BRK>A few relatively more minor issues:  The paper makes the strong assumption that the data is generated from a 1 sparse dictionary model. Unfortunately (and unless I missed something), there appears to be a crucial bug in the argument, which requires that random initialization lead to dictionary elements sufficiently close to the ground truth. I should also say that I did not check the rest of the proof carefully.