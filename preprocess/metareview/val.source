Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>There is a proposition 2 trying to explain some part of the mechanism of UGI. 2.Even though the title of the paper is "improving the gating mechanism of recurrent neural networks", the authors try to solve signal propagation problems. More explanations are needed. The writing in the description of the UGI and refine fate is not clear.<BRK>This paper proposes to improve the learnability of the gating mechanism in RNN by two modifications on the standard RNN structure, uniform gate initialization and refine gate. The authors propose a new refine structure that seems to have a longer "memory". There are several parts in the experiment that are not very convincing. What is the reason? The proposed method seems not very general.<BRK>The second modification is the introduction of a refine gating mechanism with a view to allow for gradients to flow when the forget gates f_t in the LSTM updates are near saturation. The refine gate was also adapted to memory architectures such as the DNC and RMA where it was found to improve performance on two different tasks. While I m not entirely convinced about the proposed initialization scheme but across the many different tasks tried, the use of the refine gate does appear to give performance improvements that lead me to conclude that this aspect of the work is a solid contribution to the literature. Questions and comments:* This manuscript already quite long and has several formatting issues. i.e.for the URLSTMs that performed well, were the values of the forget gate closer to 0/1 than the baselines?
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>*** SummaryThis work proposes to use an augmented RNN model to address the incremental domain adaptation problem. A proof in a highly simplified case is given in addition to empirical results showing that expanding the memory bank is better than expanding the RNN states. Section 3 is well written. The methods and motivations are illustrated clearly. A comparison between this memory and the traditional attention can help demonstrate the validity of this choice.<BRK>This paper proposes an extensible attention mechanism applied on the previous hidden state of an RNN and resulting in supplementary input for the next RNN step. This method is applied in the context of incremental domain adaptation for NLP without the possibility of storing of old samples (episodic memory). Pros:  Extensive ablation study with the different possible combinations of methods  Very interesting comparison between expanding the memory (i.e.attention) and expanding the hidden states. It would have been better to be able to observe catastrophic forgetting for the source domain. Otherwise, the paper proposes a novel method which works well in practice so I am leaning towards acceptance.<BRK>###Summary###This paper introduces incremental domain adaptation for natural language processing, assuming that each domain comes one after another and only the current domain can be accessed in the application scenario. The basic framework of this paper is based on RNN but augmented with the directly parameterized memory bank. 2).Can the proposed approach generalize to visual domain adaptation, i.e.on the visual task instead of NLP task? ### Novelty ###This paper proposes incremental domain adaptation, which is inspired by Li & Hoiem s work. Thus, the problem setting provides some novelty. The proposed claims are well supported by the experiments and analysis. 3) The paper is overall well organized and well written.
Reject. rating score: 3. rating score: 3. rating score: 8. <BRK>In this paper, the authors present a new perspective on how to effectively noise unlabeled examples and argue that the quality of noising plays a crucial role in semi supervised learning. By substituting simple noising operations with advanced data augmentation methods, their method brings substantial improvements across six language and three vision tasks under the same consistency training framework. In this paper, all the results, including the augmented methods are all well established approaches. It is difficult to convince the reviewers. I think this paper likes a technical report, not a research paper. So, why not to share the parameters directly?<BRK>The paper proposes to substitute simple noising operations with many data augmentation methods in consistency based semi supervised learning. Overall, the paper is well written and clear. However, it looks not surprising to me that more data augmentations found in supervised learning are also effective in semi supervised learning. I m willing to increase my score if the authors address my concerns.<BRK>The key insight in this paper is that, data augmentation methods that work well during supervised training should also work equally well as the noise distribution for consistency training on unlabeled data. The paper is well written and the authors present extensive comparative and ablation tests to demonstrate that their proposed method works well with both low and high amounts of labeled data. This paper should be accepted into the conference.
Accept (Poster). rating score: 8. rating score: 8. rating score: 6. <BRK>I would also caution against stating that the environment is closer to the real world. These representation learning in the paper is based on action conditional predictions of future quantities, which is complementary to the approach proposed in the paper. The paper proposes a neural implementation of particle filters, by treating samples of RNN states as particles. The particles are used to estimate moment generating functions evaluated at trained vectors, which in turn are supposed to provide more information for the policy s decision making. The ablation study suggests that all three components (particles, MGFs & discrimination) are necessary. However, the third component has been shown not to be exclusively helpful for representation learning (Gregor et al., Guo et al.) I vote for acceptance. I think the algorithmic idea in this paper is a step in the right direction and can be of interest for the community. I think it is important for the paper to qualify the kind of POMDPs being considered. The defining features of most of the environments being used is that the state is observed through a noisy channel.<BRK>Update: my concerns have been addressed and I have updated the score to 8****This paper introduces 3 neat ideas for training deep reinforcement learning (DRL) agents with state variables so that they can handle partially observed environments:1) model the latent state variable as a belief distribution, using a collection of weighted hidden states, like in the particle filter (PF), with an explicit belief update of each particle, calculation of the weight using an observation function, and a differentiable re weighting function to get the new belief distribution,2) base the policy on the whole set of particles, by quantifying that set using its mean as well as a collection of K learnable moments (specifically, K Moment Generating Functions, each one corresponding to a dot product between the moment variable and the hidden state of the particle),3) instead of generating the observations, take again the idea from PF which is to measure the agreement between the current observation o_t and the i th particle state variable h_t^i, via a learnable discriminative function. From what I understand, the only gradients in the model come from the usual 3 RL losses, and the observation functions in the discriminative PF are trained because they weigh the particles. The paper is a very well written and the experiments are very well executed. I believe that the idea is novel. I understood it was trained using discriminative training. Does it mean that different observations o_t are used, and if so, how many? Isn t there a posterior collapse, with all particles ending up bearing the same state? * In the discussion, can you comment on the relationship between Monte Carlo Tree Search in RL agents (sampling different trajectories) vs. here (sampling different states)? I would be interested in seeing more analysis of the discriminative PF RL algorithm on navigation tasks, given that that s what PF were designed for.<BRK>This is a well written paper. It combines the strength of Bayesian filtering and policy oriented discriminative modeling. DPFRL encodes a differentiable particle filter with learned transition & observation models in a neural network, allowing for reasoning with partial observations over multiple time steps. Experimental results show that DPFRL achieves state of the art on POMDP RL benchmarks. Improved performance is reported.
Reject. rating score: 1. rating score: 3. rating score: 8. <BRK>Adversarial training generalizes data dependent spectral norm regularizationThis paper shows that, projected gradient descent based adversarial training is similar to the data dependent spectral norm regularization, and under very restrictive condition, the authors show that this two methods are the same. Some experiments are conducted to support the theory. The authors only give a data dependent version of the spectral normalization based on the Jacobian of the neural networks, which I think is somewhat weak. This theorem cannot convince me that the proposed methods have a strong theoretical basis. 6.I think the discussion in Appendix A.5 is somewhat confusing.<BRK>This paper studies the link between adversarial training and the proposed data dependent operator norm regularization for ReLU network. Under specific conditions, in theory, the authors show the equivalence between the l2 PGD training and the regularization method. Empirical experiments are conducted to support the theory.<BRK>This largely theretical paper establishes a theoretical link between adversarial training and operator norm regularizationfor DNNs. It is well written and structured, and it falls squarely within the the remit of the conference.
Reject. rating score: 6. rating score: 6. rating score: 6. <BRK>This paper proposes to learn a subset of a given dataset that acts as an adversary, that hurts the model performance when used as a training dataset. The central claim of the paper is that existing datasets on which models are trained are potentially biased, and are not reflective of real world scenarios. I have updated my score to reflect this. To that end, the sentence that says it works for "any" q() is incorrect. But that does not address the central idea, that the resultant models do better in the wild.<BRK>They introduce an algorithm that selects more representative data points from the dataset that allow to get a better estimate of the performance in the wild. The algorithm ends up selecting more difficult/confusing instances. This paper is easy to read and follow (apart from some hickup with a copy of three paragraphs), but in my opinion of limited use/impact. Please fix2) I am not sure   What applications the authors suggest. They seem to say that benchmark authors should run their algorithm and make benchmarks harder. To me it seems that benchmarks become harder because you remove most important instances from the training data (so Table 4 is not surprising   you remove the most representative instances so the model can t learn)  how practically feasible it is. How would that do? For NLP (SNLI) task i think this would be a more reasonable baseline than just randomly dropping the instances,5) I wonder if you actually retrain the features after creating filtered dataset, new representation would be able to recover the performance. Changing to weak accept<BRK>the paper proposes an algorithm that adversarially filters out examples to reduce dataset specific spurious bias. the key intuition is that the datasets are curated in a way that easy to obtain samples have higher probability to be admitted to the dataset. this make the paper a promising proposal. the idea of the paper is interesting and the experiments show a substantial reduction in the performance of existing algorithms.
Accept (Poster). rating score: 6. rating score: 6. rating score: 3. <BRK>In this paper, the authors proposed a new method to model the source code for the bug repairing task. Traditional methods use either a global sequence based model or a local graph based model. The authors proposed a new sandwich model like [RNN GNN RNN]. But the message is clear. The sandwich model can benefit from GNN model that can achieve a higher accuracy at the beginning of training where transformer did a poor job. At the end of training, the sandwich model outperforms both kinds of models. Here are some detailed comments:1. It would be interesting to have the complete result from Transformer in Figure 1 and Figure 2 which is missing. Why GGNN is so slow in this paper?<BRK>The paper claims to improve state of the art results published by Vasic et al for this task, however the RNN model by Vasic et al was known to be far from optimal when the work was published. The paper does a number of contributions to the neural architecture. This change is also what makes the work perform as well or better than GGNN based approaches. The paper then proposes to improve the transformer model by modifying the attention where there are edges. Given that most of the work talks about performance, it would also help if the authors clarify what kind of hardware was used and which optimizer. More minor issues:“We conjecture that the Transformer learns to infer many of the same connections”. It seems it is q_i and k_j? I actually increase my score a bit (I was torn in the beginning), because this is one of the first papers to run transformer model on code.<BRK>Strength:  Interesting problem The paper is well written and easy to follow  The proposed approach seems very effectiveWeakness:  the novelty of the proposed is marginal  Some of the claims are not right in the paperThis paper studied learning the representations of source codes by combining sequential based approaches (RNN, Transformers) and graph neural network to model both the local and global dependency between the tokens. In the abstract, the authors said the graph neural network is more local based while the transformer is more global based. And there are actually some existing work that have already explored this idea in the context of natural language understanding, e.g.,Contextualized Non local Neural Networks for Sequence Learning.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>In this way, learning curve prediction can act as a fast method for performance measurements in AutoML. However, I have some concerns about the motivations and usage of the proposed method. Learning curve prediction is a general approach that can be combined with many zero order optimization methods. Does this paper focus on learning curve prediction on general AutoML problems or just NAS? How will the changes in the search space affect the proposed method? It is better to show what kinds of curves will the proposed method likely to give early stops.<BRK>The paper proposes a new method to rank learning curves of neural networks which can be used to speed up neural architecture search. While the method seems interesting, I don t think the paper is ready for acceptance yet, since it a) misses some important details and b) the empirical evaluation is not sufficient. I also miss a discussion of these methods in the related work section. This should be straight forward, since decisions which configuration is promoted to a higher budget can be made based on the model instead of just the last observed value. What is delta in the experiments? How sensitive is this hyperparameter in practice?<BRK>This paper considers the problem of automatic early termination in hyper parameter search and neural architecture search. Comparisons with state of the art NAS and HPO algorithms that do not use learning curves prediction (e.g., HyperBand, learning by learning algorithms using LBFGS, etc.) Unlike most previous approaches for learning curve prediction, which estimates the probability of whether the current model is better than the current best model or not by first extrapolating the learning curve and then invoke a heuristic measure, this paper proposes to predict the probability directly. The neural network f is trained with some meta dataset, and then the early termination is then decided based on this pairwise comparison probability.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>The paper proposes a new GAN training that additionally feeds adversarial examples as the real samples to the discriminator D. A key motivation here is to regularize the target real distribution simulated by D to be robust to adversarial perturbations. Experimental results show that the proposed GAN training generally improves the generation performance from the vanilla GAN training in CIFAR 10, CelebA and LSUN datasets. In overall, I liked its clear motivation and the simplicity of the method. One of my main concerns, however, is that robustifying D in GAN training is not a new idea for some readers [1], so they need more clarification on the novelty of the proposed method, e.g.by discussing about it in related work or by comparing the performance. Some questions listed here are relevant to this point:    (a) The paper only considers to use FGSM in adversarial training part, but FGSM training on large epsilon usually leads to overfitting [2] on CIFAR 10. I wonder if the authors have tried PGD counterpart in their method. (b) It seems that the method uses both natural and adversarial examples in adversarial training, as in [3]. Instead, there is another (and perhaps more common) type of adversarial training [2] that uses only adversarial examples for the training. [1] Liu, X., & Hsieh, C. J. (2019).Rob gan: Generator, discriminator, and adversarial attacker. CVPR 2019.<BRK>This paper tries to propose a new method to stabilize the training procedure of GAN. To this end, they use adversarial samples of real data to train the discriminator, and claim that it is helpful to reduce the adversarial noise contained in the gradient. Although training GAN with adversarial samples of discriminator is somewhat novel, the method and experiments are not convincing. I do not recommend the acceptance based on the limited contribution of this paper. 1.The paper uses vague description such as “This approach can improve the robustness of discriminator and reduce adversarial noise contained in gradient” without convincing justification. The author running adversarial training on CIFAR10 dataset with FGSM and the perturbation is tested from 0.2/255 ~ 4/255. The performance (FID score) is a bit sensitive to the amount of perturbation level.<BRK>This paper presents an interesting idea based on introducing adversarial noise on real samples during GAN training. This novel approach may improve GAN training and have potentially large impact, but the paper in its current form is slightly below the standard of ICLR due to its lack of clarity. Properties used to justify the approach, such as “symmetric” and “balanced” need to be explained. (after eq.8) It is unclear to me that “backward propagation of Equation 5 with respect to x with negligible computation overhead”. It would be helpful to provide an estimation of runtime overhead supported by experiments. In algorithm 1, why is it necessary to perform discriminator update twice? A solid baseline is necessary for any further assessment. The analysis also need to be improved. Nit:The 1 line derivation of eq.6 can be incorporated into the main text. Update:I read the authors  rebuttal, which addressed many of my concerns and presented additional empirical results. I therefore believe the final camera ready version can be a valuable contribution to the field, and would like to recommend accepting this paper.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>This paper proposes two techniques for fast linear interpolation on CPUs. They achieved speedups by reducing 1) fixed overhead cost and 2) per example computation (linear interpolation operation level optimization). Authors consider this problem for small operation models like linear interpolation rather than the models requiring large operations such as ResNet. This reviewer also does not have enough knowledge and background to judge this paper. This is only consider optimization on CPUs. (I don’t have much knowledge on compiler..)<BRK>(4) A necessary process of LUT from piece wise linear functions of approximating the ones that we care about is to conduct 1 D density estimation on the input domain, since more fine grained splits are required in the dense area and less splits elsewhere. Could the authors present some results for this? It is okay if there is a performance (accuracy or likelihood) and speed trade off, but the paper didn t present any results on this. I don t think the paper should downplay the part of finding T as it is crucial.<BRK>Also, the Tensorflow implementation should be briefly explained to make clear where these gains come from. While the topic is relevant for this conference, readers are likely not familiar with some of the concepts used in the paper, and a bit more explanation is needed. A memory efficient bit packing technique to store both integer and floating point representations together.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>SummaryThe authors propose learning the expected # of time steps to reach a given goal state from any other state which they call: dynamical distances. The claim is that dynamical distances can be used in a semi supervised regime, where unsupervised interaction with the env is used to learn the dynamical distances. The ideas presented in this work are interesting, but I have some major concerns (please see detailed comments below). The main experiment is shown with preferences where comparisons do not seem enough and the paper could be made stronger by thorough comparisons. In NIPS, 2013. [3] Gupta, Abhishek, et al."Unsupervised meta learning for reinforcement learning." Algorithm 1 learns the distance corresponding to the current policy. I would suggest comparing to other relevant baselines such as [3], [4], [5].<BRK>This paper presents an approach to do reinforcement learning without reward engineering. Instead, steps to reach goals are used to update policy. Can the authors elaborate on this? For example, how is the performance of a policy that just directly minimizes the distance function? Instead of using the made up toy example. d(g, g) is not 0 for all dynamical systems. Shouldn’t the policy learn to stay as close to the initial state as possible? While I understand that this method will be very effective for relatively static tasks like the valve turning, I fail to see how it can apply in unstable locomotion tasks, as mentioned in some of the questions above. Normally I will give rating 5 to this paper, but the system doesn t give me this option, so I have to lower it to 3 instead.<BRK>After a few readings my understanding of the paper is that there is a desire to develop a proxy (or basis) that is first determined in a reward free setting, agnostic to a goal. Something that I think needs to be changed is the continual use of the term distance when it is not a valid mathematical distance (this point is noted by the authors but then the term is used continuously and the notation used would be standard notation for an actual distance). Subsequently, this proxy can then be combined with a goal and improve efficiency in developing a suitable policy for that goal rather than starting from scratch with something like Q learning. The distances between states from the regressor is policy dependent and then this distance is used to inform the policy update   how can we be certain that this alternating optimization will not fall into a local minimum depending on the initial policy?
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>This work presents the value iteration with negative sampling (VINS) algorithm, a method for accelerating reinforcement learning using expert demonstrations. In addition to learning an expert policy through behavioral cloning, VINS learns an initial value function which is biased to assign smaller expected values to states not encountered during demonstrations. In those cases, a useful notion of similarity would likely have to be learned from the data. It is unclear that VINS would generalize well beyond robotic control domains.<BRK>The authors proposed the algorithm called value iteration with negative sampling (VINS) of which the main ideas can be summarized as follows. The second main idea of this work is to use *self correctable policy*, where the approximate dynamics and behavioral cloning (BC) policy were used to select the action which is expected to give higher value at the successor states. To consolidate their ideas, the authors proved Theorem 4.4 showing that state visitation distribution of resultant policy is approximately close to that of an expert under a few assumptions. Empirically, they considered two experiments. For instance, we can simply think about GAIL with BC initialization, but it seems to me that GAIL with random initialization was used in the second experiment (since authors mentioned GAIL in OpenAI baselines was used without hyperparameter tuning (https://github.com/openai/baselines/blob/master/baselines/gail/run_mujoco.py#L53)). I think the authors should have compared the performance of VINS + RL with those baselines in the second experiment if they tried to emphasize the sample efficiency of VINS + RL.<BRK>More specifically, policies learned in this manner can often fail when they encounter new states not seen in demonstrations. The paper proposes a method for learning value functions that are more conservative on unseen states, which encourages the learned policies to stay within the distribution of training states. A practical algorithm is also presented and experiments on continuous control tasks display the effectiveness of the method, with particularly good results on imitation learning followed by reinforcement learning. The theory may also have some restrictive assumptions, limiting its significance. Overall, I am divided about this paper. 4) It could be said explicitly that the expert policy is assumed to be deterministic. Experiments:1) It seems like VINS relies heavily on the assumption that the environment is deterministic to learn an effective model.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>This paper proposes a feature partitioning scheme for efficient multi task neural architecture search. The problem of neural architecture search is important and beneficial to deep learning community to be able to extract the best out of these methods. I find the approach of this paper a heuristic.<BRK>This paper proposes a framework for learning multi task convolutional neural networks. However, I am not convinced by the presentation of the paper and by the lack of multi task learning baselines in the experiments. I will consider changing my score if the following comments are addressed. Why does this happen? The Figure is not very informative. Some questions:  how long does it take to solve? Please provide more details.<BRK>Instead of deciding on other hyper parameters such as the number of layers, the authors chose to study how to efficiently share the capacity of the network: to decide which filters should be used for which tasks, and which filters should be shared between tasks. The advantages of these approaches are well discussed and validated quantitatively. The paper is well written and the approach itself appears to be sound and it led to improvement over independent task estimator. However, I am mostly concerned about the experimental setting: there are no comparisons with any other MTL algorithm. This could potentially lead to improvement beyond multi task learning. Overall, I think this paper makes a borderline case.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>[3] Some experimental settings are not clear. But the following should be improved in the following aspects: [1] In the proposed method, the model parameters are updated both on the unlabeled samples and validation data set. The experimental results show that such a strategy is effective to improve the performance of the state of the art method. [2] How the validation data can improve the generalization ability of the model should be given with theoretical analysis.<BRK>I have 3 main concerns with the paper 1. The authors mention that  the meta validation set is a random subset of train set. The set of labeled points should be partitioned into train and meta validation set. Moreover, the experiment results are mostly declared without any justification (for example, the proposed method does not always lead to improvement and not all cases are explained.The authors only note that the method works well in low data regime). Is there a reason for this?<BRK>This paper uses a meta learning approach to solve semi supervised learning. Experiments on classification and regression problems show that the proposed method can improve over existing methods. The idea itself is intriguing but the derivation and some design choice are not very well explained. The pseudo code does not help much. Error bars in the tables and Fig.2? What are the candidates for the hyper parameters? Typos:  In the first paragraph of Sec.2, one of the x and one of the y should be bold.
Accept (Poster). rating score: 8. rating score: 6. rating score: 3. <BRK>This paper proposed a new pre trained language model based on BERT, called StructBERT. Unlike the original NSP (next sentence prediction) task, which is simple but tends out to be not so helpful in many downstream tasks, both proposed pre train objectives seem to be rather useful in benchmarks tested in the paper, including GLUE, SNLI, and SQuAD. The paper is well written and understandable for anyone who has a basic background about BERT or pre train. I wonder what intuition/theory leads to the selection of these two tasks? If the authors have test multiple other tasks that were not as helpful, it is also interesting to know them. Personally, I don t think the leaderboard results are that critical, but just want to make sure the writing is accurate at the time of publishing.<BRK>This paper introduces two new tasks for large scale language model pretraining: trigram word unscrambling and contextual sentence ordering. Using these tasks to pretrain on top of masked language modelling shows improvements when the resulting model is finetuned on downstream tasks. For this reason, I recommend acceptance of this paper. The references to Elman 1990 also don t serve to clarify anything, I suggest that they are removed. 3) The permutation objective seems very similar to the XLNet objective. Could the authors elaborate more on this in the paper? 4) Did the authors try with other n gram shuffling orders? 5) The sentence ordering task has been used previously (e.g.[2]).6) Table 1 overhangs the right margin.<BRK>This paper proposes to use additional structures within and between sentences for pre training BERT. Overall, I think the experiments and results in this work are not sufficient enough to support the claim:  It is necessary to show the performance of BERT only trained with the proposed word and sentence objectives. Is there an explanation?
Accept (Spotlight). rating score: 8. rating score: 8. rating score: 6. <BRK>This paper proposes a new pre trained BERT like model called ALBERT. The contributions are mainly 3 fold: factorized embedding parameterization, cross layer parameter sharing, and intern sentence coherence loss. Other comments:  Section 4.9.<BRK>They also utilize sentence order prediction to help with training. Positives: This paper has a dramatic, seemingly statistically significant reduction in error across a wide variety of tasks. It provides a thorough experimental plan and approaches the few addendums to training (splitting the embedding matrix, the layer wise parameter sharing, and the sentence order prediction). Concerns & Questions: There s a lot of experimentation here and a lot of seemingly deliberate choices after seeing empirical results during the research phase.<BRK>They show that despite being much smaller, the performance is very strong and achieves state of the art on a variety of different tasks. Cross layer parameter sharing has a regularization effect that simply scaling up BERT large to x large or such sizes does not have. This raises several questions: is it better to have models that are deeper or more wide?
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>The paper proposed an adaptive learned bloom filter. The paper proposes efficient ways to tune the hyper parameters, and provides the analysis of the error. My decision depends on the responses of the author(s). (1) Although the paper claims the score information can be fully exploited, the paper seems to do hashing for all possible queries. (2) The proposed method seems to be a hierarchical hashing strategy. What is the major benefit of collecting training examples to run a machine learning model?<BRK>This paper extends the Bloom filter learning by using the complete spectrum of the scores regions. The experiments also show the two proposed methods outperform learned Bloom filter in FPR and memory usage. Though the experiment results support this observation, some theoretical analysis on this and its relationship with the final FPR could be provided.<BRK>This paper proposes two new bloom filter algorithms that incorporate a learnt model for estimating if an input is in the set or not. However, the experiments are on such small datasets that the true impact of these models aren t as impressive as they could be.
Reject. rating score: 1. rating score: 3. rating score: 8. <BRK>The authors present a Sepsis 3 compliant labeling of the MIMIC III dataset and a sepsis prediction model largely based on MGP TCN that uses attention mechanisms to enable explainability. Unless the authors provide evidence that this is reasonable, it is not necessarily clear whether labels resulting from the proposed scheme will be biased and affected by differences in clinical practice at different sites or data collection practices. That being said, it is not clear whether the proposed labeling is a contribution from the work. The fact that the proposed labels are harder to fit does not imply that the proposed labels are better or more reasonable. I understand the author s motivation for doing it, however, their approach is not sufficiently justified. Being in page 2 makes it very difficult to understand.<BRK>I ve read the rebuttal and I d like to keep my score as is. This would have been typically enough for a paper with major technical novelty; however, for this paper, I believe adding more recent baselines and discussing the advantages of the method over these baselines would be necessary. The sepsis detection problem is of paramount importance in the clinical domain and the authors rightly emphasized that point. Also the paper tries to combine interpretability with prediction accuracy by using attention mechanism.<BRK>The authors consider a combination of an Gaussian model and neural network learned together to be able to find specific Gaussian features that would predict sepsis in a more intuitive, interpretable way for a medical experts. I would state that this as interpretable,  as an explicitly visible signal would be. Gaussian process by itself is not giving understanding nor interpretability as it is too general. It has the analogous two model structure like the one in the manuscript. As a summary, the authors have done solid and valuable work in improving the accuracy detection.
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>The paper studies methods for detecting adversarial examples using saliency maps. Moreover, the robustness against white box adversaries is not sufficiently studied. From a conceptual perspective, the impact of detecting specific adversarial attacks is not clear.<BRK>This paper proposes an adversarial defense method that is a saliency based adversarial example detector. Is it possible to train a single detector that can handle all different adversarial attacks? Although the overall results are improved from the previous methods, the proposed method is lack of novelty.<BRK>This paper presents a method for training networks to detect adversarial examples and by virtue of doing so, providing defense against adversarial attacks. Two different approaches are examined, in which a saliency map is used in combination with the input as a mask. Overall, this presents a relatively simplistic way of deriving representations of saliency and combining these with inputs for training that builds robustness against white and black box attacks.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>This paper provides a theoretical justification for the benefit of multi task deep RL (MTRL) with shared representations. I believe that is not the main argument of the paper. The results show that MTRL with shared representation can outperform their single task counterparts to some degree. While the theory seems a bit incremental, it’s the first paper that theoretically validates the benefits of sharing knowledge, which is a contribution to the MTRL field.<BRK>The submission derives bounds for approximate value and policy iteration for the multitask case in reinforcement learning. In addition, two common RL algorithms are adapted to demonstrate benefits of multitask RL given related tasks. The main contribution of the submission is the extension of an existing bound to the multitask case as the architectures are common across existing work. The extension is relevant given growing interest in meta and multitask RL but the changes in comparison to the single task case are minor and the experiment’s value purely lies in supporting this extension.<BRK>The paper attempts to give theoretical support for using shared representations among multiple tasks. The main contribution of the paper is the theory that it claims to support this architecture. This paper considers the same difference, separately for each task, so that the same bound from Farahmand (2011) can be trivially used. Because the definition of approximation error epsilon_k in Farahmand (2011) is very different from epsilon_{avg,k} used in this paper, this warrants the analysis to start from the beginning, deriving the bounds from relating Q_t*   Q_t^{\pi K} to (\epsilon_{avg, k})_{k 0}^{K 1}. I had to read to section 3 to be sure that k stands for a sequence of number 0 to big K and i stands for 1 to n with n being the number of samples.
Reject. rating score: 1. rating score: 1. rating score: 3. <BRK>The paper uses two simple CNN models and train them on a collected dataset, compare with other antivirus software, and conclude that CNN performs better. But I have serious concerns about the experiments. 1.The major concern is with the dataset. 3.The experiments done in this work is also not of a satisfactory level. Why is that? The fonts are too small. 4.No major novelty is introduced. The work is an application paper using very simple CNNs on the malicious PDF detection problem. I vote for rejection of the paper.<BRK>The paper presents a simple application of a small CNN to PDF malicious classification, the main contribution of the paper is the dataset collected, which is not released for privacy reasons. The experiments lack strong baselines, and comparisons with previous ML solutions, how important is the design of the CNN for this task.<BRK>This paper presents a model that detects malicious PDF files. This paper applies an existing CNN architecture. I do not observe any novelty in terms of modeling. I suspect this paper is not interesting to most members of the ICLR community. Therefore, I do not suggest the acceptance of this paper.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>The paper tackles the problem of self supervised reinforcement learning through the lens of goal conditioned RL, which is in line with recent work (Nair et al, Wade Farley et al, Florensa et al, Yu et al.). The technical novelty is quite limited   the paper mostly uses the framework from Andrychowicz et al., 2017 with a specific choice of epsilon ( 0) for giving positive rewards. The main technically novel component is likely the reward filtering mechanism, but I find it to be somewhat ad hoc since it assumes that the Q values learned by the Q network to be reasonably good during training time, which is not the case for most modern Q learning based methods [1, 2]. The third task of rope manipulation is fairly interesting at a first look   but it appears to have been greatly simplified. This also appears to hint that the method did not work well with realistic visuals, highlighting a major limitation of the proposed approach. For the real world experiments, the task being considered is extremely simple (free space reaching), and does not even require pixel observations. Minor points  Section 4 contains a nice discussion on false positives and false negatives when using non oracle reward functions for reinforcement learning, where they also perform a simple experiment to show how false positives can negatively impact learning much more severely than false negatives. For example, Singh et al.[3] are able to learn to manipulate a deformable object (i.e.a piece of cloth) directly from high dimensional observations using deep RL in the real world, and do not require object models (or ground truth state), but do require other forms of sparse supervision.<BRK>The authors also propose to (1) filter transitions that are likely to cause false negative rewards and (2) balance the goal relabeling so that the number of positive and negative rewards are equal. The authors demonstrate that these two additions result in faster and better learning on a simulated 2d and 3d reaching, as well as a rope task. The authors also show that the method works on training a real world robot to reach different positions from images. Overall, the paper is a fairly straightforward and simple extension of HER, and the proposed changes seem to result in consistent improvements. Most of the writing of the paper is relatively clear, but there are a couple of assumptions that should be discussed more clearly. 2.The analysis section is quite confusing to me and I do not understand its significance. 5.For the "Indicator" baseline, what is the probability used for relabeling with a future state? I don t think this detracts from the author s submission, but it would be good for the authors to highlight the main paper. seems unsubstantiated by the experiments only filtering seems important. The experiment section then says "Oracle uses the ground truth, state based reward function."<BRK>### Summary ###In this paper, the authors focus on the problem of goal conditioned reinforcement learning. Specifically, the authors consider the setting where the agent only observes vision as input and the ground truth state is not observable by the agent. In this setting, it is hard to specify a reward function since the reward function has to compute rewards from images. The authors combine the indicator reward function with a mixture of goal relabeling schemes and a heuristic way of filtering out data with false negative rewards. The results presented by the authors suggest that the proposed method performs better than baseline methods. The structure of the paper is well organized and  the authors include informative explanations and empirical evidence to support the crucial assumption that false positive rewards are worse than false negative rewards. The results for the main experiments are also easy to understand. In two of the three simulated robotics environments, the proposed method performs similarly to the indicator + balance configuration, which in my opinion is only a slight variation of HER. Therefore, I do not find the claimed advantage of the proposed method to be convincing. Therefore, I would not recommend acceptance before these problems are addressed. References[1] Andrychowicz, Marcin, et al."Hindsight experience replay."
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>This paper presents two novel VAE based methods for the (more general) semi supervised anomaly detection (SSAD) setting where one has also access to some labeled anomalous samples in addition to mostly normal data.<BRK>This paper proposes two variational methods for training VAEs for SSAD (Semi supervised Anomaly Detection). In generally, the paper is well written. But I have some concerns. In addition to VAEs, there is another class of deep generative models   random fields (a.k.a.energy based models, EBMs), which have been applied to anomaly detection (AD) recently. The authors should add comments and comparisons. However, I think, the proposed methods in this paper will not be as competitive as semi supervised deep energy based models.<BRK>The papers proposes to use VAE like approaches for semi supervised novelty detection. (1) without the reconstruction term, the methods are small variations of supervised methods.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>2) The convergence results of the proposed method in the paper are not state of the art.<BRK>The experiments show the performance of the proposed algorithm is better than other recent methods. (1) Since SCSG is a member of the SVRG family of algorithms, the difference between this paper and [Xiangru Lian, Mengdi Wang, and Ji Liu, 2017] is not significant enough, especially in the algorithm design and the proof of the theoretical theorem.<BRK>Although derived convergence rates are better than existing primal methods, this paper lacks a comparison with the recently proposed primal dual method by [A.Devraj & J.Chen (2019)]. Thus, the contribution of the paper is not lost, but it is better to compare SCCG with the method in [A.Devraj & J.Chen (2019)], empirically and theoretically.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>My main concerns are the novelty of the work, the theoretical soundness of the method for small data settings and its robustness in settings with model misspecification. #################################The paper proposes a new approach based on the notion of typical set in probability and tackles the challenging problem of detecting OOD using deep generative models. This major limitation has not been addressed in the experiments. This paper, does a good job in finding the OOD data points if the likelihood histograms do not overlap using the typicality notion. However, this idea had already been proposed and explored in Choi. et al.2019 (although for a flow based model).<BRK>This paper is concerned with how to determine whether a set of data points are from a given distribution. In this case, a better justification of the reliability of the proposed approach would be helpful. It proposes a statistical test using the empirical distribution of model likelihoods to determine whether inputs lie in the typical set if the considered model. The motivation of the work is very clear, and the paper is well organized.<BRK>My major concerns about the proposed method are whether "the typicality set" could be faithfully applied in the small data regime. The authors also clarify the difference between different baselines. To explain this phenomenon and to tackle the problem for OOD detection, this paper adopts "typical sets" for identifying in distribution samples. Specifically, a "typical set" is a set of examples whose expected log likelihood approximate the model s entropy. Empirically they demonstrate competitive performance over MNIST and natural image tasks. Typical set seems natural for out of distribution detection.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>The authors propose learning a quantizer for mixed precision DNNs. Novelty wise, I don t have enough background to tell if this is much of a leap from related work that has already proposed learning certain parameters of quantizers (but different parameters, or not the exact 2 proposed by the authors).<BRK>The paper is clearly written and easy to follow. Although the argument the authors used to support the finding is not very rigorous, the finding itself is still worth noting.<BRK>post rebuttal comment  I thank the authors for their detailed response. Since quantization involves non differentiable operations, this paper discusses how to use the straight through estimator to estimate the gradients,  and how different parameterizations of the quantized DNN affect the optimization process. In the discussion for the three parameterization choices in section 2.1.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>These approximations were motivated by the scale while looking at the training times they barely make any difference. The same is true for other metrics. If this is the case for generation then it should be discussed in the main part of the paper and contrasted with methods that can start from scratch. 7) It seems that many hyperparameters mentioned in A.7.2 are chosen in an ad hoc manner without proper model selection and seem to vary across each different versions of GRAM for each different dataset. So without proper model selection routines, the results may not be representative of what the model discussed.<BRK>(4) Finally, I did not see any error bars added to the main results in the paper. 2.The paper’s clarity could be improved, with some parts presented in an unnecessarily complicated manner (e.g.the graph attention mechanism) and others without sufficient detail (e.g.the edge estimator module, the zero ing heuristic for attention or the generation of graphs based on “seed graphs”, which is only mentioned in the appendix). The manuscript presents the proposed approach in a way that does not clearly differentiate between prior work and original contributions. 4.2.The graph attention mechanism was claimed to be an original contribution.<BRK>Although the paper claims to propose simplified mechanism, I find the generation task to be relatively very complex in comparison to GraphRNN and GRAN (published at NeurIPS 19). As mentioned below, the use of certain module seems ad hoc. Further, the results on the new metric is at times inconsistent with other prior metrics.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>This paper addresses the problem of unsupervised model selection for disentangled representation learning. Experimental results clearly show that UDR is a good approach for hyperparameter/model selection. Overall, I think a reliable metric for model selection/evaluation is needed for the VAE based disentangled representation learning. Specifically, for concrete supervised classification tasks, VAE with beta smaller than 1 (not towards disentanglement) might be the best (Alexander A. Alemi et al.2017, Deep VIB). Another concern is about the choice of some key “hyperparameters”. For me, as you are contributing a ``quantitative measurement”, it is interesting and important to see how this threshold would generally affect UDR’s behavior in one (or more) datasets you have tried. Another hyperparameter I cared is P (number of models for pairwise comparison). In the paper, you validate the effect of P in the range [5,45]. Thus, I also have a little concern about the computation cost of the proposed metric (as also mentioned by the authors).<BRK>The score is computed based on the assumption that good disentangled representations are alike, while the representations can be entangled in multiple possible ways. The UDR score can be used for unsupervised hyperparameter tuning and model selection for variational disentangled method. In the abstract, it is not mentioned at all what is the proposed approach. Therefore, I am not convinced that I should trust the results of the UDR, which combines multiple disentangled models. There is no theoretical guarantee that UDR should be a useful disentanglement metric. In summary, this paper focuses on solving an important problem. Therefore, I am inclined to reject this paper. "Adversarial feature learning."<BRK>The paper proposes a metric for unsupervised model (and hyperparameter) selection for VAE based models. This method relies on a key observation from this paper [A] viz., disentangled representations by any VAE based model are likely to be similar (upto permutation and sign). I am inclined to accept the paper for the following reasons:1. The proposed approach is clear and easy enough to understand and well motivated2. 5.The supplementary material also shows that the metric correlates well with the task performance. Based on the several discussions by the other reviewers and the discussion that happened, I am inclined to lower my scores to a weak accept.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>This paper proposes controllable and interpretable high resolution and fast face completion by learning generative adversarial networks (GANs) progressively from low resolution to high resolution. The proposed frequency oriented attentive module (FOAM) encourages GANs to highlight much more to finer details in the coarse to fine progressive training, thus enabling progressive attention to face structures. The novelty, however, is not strong as the simple summation provides reasonable performance as convinced in the progressive growing GAN paper.<BRK>The authors propose a progressive GAN with frequency oriented attention modules for high resolution and fast controllable and interpretable face completion, which learns face structures from coarse to fine guided by the FOAM. This paper is well written and is easy to understand. 2.The experiments are unconvincing. 3.In general, the framework of the proposed method is very common.<BRK>This paper proposes a face completion network that synthesizes the missing part in the face images with GANs. Moreover, the proposed Frequency Oriented Attention Module (FOAM) enables an interpretable coarse to fine progressive generative process. Overall,  the method shows how the face completion can be controlled and how the face completion is done by improving details. The attentive framework makes possible to do kinds of band pass filtering.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>This paper presents a method for adding credit assignmentto multi agent RL and proposes a way of adding a curriculumto the training process.<BRK>The paper is well written, motivated and clear to read. Therefore, I assign a rating of weak accept which I am happy to raise if clarity of paper can be improved.<BRK>Review:The paper is well written and easy to follow, and makes a good case by having a thorough experimental analysis, as well as a theoretical analysis of the credit function.
Reject. rating score: 1. rating score: 3. rating score: 8. <BRK>Summary: In this paper, a diffusion based VAE is proposed. 2) A sufficient condition to measure the consensus between latent and input data distributions. 2) The novelty in this paper is limited. The diffusion VAE was proposed in Rey’19 https://arxiv.org/abs/1901.08991 with a similar random walk procedure with transition kernels on the manifold of input.<BRK>The paper proposes a new generative model for unsupervised learning, based on a diffusion random walk principle inspired by the manifold learning literature. This "bi Lipschitz" property is only introduced in Sec 5.1, and the discussion is not too approachable to someone unfamiliar with the area. In particular:  it is not clear how precisely the discussion in this section relates to the VDAE algorithm described in the previous section. The experiments show that the proposed method can generate meaningful samples for synthetic manifold data, as well as on the MNIST dataset.<BRK>** EvaluationThe starting point of the paper seems very solid: diffusion maps are capturing the geometry of data very effectively and bringing some of those characteristics into the more scalable approach of VAE is an interesting approach. In the proposed method, this translates into introducing a learned diffusion map from manifold to an Euclidean space into the inference part.
Reject. rating score: 1. rating score: 1. rating score: 1. <BRK>The aim of this paper is to provide a theoretical analysis of adversarial training under the linear classification setting. Here "fast" is not the standard 1/T fast rates but, rather, a rate of o(1/log T) (in comparison to recent results that looked into the convergence of gradient descent with logistic loss to the hard margin SVM solution). For example, the authors decided to use x_i to replace the product y _i x_i in order to "simplify" notation. Second, the paper needs to be proof read. I don t see how this follows from the assumptions. So, this did not affect my score. I agree that the example they mentioned satisfy it but it is not a common loss used in practice.<BRK>TL;DR: The paper gives interesting, theoretical results to adversarial training. Some conclusions from theorems can be vague or informal, and therefore are not very convincing. 1.What is the specific question/problem tackled by the paper? The paper gives a theoretical analysis to the theoretically less studied procedure of adversarial training, and shows properties of adversarial training in comparison to regular training, for both linearly separable data or inseparable data. 2.Is the approach well motivated, including being well placed in the literature? However, the authors only analyzed linear classifiers. I am not certain that this is a very useful result, and I am open to counter arguments. In the end, the results are not very convincing or useful for informing deep learning research.<BRK>This paper provides some analyses of the difference between adversarial training and standard training for linear classification problem. The first result of this paper is interesting, that adversarial training converges faster than standard training. However, I still have two main concerns about the current version of the paper. 1.The paper is trying to develop rigorous results, but its writing is arguably not rigorous. See more concrete comments below. The results highly depend on the linear setting with convex losses. 8.Is w^* unique in Theorem 2?
Reject. rating score: 1. rating score: 3. rating score: 6. rating score: 8. <BRK>Temporal and positional encoding is important to many applications, including NLP, sound understanding and time series modeling, so the topic is certainly of interest. However, the method they propose offers very little that is new when compared to e.g.Vaswani (https://arxiv.org/pdf/1706.03762.pdf, section 3.5) (the authors acknowledge this work several times). In addition, the authors compare to a baseline that seems to consist of passing time as a float. Due to the incremental nature of the improvement and the weak baseline, I don t think this paper should be accepted to ICLR. 2.Often, positional encodings are used to encode ordering for a model architecture that is not inherently sequential. This is the case for the positional encodings in the transformer model. i.e.I think it s missing a  tau 4. Since positional encoding with Fourier transforms is well known, this seems like the relevant benchmark but it receives only a brief treatment. The authors compare these methods only on Event MNIST and only for 16 frequencies.<BRK>This paper introduces a particular learnable vector representation of time which is applicable across problems without the use of a hand crafted time representation. They motivate their problem well, explaining why time data is important to a variety of problems and situate their solution as an orthogonal approach to many current solutions in the literature. While I think this work has the potential to be a significant contribution, I rate this a weak reject because the theoretical motivation and analysis of the experimental results are lacking the depth of evidence I would expect for an ICLR paper. * p.6 Showing accuracy/recall across training epochs is not sufficient evidence to show that this is a useful representation. * p.8 I think sine functions make optimization harder because they make the gradient function periodic with respect to the weights, creating infinitely many local extrema. Historically this may have been an issue, but deep neural networks have so many local minima it might not matter.<BRK># SummaryThis paper proposes a simple representation of time (Time2Vec) for modelling sequential data. The idea is to apply multiple sine functions to the time with trainable period and offset and concatenate them together, which is similar to positional encoding [Vaswani et al.] except that the periods and offsets are learned. The results on several sequential modelling datasets show that Time2Vec performs better than naive representations and alternative baselines. # Originality  Although the proposed representation looks simple and similar to positional encoding [Vaswani et al.], the idea of parameterizing sine functions is novel and interesting. # Quality  The proposed idea is very simple but seems very effective in practice as shown by the empirical results. The paper also provides in depth analysis and ablation studies showing that each of the proposed component is helpful. Although the results presented in this paper look very promising, it would be much stronger if the paper presented results on other sequential modelling tasks such as machine translation and language modelling that the research community cares about much more. Figure 4 is not mentioned in the main text. # Significance  This paper proposes a simple but effective idea that can be potentially widely used by the research community. The paper would be stronger if it included more results on high impact sequential modelling tasks and datasets such as machine translation.<BRK>I would like to recommend an accept based on the following reasons:* Modeling time is crucial for quite a few machine learning tasks. * The authors are good at story telling and this makes the paper very readable and approachable. This increases the chance of the contribution made in this paper to be applied in real world applications. * This work did clear and detailed analysis on both the empirical results and the probing experiments.
Accept (Poster). rating score: 8. rating score: 8. rating score: 1. <BRK>The paper first points out how fair comparisons of NAS methods is difficult, especially those with different search spaces. The paper proposes making relative comparisons to random "samples" of architectures in search space to remove advantages of expertly engineered search spaces or training protocols. Also, the paper further investigates the case of commonly used the DARTS search space through ablation studies. The paper concludes with best practices to mitigate these disturbing factors to design NAS with reproducibility. The topic of empirical comparisons of NAS algorithms is already very difficult to tackle in a fair way, but it gives thought provoking strategies to evaluate the target NAS algorithms. Also, the fact that even random sampling (without search) provides an incredibly competitive baseline is quite informative and gives a very important recognition on how to design and evaluate NAS. The paper is well written and well organized, and I have no problems to report, but would like to make sure one thing. In section 4.1, the same 8 initial random architectures from DARTS search space are used for all of the variants? Since the non negligible impact of random seeds is reported, I just wonder how seeds are controlled in individual experiments.<BRK>The first contribution is to compare architectures found by 5 different search strategies from the literature against randomly sampled architectures from the same underlying search space. The second major contribution of the paper is to show that the state of the art performance achieved by the many neural architecture search methods can be largely attributed to advanced regularization tricks. The paper sheds a rather grim light on the current state of neural architecture search, but I think it could raise awareness of common pitfalls and help to make future work more rigorous. While poorly designed search spaces is maybe a problem that many people in the community are aware of, this is, to the best of my knowledge, the first paper that systematically shows that for several commonly used search spaces there is not much to be optimized. Besides that, the paper shows that, maybe not surprisingly, the training protocol seems to be more important than the actual architecture search, which I also found rather worrisome. It would be nice, if Figure 3 could include another bar that shows the performance of a manually designed architecture, for example a residual network, trained with the same regularization techniques. The paper highlights two important issues in the current NAS literature: evaluating methods with different search spaces and non standardised training protocols. I do think that the paper makes an important contribution which hopefully helps future work to over come these flaws.<BRK>In this submission, the authors conduct a series of experiments on five image classification datasets to compare several existing NAS methods. Based on these experimental results, they point out: 1) how a network is trained (i.e., training protocols/tricks such as DropPath, Cutout) plays an important role for the final accuracy; 2) within the search space, the existing NAS methods perform close to or slightly better than a random sampling baseline; 3) hyperparameters of NAS methods also have significant effect on the performance. The reasons are as follows:1) For the first finding of training protocol, several existing papers and books already discussed it, such as Li & Talwalkar (2019) and the book chapter {Neural Architecture Search} by Thomas, Jan Hendrik and Frank. 2) For the second finding of the search space and the performance of a randomly sampled architecture, existing work from Facebook AI Research group has studied this. And the existing work gives more experiments and discussion than this submission (from my own perspective). For example, only datasets of image classification are adopted. Another factor is the hyper parameter tuning (actually, the authors also mention this in the last paragraph on Page 4). The above mentioned existing work makes the contributions of this submission less, and the experimental results may not be convincing enough. These lead to a reject.
Reject. rating score: 6. rating score: 6. rating score: 8. <BRK>*UPDATE* I have read the other reviews and authors  responses. All the reviewers agree that improving single shot NAS is an important problem, and that sampling single paths can be a plausible approach for it that avoids weight coupling. Consequently, I have updated my rating to weak accept. I think the paper can be substantially stronger though. The key claim that set this paper apart from other single path NAS approaches is that they use a fixed distribution (in particular, the uniform distribution) to sample from unlike others like FBnet who use a trainable distribution. Reviewer2 has a similar question in their review. Could such a distribution also be parameter free and give good benefit over uniform distribution without needing to be updated during supernet training? Such an analysis of the prior distribution will make the paper even stronger. The paper studies a sequential optimization approach to neural architecture search that can provide some benefit over nested or joint approaches. The core challenge in sequential approaches (which first train the weights of a supernetwork; then search through possible architectures which inherit appropriate weights from the supernetwork) is that the weights for a giant network may not be optimal for the weights of a sub network encountered during subsequent architecture search. The core benefit of such an approach compared to nested approaches is that the subsequent search phase only needs to perform network inference with inherited weights; not train a sub network from scratch. The primary contribution is to fix a prior distribution over architectures and sample from them when training the supernetwork. This simple fix helps the weights of the giant network be more useful when inherited into any sub networks during architecture search. Does this paper specifically adopt more complex methods to address the shortcomings of gradient methods.<BRK>Authors revise the one shot NAS algorithm in this work. One shot NAS that employs a supernet to share the weights between subnets is an efficient NAS algorithm. Authors develop a new training paradigm to train the supernet sufficiently. Specifically, they uniformly sample a single path from supernet at each iteration to make the training effective and stable. Pros:1.Improve the one shot NAS by uniform path sampling. Cons:1.Authors only report the performance of the best architecture after fine tuning. It is interesting to see the performance of subnets after obtaining the supernet. Is the better subnet in supernet still better than others after fine tuning? 2.Given the large number of single paths, it is hard to train each one sufficiently within a supernet. Authors may demonstrate how one shot NAS can address the problem.<BRK>This paper presents a new one shot NAS approach. In the process of parameter optimization, different from the previous methods, the network samples the structure according to the uniform probability distribution. After training the supernet, the network uses the genetic algorithm to search the structure. + The method proposed in this paper is very efficient in the search stage and saves memory. During the searching stage, the constraints of the model can be restricted by the genetic algorithm. + This method could directly search architectures on the large scale dataset. Still, I have several minor concerns regarding the algorithm and experiments. 1.Why does the author think that the supernet needs to be trained by single path all the time? In the architecture searching space, under the same computational constraints, some models perform well, and some do not. Wouldn t it require much more time to optimize the supernet? When the temperature \tau is high, the distribution of the samples degenerates into the single path sampler, and the accuracy is used to optimize the parameter \theta, which makes \theta tend to select the well performed models. Therefore, what is the advantage of the single path sampling method over \tau controlled sampler? It seems that gradually pruning the worse performed search space would accelerate searching time. More analysis is preferred rather than the superior results from the experiments. For at the last of Page4, the author said  our choice block does not have an identity branch , and the listed architecture on page 13 has the identity. (This beyond the scope of this paper, but relates to the NAS area)4. 3 & Tab.4?Listing the parameters makes it easier for the followers. 5.What kind of structure do the mixed precision networks use? 6.While recalculating the statistics of all the BN,  is backpropagation required or just run the inference without gradient backpropagation. If we directly inherit the parameter from the supernet, can we accelerate the training of searched good structure? Will Top 1 acc lower than training from scratch? [r1] Bi real net: Enhancing the performance of 1 bit cnns with improved representational capability and advanced training algorithm
Reject. rating score: 3. rating score: 3. rating score: 6. rating score: 6. <BRK>I believe the authors would need to either revise this terminology (e.g., by referring to it as “soft topology”, as a generalized definition of hard topology), or provide a way to induce discrete subgraphs from the continuous architecture. The paper is well organized and easy to follow. I m a bit concerned about the technical novelty, however, as the approach can be viewed as an application of (a simplified version of) differentiable NAS to a search space analogous to the one used in [1].<BRK>I.Summary of the paperThis paper describes a principled strategy for searching for the mostsuitable neural network architecture out of a particular class ofarchitectures. Specifically, the problem is framed as an optimisationproblem over a set of directed acyclic graphs (DAGs) that correspond topotential network architectures. Is this a reference to limitations of existing networks? This needs to be assessed in the experimental section.<BRK>While the literature on manual design of architectures is thoroughly reviewed, there is missing related work in the context of neural architecture search, as already discussed above. Originality and significance. This paper addresses this problem to some extent.<BRK>The paper proposes a refinement of the idea behind DenseNets   rather than summing over all previous layers  outputs, sum a weighted combination instead where the weights are learned. Without additional information behind the numbers for the baselines in Table 3, it is unclear if TopoNets indeed give an improvement over the baselines (Random and Residual). This is practically achieved by enforcing a sparsity constraint on the learned weights.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>This paper present a novel approach to reinforcement learn from batched data that come from very different sources. To achieve this, they propose to learn a prior model and then constrain the RL policy to a trust region that does not deviate from the domain where the current policy is close to. The experiment itself shows superior performance than other methods. This method also works for real robots. The paper mentions stableness for the method however the analysis on this aspect is limited.<BRK>This paper proposes a novel off policy reinforcement learning algorithm based on a learned prior. The experimental results and comparison are sufficient. But the authors have not taken it into consideration in the optimization process.<BRK>They achieve this by constraining the policy that is being learned to stay close to a learned “prior policy” (using KL divergence as a distance metric). The authors provide experiments on the standard DM control suite tasks and some robotic tasks (both simulated and real world). For all experiments, the authors collect data by first running MPO in the standard RL setting (i.e.online data collection), and use the replay buffer from these successful RL runs to relearn a policy. The gains are more significant in the non standard robotics domains (Stack, Stack/Leave). For the paper to be accepted for publication, I think it needs to make a stronger argument (experimentally, at least) about the proposed algorithm being superior to ABM.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>In this paper, the authors investigate the use of ellipsoidal trust region constraints for second order optimization. The authors first show that adaptive gradient methods can be viewed as first order trust region methods with ellipsoid constraints. The ideas are interesting. I am also a bit confused about why different batch sizes were used for the first order gradient methods and the second order TR methods? The method overall doesn t seem to be able to match first order gradient methods, and it is not clear whether this is because of using the RMSProp/Adam preconditioner as a curvature matrix. Edit after rebuttal:I thank the reviewers for their response.<BRK>This paper proposes ellipsoidal trust region methods for optimization on neural networks. This approach is motivated by the adaptive gradient methods and classical trust region methods. The idea of the design is reasonable, but the theoretical and empirical results are not strong. I can not support acceptance for current version. 3.The experimental section only reports “log loss”, which is not enough to deep learning applications. The values of kappa in the second and the third sub figures of Figure 1 should be different.<BRK>My understanding is that the paper does not claim to deliver some great results here and now but instead suggest a promising direction ("that ellipsoidal constraints prove to be a very effectivemodification of the trust region method in the sense that they constantly outperform the spherical TRmethod, both in terms of number of backpropagations and asymptotic loss value on a variety of tasks"). It would not be a problem if the paper were the first to deal with second order methods. Minor notes:backprogations  > backpropagations  Update: I didn t change my score.
Accept (Poster). rating score: 6. rating score: 6. rating score: 3. <BRK>This paper proposes a method, Max Margin Adversarial (MMA) training, for robust learning against adversarial attacks. In the MMA, the margin in the input space is directly maximized. In order to alleviate an instability of the learning, a softmax variant of the max margin is introduced. Moreover, the margin maximization and the minimization of the worst case loss are studied. Some numerical experiments show that the proposed MMA training is efficient against several adversarial attacks. The authors could shorten the paper within eight pages that is the standard length of ICLR paper.<BRK>3.For the baseline, the authors lack some necessary baselines, like the following [1] and [2][1] Theoretically Principled Trade off between Robustness and Accuracy. Specifically, for correctly classified examples, MMA adopts cross entropy loss on adversarial examples, which are generated with example dependent perturbation limit. 2.For the epsilon, since it is different from the standard adversarial settings, how to guarantee the fair comparison? Summary:The paper propose to use maximal margin optimization for correctly classified examples while keeping the optimization on misclassified examples unchanged.<BRK>Theoretical analyses have been provided to understand the connection between robust optimization and margin maximization. The main difference between the proposed approach to standard adversarial training is the adaptive selection of the perturbation bound \epsilon. This makes adversarial training with large perturbation possible, which was previously unachievable by standard adversarial training (Madry et al.) But it turns out the MMA benefits a lot the clean accuracy? 2.The margin d_\theta in Equation (1)/(2)/... defined on which norm? The experimental settings are not clear, and are not standard. The authors seem have misunderstood my request for CWL2 results, I was just suggesting that the average L2 perturbation of CWL2 attack can be used as a fair test measure for robustness, instead of the AvgRobAcc used in the paper, and the susceptible comparison between  MMA 12 vs PGD 8, or MMA 32 vs Trades. What CIFAR10 \ell_{\infty} means: is it the CW L2 attack, used for training, or for testing? How the m models were trained? Since MMA changes \epsilon, how to fairly compare the robustness to standard epsilon bounded adversarial training is not discussed.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>The paper presents a way of using generated explanations of model predictions to help prevent a model from learning "unwanted" relationships between features and class labels. I like the high level idea of this work and agree that there is not much work on using prediction explanations to help improve model performance.<BRK>The motivation for the proposed research is interesting and has some merit. Which prior knowledge and explanations to use seem to affect a lot about the learned model.<BRK>This paper presents a method intended to allow practitioners to *use* explanations provided by various methods. Overall, this is a nice contribution that offers a new mechanism for exploiting human provided annotations. I do have some specific comments below. I am not sure I agree with the premise as stated here. The experiment with MNIST colors was neat.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>This paper proposes to address the problem of spatio temporal forecasting in urban data, in a way that can accommodate regions with highly distinct characteristics.<BRK>Summary: This paper proposes a clustering attention based approach to handle the problem of unsmoothness while modeling spatio temporal data, which may be divided into several regions with unsmooth boundaries.<BRK>The major concern is the presentation of this paper. First, the key problem to address is claimed to be the spacial and temporal unsmoothness.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>Based on the concerns of novelty, lack of considering node topologies, and lack of comparison with strongly related methods, it is hard to recommend acceptance of this paper.<BRK>  Minimal theoretical novelty: The paper is too focussed on the empirical advantage achieved on the datasets used in the experiments. p3: "a more sophisticated neighborhood functions". There are too many typos and grammatical mistakes.<BRK>I am not a direct expert in the area and felt that the paper was somewhat lacking. Applications on LinkPrediction and Node Clustering are demonstrated on three benchmark datasets. If this is not used then the alternative scheme used should be explained and argued for.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>4.The submission proposes a new large scale temporal event dataset, and states that this dataset is more realistic than the current benchmarks. However, the reviewer does not find any argument in the paper to support this statement. This paper could be weakly accepted because the paper introduces new regularization schemes based on the tensor nuclear norm for tensor decomposition over temporal knowledge graphs, which could be a significant algorithmic contribution. However, the paper does not provide information about error bars as well as the unfiltered version of the experiment results.<BRK>The work in this paper is focused on the task of knowledge base completion, dealing specifically with temporal relations, which is quite important in practice, and also not as well studied in literature. They present an order 4 tensor factorization for dealing with temporal data, which is a nice extension of the work in Lacroix 2018. The authors introduce different forms of regularization to extend to the order 4 tensors. 3.Finally, the authors mine wikidata for temporal relations and contribute a dataset based on wikidata that is much larger than existing datasets for this task. Areas to be addressed:1. Also, it seems that the results in Table 3 are comparable to the “ranks multiplied by 10” setting in Table 2.<BRK>In this paper, the authors study an important problem, i.e., time aware link prediction in a knowledge base. In particular, the authors design a new tensor (order 4) factorization based method with proper regularization terms shown in Eqs. (4 6).The authors also prepare a dataset which may be helpful for further study on this topic, which is highly appreciated. The authors are encouraged to include those works in the related work and in the empirical studies.
Reject. rating score: 1. rating score: 3. rating score: 6. rating score: 8. <BRK>This paper focuses on verifying sequential properties of deep beural networks. Linear Temporal Logic (LTL) is a natural way to express temporal properties, and has been extensively studied in the formal methods community. The authors extend that to get conservative estimates of the level of satisfaction of the STL formula, and use that in the training process. Overall : Though the direction of this work is interesting but lacks sufficient technical novelty.<BRK>I feel language generation is probably not a suitable task for the proposed training method. I am okay with accepting this paper as it does have some interesting bits, but it is clearly on the borderline and can be further improved. This paper makes valid technical contributions, especially the conversion from STL specifications to lower bounds of the quantitative semantics is interesting.<BRK>I recommend ACCEPTing this paper, albeit with low confidence. Section 4 is very technical, and I do not have enough knowledge to verify it thoroughly, but the proposed approach seems to make sense. These three experiments seem to be enough variety to prove the utility of the method.<BRK>This paper presents a way to train time series regressors verifiably with respect to a set of rules defined by signal temporal logic (STL). The resulting lower bound of an auxiliary quantity (which is required to be non negative) is then maximized for verifiability. This technique is demonstrated on three tasks and compares favorably to the baseline from Wang et al.(2019).I am not an expert in this area. Therefore I recommend acceptance.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>Experiments demonstrate that this approach can significantly improve perplexity scores on several datasets popular for NLP. NLP is not an area of research I m very familiar with so this review is limited to my understanding of temperature scaling as a general technique to improve learning. The paper proposes to learn a function that given context, adjust the temperature automatically.<BRK>Experiments on the language modeling datasets show some effects of the method. The paper parameterizes this mechanism with DNNs for the language model. Though the idea looks interesting, it fails to explain why the scaling is better than other dynamic temperature scaling frameworks. The experiments are not solid.<BRK>This work proposes a learned and context dependent way to calculate the temperatures for the softmaxes. Can the authors explain the motivation behind the use of softmax? The analysis is also interesting. I vote for an acceptance, if the authors can polish the writing.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>After Rebuttal:After the discussion with the other reviewers, I tend to agree with them  regarding the need for more experimental evidence given the strong title and claims of the paper. ************************************The paper aims to answer the question proposed in the title. The authors conduct a series of experiments using well known hierarchical and non hierarchical algorithms in order to extract the what is it that makes hierarchical reinforcement learning (HRL) efficient. I really enjoyed reading the paper and I believe it is an important contribution to the community. I believe the experiments are sufficient to support the hypothesis stated in the paper. For the previous reasons I suggest the acceptance of this paper, although some improvements could be made. Things to improve:The data from all the figures presented in the paper could  be used to perform statistical tests to support the authors’ statements.<BRK>This is an interesting paper, as it tries to understand the role of hierarchical methods (such as Options, higher level controllers etc) in RL. The core contribution of the paper is understand and evaluate the claimed benefits often proposed by hierarchical methods, and finds that the core benefit in fact comes from exploration. While the conclusion suggesting HRL leading to better exploration seems interesting, I am not sure whether this is in fact too surprising? While in these approaches, often the benefits are claimed to be in terms of both exploration and transfer learning, this paper seems to contradict that? Experimentally, I would expect a more wide range of task setups and domains to be studied   since this is mainly a paper based on experimental studies and trying to draw conclusion for existing HRL methods without proposing new approaches.<BRK>This paper evaluates the benefits of using hierarchical RL (HRL) methods compared to regular shallow RL methods for fully observed MDPs. 1) The claim needs more support. Maybe on these sets of tasks, exploration is the main issue, and not the training. In Sec 5, the authors test their method on a specific form of HRL method, but from Introduction and Conclusion, it seems that they are generalizing this conclusion to all HRL methods. The authors need to be either explicit about that these results only hold for HIRO, or provide some evidence that supports this generalization to other HRL methods. Wouldn’t change in this ratio, can also lead to a different result for that comparison (H1 and H3)? References: [1] Lillicrap, Timothy P., et al."Continuous control with deep reinforcement learning."
Accept (Spotlight). rating score: 8. rating score: 6. rating score: 6. <BRK>Although I recognize that to do so would be difficult, I think what would add a lot to this paper would be side by side comparisons of real neural data with “neural” data from the artificial rodent. The authors use a virtual rodent to study flexible behavior, a key concept at the intersection of AI and neuroscience. I acknowledge that it is a feature of the paper that so many different analysis techniques from neuroscience—dynamical systems to representation analysis to lesion studies—were applied, and the sheer breadth of the analysis was impressive, if difficult to evaluate.<BRK>This is a fascinating paper that uses methods from computational neuroscience to characterize a neural network that controls a virtual rat (or, well, something ratlike). So I welcome this direction of research. The learning of a network that can perform these four independent tasks is quite impressive in its own right. I applaud the intent of the paper, the competence with which it was executed, and the learning of the network.<BRK>  Update after rebuttal  I thank the authors for their rebuttal and the revisions. Currently, the architecture choice seems to be dictated primarily by trainability considerations (more specifically, trainability by current deep learning methods). This paper introduces a virtual rodent model with a complex set of actuators and visual and proprioceptive inputs. The effort put into training and analyzing the rodent model is quite impressive. However, my main concern about the paper is that given the architecture choice made in the paper, most of the main results do not seem very surprising. Why was this particular choice made?
Reject. rating score: 6. rating score: 6. rating score: 6. <BRK>The empirical results suggest that the proposed approach is able to generalize better than traditional architectures (which all have the implicit assumption that all processes interact). This paper is well written and it provides a very thorough empirical analysis of the proposed idea. Moreover, for how long was PPO (and RIMs PPO) trained in terms of number of frames? I also agree with concerns raised by other reviewers. As I stated in the discussion with the authors, the clarifications and additional experiment does improve the paper a bit.<BRK>But the authors did not elaborate how significant will this structure change the state of art. The reviewer feels that the paper stands at a high level in general, but lacks concrete examples/applications for general readers to appreciate the significance.<BRK>This paper draws inspiration from Physical world and considers an independent mechansim among recurrent modules. For the model itself, I appreciate its simplicity, but I also have some concerns. I believe the framework will be more interesting if the model can determine this number automatically. However, it is still interesting to see that RIMs obtain significant gains over some baselines. I suggest the authors make the experiments more self contained in the main paper, such that authors do not need frequently scroll down to the appendix and check the details.
Reject. rating score: 3. rating score: 3. rating score: 8. <BRK>Thank you for an interesting read. As far as I understand, the paper claims two contributions:1. 2.The combination of the above two inference methods on S(N)LDS is new to the best of my knowledge. The proposed approach performs significantly better which is a good sign.<BRK>STRUCTURE:The paper is well written and easy to understand. The transition distributions are non linear. While the problem of unsupervised time series segmentation is an important one, I m not sure the proposed technique addresses it completely.<BRK>In this paper, the authors consider the problem of learning model parameters of a switching nonlinear dynamical system from a dataset. The main text of the paper is written well, but the experimental result section seems to be rushed and needs to be polished slightly. Some minor comments are added below. I am reasonably positive about the paper.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>I think that the paper displays some appealing empirical and methodological contributions, but it is not sufficiently theoretically grounded. For this reason, I would vote for rejection. I would advise the authors to rephrase their work as a primarily empirical contribution, in order to emphasize the merits of their method over a lacking theoretical analysis.<BRK>If the authors prove it in this paper, implying it in this paragraph is also helpful. 1) The authors investigate an important problem and I would appreciate the authors if they could motivate its importance more in their work. A bit of help from the authors would be appreciated. I also recommend to even not calling it a theorem since it, as mentioned, is as clear as the definitions.<BRK>Also, experiments on more tasks (such as Atari) are needed to evaluate the performance of the purposed method. I did not see why doing this approximation is good from both theoretical and empirical perspectives.
Accept (Talk). rating score: 8. rating score: 8. rating score: 6. <BRK>Assuming a neural network architecture, they compute the gradients of each unlabeled example using the last layer of the network (and assuming the label given by the network) and then choose an appropriately diverse subset of these using the initialization step of kmeans++. 1.The authors keep emphasizing a connection to k dpp for the sampling procedure emphasizing diversity. 4.Finally, recent work in Computer Vision has shown that uncertainty sampling with ensemble based methods in active learning tends to work well. Overall I think this paper is a good empirical effort that I recommend for acceptance. "The power of ensembles for active learning in image classification."<BRK>This paper introduces an algorithm for active learning in deep neural networks named  BADGE. >>> Update after rebuttal: I stand by my score after the rebuttal. This is a very well written paper that seems to make a meaningful contribution to the field with a very good justification for the proposed method and with convincing empirical results. Below I have a couple of (minor) comments and questions:1.<BRK>The paper proposes a new method for active learning, which picks the samples to be labeled by sampling the elements of the dataset with highest gradient norm, under some constraint of diversity. The aforementioned gradient is computed w.r.t.the predicted label (rather than the true label, that is unknown) and diversity is achieved by sampling via the k MEANS++ algorithm. 5) The paper builds on the claim that the gradient norm w.r.t.the prediction is a lower bound for the gradient norm induced by any other label, yet Proposition 1 that proves it is in Appendix B. 9) The random baseline seems to be very competitive.
Accept (Poster). rating score: 8. rating score: 6. rating score: 3. <BRK>They also experiment with using idf to weight importance. Overall, I like the paper   it is simple and effective on its goal task of automatic evaluation for text generation. I think we are moving that way as a field and this paper proposes a useful method and is additionally a good study on the subject. Edit: I also wonder if incorporating idf would be better if the values were computed by a larger corpus. I think it would make the most sense to compute these from the training data for the underlying BERT models. They use semantic similarity to fine tune NMT systems with their own embedding based (semantic similarity) metric and they found some nice properties from training in this way. Have you tried BERTScore on sentence similarity tasks? It s possible BERTScore could have strong performance and some readers may wonder this.<BRK>Paper ContributionsThis paper introduces a new text generation scoring approach using BERT, called BERTScore. I like that the authors were open and clear regarding this in their discussion. The authors haven t come up with a recommendation for a single configuration of their approach. I identify this ambiguity between BERTScore versions as an important weakness of the paper. It s unclear throughout whether words or wordpieces are the main token being considered. I recommend adjust the language to be more consistent throughout. The IDF scores would be stronger if they were computed on a bigger in domain corpus than the gold test set.<BRK>This paper presents a simple application of BERT based contextual embeddings for evaluation of text generation models such as machine translation and image caption generation. An extensive set of experiments have been carried out to show that the proposed BERTScore metric achieves better correlation with human judgments than the existing metrics. Overall, the paper is well written and the motivations are clear. However, I am not sure about the technical novelty of the paper as the proposed approach is a natural application of BERT along with traditional cosine similarity measures and precision, recall, F1 based computations, and simple IDF based importance weighting. Other comments:  It would be interesting to see how the proposed metric performs to evaluate paraphrase generation and text simplification models as the models need to follow specific constraints such as semantic equivalence, novelty, simplicity etc. Another limitation of the proposed metric is memory and time complexity as it takes relatively more time to evaluate the sentences compared to BLEU, as authors acknowledged in Section 5.
Accept (Spotlight). rating score: 8. rating score: 6. rating score: 6. <BRK>This paper studies the problem of designing effective exploration strategies in multi agent domains. The key idea is to define one agent s exploration in terms of its interactions with other agents. My main reservation is a lack of comparisons to single agent exploration methods. I expect that this paper will encourage future work to explore more problems in this area.<BRK>This paper proposes methods for incentivizing exploration in multi agent RL. There are two approaches that are proposed, both framed as influence maximization (of either the state transitions or the decisions of the other agents). This influence objective is the appended to the standard intrinsic motivation objective for single agent RL. The proposed approaches are pretty elegant, and in a sense seem fundamental. (See related work comments below.)<BRK>Summary:  This paper proposes the use of two intrinsic rewards for exploration in MARL settings. The first one is an information theoretic influence (EITI) bonus and a decision theoretic influence (EDTI)  bonus. Can you discuss in more detail the difference between EITI and the intrinsic reward based on social influence used in Jacques et al.(2018)?They seem to be quite similar conceptually and the related work part related to this is rather vague. The experimental section is thorough, the authors include relevant ablations, baselines and popular algorithms used in MARL settings.
Accept (Poster). rating score: 6. rating score: 6. rating score: 1. <BRK>The authors build on recent work for non autoregressive encoder decoder models in the context of machine translation (most significantly [Gu, et al., ICLR18]) and adapt this to dialogue state tracking. However, it is done well and the results are convincing and interesting. The resulting model achieves state of the art empirical results on the MultiWOZ dataset while incurring decoding times that are an order of magnitude faster.<BRK>[Contribution summary]Authors propose a new model for the DST task that (1) reduces the inference time complexity with an non autoregressive decoder, and (2) obtains the competitive DST accuracy (49.04% joint accuracy on MultiWoZ 2.1). [Comments]  The proposed model is well motivated and well structured. Some of the details are not entirely provided   e.g.please provide the loss hyper parameter values (e.g.Eq.23) and optimizer parameters for the training. Overall presentation, notations, figures, etc.<BRK>This paper proposed a model that is capable of tracking dialogue states in a non recursive fashion. The paper did illustrate a strong experimental results on a recent dataset comparing with many state of the art models. However, it is not clear how much innovation this work generates and how the ICLR community would benefit from the problem that the paper is addressing.
Accept (Poster). rating score: 8. rating score: 6. rating score: 3. <BRK>The paper introduces a meta learning approach that can learn from demonstrations and subsequent reinforcement learning trials. The only concern I have is the presentation of the paper. This should at least be done in the appendix. The approach seems really interesting and I think combining demonstrations with reinforcement learning for meta learning is a very promising approach.<BRK>The paper proposes an approach for combining meta imitation learning and learning from trial and error with sparse reward feedback. I found the idea of having separate networks for the two phases of the algorithm (instead of recollecting on policy trial trajectories) interesting and possibly applicable in other similar settings. The paper has a comprehensive analysis of the advantages of the method over other reasonable baselines which do not have the trial and error element.<BRK>This work focuses on meta learning from both demonstrations and rewards. Currently it looks like that the two parameters are fixed in meta testing. If so, this is a bit strange. I d like to see an example formulation of the policy.
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>The paper proposes an implicit function approach to learning the modes of multimodal regression. The basic idea is interesting, and is clearly related to density estimation, which the paper should have discussed.<BRK>The paper proposes a parametric modal regression algorithm for multi modal distributions. Existing non parametric approaches to learning the conditional mode are difficult to scale. The key idea is to learn a (parametric and implicit) function f(x,y) whose minima(s)  y  corresponds to the conditional modes. However, the paper does not explain clearly how the above idea is put to practice as an algorithm in Section 3.<BRK>This paper considers the regression problem in scenarios in which the conditional distribution of the response variable y given the input x is multimodal. I think this is a very interesting and novel approach to regression. To achieve this, the authors take inspiration from the implicit function theorem and additionally seek an f with ∂f/∂y  1 at the modes for each x.
Accept (Poster). rating score: 8. rating score: 6. rating score: 3. <BRK>Overall, this reviewer thinks this is a very interesting approach with a lot of potential, however, the experimental validation could be stronger. Embedding in previous work:Several key references should be added. I acknowledge the short time the authors have  to run additional experiments.<BRK>A more sincere baseline would be to take a baseline model and apply it to SELFIES, while showing that the genetic algorithm based approach shows more viability. If it is well trained and with a high penalty (e.g.time adaptive case), the GA will pick high J(m) molecules that are in the dataset. Because of the novel genetic algorithm based search method, as well as the large improvement on prior literature, I am leaning towards an accept for this paper.<BRK>Zinc is a database of small drug like molecules. Prior approaches to solve this problem has explored approaches like VAEs, GANs and Genetic Algorithms. Code for this (along with examples) can be found in the MOSES toolkit: https://github.com/molecularsets/moses
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>It was shown that in the context of natural distribution shifts, no current robustness intervention can really outperform standard models without a robustness intervention. Let us take adversarial robustness as an example, I am NOT surprising that the robustness on crafted adversarial examples cannot be generalized to the robustness over natural distribution shifts. 2) The significance of  effective robustness  is not clear. I am still not fully convinced by the significance of the findings in this work. In the paper, the authors highlighted that "our results show that current robustness gains on synthetic distribution shifts do not transfer to improved robustness on the natural distribution shifts presently available as test sets."<BRK>Summary: This paper tries to evaluate whether robustness ‘interventions’ such as robustness to adversarial examples and other synthetic distribution shifts on natural distribution shifts. It’s unclear what the distribution shift is and whether there is a distribution shift. Hence it seems unreasonable to use this dataset for a shift. It does not seem unreasonable that robustness to one kind of shift doesn’t transfer to another. It seems like the right questions to ask would be the following: Do the synthetic robustness goals seem like they would occur in natural settings?<BRK>  Update after rebuttal  I thank the authors for their detailed rebuttal. The authors argue that the synthetic robustness measures considered in this paper are not predictive of natural robustness when the effect of baseline accuracy is subtracted. However, I have a number of questions and concerns about the results. I would be happy to increase my score if the authors could address some of these issues:1) Another important recent benchmark not mentioned in the paper is ImageNet A (https://github.com/hendrycks/natural adv examples).
Reject. rating score: 3. rating score: 8. <BRK>This paper presents the retrospective loss to optimize neural network training. Extensive experimental results on a wide range of datasets are provided to show the effectiveness of the retrospective loss. The retrospective loss is additionally controlled by two hyperparameters, the strength parameter K and the update frequency T_p. The geometric intuition of the added loss term is that this pushes the model away from the model at iteration T_p. More detailed questions:  What are the standard deviations for the experimental results (as you reported in Table 4 but not in other experiments)?<BRK>The paper proposes a new loss function which adds to the training objective another term that pulls the current parameters of a neural network further away from the parameters at a previous time step. However, I am not entirely convinced about the intuition of the proposed method and I think further investigation are necessary. While the method is simple and general, it also seems to be rather heuristic and requires carefully chosen hyperparameters. post rebuttal I thank the authors for clarifying my questions and providing additional experiments. I think that especially the additional ablation studies and reporting the mean and std of multiple trials make the contribution of the paper more convincing.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>I encourage the authors to pursue this line of work, but test this on more complex prediction taskswhere entirely model based approaches are unreliable, and entirely black box estimators are sampleinefficient.<BRK>  Overall comments  This paper proposes to generalize approaches to physics based learning (PBL) by performing network architecture search (NAS) over elements from PBL models found in the literature. I think the idea has merit and rather like it.<BRK>The authors apply neural architecture search techniques to the problem of physics based learning. It is interesting because it cleverly tackles the challenge of manually designing priors and network architectures. Despite of the above upsides, I have the following questions/concerns. 1.There is limited technical novelty as the entire method is mainly based on previous work on neural architecture search.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>This paper proposes a novel approach to fair inference/learning by using the Renyi correlation in place of the standard correlation measures (e.g.Pearson correlation) as a measure of "unfairness" expressed as a form of dependence between an outcome and a sensitive variable (which includes a number of standard group fairness definitions including demographic parity and equality of odds). The experimental results show quite convincingly that the trade of is improved by Renyi correlation as compared to the use of standard correlations.<BRK>This work shows an interesting approach to introduce fairness to machine learning. The introduction provides a valuable overview and characterization of existing work and motivates the approach proposed in this work. First of all, for readers not familiar with the task used here, a more detailed description would be desirable, including moving Supplementary Section D into the main text.<BRK>Based on this, they reformulate the objective which can be optimized more efficiently. They show the performance of their model for supervised and unsupervised learning problems on 4 different dataset by comparing to standard correlations such as Pearson. Overall the paper is clearly written and I liked the idea of using renyi correlation which also has a nice theoretical formulation allowing to be optimized more efficiently. Since their main focus is on discrete case, the authors can show if training a word embedding model with renyi regularization helps improve fairness of word embeddings. I have several question regarding the paper:The datasets that authors use have a predefined feature space. Since the model is trained with gradient descent, how would a more simple baseline where the gradient of the sensitive feature is penalized work?
Accept (Poster). rating score: 6. rating score: 6. rating score: 3. <BRK>2.2.Minor: As for the notation, I found $A_j$ quite strange for a policy; you may want to consider something like $\pi_j$. The paper is in general well written and motivated. There are however certain issues that should be addressed. 2.1 What is the optimal value function of an agent?<BRK>The main idea is to have local (agent specific) value function and one global value function (for all agents). I found the paper interesting and empirical evaluation is good. However, my knowledge in the field is quite limited.<BRK>The authors propose a framework for combining value function factorization and communication learning in a multi agent setting by introducing two regularizers, one for maximizing mutual information between decentralized Q functions and communication messages and the other for minimizing the entropy of messages between agents. How does the approach work in competitive environments? The paper addresses an interesting problem, and the authors show that their approach gives good performance compared to alternative approaches even when a large percentage of communication is cut off between the agents. Questions/Comments:  Implementation details (e.g., hyper parameters, model size) are missing from the paper.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>This paper proposes to apply the Neural ODE framework (Chen et al 2018) for image segmentation. The method is here applied in two segmentation tasks: kidney segmentation and salient object detection. The concept underlying the paper is interesting, and leverages on very recent advances in the field. Unfortunately the content of this work seems quite preliminary in terms of presentation and experiments. Given that the the training of neural ODE is not straightforward and computational expensive, the use of this model for achieving a tiny accuracy improvement seems overkill for this kind of application.<BRK>This paper proposes to utilize Neural ODEs (NODEs) and the Level Set Method (LSM) for the task of image segmentation. The authors propose two architectures and demonstrate promising performance on a few image segmentation benchmarks. This suggests that the main benefit of the proposed method comes from applying an NODE based architecture to a supervised learning task, rather than the inductive prior brought by LSM. Given this, I think a much more proper way of presenting this work should be from the view of applying an NODE to the supervised image segmentation task. For example, \gamma^{(1)} is not defined or explained in main text.<BRK>This paper proposes to integrate Neural ODEs into image segmentation using level sets. Moreover, it seems to me that the saliency object detection experiment is not a very convincing one as the methods compared are a bit old (mainly from 2015 2016). I strongly recommend the authors try to publish this at MICCAI focusing on kidney segmentation or any other related medical imaging application.
Accept (Poster). rating score: 8. rating score: 6. rating score: 3. <BRK>In this paper, a framework for building group CNN with an arbitrary Lie group G is proposed. 3.In comparison with standard CNN, the effectiveness of the B Spline based G CNN is validated through experiments on two typical data sets. 2.[Experiments] The proposed G CNN has some similarities with data augmentation (like rotation, scaling) based CNN. Then, how better can the G CNN perform than CNN with data augmentation? 3.[Implementation] Considering the complicated mathematics in this paper, I am afraid that implementation of the proposed G CNN is also very hard. It would be better for the authors to discuss the implementation.<BRK>This paper proposes a neural network architecture which that enables the implementation of group convolutional neural networks for arbitrary Lie groups. This lifts a significant limitation of such models which were previously confined to discrete or continuous compact groups due to tractability issues. It relies heavily on field specific terminology and as such is likely to be accessible to a relatively small subset of researchers. This looks to me like a solid contribution, however I m really not qualified to judge.<BRK>The paper proposes an (approximately) equivariant neural network architecture for data lying on homogeneous spaces of Lie groups. The approach is appealing in its simplicity and generality. No need to worry about irreducible representations and Fourier transforms, the formalism works for virtually any Lie group, no problem with non compact groups. The authors assure us that "we find that it is possible to find approximately uniform B splines... e.g.by using a repulsion model". The main difference of the present paper relative to that one is that the idea is fleshed out in a little more detail and is generalized from SE(2) to arbitrary Lie groups.
Reject. rating score: 3. rating score: 6. rating score: 8. <BRK>Contribution:This paper proposes PassNet an architecture designed for soccer pass analytics. PassNet approach is similar to UNet, having a downsampling and upsampling modules with a set of skip connection between the two modules. It seems that the paper is a direct application of Unet type of architecture on the specific problem of pass analytic.<BRK>The aim of the system presented in this paper is to produce a 2D map of probabilities showing the chance of successful completion of a soccer pass to all locations on the field, given coordinate locations of players and the ball sampled over time. Even with this issue, though, I feel that this is an interesting application and system that seems reasonable in its current state, if with important caveats. However, I d encourage the authors to discuss these differences and issues of output interpretation, and to try addressing if possible.<BRK>It also shows results regarding the probability that a pass to a particular position is attempted. The related work appears to be extensive and the description of the design choices of the architecture and the training procedure is clear and thorough. You mention that you tried a class weighting with no sampling approach but that it did perform as well. Why not include these results in the paper? It appears to successfully address an interesting problem, it is well organized, and its solution methodology may have applications to other related problems.
Reject. rating score: 1. rating score: 1. rating score: 1. <BRK>The paper proposes a variant of the max sliced Wasserstein distance, where instead of sorting, a greedy assignment is performed. As no theory is provided, the paper is purely of experimental nature.<BRK>The paper suggests a new way to train max slides Wasserstein GANs. The authors themselves described that the difference is ‘instead of sorting the samples of the projections we iteratively select the most similar pairs of them for loss calculation’. I think it is not enough for a publication. ‘As it can be seen from the figure, for example…’ I think ‘for example’ here is redundant.<BRK>This paper proposes two alternative approaches to max sliced Wasserstein GANs. Because of these, I would not be able to recommend acceptance of this paper. The other proposal, described in Section2.3, is a hybrid of the greedy approach in Section 2.2 and the original sliced Wasserstein distance.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>The paper considers distributed stochastic gradient descent, where some (unknown) compute nodes may be unreliable. New heuristics for filtering out replies from unreliable servers are introduced alongside a new protocol that helps keeping nodes in sync. As far as I can tell, the experiments do not really show an improvement over existing methods in this domain. This is not my area of expertise, but I cannot recommend the paper for publication in its current form as(a) it s not clear to me that the paper improves on existing methods, and(b) it s not clear to me what the real novelty of the work is. They clarified some aspects for me, and the paper appears to have improved over the rebuttal period. I did not change my rating, but I want to emphasize that this is only because my knowledge of this field is so limited.<BRK>Here s another shorter attemptI haven t really followed along the literature for this. But from the results, it s not immediately clear to me what practical setup this is useful in. The authors assume perfect network synchrony, they have a 25% overhead on TensorFlow and they have a comparison to another algorithm that operates under different assumptions. Who would ever use this and why?<BRK>This paper introduces an algorithm to build distributed SDG based training algorithm that are robust to Byzantine workers and servers. I am not very familiar with this area of research, but I feel the authors did a good job providing clear explanations and introducing all the relevant concepts needed to understand the proposed algorithm. The experimental section of the paper is lacking in some aspects:  One of the main ideas introduced in the paper is that of filters to check the legitimacy of models from model servers.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>This paper studies the different types of noises that could be added to the training image dataset while training an CNN model for classification. They are running experiments of 5 different known noise functions, on two image datasets, on a single deep learning models. Maybe for this combination speckle noise (and not Gaussian, as pointed out in the comments by the authors) is better. Writing of the paper could be improved: 1. The need for noise based augmentation of is well known (Section 1).<BRK>The paper studies the effect of various data augmentation methods on image classification tasks. The Authors propose the Structural Similarity (SSIM) as a measure of the magnitude of the various types of data augmentation noise they consider. The Authors argue that SSIM is superior to PSNR as a measure of the intensity of the noise, across various noise types.<BRK>This paper aims at analyzing the effect of injecting noise to images as data augmentation in training CNN for the image classification task. Experimental results on two sub datasets of ImageNet suggest that Speckle noise would lead to better CNN models. The results is too specific to both the model chosen resnet18v2 and also in the chosen dataset. Besides, my bigger concern is that the contribution of this work is highly limited, since there are a bunch of data augmentation techniques: cropping, flipping, color space transformation, rotation, noise injection, etc.
Reject. rating score: 1. rating score: 3. rating score: 8. <BRK>This paper proposes a method for adversarial defense based on generative cleaning. In the one place where a larger number of attack iterations is used (100 for BPDA) the gap with adversarial training mostly vanishes. In the absence of these best practices it is impossible to assess the validity of the results, so the paper should be rejected.<BRK>This paper developed a method for defending deep neural networks against adversarial attacks based on generative cleaning networks with quantized nonlinear transform. The network is claimed to recover the original image while cleaning up the residual attack noise. The authors developed a detector network, which serves as the dual network of the target classifier network to be defended, to detect if the image is clean or being attacked. This detector network and the generative cleaning network are jointly trained with adversarial learning so that the detector network cannot find any attack noise in the output image of generative cleaning network. 3.The proposed defense showed only empirical results against the target attack. It seems to provide no theoretical / provable guarantees.<BRK>This paper proposes a new method to defend a neural network agains adversarial attacks (both white box and black box attacks). The authors use state of the art attack methods on various models, and the proposed model consistently outperforms all baseline models, even dramatically outperforming them for some specific attack methods. Comment:Is there a reason the authors did not test the same set of attack methods for SVHN as they did for CIFAR 10?
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>There is a required $\epsilon>G62d_1(\mu_V,\mu_T)^2$ in the results. The authors consider constant step sizes.<BRK>The authors use these results to motivate variants of existing optimization algorithms. The paper is interesting but its message is a bit blurred to me.<BRK>The main results in the paper are built upon a new, general framework to analyze the SGD type of algorithms. The authors should elaborate more on this point. What is the computation overhead?
Reject. rating score: 1. rating score: 6. rating score: 6. <BRK>The paper proposes an backpropagation free algorithm for training in deep neural networks. Quality: Unfortunately I have a number of major issues with this respect. Authors conduct experiments on MNIST and CIFAR where they find their method to reach performance similar to BP. I would also appreciate a clear discussion on the theoretical properties of the algorithm, for example, is it guaranteed to converge to a critical point of some loss function?<BRK>Nonetheless, I think the paper does offer an interesting proposal of a more biologically plausible form of deep learning. The idea relies on feedback mechanism that can resemble local connections between real neurons. This paper is an interesting approach to provide a reinforcement learning paradigm for training deep networks, it is well written and the experiments are convincing, although more explanation about why these specific architectures were tested would be more convincing. I also think the assumptions about feedback connections in real neurons should be visited and more neuroscientific evidence from the literature should be included in the paper.<BRK>It should be noted that other biologically plausible schemes like feedback alignment were able to solve CIFAR and other smaller image classification tasks, but struggled when applied to the larger scale ImageNet problem. The paper could be improved by pointing to this limitation of the present work, the possibility that performance could change on larger tasks, and the need to conduct larger experiments in future work. Personally I think the statement at the beginning of the introduction that only RL occurs in animals and humans is overstated. It seems so from what I understand, and this may be a straightforward way to explain the algorithm.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>A method that was proposed by authors deals with a problem of non uniform data in time series. Thus, the authors propose to search for a kernel in a form neural network. To this term they also add bias term which is also a neural network. Basic idea of the paper seems promising, but reported results are only partial. Since a paper is experimental, i.e.no theory at all, then the main judgement should be based on experimental results. They are not convincing, as CCNN is compared with methods that can not be called state of the art.<BRK>The paper proposes a continuous CNN model to accommodate the nonuniform time series data. The model learns the interpolation and the convolution kernel functions in an end to end manner, so that it can capture the signal patterns and be flexible. The paper also introduces an application of the proposed CCNN by combing with temporal point process. Overall, the paper has some incremental improvements on the existing methods that dealing with the nonuniform time series data. However, this section and the introduction can be better organized to distinguish the novelty and the contribution of the work. It will be better if there are a little more analysis of the experiment on predicting time intervals to next event. The upper plots in the figure may be not convincing enough to support the claims. Sometimes the usage of “CCNN” is not clear, for example, the experiment on speech interpolation compares the “CCNN th” method with baselines, but uses “CCNN” in the analysis. “The left plot shows” in the last line of the caption of figure 3 should be “right”.<BRK>1.The motivation of continuous convolution is not very clear, can the authors please motivate? To my understanding this is just to handle inputs with unequal time steps, but that can be handled multiple ways, why not just naively resample? 2.The proposed network was defined as continuous convolution followed by the standard convolution. 3.Continuous convolution should be a general case for standard convolution, can authors explicitly show it? 5.Two hot encoding seems another way to discretize, no? 6.The experiments section is rather weak, CCNN seems to have a lot of spikes in prediction, e.g., in Fig.5.7.It’s very strange why two hot encoding does not perform that well, while reading the method section, it seems very obvious to take two ends of an interval, in that way two hot encoding seems logical. Overall it seems like an easy extension with a lot of parts not well justified. Also I don t clearly have a well grounded motivation for a continuous convolution.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. rating score: 6. <BRK>This paper solves an interesting scientific and applied problem: can we construct an algorithm to predict uncertainties without re training/modifying existing neural network training algos? The authors describe the theoretical foundations as well as show empirical results on multiple datasets. My thoughts on the paper:  The paper is well written and from section 2.1 it is clear how one could re produce their method. The theoretical section 2.2 feels a bit rushed, I think it would be worth sharing the high level intuition behind some of the theory first before going into the details. I.o.w.from a practical point of view, the method is only limited by approximate inference for Gaussian processes. The empirical section is particularly strong and contains a wide variety of experiments with detailed analysis. As a result, I think this is a good piece of scientific work that could be interesting to the wider community.<BRK>The paper focuses on the model inference of neural networks (NN). The authors propose to use NN for the model, and fit the prediction residuals with a Gaussian process with input/output (IO) kernel. The authors show that the NN+GP scheme has lower generalization error compared with solely using GP or NN to fit the model. In general it is a good paper, with good applications. 2.Is this the only proposal for fitting the residuals for uncertainty estimation? 3.Summarizing the whole procedure in an algorithm could make things clearer.<BRK>This paper proposes a new framework (RIO) to estimate uncertainty in pretrained neural networks. It is not clear why you focus on employment of the proposed method for vanilla NNs. Have you applied RIO for other learning algorithms as well? Could you please explain more precisely, how you utilize which particular properties of NNs in RIO, and/or how RIO helps quantification and improvement of uncertainty of NNs particularly? However, you should not that the error functions given in Theorem 2.6 are calculated in a cascaded manner, i.e., by applying a GP at the output of a NN. The main proposal of the paper is that RIO makes it possible to estimate uncertainty in any pretrained standard NN. In order to verify that proposal, you should improve the experiments, esp. using larger datasets with larger neural networks, including deep neural networks. After Rebuttal:I read the comments of the other reviewers and response of the authors. Most of my questions were addressed in the rebuttal, and the paper was improved.<BRK># SummaryThe authors propose a method for post hoc correction and predictive variance estimation for neural network models. The authors suggest that residual means and variances at test points can then be calculated explicitly using predictive distributions from the GP. The authors run a large panel of experiments across a number of datasets, and compare to a number of methods that draw connections between neural networks and GP’s. It has the flavor of a number of other composite ML methods that have worked well in the past e.g., boosting and platt scaling but is different enough to stand on its own. It would be far more compelling if the authors proposed the very standard approach to modeling data via covariance kernels, where one first models non stationary portions of the data with a base model, then models the correlation in the residuals with something like a GP. However, I am torn about the paper, because the theoretical discussion of the method is quite convoluted and seems either irrelevant or incorrect. The methods properties as an uncertainty quantification tool are underdeveloped. The substance also has some issues. In the theory, it is assumed that the GP will only model the portion of the labels y_i for which it is property specified (in this case, f(.)).
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>This paper proposed Graph Enhanced Transformer(GET) to combine the graphical and sequential representations of the molecule to improve the retrosynthesis prediction performance. Experiments indicated that the proposed model outperforms state of the art Seq2Seq based methods on USPTO 50K dataset, and showed ability in reducing invalid SMILES rate. This paper provide no novelty with respect to deep learning method. It is just a combination of sequence transformer and graph neural network (using RDKit(Landrum, 2016) to transform a SMILES into the molecular graph). The decoder is the same as vanilla Transformer to generate SMILE string output. 2.The writing can be improved.<BRK>This paper focuses on the retrosynthesis prediction problem which to my understanding is the factorization of a target molecule into simpler structures. This sequential approach was possible because molecules can be expressed as strings using the following format: Simplified Molecular Input Line Entry System (SMILES). Despite its good performance, language translation methods ignore the graphical structure of molecules. This paper proposes to add a graph neural network in front of the Seq2Seq/Transformer network to exploit the graphical structure, hence the name “Graph Enhanced Transformer (GET)”. The main contribution is the addition of a Graph Neural Network to a Seq2Seq model for retrosynthesis prediction which provides state of the art results. Things to improve:There are plenty of works related to graph Autoencoders and Graph generative models that are not mentioned in the related work.<BRK>~The authors propose an enhancement to the transformer architecture that takes molecule graph structure into account.~I applaud the authors work on making more physically plausible machine learning constraints. Does bootstrapping your Transformer model with multiple non canonical SMILES for the same input molecules improve performance? Many seq2seq molecules allow an attention mechanism on the input sequence while decoding, and that seems like this would be useful for this data. Does your model generalize to unseen molecules or reactions better than previous methods? How would this model perform with SELFIES representation of small molecules, which are more robust representation [Krenn et al., 2019]?
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>This paper gives theoretical and empirical results for a gradient clipping variant of Adam they call ACClip. But that is a long discussion that is not specific to this paper. The experimental results are not compelling. Postscript:  I have modified this review in response to the authors. I still believe the theorems do not add really add anything to the intuition and it is the experiments that matter.<BRK>The paper proposed a very interesting claim: When training a neural network, if the (stochastic) gradient noise is Gaussian like, then SGD performs better than Adam; On the other hand if the gradient noise is Heavy tailed, then Adam perform better than SGD. After Rebuttal: I have read the authors  responses and acknowledge the sensibility of the statement. Moreover, the theoretical result in this paper also worries me quite a bit, since from the bounds it seems that Adam is the dominating algorithm (both in the heavy tail case and in Gaussian tail case).<BRK>This paper demonstrates empirically that the gradient noises of SGD with ResNet and Adam with Bert are different: one is well concentrated, while the other one is heavy tailed. Furthermore, the authors proposes gradient clipped SGD and its adaptive version ACClip. In general, the paper is well written and has addressed an important practical and theoretical problem of why SGD fails to train Bert and how to fix this problem. Experiments show that it outperforms Adam on training Bert. Is ACClip competitive to Adam in those applications? Page 1: thereby providing a explanation2.
Reject. rating score: 1. rating score: 3. rating score: 3. rating score: 6. <BRK>The paper analyses the effect of different loss functions for TransE and argues that certain limitations of TransE can be mitigated by chosing more appropriate loss functions. Furthermore, the paper proposes TransComplEx   an adaption of ideas from ComplEx/HolE  to TransE   to mitigate issues that can not be overcome by a simply chosing a different loss. As such, the main novelty would lie in the experimental results which, unfortunately, seem problematic.<BRK>In this paper, the authors investigate the main limitations of TransE in the light of loss function. The authors claim that their contributions consist of two parts: 1) proving that the proper selection of loss functions is vital in KGE; 2) proposing a model called TransComplEx. The results show that the proper selection of the loss function can mitigate the limitations of TransX (X H, D, R, etc) models. My major concerns are as follows. 1.The motivation of TransComplEx and why it works are unclear in the paper. However, with their setting, the performance of RotatE is much worse than that in the original paper [1]. Therefore, the experiments might be unfair to RotatE.<BRK>The paper revisits limitations of relation embedding models by taking losses into account in the derivation of these limitations. They propose and evaluate a new relation encoding (TransComplEx) and show that this encoding can address the limitations previously underlined in the literature when using the right loss. A loss minimization won t make equalities in (3) and (5) hold exactly, which the analysis do not account for. A rewriting of the essential elements of the different proofs could make the arguments clearer. Paper writing: * The manuscript should be improved with a thorough revision of the style and grammar. * The 10 pages length is not beneficial, the recommended 8 pages could hold the same overall content. * Parentheses are missing around many citations and equation referencesTheory:Equation (2) and (4) do not seem to bring much compared to the conditions in Table 1.<BRK>Summary:This paper list several limitations of translational based Knowledge Graph embedding methods, TransE which have been identified by prior works and have theoretically/empirically shown that all limitations can be addressed by altering the loss function and shifting to Complex domain. The authors propose four variants of loss function which address the limitations and propose a method, RPTransComplEx which utilizes their observations for outperforming several existing Knowledge Graph embedding methods. Also, the reported performance of TransE in [1] is much better than what is reported in the paper. Overall, the proposed method is well motivated and experimental results have been found to be consistent with the theoretical analysis.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>This paper investigated the effect of depth on the meta learning model. The paper mainly studies through experimental means and does not have mathematical analysis to demonstrate. In this way of analysis, a large number of experiments are necessary. For the experimental part, I am afraid the results are also weak. For example, please notice that many meta learning models have proposed. I believe authors should compare more existing works to demonstrate the superiority of the proposed one. [Update after rebuttal period]It may seem reasonable that depth enables task general feature learning. However, in fact, it is not true. This is true but not the reason for good performance in feature learning. Because of back propagation, the feature extraction layers can be trained well to extract features from objects of different scales. The major reason for poor performance in feature learning is that the header that creates an object template is not well trained for objects of different scales. As a result, I still keep the confusion in terms of the effectiveness of the proposed method.<BRK>This paper analyzes the popular MAML (Model Agnostic Meta Learner) method, and thereafter proposes a new approach to meta learning based on observations from empirical studies. The key idea of the work is to separate the base model and task specific adaptation components of MAML. This decoupling of adaptation and modeling reduces the burden on the model, thus enabling smaller memory efficient deep learning models to adapt and give high performance on meta learning tasks. (I would be willing to increase my rating to 4 or 5, which however are not available on the drop down, but perhaps not beyond). + The idea to leverage the parameters of a meta optimizer for adaptation instead of using model parameters is novel and interesting. Considering the largely empirical nature of this work, showing its generalizability would be required, in my opinion, to make the conclusions of this work useful to the audience. Expecting that it would naturally hold for other methods like REPTILE may not be sufficient. + The paper presents fair comparison in all experiments with appropriately chosen baseline models, and the proposed approach is validated for both linear as well as non linear models using benchmark datasets. Some discussion of this would have been useful to understand the generalizability of the idea. In Sec 3.2, the paper compares the 1 step adaptation accuracy of a shallow network and a deeper 4 layered linear network and claim that shallow networks underperform. However this underperformance might be due to the difference in required number of steps to reach optimal performance by the two models, and may not be a fair comparison. It may be important to show results on deeper models to be more confident about its applicability. Although one can obtain smaller meta learned models using the proposed method, training via this method will incur a higher computational burden than MAML trained deep models. The paper does not talk about this additional complexity at all. I am on the borderline on this work   it is a well written paper with a clear objective and support.<BRK>This paper presents an experimental study of gradient based meta learning models and most notably MAML. The results suggest that modeling and adaptation are happening on different parts of the network leading to an inefficient use of the model capacity which explains the poor performance of MAML on linear (or small networks) models. To tackle this issue they proposed a kronecker factorization of the meta optimizer. The paper is well motivated and well written in terms of clarity in the message and being easy to follow. One major issue is that the experimental study is not that comprehensive to support the claim of the paper. Especially, in analyzing the failure case of linear models.For example, one may try small (but nonlinear networks) and compare its performance with larger (possibly overparameterized) ones on at least 2 standard network architectures. The paper yet has a message and it s delivered clearly. I wonder if the overparameterized is just related to depth or overparameterization in width would work too? If not then it might be the "nonlinearity" that is doing the workIn section 3.2 (Figure 2, left) and (Figure2, mid) show that FC follows the pattern of C1 C3. However, one can do similar experiments for C1 C3 and claim they are also important to adaptation. For a non expert reader it s not readily clear that how the kronecker factorization of A leads to equation 5. There are a few typos in the paper that can be removed after a thorough proofreading.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>This paper studies optimal control problems where a physical simulator of the system is available, which outputs the gradient of the dynamics. Note that in DDPG, the action is given by a deterministic policy. However, I cannot understand what $\nabla_{\pi} Q$ stands for. 2.Based on the experiments, it seems that the proposed method does not always outperform MPC or DDPG, even in a small scale control problem Mountaincar. Moreover, it seems that the performance is similar to that of the DDPG. 3.Here the model based gradient in equation (2) is defined by only unroll one step forward by going from $s_i, a_i$ to $s_{i+1}$. It would be interesting to see how the number of unroll steps affect the algorithm, which is a gradient version of TD($\lambda$).<BRK>This paper shows how the derivatives from a differentiableenvironment can be used to improve the convergence rate ofthe actor and critic in DDPG. The empirical results show that their method of addingthis information (D3PG) slightly improves DDPG sperformance in the tasks they consider. Why is this?<BRK>It is more widely applicable than traditional model based approaches like MPC, since it doesn t require differentiable models of the dynamics. This paper proposes a method for extending DDPG to exploit simulator gradients. You argue that DRL is better than MPC because DRL explores better. Overall Assessment I recommend acceptance.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>This paper presents a small multiple choice reading comprehension dataset drawn from LSAT and GMAT exams. I like the idea of using these standardized tests as benchmarks for machine reading, and I think this will be a valuable resource for the community. The two major concerns I have with this paper are with its presentation and with the quality of the baselines. Presentation:The main contribution here is in collecting a new dataset drawn from the LSAT and GMAT. I have a lot of questions about this dataset that could have been answered in the main text had more of the paper been given to actually describing the data. I think that this is a good paper and it should be accepted. Given that the best performance is at ~54% on the full test set, there isn t a lot of need for this. It s not really clear what to conclude from the easy vs. hard split, other than the models that you used to create it expectedly do well on the easy split and hard on the test split.<BRK>This paper presents a new reading comprehension dataset for logical reasoning. It is a multi choice problem where questions are mainly from GMAT and LSAT, containing 4139 data points. The analyses of the data demonstrate that questions require diverse types of reasoning such as finding necessary/sufficient assumptions, whether statements strengthen/weaken the argument or explain/resolve the situation. The paper includes comprehensive experiments with baselines to identify bias in the dataset, where the answer options only model achieves near half (random is 25%). Based on this result, the test set is split into the easy and hard set, which will help better evaluation of the future models. The paper also reports the numbers on the split data using competitive baselines where the models achieve low performance on the hard set.<BRK>Paper Summary:This paper presents a machine reading comprehension dataset called ReClor. It is different from existing datasets in that ReClor targets logical reasoning. The authors identified biased data points and separated the testing dataset into biased and non biased sets. Experimental results show that state of the art models such as XLNet and RoBERTa struggle on the non biased HARD set with poor performance near that of random guess. Strengths:—The dataset, which is extracted from standardized tests such as GMAT and LSAT, requires the ability to perform complex logical reasoning. Weaknesses:—The dataset seems small to acquire the ability to perform complex logical reasoning. —The paper does not show statistics of the dataset such as question/passage length and question vocabulary size. —Unlike other datasets, the questions themselves show their required logical reasoning types in ReClor. This characteristic makes it difficult to use the ReClor dataset as an evaluation benchmark for models trained with large scaled reading comprehension datasets such as RACE.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>The paper presents a python package, called JAX MD for simulating molecular dynamics (MD). JAX MD provides automatic derivations and allows to easily incorporate machine learning models in the MD workflow. The paper is clearly written and seems technically correct. Furthermore, even if this work will surely be of great use for the physics community, I am not not sure that the contribution of this paper is sufficient for ICLR.<BRK>This paper describes a general purpose differentiable molecular dynamics physics package, JAX MD. It shows several instances, where it simplifies the research process and enables new avenues of work. The Github link is provided for reproducible research and future development. It should be encouraged. I am sure whether this paper fit the ICLR or not, or how deep learning community can benefit from it. The writing does not feel academic enough sometime. For example,  "Please let us know if there are features that you would find interesting.<BRK>I lean toward accepting this submission. If it were only about simulation molecular dynamics using hardware accelerators, I would question the appropriateness of the venue, but because it is explicitly intended to support training and usage of learned potential functions, it seems suitable. Still might be better placed in a physics/chemistry venue, as where most of the references come from and likely where users would, too. The paper is clearly written, with enough specific examples to contrast previous pain points in this line of work against its smoother interface. All of these points are fine for a package release/tutorial paper, but for a conference paper, might hope to see these addressed:Description of the elements of the design of JAX which are useful here are presented, and appear distinct from other AD libraries like Tensorflow or PyTorch, although the authors stop short of explicitly stating which functionality would be more difficult/impossible to support with the possible alternatives (automatic vectorization of the simulations seems like one?). are not explicitly mentioned. Despite mentioning numerous existing MD libraries, no performance comparison is drawn against any other. Could also show some demonstration of running an experiment which has complexity on par with state of the art research? The bubble raft example is great for illustrative purposes, but it could be better to save some of that for a tutorial and use space to exercise this library on a relevant problem and show performance there.
Reject. rating score: 1. rating score: 6. rating score: 6. <BRK>Since the authors place their work in the setup of sequential prediction, this is what has to be respected. In general I like the idea, and the presentation seems solid to a large degree. I have two more questions with respect to the proposed regularisations.<BRK>The main innovation, in my opinion, is the combination of several ideas applied to the problem of sequence prediction.<BRK>The paper is clearly motivated and easy to follow. Experiment results on MNIST, Stanford Drone and HighD datasets show the proposed that the model achieves better results than previous state of the art models by significant margins.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>The paper I find very poorly written hence my certainty about understanding the method cannot be very high. I have added some initial pointers that would help making this more readable but implementing these would only allow us to assess what is being done rather than guarantee acceptance. Since the rebuttal is not intended as a deadline extension I recommend rejecting this paper! There is content but what the reader cares about it situating the paper in the landscape of existing methods. It needs to tell us roughly what is similar in this work to what was previously existing (roughly at least). Introducing formulas without explaining notation like eq (1 4) serves only to alienate the reader and the (well intentioned) reviewer.<BRK>Overall, I find the idea interesting and the experimental evaluations promising. I found the paper hard to understand. If so, where is the model actually being used during training? Figure 1 is taken directly from the PPN paper without any reference or citation (as far as I can tell). I think the writing has improved significantly, but could still be further improved and clarified. At least for me some of the confusion arises not due to the complexity of the proposed approach, but just because combining real and  simulated  transitions can be used and mixed in so many different ways that it s important to be clear about it. Overall, I think the presentation is on a good way but needs some more work.<BRK>The notation is also confusing. It seems to me that pi(a|s) is the density of action a, so what does sqrt(value * density) mean? Besides, I have some questions. 1.Figure 1 looks the same as Figure 1 in https://arxiv.org/pdf/1909.07373.pdf, but I don t find any reference in the paper. More importantly, note that the policy in PPO is stochastic, so how is PTN compared to the deterministic policy? One can have infinite b but sample a uniformly to optimize Q (and then pi_F becomes maxQ policy), so I don t think b can be simply characterized as the confidence.
Reject. rating score: 3. rating score: 6. rating score: 6. rating score: 6. <BRK>Actually minimizing the usual isotropic 2D TV is tricky, and there are many optimization papers written about it. It s an interesting combination of compressed sensing and deep learning. Overall, I lean toward weak reject, as I think the regularization parts of the paper would benefit from a major revision of the paper. But pure CS, with a Gaussian measurement matrix, and noiseless measurements, is quite academic and not applicable to the real world. The experiments were also noiseless, and they had Gaussian or the Fourier sampling (which is not random, but rather heavily biased toward DC). The writing was overall good. If that s true, then please show it!<BRK>This paper proposes use of the deep image prior (DIP) in compressed sensing. It is especially beneficial in that it does not require training using a large scale dataset if the learned regularization is not used. Results of numerical experiments demonstrate empirical superiority of the proposed method on the reconstruction of chest x ray images as well as on that of the MNIST handwritten digit images. I would thus like to recommend "weak accept" of this paper. I think that the theoretical result of this paper, summarized as Theorem 4.1, does not tell us much about CS DIP. As the authors argue, it would suggest necessity of early stopping in the proposal.<BRK>This paper proposes a new algorithm for compressed sensing using untrained generative model. This provides theoretical justification for early stopping adopted by the authors. My complaint to the paper is that the theoretical justification of the generalization ability of the proposed method is missing. The error goes to 0 is not surprising by many existing works, and the authors completely ignore the generalization error analysis of the proposed method.<BRK>This paper proposes a deep learning based compressed sensing method, CS DIP which employs deep image prior algorithm to recovering signals especially for medical images from noisy measurements without pre learning over large dataset. Experimental results show that the proposed methods outperformed the others. The theoretical analysis of early stopping is also given. Overall, the writing of this paper is good, the idea is novel and the contribution is sufficient.
Accept (Spotlight). rating score: 8. rating score: 6. rating score: 6. <BRK>This paper proposes to incorporate a latent model (in the form of a variational auto encoder) in the decoding process of neural machine translation. So far there are not that many successful demonstrations of VAE in neural machine translation. The method is sound and interesting. The results show convincing improvements; some practioners may argue that reported BLEU gain (e.g.0.8) is not impressive, but I think for a new model like this it is worthy. This will help distinguish whether the proposed method is improving by getting the morphological inflections correct, or whether it is improving across the board on various word types. I wonder if different kinds of latent spaces will be learned with different depth.<BRK>This paper addresses the problem of translating into morphologically rich languages, which suffers from the problem of sparse vocabularies and high numbers of rare and unseen words. More concretely, this paper models the generation of target words in a stochastic, hierarchical process, where the morphological features are modelled as latent variables. Experiments on translations into three morphologically rich languages, English {Arabic, Czech, Turkish}, indicate fairly small but consistent and statistically significant gains in BLEU. Overall, this paper proposes an elegant solution to an important problem, and yields statistically significant BLEU improvements over the baselines. I would be willing to raise my scores assuming my concerns are sufficiently addressed. Pros:1.The proposed approach is easy to follow and explained clearly, and the paper is overall well written. This would better convince the reader that the latent inflectional features really are capturing useful morphological information, and that the target word generation process is appropriately controlled by the latent variable. The explanation that "[the character model] s capacity cannot cope with the increased amount of sparsity" does not seem satisfactory. 2.It would be interesting to explore other potential metric for measuring morphological generalisation.<BRK>This paper proposes a method, Latent Morphology Model (LMM), for producing word representations for a (hierarchical) character level decoder used in neural machine translation (NMT). The literature review of NMT and the discussion on the potential advantage of morphology are concise. Overall, this paper could provide a novel insight into the role of modeling morphology as latent variables. However, the experiments and analyses do not sufficiently support the claim of mimicking the process of the inflection (besides the gain in performance). A contrast of performance with less morphological languages might reveal some insight (unfortunately I do not have enough knowledge to recommend languages).
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>The paper focuses on in domain uncertainty estimation complementing the recent similar review on out of domain uncertainty estimation. Based on this, I believe this is a strong technical paper and it should be accepted.<BRK>After exploring common standards for uncertainty quantification, the authors point out pitfalls of existing metrics by investigating different ensembling techniques and introduce a novel metric called deep ensemble equivalent (DEE) that essentially measures the number of independent models in an ensemble of DNNs. The relationship to previous works is also well described. Overall, I think this is a good paper, which gives a detailed overview of existing metrics for accessing the quality in in domain uncertainty estimation.<BRK>To that end, why do the authors suggest that it cannot be used as criteria for comparison across models? Why is this the case? I went back and did another thorough read of the work. The authors evaluate a variety of ensemble models in terms of their ability to capture in domain uncertainity.
Reject. rating score: 6. rating score: 6. rating score: 6. <BRK>The meat of the paper is found in Section 4, which I found a bit difficult to follow. A stochastic variational inference scheme is then proposed to infer the posterior over both the Gaussian process and the weights themselves. My primary concern here is that the prior ends up becoming Kronecker structured (after Eq.7), so it isn’t clear to my why dense matrices and dense variational bounds have to be derived in this setting. Furthermore, Kronecker inference for non Gaussian likelihoods for Laplace approximations was proposed back in 2015: http://proceedings.mlr.press/v37/flaxman15.pdf. I do agree that the approximation in Figure 2 does seem to be relatively accurate, although I would ask the authors to compute a relative error for that plot if possible. **tldr**: While I appreciate the concept of this paper, I tend to reject this paper because I find the experimental results to be on too small scale of datasets. Could the authors perform a set of experiments showing the necessity of this kernel matrix in the rebuttal? Neural processes (Garnelo et al; 2018) propose a somewhat similar approach to training – with a latent process over some stored weight space. However, even that is quite distinct from the method proposed in this paper, and I tend to prefer this approach. **Quality**: I really appreciate the merging of neural network and Gaussian process methods; however, tragically, I do wonder if the proposed approach combines the worst of both worlds – the necessity of architecture search for neural networks with the choice of kernel function (as illustrated in Figure 5). Active learning experiment: While I appreciate the comparison here, it seems like here standard HMC should be trainable over well designed priors on these architectures. With that being said, to only have experiments on the last layer implies that one should compare to Bayesian logistic regression and linear regression on the last layer of neural networks (e.g Perrone et al, 2018 and Riquelme et al, 2018). Experiments with other methods that combine Gaussian processes with representations on the final layer (e.g.Wilson et al, 2015) are also probably worth running. Figure 4 is a very well done experiment, if a bit tough to read. I’d suggest that the out of distribution examples get their own figure, with the in distribution examples going into the appendix.<BRK>This paper proposes an improvement over Probabilistic meta representations of neural networks by replacing the NN parameterization of the network weights given latent variables by a probabilistic distribution whose mean is distributed by GP. Inference of the induced hierarchical model is achieved by variational inference and variousapproximations when needed. The authors claim that the proposed method aims to increase the robustness in the small data settingsand improve its out of sample uncertainty estimates. The second part is well justified. 2.What exactly is the gain obtained by replacing a NN parameterization with a GP parameterization? It seems like the proposed method gains the ability to model uncertainty, but potentially incurs performance trade off from a series of approximation. 3.Following from comment #2, I am a bit surprised by the lack of comparison against the work of Karaletsos although this work was built on top of it. 5.For the text before Eq.(8) should the inducing inputs be xu instead of zu? It seems like a systematictypo here because in the formulation for the lower bound it becomes p(u|xu) again instead of p(u|zu)6. This would not permit large NN anyway, which kind of defeats the purpose. Overall comment:I think the paper presents an interesting idea but I have questions regarding its practical significance as highlighted in my specific comments above. I hope the authors would clarify these so I can converge on a final rating.<BRK>The paper presents two models extended from a meta presentation of neural networks (Karaletsos et al.2018) in which neural network weights are constructed hierarchically from latent variables associated with each layer. Variational inference is followed by the pseudo inducing point approach. Pros:The paper is clearly written. This can be one of the reasons that the method performed well in active learning. Cons:The approach is incremental or not so novel in terms of meta representation for neural networks. Comments and questions:The prior distribution for latent variable $z$ is not specified. I assume the prior is independent Gaussian. Do you think that there is a connection between contextual metaGP and residual nets? Can you comment on the convergence of the estimation of the last term in the variational bound? Minor: a missing period in Sec.6.3 “quadratic kernel In this example”
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>The technique is reminiscent of t SNE, with the difference that it get weighted triplets (i,j,k) as inputs (meaning that j is closer to i thank). A paper is purely experimental. I did not see any evidence that images of TriMap somehow give a new insight into data (in comparison with other methods).<BRK>The paper proposed ``TriMap’’ a novel dimensionality reduction technique that learns to preserve relative distances among points in a triplet. If the latter holds, then how was it chosen and how large is it compared to the training data used by other methods? Major merits of this paper are: 1. But I am not convinced that the preserved information is actually global.<BRK>Authors introduce TriMap based on triplet constraints that preserves the global accuracy of the data. A measure of global accuracy is proposed to reflect the global accuracy of the embedding. Experiments on various datasets the better performance than baselines. Authors define the minimum reconstruction error from the embedding as the global measure in reflecting the global structure of the data similar to PCA.
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>The authors also present the spectrum and leading eigenspace of the Gram matrix for representations by CNNs of images generated by a GAN. It is not clear to this reviewer what exactly the authors have proved and what significance it has. This is well known from the random matrix theory literature. The authors claim that their results constitute "a first step towards the theoretical understanding of complex objects such as DL representations." This very conference is on Learning Representations, and presumably at least one paper in the past 7 years makes progress towards the theoretical understanding of Deep Learning representations.<BRK>This paper provides a formal proof that the data produced by a GAN are concentrated vectors. To what extent could these results extend to other distributions? This theorem is essentially a concentration bound for the resolvent of the gram matrix G around its mean. The expectation is already computed in (Louart & Couillet, 2019) so the contribution in this theorem seems to be in showing that the result only depends on the first and second order statistics. You claim this is a surprising result, although it does not seem so surprising to me given that this is an asymptotic result.<BRK>The authors generalize Gaussian random vectors to a broader class of "concentrated" vectors which they use as their primary tool for analysis of the latent representations learned by GANs. They show that the spectral behavior (i.e.spectra and leading eigenspaces) of the Gram matrix computed over GAN representations is the same as those produced by a high dimensional Gaussian Mixture Models (GMMs). Thus, for data that follows Gaussian mixture patterns, GANs and GMMs behave identically. Overall, the paper is well organized and the theoretical results are both compelling and thorough. The experimental results also follow nicely from the theory. Admittedly, this reviewer is not well versed enough in this area of mathematics to provide thorough critical insight about the derivations and proofs.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>The paper proposes a new graph pooling method by learning the node assignments from a CRF based structure prediction formulation. To justify the usefulness of CRFs instead of other clustering methods for node assignment, I think there should be a baseline which removes the pairwise energy and just use the unary energy for node clustering. The paper is written clearly, and the experimental results are good. (BTW, it is better to add the related works which combined CRF and GNNs, considering the close connection to this paper.)<BRK>The authors here introduces a novel  graph pooling technique called StructPool that uses the underlying graph’s structural information to behave as a node clustering algorithm and learns a node clustering matrix. The unary potentials of the cliques are computed used the GCN to measure energy of each node. I have  a few questions as below:I think the authors can better elucidate the motivation for using  the attention matrix over Gaussian kernels to measure pairwise energy in section 3.3; an  empirical experiment for drawing comparison wrt to the computational time and number of feature dimensions on a toy problem seems important. Otherwise, the paper is rather well written and has clarity.<BRK>Strength:  An interesting idea to use CRF idea to cluster the nodes on a graph for pooling purpose  The paper is well written and easy to follow   On a few datasets and task, the proposed method works pretty wellWeakness:  The computational complexity of the proposed algorithm is on(n^3), which is too expensive This paper studied to use CRF to define the cluster assignment of the nodes  for graph pooling, which model the dependency of the cluster assignments between the nodes. What would be the results if multiple layers are used?
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. rating score: 6. <BRK>This paper extends Jin et al.(2018) s idea to infinite horizon and improves the best known sample complexity to $\tilde{O}(\frac{SA}{\epsilon^2 (1 \gamma)^7})$. Overall I think this paper is sufficient to get in the conference. Novelty: In section 3.2, the authors discuss the difference between finite case and infinite case. In this case, the latter rewards counted for $V(s_1)$ will multiply by $\gamma^t$ which is pretty small, and will not contribute too much on the error.<BRK>Summary:In this paper, the authors extend the UCB Q learning algorithm by Jin et al.(2018) to infinite horizon discounted MDPs, and prove a PAC bound of \tilde{O}(SA/\epsilon^2 (1 \gamma)^7) for the resulting algorithm. The algorithm is quite similar to the one by Jin et al.(2018), which is for finite horizon problems. The resulting regret bound is similar to the one in Jin et al.(2018), but the PAC bound is new. This bound improves the one for delayed Q learning by Strehl et al.(2006) and matches the lower bound in terms of \epsilon, S, and A.<BRK>Summary: This paper adapts the UCB Q learning method to the inifinite horizon discounted MDP setting. This is an important setting in reinforcement learning. However, the bound is not optimal as the dependence of (1 gamma) is significantly larger than the lower bound. As a result, the analysis and algorithm in this paper are very similar to that of Jin et al 2018, who nearly implicitly contain the results in this paper. Thus, we obtain an algorithm for the inf horizon as well.<BRK>This paper considered a Q learning algorithm with UCB exploration policy for infinite horizon MDP, and derived the sample complexity of exploration bound. The bound was shown to improve the existing results and matched the lower bound up to some log factors. ~~~~~~~~~~~~~~~~~~~~~~After rebuttal: Thanks the authors for addressing my questions.
Reject. rating score: 1. rating score: 1. rating score: 3. <BRK>The paper "Abstractive Dialog Summarization with Semantic Scaffolds" presents a new architecture that the authors claim is more suited for summarizing dialogues. The new architecture is a minor variation of an existing pointer generator network presented by See et al.First the authors used two different sets of parameters to encode the user and the system responses. The authors also pre process the dialog by replacing the slot values by their slot keys. Finally, the authors use an auxiliary task of detecting the domain of the dialog. These three different enhancements are all called "scaffolds" by the authors, hance the title of the paper. This paper is not suited for ICLR because of its limited novelty. The three enhancements proposed by the authors are long known and incremental.<BRK>Authors proposed an enhanced Pointer Generator model called SPNet. The key difference between SPNet and PG are the separate handling or using of speaker role, semantic slot and domain labels. Authors also proposed a new metrics called Critical Information Completeness (CIC) to address ROUGE s weakness in assessing if key information is missing in the output. The above inconsistency suggests the paper may not be quite ready for publication.<BRK>The authors also extend the pointer generator network of See et al.(2018) to use speaker, semantic slot and domain information. They show that this new model (SPNet) outperforms the baseline on existing automatic metrics, on a new metric tuned to measure recall on slots (dubbed CIC), and a thorough human evaluation. This paper is well written and executed, but unfortunately, I lean towards rejecting this paper because of a fundamental flaw in the nature of the proposed dataset that limits its applicability to the task of abstractive dialog summarization (more below).
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>the paper attempts to infer Granger causality between nonlinearly interacting stochastic processes from their time series measurements. in particular, they use group wise regularizing to accompany the particular structure of the model to aid interpretability. they compared the performance with existing models with MLP/LSTM and show some gains in a few examples (but not all.)<BRK>In this paper the authors propose using Statistical Recurrent Units to predict the network for Granger causality. The authors clearly present their two main contributions and verify them using varied datasets. The inclusion of the literature review in the appendix is also greatly appreciated.<BRK>The experiments seem convincing to me and I really appreciate the authors provided the tuned hyper parameters in the appendix. This paper extended this algorithm for inferring granger causality through applying group sparse regularization, which is a pretty smart design to me. I can follow the paper without problem. The effectiveness of the algorithm depends on the sparse regularization, which lacks theoretical guarantee for non convex optimization.
Accept (Poster). rating score: 6. rating score: 6. rating score: 1. <BRK>This paper introduces the problem of overlearning, which can be thought of as unintended transfer learning from a (victim) source model to a target task that the source model’s creator had not intended its model to be used for. The paper raises good points about privacy legislation limitations due to the fact that overlearning makes it impossible to foresee future uses of a given dataset.<BRK>This paper demonstrates some limitations of censoring for privacy with respect to sensitive attributes. In particular, the authors show that censoring reduces, but does not eliminate, the ability of a neural network to infer private/sensitive attributes, e.g.to infer race from a model aiming to predict gender. The authors show that censoring strength often does reduce the ability to infer sensitive attributes, but also affects the ability to perform the main (non sensitive) task; and in some cases, may actually increase ability to infer sensitive attributes.<BRK>This paper highlights the problem of model overlearning   learning more than it is trained to do. Did they not observe overlearning in these models? 4.As for section 4.4, it is pretty understood that lower layers of a DL model, learns very basic low level features from the images such as edges, corner.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>The submission proposes a novel method for explicit decomposition of hierarchical policies for long horizon navigation tasks. The approach proposes to separate a policy into 3 modules, high level planner, intermediate planner and low level control. The variety of different techniques combined instead of a single main contribution renders it challenging to follow all aspects and in particular to trace relevant contributions to performance   which is rendered harder by a limited evaluation section. It is commendable that the authors have introduced adaptations and improvements to their baselines for a stronger and fairer comparison but the evaluation remains very limited. But more importantly I suggest to run further ablations without the intermediate planning layer & with absolute goal positions.<BRK>The paper proposes a neat framework for creating HRL framework that will be able to generalize its application to slightly different environment layout. This is done via an image based top down from as input to the high level. The results are also only shown for a single environment. This should be discussed more in the paper. Are these averaged because the agent has a stochastic policy during evaluation? The authors point out that the use of relative goal positions "ensures generalization to new environments", this is a rather strong statement. For example, a top down view of the environment is needed which is not often feasible. HIRO and HAC use a more proprioceptive state space but I don t think the sharing of global states is intentional. In section 4.3 it says that the control layer is the only layer with access to the agent s proprioceptive state.<BRK>This paper addresses hierarchical deep reinforcement learning (RL), an important problem in control learning and RL. In contrast, HiDe uses a top down view of the maze and the x y position of the agent, which certainly is more privileged information. Second, the experimental setup should be elaborated on: is HIRO or HAC modified to include the same information for the top level policy? I do not think that requiring this information is egregious, but currently the experimental comparison is not clear in this regard. The experiments are arguably the strongest part of the paper, and the transfer results and videos are quite nice. Edit after author response: I appreciate the authors  efforts in providing extensive responses to all of the reviewers  concerns as well as a significant general response detailing what seems to be a large amount of additional experimental work.
Accept (Spotlight). rating score: 8. rating score: 6. rating score: 6. <BRK>This paper extends recent work by Khemakhem et al on nonlinear ICA to allow for unknown number of generative factors. I think that this research direction is extremely promising, and obtaining a theoretical understanding of when/why disentangling could work would be particularly valuable to the field, and I would lean towards acceptance so that this work gets more attention.<BRK>The paper s presentation is relatively clear, although all the theoretical results are relegated to the appendix. The extension to unknown latent space dimension seems to be quite straightforward, given the recent work that this paper is based on. However, the experimental results performed on EMNIST are quite convincing and the results are interesting.<BRK>This paper builds upon the recent theoretical framework on nonlinear ICA, put forward in recent work Khemakhem et al.(2019) that draw a lot of attention. On the negative side, The paper is largely based on the results of a recent technical report (Khemakhem et al.(2019)) and is not self contained, hence rather hard to digest. It would be also informative to discuss the links with this approach.
Accept (Talk). rating score: 8. rating score: 8. rating score: 6. <BRK>The key idea to theapproach is to keep additional statistics about the number of on going simulations from each of the nodes in the tree. I recommend that this paper be accepted. The approach is well motivated and clearly explained, and is supported by the experimental results. The experiments are reasonably thorough and demonstrate the claims made in the paper.<BRK>This algorithm is evaluated in two domains, a mobile game called “Joy City” as well as on Atari. While significant effort has been made by the RL community to scale up distributed model free algorithms, less effort has been made for model based algorithms, so it is exciting to see that emphasis here. Overall I thought the main ideas in paper were clear, the proposed method for how to effectively parallelize MCTS was compelling, and the experimental results were impressive. P UCT is also not that descriptive, given that there are other existing algorithms for parallelizing MCTS. Is this the number of steps taken to pass the level?<BRK>The paper introduces a new algorithm for parallelizing monte carlo tree search (MCTS). The paper introduces a new algorithm that updates the visitation counts before evaluating the rollout (which takes long), and therefore allows other workers to explore different parts of the tree as the exploration bonus is decreased for this node. The algorithm is evaluated on the atari games as well on a proprietary game and compared to other parallelized MCTS variants. The makes intuitively a lot of sense, albeit it is very simple and it is a surprise that this has not been tried yet. The algorithm seems to be effective and the evaluations are promising and the paper is also well written. The focus of the paper is planning, not learning.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>This paper proposes an architecture for synthesizing tools to be used in a reaching task. Is it that tool synthesis is a challenging problem? The paper demonstrates that this approach can achieve ok performance on familiar scenes with familiar tools, but that it fails to generalize when exposed to unfamiliar scenes or unfamiliar tools. The combination of these results suggest that the model has learned something about which tool dimensions are important for being able to solve the types of reaching tasks given in the paper. Specifically, (1) neither the particular task, results, or model are not very compelling, (2) there are no comparisons to meaningful alternatives, and (3) overall I am not quite sure what conclusions I should draw from the paper. However, given the coolness of the problem of tool synthesis, I definitely encourage the authors to continue working on this line of work! 3.Overall, I am not quite sure what I am supposed to get out of the paper.<BRK>The authors constructed an interesting dataset named reaching task, where the model need to predict if the given toolkit is able to solve the corresponding task or not. Using the activation maximisation technique (which was phrased as the imagination process), they are able to modify the input tools into the ones that is suitable to solve the corresponding task. However, I do not find the authors has a strong case of proven it is the case in this manuscript. So, based on the author s assumption, it should not be benefit of having the tool affordance directions in the latent space. This is particularly true for the Scenario E, F, G (the interpolation tasks), which is more about generalization and is more important. The authors used activation maximisation approach to travel in the latent space. Unfortunately, is that a  direction ? Using MoNet to decompose tools from a toolkit is nice.<BRK>This paper proposes an algorithm that learns to synthesize tools for the task of reaching. It s studying an important problem from a cognitive perspective; it also proposes a novel model for the task, building upon SOTA models. However, the current problem formulation and experiment setup are not well justified, and the experiments are quite limited. This is revealed in the results on case H, where the model doesn t work at all. In addition, comparisons with published methods are missing. Due to all these limitations, I lean toward rejection.
Accept (Spotlight). rating score: 8. rating score: 6. rating score: 3. <BRK>I really believe such a suite of RL tasks can indeed be extremely useful to RL researchers developing new algorithms, and as a result I would like to encourage this initiative and see it published at ICLR to help it gain additional traction within the RL community. The paper is easy to read, motivates well the reasons behind bsuite, and shows some convincing examples. However, in my opinion there remain a few important issues with this submission:1. I believe it is important to add one. 3.I wish an anonymized version of the code had been provided, so that reviewers could test it.<BRK>In this paper, the authors propose a set of benchmarks for evaluating different aspects of reinforcement learning algorithms such as generalisation, exploration, and memory. This can be for example showing how the generalisation score proposed here is linked to theoretical accounts. The paper is well written and clear, and generally can provide a useful contribution. Based on section 1.1 and elsewhere, it seems that the main driver for developing this benchmark has been connecting theory to practical algorithms (which in my opinion is an important step).<BRK>Behaviour Suite for Reinforcement LearningIn this paper the authors provide a set of light weighted but dedicated designed environments, so that researchers can use the environments as a quick indication of the ability of the proposed (or existing) algorithms. I think the paper is well written, with the intuition clearly demonstrated. But I believe in general it is a very valuable project that will be beneficial to future research and I would like to recommend for a workshop publication. Pros:  The paper is well written, easy to understand. The project will be of great value to the research community in the near future.
Reject. rating score: 1. rating score: 6. rating score: 6. <BRK>In practice, however, Adam with large epsilon can approximate SGD with momentum. I have some difficulties understanding the contribution of the paper. For example "When tuning all available metaparameters under a realistic protocol at scales common in deep learning,we find that more general update rules never underperform their special cases." In practice you do adjust hyperparameter search spaces to fit your conclusions, e.g., "We found that searching over (epsilon, alpha0/epsilon) was more efficient than searching over (epsilon, alpha)." Second, for any person working in black box optimization it is clear that 16 experiments is next to nothing. Update#2:As I mentioned in my review, Adam with large epsilon is not equivalent to momentum SGD but only approximates the latter. This is because the original Adam has a bias correction term and even if the same *global* learning rate schedule is used both for Adam with large epsilon and momentum SGD, they are not equivalent. In order to obtain the exact equivalence, one would need to either1) drop the bias correction term of Adam and thus modify the algorithm in order to satisfy the claimed equivalenceor 2) set a particular learning rate *for each batch pass* of Adam to simulate the effect of the bias correction term, this leads to a large number of hyperparameters   as many as the number of batch passes, this is intractable (the setup of the authors does not optimize such batch wise hyperparameters, they are defined by a global scheduler as a function of batch/epoch index). My main concern is described in the first Update.<BRK>This paper presents experimental data supporting the claim that the under aggressive hyper parameter tuning different optimizers are essentially ranked by inclusion   if the hyper parameters of method A can simulate any setting of the hyper parameters of method B then under aggressive hyper parameter tuning A will dominate B. One way to achieve this rather trivially is to do a hyper parameter search for B and then set the hyper parameters of A so that A is simulating B. But the point here is that direct and feasible tuning of A with dominate B even in the case where A has more hyper parameters and where hyper parameter optimization of A would seem to be more difficult. An important conclusion is that without loss of generality one can always use Adam even in vision where SGD is currently the dominant optimizer used in practice. First,"Hyper parameter" please not "meta parameter". I don t think algorithm 1, or the definition of a first order optimizer adds anything to the paper.<BRK>The paper provides an empirical comparison of a set of first order optimization methods for deep learning models. Those optimizers include stochastic gradient descent, momentum  method, RMSProp, Adam, Nesterov, and Nadam, which arguably covers all popular variants used in the literature. Although it is not the first empirical study on this topic, its conclusion differs slightly. Cons:  I am not entirely convinced that the inclusion relationship is indeed a major cause or indicator of different optimizers  performance. There is no theoretical justification; Empirically, if one takes two optimizers equally rich and tunes one of them more intensively, one should expect a better performance, too. Suggestions:  I think at least the basic definitions of different optimizers should be given in the main text. For example, the paper starts talking about the taxonomy of the optimizers with their corresponding hyperparameters in Section 3.2 before giving any functional form of the optimizers. I would suggest the authors to follow the convention and use the term "hyperparameter" rather than "metaparameter". The readers of this paper are not primarily Bayesian, there is really no need to divert from the convention. Besides, the term "Bayesian hyperparameter tuning" is widely used even.
Reject. rating score: 1. rating score: 1. rating score: 1. <BRK>Unfortunately, I think the paper in its current state does not meet the bar for ICLR   I suggest the authors consult the vast literature in semi supervised and continual learning, and try to place their work in this context, along with external comparisons. It is an interesting idea, and worth exploring. In addition, I think the paper is lacking some grounding and context in terms of what problem is being solved and what previous work exists. Lastly, the experiments show the performance as a function of queue length for different features and for CNNs versus decision trees, but there is no comparison to existing methods and very simple models are used   this means that again, it s difficult to gauge the efficacy of the approach and place this in the context of prior art.<BRK>The paper claims to tackle a semi supervised continual learning problem where the feedback or the labeled data is delayed and is provided based on the model performance. 2  As one of the main motivations for the paper, authors claim humans learn continuously in an unsupervised fashion (paragraph one). The proposed method is an online learning method with delayed feedback which has been extensively studied before. Authors should consider citing the pioneering work in this field such as Weinberger & Ordentlich (2002) [2] or Joulani et al from ICML 2013 [3]. Was this investigated at all? This is vague to me and I think it is not true because there are plenty of supervised continual learning approaches where the labeled data is available when a task is learned (for example [4,5,6])7  The experimental setting is not well designed and does not use a standard continual learning setting and there is no baseline included which are very important reasons for rejecting this paper.<BRK>GeneralThe paper is quite hard to follow. The paper claims that it is about continual learning, but it does not give ANY experimental results on the continual learning benchmarks. The paper says it generates random one hot vector when queue is full, but what does it have to do with delayed feedback? The algorithm requires a completely trained model and a queue that needs to store large amount of data. There is no baseline in the experimental results. This makes the result dubious.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>This paper introduces SANE, a new approach for explaining image similarity models by combining a saliency map generator and an attribute predictor. In this way, the method is not only able to highlight what regions contribute the most to the similarity between a query image and a reference image, but also predict an attribute that explains this match. During training, SANE jointly optimizes the attribute prediction of the query image and maximizes the overlap of the saliency map of the image similarity and the attribute activations. I think the paper addresses a very interesting problem that has been commonly overlooked. It is also novel and interesting the addition of an attribute predictor in the system which provides additional information that cannot be captured by the saliency map alone. Aren t there other activations and losses better suited for multi label classification, such as sigmoid + binary cross entropy loss, where there s no need to divide the ground truth labels? In order to match image similarities with attribute descriptions the authors propose matching similarity saliency maps with attribute map activations. A final minor comment: as I mentioned before, the introdution of attributes in the explanation process is a very interesting contribution since they provide the user an explanation that is a step closer to a description in natural language. Although the paper proposes a very interesting approach for explaining image similarity models, I also have some concerns that I think should be addressed before its acceptance.<BRK>I SummaryThis paper proposes a novel method for image similarity models explanation, introducing Salient Attributes for Network Explanation (SANE). The method identifies attributes that contribute positively to the similarity score, thus explaining the important image properties, and pair them with a generated saliency map unveiling the important regions of the image. What is the context in improving image similarity explainability? Moreover, the section on TCAV should be in the related work, whereas how it is used for this specific case would be described in 3.3. In eq 4, â is mentioned but s is used. In 4.2 there is a small user study to verify if the explanations were useful, the study is a nice addition, I really like this kind of results! It would be even more interesting if it compared the results with other baselines. This led to a better comprehension of the challenges.<BRK>Overview/Contribution: The paper proposes an explanation mechanism that pairs the typical saliency map regions together with attributes for similarity matching deep neural networks. Hence, saliency maps are considered as explanation on their own by many. Fig.1 (b) also is a clear example of the kind of explanations generated using a template with the key attribute in question accompanied by the visual saliency map interpretation. The attribute ranking and selection method of informative attributes using combinations weighted TCAV and cosine similarity between the attribute activation map and the generated saliency map is novel. I suggest the authors discuss more of the image similarity based applications and less on the discussion and heavy citation of generalized deep neural networks. The method is described well but why cosine similarity was chosen in terms of its benefits compared to other similarity metrics is not that clear. Evaluation on more datasets such as person/pedestrian attributes datasets would have demonstrated the generalizability of the proposed method across multiple practical domains.
Accept (Spotlight). rating score: 8. rating score: 6. rating score: 6. <BRK>The authors improved a lot the manuscript and incorporated reviewers feedback. ###Summary of the paper: The paper provides a way to estimate the natural Wasserstein gradient using Kernel estimators. Authors give variational forms of the Fisher information matrix of an explicit model , using  the variational form of the chi squared or the Fisher Rao divergence. Similarly authors give a variational form of the wasserstein natural gradient . It would be great to baseline this one ? the method comes disappointing since it seems that the preconditioning that the Wasserstein gradient gives is not enough and $r(u) u^{\top}D u$ is need where D is diagonal depends on T. Have you tried with $D Identity$? Overall assessment: That is a good theoretical work with provable guarantees.<BRK>It s important to be able to estimate natural gradient in a practical way, and there have been a few papers looking at this problem but mostly for the case with a Fisher Rao metric. Some theoretical guarantees of the proposed method is established together to some experimental study. I find this work interesting with some important merit, as it tackles an important problem in statistical learning. Having said that, I believe this paper provides an important first (and alternative) step towards an important problem. 2) The sentence on line 8 in Introduction reads ".. This is when the authors are talking about the adaptive learning methods. It is not very clear (to me) how to get this.<BRK>The authors leverage the dual formulation and restrict the feasible space to a RKHS. The flow idea is clear. Overall, I lean to the acceptance side. Below are some of my concerns:1) It seems that the natural gradient under Wasserstein metric is well motivated for models which do not admit a density (to compare with the natural gradient under Fisher information metric). However, it seems that there is no supporting experiments about it yet. and how s about the 2nd term?
Accept (Poster). rating score: 6. rating score: 6. rating score: 3. <BRK>The weights of each model can be represented as element wise product of two matrices: shared one and matrix with rank 1 that can be efficiently stored. The idea is quite interesting despite its simplicity. I would like to highlight the lifelong learning as the strongest experimental result achieved by the authors. This method is difficult to generalize for the case of very diverse tasks despite its scalability. The same is true for machine translation section. Whym  heads  are  better  than  one:  Training  a  diverse  ensemble  of  deep  networks.arXiv  preprintarXiv:1511.06314, 2015bOverall, it is an interesting paper, that has several drawbacks.<BRK>The method works by maintaining a shared “slow” weight matrix per layer, along with an ensemble of rank 1 “fast” weight matrices that are combined individually with the slow matrix via a Hadamard product in order to generate the network ensemble. The method is evaluated across a host of experimental settings, including image classification, machine translation, lifelong learning and uncertainty modelling. * Machine translation experiments. * Was a naive ensemble trained on the machine translation tasks for comparison? It would be good to see some discussion of whether and how BatchEnsemble could be combined with other neural network ensemble methods.<BRK>This paper aims to improve the efficiency of ensembles of neural nets in traditional supervised learning and life long learning (learning on a series of tasks). The main idea is to let all the neural nets in an ensemble share the same weights W for each layer, and the weights for each neural net is generated by the Hadamard product of W and a specific rank one matrix of the same size as W that is different across members in the ensemble. In experiments, they evaluate the method with some baselines on life long learning, traditional classification, NMT tasks, and uncertainty modeling. It is easy to understand that the ensemble defined here can improve efficiency and reduce memory cost. How to control efficiency performance trade off in the proposed method?
Reject. rating score: 3. rating score: 3. rating score: 8. <BRK>2) The authors have a done a commendable job of coming up with a meaningful set of experiments by varying base models, self supervised methods, datasets, and few shot learning methods in Section 4.1. While it is a different setting it is inline with one of the main conclusions of the paper. In Figure 4d, it is misleading to show a trendline that includes the same domain as that will always be 0. But this definition of domain distance is more meaningful in the domain adaptation setting (like Amazon Office dataset used for domain adaptation (https://people.eecs.berkeley.edu/~jhoffman/domainadapt/)) as in that case the requirement is to get the embeddings close to each other for the same class but from different domains. This technique probably works possibly due to the ResNet being pre trained with so many labeled classes. I am not sure how well their heuristic will work for an unlabeled pool that the classifier has never seen. In practice, a self supervised learning method would be applied on a large unlabeled pool of images.<BRK>Summary & Pros  This paper proposes a few shot learning method that uses self supervision as an auxiliary label and trains primary and auxiliary labels via multi task learning. Concerns #1: Novelty of the proposed method  This paper uses a multi task learning approach with self supervision. But this approach is already used in various tasks, e.g., domain adaptation, semi supervised learning, training GANs. Thus I think results in the paragraph "Gains are larger for harder tasks" might be predictable. However, I think Figure 4d is not matched to the claim. So I wonder how to draw the lines in Figure 4d.<BRK>The paper also considers the domain mismatch issue where unlabeled images come from a different domain. Applying self supervised learning techniques to the few shot learning regime is a simple idea, and this paper clearly shows that it can be beneficial. However, as the authors note they include additional experimental settings (like the domain selection idea) that are not in Gidaris et al.(2019), so the works are somewhat complementary. The only other comment I have is that the paper is quite large in scope for a conference submission and as a result there are many details and experiments that are left for the appendix. I could also see the domain selection experiments constituting their own submission. Specific comments:  Truly a minor suggestion but I suggest moving Figure 1 to the top of page 2. The paragraph beginning "The focus of most prior work..." in the Related Work section provides a nice framing of your work and so might make more sense in the introduction.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>I think the authors should make sure that they are not "overfitting" to the test set with the following set of tests:1. Based on the latest iteration of the paper, I am changing my score to 8]This paper studies the representations learned by large pre trained models trained on language modeling objective (or language modeling like objective, in the case of masked models). [EDIT: Thank you very much for the thoughtful and extensive response.<BRK>The authors demonstrated that the pre trained language models have some properties that are similar to constituency grammar by showing some interesting features of the extracted trees. This study is based on the motivation to unveil the reason why such pre trained language models work and the extent to which pre trained language models capture the syntactic notion of the constituency. Also, this paper is well structured and offers a good literature review.<BRK>I am satisfied with the author s response and I am increasing the score to 6 after the rebuttal. This paper introduces a new and simple method of probing whether syntax information under the form of constituency trees is present in recent pre trained language models (e.g.BERT, RoBERTa, XLNet and GPT2) without any additional task specific training. Results suggest that large, pretrained models capture constituency trees to some extent. Therefore they actually have a bias ? Do you have any hypothesis for why this is happening?
Accept (Poster). rating score: 8. rating score: 3. rating score: 3. <BRK>Generalizing attention from 2nd  to 3rd order relations is an important upgrade, and the mathematical context in which this is derived is insightful and may lead to further progress in the development of Transformers capable of constructing still richer structures.<BRK>The paper proposes a transformer block with higher order interactions. More precisely, instead of computing a dot product between a query vector and a key vector, 2 simplicial attention computes scalar triple product. More generally, what kind of tasks can 2 simplicial attention address better? Answering/discussing this question can go a long way in making the paper more valuable. Is it possible to evaluate the improved expressivity of 2 simplicial attention on real world datasets/tasks?<BRK>This paper is an extension of the Transformer Algorithm used to solve sequential problems such as in NLP and games (such as the BoxWorld environment from Zambaldi et al.), stating that the Transformer Algorithm is an inductive bias for learning structural representations.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>Using a combination of RL based solution as a warm start, this paper shows that by adding more improvement and perturbations, the quality of the solutions for capacitated VRP can be further improved. The numerical experiments show that with these extensions, the proposed mechanism is able to perform better than the SOTA LKH3 OR based method in a shorter amount of time. 3) Maybe in future research, the ensemble idea can be tested for making the solution independent of problem size.<BRK>This paper proposes a framework combining RL and OR for solving the capacitated vehicle routing problem (CVRP). The main idea is to train an RL based controller for choosing the OR operations necessary for improving & reinitializing the solution. The proposed method is shown to empirically outperform the existing OR method LKH3 for solving CVRP. The writing is clear and easy to read. One weakness of the paper is the lack of experiments.<BRK>Cons:  The proposed approach has the benefit of using a handcrafted pool of improvement operators that other learning based approaches don’t have. The paper proposes an algorithm for the Capacitated Vehicle Routing problem that starts with a random solution and then iteratively improves it by using a learned policy to select an improvement operator to apply to the current solution. The problem is posed as a sequential decision problem, and the policy is learned using reinforcement learning.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>This paper proposed a method called SVD RND to solve the out of distribution (OOD) detection problem. SVD RND outperforms state of the art methods in several OOD tasks. I believe the proposed method is interesting, and I have not seen a similar approach before. It is a simple method, but it achieves excellent performance in multiple OOD tasks. In summary, I am inclined to accept this paper because it proposes a simple method that gives high performance.<BRK>An example with high error in this task is treated as an out of distribution example. They find that their method of consistently can achieve strong detection rates across multiple target dataset pairs. * The model used for f and g is not mentioned in the text. Please run a model with all the geometric transforms. The original RND paper avoided this problem by also using the network to learn a policy, but this does not exist in this approach.<BRK>####################This paper presents the idea to use blurred images as regularizing examples to improve out of distribution (OOD) detection performance based on Random Network Distillation (RND). The paper proposes to generate sets of such blurred images via Singular Value Decomposition (SVD) on the training images by pruning the lowest K non zero singular values. The main idea of the paper to generate adversarial examples for training via blurring is rather simple and thus the novelty of this work is somewhat minor. 34.Introduce the effective rank at the point where it is used (Section 6.2). (v) What is the idea behind choosing the log effective rank in such an equidistant manner as proposed? A. Alemi.Waic, but why?
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>Comments: pixel real estate and resolution makes it unclear which dataset is bigger, though the authors attempt to discuss this. The paper might be a stronger fit for a targeted workshop on its topic. Some of the tasks the authors attempt might best be attempted with different models.<BRK>Overall, I prefer to reject this paper based on the following reasons:(1) It claimed to address the question “what characteristics should a dataset have to be a good sourcefor remote sensing representation learning”. Later, it used the best in domain representation models to estimate the state of the art baselines on various training size. It is not clear how to select the best in domain representation models.<BRK>​The reviewer understands these could be out of scope of this paper. Again, this is not a significant contribution.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>Summary: The paper shows a deep linear network has no spurious local minima as long as it is true for the two layer case for any convex differentiable loss. 3) The paper looks like a technical report and seems not to be ready. The results are quite incremental from the existing ones. The contributions of this work to the deep learning community are still ambiguous.<BRK>The paper shows that for any convex differentiable loss function, a deep linear neural network has no so called spurious local minima, which to be specific, are local minima that are not global minima, as long as it is true for two layer Neural Network. The result also holds for general “multi tower” linear networks. Overall, this paper could be an improvement of existing results. 2)	How does the result help us understand non linear deep neural network, which is commonly use in practice?<BRK>The paper shows an interesting result: deep linear NN has introduced no more spurious local minima than two layer NN and provides an intuitive and short proof for the results, which improve and generalize the previous results under milder assumptions. Also, it would be of great interest to see concrete results on non linear neural networks, since that is exactly what is used in common practice.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>While well motivated in terms of the background and methodology (indeed, this is a simple way to prevent interference in fast weights), and nicely explored experimentally with lots of examinations into the workings of the method, the weak results on the simpler continual learning settings lead me to consider this a weak reject. The authors show that fast weights can be applied in the continual learning setting, but alone they do not perform that well on the more challenging datasets, with mixed results on how much better they are as compared to a naive fine tuning baseline, and they definitely lag behind synaptic consolidation methods.<BRK>The authors introduce DIFFERENTIABLE HEBBIAN CONSOLIDATION,a new framework for continual learning that can be implemented in the usual differentiable programming setups. 1)Authors comment on two paradigms to hebbian based continual learning: the task specific and theirs, based on CLS. First, the paper is well written, and the method is well motivated in terms of cognitive principles with a nice commentary about underlying neurobiological substrates. Importantly, it is differentially programing friendly.<BRK>This paper tackles the problems of continual learning and catastrophic forgetting in neural networks. In terms of motivation, can you explain why this Hebbian strategy is applied only to the final softmax? The paper addresses an important topic. A figure might be helpful.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>This paper want to show that minimizing cross entropy loss will simultaneously minimize Hinge loss with different margins, cross entropy loss with different temperatures and a newly introduced Gcdf loss with different standard deviations. The main contribution is a new gcdf loss based on Gaussian perturbed parameters. Also, in the last sentence in Sec 3.1, the meaning of x is normalized is ambiguous.<BRK>The results in the paper are not described in enoughdetail to be reproduced. I am convinced that Figures 6 and 12 of this paper showthat optimization of the softmax with a larger step sizeimplicitly optimizes a loss function that rewards robustnessto a greater extent than when a small step size is used. I find this interesting. In Figures 2 and 3 I don t see that they have adequately controlledfor the effect of the learning rate on how fast the explicitlyminimized loss is reduced.<BRK>The results reported in the paper are interesting. However, currently I am not convinced that the contributions are sufficient for publication at ICLR as the scope of the performed analysis is limited. These experiments would help to better understand the observed phenomenon and analyze the effect of different settings. The authors consider alternative loss functions for deep networks: (1) the temperature scaled cross entropy loss with different values of the temperature; (2) the hinge loss with different values of the margin parameter; (3) the Gcdf loss with different values of the variance parameter.
Reject. rating score: 1. rating score: 1. rating score: 1. rating score: 1. <BRK>2.Assessment: The problem studied in this work is very interesting and important. The high level idea also looks interesting. However, this paper is clearly not ready to submit as it contains a lot of grammar errors and lacks a lot of important details. What are the details of reference response retrieval? To many such important details are missing.<BRK>The basic idea of integrating templates for dialog generation is interesting. Worst of all, the experimental results are missing in table 2, the only placeholder for results in the paper.<BRK>This paper introduces a based model for the problem of task oriented dialog. The paper studies an interesting task however it is not ready forpublication:  Empirical results of all baselines are missing (Table 2)  Other results are mentioned but are absent from the manuscript  The related work does not provide details as to how the proposed model to prior work  The figures are difficult to understand (although they do help make the model clearer and so I suggest polishing them for the next version of this work)  The manuscript should be carefully copy edited.<BRK>This paper describes a method to incorporate candidate templates to aid in response generation within an end to end dialog system. While the motivation and task setup is interesting, the paper is clearly unfinished.
Accept (Poster). rating score: 6. rating score: 6. rating score: 3. <BRK>In general, the paper is of values to the community. The paper introduces four techniques to improve the deep network model through modifying Batch Normalization (BN). The paper studies each techniques with the support from experiments. The inspirations are from the gaps between train&test and between batches in multi gpu training, comparison to other normalization methods, and weight decay in regularizing convolution weights training.<BRK>The paper performs an empirical study of four batch normalization improvements and proposes a new normalization technique for small batch sizes, based on group and batch normalizations. Concerns:(1) The comparison with baselines in section 4.2 seems to be unclear. Additional elaboration on what does this means is required. However, the thorough empirical study of existing improvement techniques would be a good addition to the conference. I would also recommend authors to include the following papers to the related work section:1.<BRK>The authors discuss four techniques to improve Batch Normalization, including inference example weighing, medium batch size, weight decay, the combination of batch and group normalization. The proposed inference example weighing method yields promising results and does not require any re training. What is the essential difference between these methods? However, this paper shows that training ResNet 50 with weight decay improves the performance. What would happen if the authors apply the proposed techniques to the non i.i.d.case?7.Some closely related work should be discussed in the paper, such as[1] "Decorrelated Batch Normalization."
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>Summary:This paper studies the certifiable bounds for adversarial perturbations in \ell_2 radius for top k predictions instead of top 1 predictions. The experimental results (Figure 1) support the claim that there is a non trivial difference between the certified radii of top 1 and top k predictions.<BRK>Summary.The paper proposes an extension to the work of Cohen et al.where a certified radius is deduced using a randomized smoothing approach. In particular, the authors show the radius at which a smoothed classifier g at under Gaussian perturbations is certified for the top k predictions. That is to say that the prediction will remain within the top k predictions of g. Setting k 1, one recovers Cohen et al.results.The authors show that the derived radius is tight. The paper is also easy to read. May the authors comment on the following. At least when k 1, increasing sigma increases the certified radius in which I expect to see that most of the samples to be actually within the radius and it should perform much better than lower sigma {0.25,0.5}.<BRK>This paper builds upon the random smoothing technique for top 1 prediction proposed by Cohen et al.for certifying top k predictions with probabilistic guarantees, which enjoys good scalability to large neural networks and in principle can be applied to any classifier. The authors aim to provide (probabilistic) certification on top k predictions, which to my knowledge is the first work to consider this setup. I hope the authors can address my concerns in the Questions below. 3.Experimental results on Cifar 10 and ImageNet showed improved lower bound on certified L2 norm radius when increasing k. The authors also performed an ablation study of different parameters in the proposed algorithm. 2.The discussion on Fig.3 says "We observe that  \sigma controls a trade off between normal accuracy under no attacks and robustness.
Reject. rating score: 1. rating score: 1. rating score: 1. <BRK>Discriminator actor critic: Addressing sample inefficiency and reward bias in adversarial imitation learning. Specifically, the paper extends f VIM (Ke et al., 2019), which uses the f divergence for IL, by using a sigmoid function for discriminator output’s activation function. Figures are too small and difficult to see, especially the legends. This proposed method is named f VIM sigmoid. The title of the Algorithm 1 should be f VIMO sigmoid instead of f VIMO. The paper extends f VIM sigmoid to the setting of IL with observation and proposes f VIMO sigmoid. In order to make the comparison fairer, I suggest the authors to evaluate TV VIM with sigmoid reward output, or include environments that do not have survival bonuses.<BRK>Summary: The submission performs empirical analysis on f VIM (Ke, 2019), a method for imitation learning by f divergence minimization. The paper especially focues on a state only formulation akin to GAILfO (Torabi et al., 2018b). The main contributions are:1) The paper identifies numerical proplems with the output activations of f VIM and suggest a scheme to choose them such that the resulting rewards are bounded. 2) A regularizer that was proposed by Mescheder et al.(2018) for GANs is tested in the adversarial imitation learning setting. 3) In order to handle state only demonstrations, the technique of GAILfO is applied to f VIM (then denoted f VIMO) which inputs state nextStates instead of state actions to the discriminator.<BRK>This paper proposes the application of the f VIM framework (Ke et.al., 2019) to the problem of imitation learning from observations (no expert actions). The authors first identify a potential source of numerical instability in the application of f VIM to imitation learning – the rewards for the policy gradient RL are given by a combination of a convex conjugate and an activation function. Lack of novelty – Although I appreciate the reparameterization applied to f VIM to make it potentially more stable for imitation learning in large state  and action spaces, I don’t think that by itself meets the bar for ICLR. Algorithm 1 is basically the GAILFO algorithm (Torabi et al.2018) written in the f Vim framework, with the proposed reparameterization. What about the JS divergence (GAIL)?
Accept (Poster). rating score: 8. rating score: 6. rating score: 3. <BRK>To this end, the authors propose a variant of Adam   called SAdam   which indeed satisfies such a desired bound. The regret analysis of SAdam is conceptually simple and elegant. The experimental protocol is well detailed, and the results look promising.<BRK>The idea seems interesting, the writing is well written, and the analysis seems correct (I did not fully check all steps, but the key steps seems ok to me). Probs:1.The proposed SAdam is an effective variant of Adam designed for strongly convex functions. The authors also fix a small bug in the analysis of AMSgrad.<BRK>However, I have some concerns on the possible impacts of the results especially in the context of ICLR:  First of all, the assumption to show improved regret is strong convexity of all functions $f_t$. Overall, I think that it is interesting to see that a variant of Adam can be shown to obtain improved regret under strong convexity, I find the assumptions strong and the impact for neural network training, therefore for ICLR, quite questionable.
Reject. rating score: 3. rating score: 6. rating score: 8. <BRK>This work tries to build a sub pile of the test data to save the testing time with minimum effect on the test adequacy and the output distribution. In this paper, the work is done by adding a test sample search algorithm on top of the HGS algorithm to balance the output distribution. However, the novelty of the proposed work is limited, and there is no evidence to show the proposed algorithms can be applied to other related works. In Definition 1 the authors declare that the goal is to satisfy f(T,M) f(T’M) and g(T,M) g(T’M), and then in the following paragraphs they change it to f(T,M)≈f(T’M) and g(T,M)≈g(T’M) with no justification. 2.In Table 2, the authors try to compare the output distribution. To better demonstrate the change between raw testing set and proposed subset, I think that it could be better to present the metrics of distribution or the accuracy of each class instead.<BRK>The paper develops methods to reduce the test data size while maintaining the coverage and the effectiveness on large test data. The paper proposes  a two phase reduction approach to select representative samples based on heuristics. The paper targets a very important problem in practice. Effectively selecting small, representative test sets can save many computational resources and greatly accelerate the research and development. Overall, the work can be much improved if a theoretical framework is proposed.<BRK>The paper presents a new approach to create subsets of the testing examples that are representative of the entire test set so that the model can be tested quickly during the training and leaving the check on the full test set only at the end to validate its validity. The key idea is to create the smaller possible subset with the same or similar coverage (in the paper the neurons coverage is considered) and output distribution, maintaining the difference below a (small) threshold. In this way, an estimate of the output distribution is considered during the extraction of the representative subset of the testing data. The whole process is divided into two phases, the first is to create a first subset using HGS, the second refines this subset in order to achieve the desired precision in the output distribution. Moreover, a similar problem is present for TI, which is introduced in Algorithm 1 and described later. I would expect monotonicity here. Do the authors have any idea of the reasons for this? Finally, it would be interesting to know the runtime to obtain the subsets of the test data of Table 2 required by the considered systems.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>This paper tries to study the importance of different components of GNNs. 1.There is no theoretical analysis in the paper. To study this problem, this paper proposes two models, Graph Feature Network (GFN) and Graph Linear Network (GLN). For example, on some datasets, GFN, GLN, and GNN s performances are close while on other datasets, there are gaps.<BRK>If the suggestions below can be addressed in author response, I would be willing to increase the score. Although this decomposition may not be unique in general, as pointed out in the paper, these two parts can help analyze the impact of each part in the GNN model. Overall, this paper is well written and the contribution is clear.<BRK>The paper dissects the importance of two parts in GCN: 1) nonlinear neighborhood aggregation; 2) nonlinear set function by linearizing the two parts and resulting in Graph Feature Network (GFN) and Graph Linear Network (GLN). Extensive ablation studies are conducted to single out the effects of various factors. The paper is also clearly written, with clean notations, and well structured sections.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>Discreteness in activations is one form of regularization to reduce |tilde(x)|. I liked the motivation and presentation of the paper but see some critical shortcomings:  In Theorem 1, shouldn t there be a term that accounts for the complexity of the hypothesis class (VC dim, Rademacher complexity etc.). The experiments do not compare with any mutual information related baselines.<BRK>The proposed method is also limited in its scope to classification tasks only and the authors make no attempt to address regression or reinforcement learning problem, which limits is widespread applicability. Most notable among them is the work of Kim et al."Bayesian Model Agnostic Meta Learning" (https://arxiv.org/pdf/1806.03836.pdf), which is not referenced or compared against in this paper at all.<BRK>Finally, that both experiments are image based raises questions as to the generality of the method. Thus, I do not believe this work is ready for publication in its current form.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>Summary: The paper proposes behavioral repertoire imitation learning (BRIL) which aims to learn a collection of policy from diverse demonstrations. BRIL learns such a collection by learning a context dependent policy, where the context variable represents behavior of each demonstration. This feature space is then reduced by using a dimensionality reduction method such as t SNE. Score: The weaknesses of the paper are novelty, clarity, and evaluation. I vote for rejection. The major issue of the paper is the lack of novelty. The main difference is that, BRIL relies on a manually defined context variable (behavioral feature space). The paper lacks important baseline methods in the experiment. Moreover, BRIL is evaluated only on the StarCraft environment with only one kind of manually specified feature.<BRK>BRIL then preforms behavioral cloning on these demonstrations, with the reduced representation of the current strategy as an additional input to the policy model. Empirical evaluation of BRIL is conducted in StarCraft II, where the agent is tasked with scheduling the construction of different units (other aspects of play are controlled by built in AI). The best way to view this work is as a method for learning goal conditioned polices from demonstrations. Neither the theoretical discussion nor the empirical results compare BRIL against existing work on learning goal conditioned policies. This idea is not explored in any great detail however, and no comparisons with existing methods combining IL with RL are conducted, so the value of BRIL in that context is unclear. I would, however, recommend this as direction for future work with BRIL.<BRK>Demonstrations used in training are labeled with differences in behavior across dimensions (which are then reduced to two dimensions using t SNE), and then these behavior labels are provided as additional input when training a NN from demonstrations using behavior cloning. in order to have a better evaluation of the BRIL approach. The biggest weakness in this paper   and barrier to acceptance   is in the really small sample size of the results where only 4 cluster behaviors out of 62 are evaluated.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. rating score: 3. <BRK>This paper describes a neural architecture search method for computation resources allocation across feature resolutions in object detection. The experiment results have quite nice improvements on several standard data sets. This is a great, well written paper overall. I only have very small questions and suggestions to this paper. I read the Figure 4, Table 5 and Table 6, but I really cannot understand why those networks are that  good .<BRK>The paper attempts to apply neural architecture search (NAS) to re arrange, or re allocate the network backbone blocks and the convolution filters for object detection. After search, the model is shown to have 1) better AP results; and 2) more balanced effective receptive field (ERF). + I am not aware of any work that performs search on backbone architectures for object detection yet.<BRK>This paper works on neural architecture search for object detection. The results show healthy improvements among different network architectures. Overall it is a valid paper with reasonable ideas and decent results. However, the results are not exciting enough. I will be happy to alter my rating if the authors show more exciting observations (not limited to the above direction).<BRK><Post rebuttal comments>Authors  responses partly resolved my concerns on the experiments. I have no object to accept this paper. 2.Experimental results are rather weak.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>The proposed AUL (area under the loss curve) makes intuitive sense, and exploiting the fact that noisy examples are hard to learn at the early stage of training, leading to higher AULs than clean examples. 3.Experimental results suggest advantage of the proposal. This has been the concern not only for this work, but also for this general research area. For instance, on Tiny ImageNet dataset (e.g., used in SELFIE: Refurbishing Unclean Samples for Robust Deep Learning (ICML19), which could btw be used in the benchmark), a clean dataset only gives ~55% test error, compared with about ~10% on CIFAR10 and ~30% on CIFAR100. The robustness of AULs needs to be tested on those harder problems as well. 2.AULs are based on the assumption of a clear separation of two types of examples   clean and noisy. This raises the question of where to place hard clean examples between those two modes. 3.It usually helps to include a real world noisy datasets where its noisy corruption is unknown. One would be curious to know the noisy level estimate. Is it 2x, 3x, considering there are distinct stages of training before and after AUL estimation?<BRK>In this paper, the authors proposed methodologies to identify mislabeled training examples. To mitigate the randomness in the training loss, the authors proposed an AUL (area under the loss) metric, which is less noisy that directly examining the loss. The authors proposed to downweight training examples with high likelihood of being mislabeled. While I agree the method has a good potential to be significant, in its current form, I have several concerns that prevent me from recommending acceptance. 1.How can we be sure that examples with large training loss are mislabeled examples, rather than examples that are inherently difficult to classify? This question becomes more relevant when the model does not have sufficient complexity, or does not have the correct form of complexity. 2.If we cannot distinguish mislabeled examples with examples that are hard to classify, then it seems to me that a simple downweighting based on AUL could potential lead to the opposite outcome. What it we have a different error distribution, e.g., the label has p probability of being correct, and (1 p) probability of being k, where k is a constant?<BRK>This paper proposes a new method of detecting label noise through calculating the Area Under the Loss statistic, which is based on the learning trajectory. I believe this paper is NOT the first one to point out the different training behavior of clean and noisy samples in the label noise problem. While the author mentioned that Shen & Sanghavi used the training losses for selecting data, Shen & Sanghavi also observed the training loss for good and bad samples are different across time. Therefore, it would be good to give correct credit to previous work, and not over emphasizing the contribution. Please proofread the paper, and correct the typos.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. rating score: 3. <BRK>This paper proposes MIGE a novel estimator of the mutual information (MI) gradient, based on estimating the score function of an implicit distribution. I strongly encourage the authors to cite [1] and [2] and mention them in the related works. I recommend ACCEPTing this paper. While the proposed technique consists of previously known building blocks (spectral Stein gradient estimator and random projections), it is cleverly applied in a novel context of estimating MI gradients.<BRK>This paper proposes the Mutual Information Gradient Estimator (MIGE) for estimating the gradient of the mutual information (MI) instead of calculating it directly in learning representation. They are using Stein s estimator following by a random projection to build a tractable approximation to the gradient of the MI. The MIGE is evaluated on several of unsupervised and supervised tasks, and shown improvement over prior MI estimation approaches in maximize the MI and learning features for classification.<BRK>This paper works out estimators for the gradient of Mutual Information (MI). The focus is on its recent popular use for representation learning. Minor comments:   *’In practice, we do not care about MI estimation’. The information ‘between z and z’ is probably a typo? Is it the improved representations (as obtained by using MIGE) or is it the change classifier? 3)One contribution of the paper is to make the gradient estimator work in high dimensions. To this end, the authors propose Random Projections.<BRK>The paper argues that directly estimating the intractable mutual information (MI) for representation learning is challenging in high dimensions. Using some identities of MI the authors arrive at an expression for the gradient of the mutual information between input and latent representation (eq 10) and proposes to use a generalization of the reparameterization trick and spectral stein gradient descent to approximate this gradient. Pros:1) I find the approach taken by the authors interesting and different from current MI estimation approaches. Further i would like some discussion on the quality of this approximation?
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>The authors observed that the wider deep neural networks can learn much rich representative features than shallower deep neural networks while both networks show similar level of the test performance. I wonder that the results on figure 4 are caused from this problem. Comparison with just two different width is not enough to analyze the situation.<BRK>This paper considers the effect of network width of the neural network and its ability to capture various intricate features of the data. I find the results promising but the paper is not yet ready.<BRK>This paper investigates wider networks using a recent feature visualization technique named activation atlases. However, I tend to reject this paper since it doesn’t show very compelling evidence through experiments. But all the datasets and architectures used in this paper are quite simple from the view of deep learning.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>This paper studies activation quantization in deep networks. The authors first compare the coordinate discrete gradient and those obtained by various kinds of straight through estimators, and found 1 bit activation networks have much poorer gradient estimation than 2 bit ones.<BRK>Do you mean 1 bit activation has larger gradient mismatch than other bits, at least in the defined cosine similarity by this paper?<BRK>"Please note that BN layers followed by binary activation layer can be merged to the threshold of the binary activation layer, incurring no overhead at inference stage." This could also be due to poor initialization in the binary case.
Reject. rating score: 3. rating score: 3. rating score: 8. <BRK>The work and its results heavily peg on the DeepBugs and increases the precision of its first step by a significant margin, but does not show getting any more useful results. Technically, the paper improve this first step of DeepBugs by using a standard variant of ELMO. The evaluation is detailed, but the results are unsurprising. The paper simply tech transfers the idea from NLP to Code.<BRK>This paper leverage recent advances of ELMo in context embedding and apply it in the source code embedding. To evaluate the effectiveness of the proposed approach, authors conduct experiments on the downstream task of the bug detection. 2.The application and combination of different techniques in this paper are smart. Cons:1.It is a good application of known techniques, but the novelty is limited.<BRK>The paper proposes an embedding method for source code tokens, which is based on contextual word representation, particularly is based on the method of ELMo. The learned representation is evaluated on the task of bug detection, with promising performance. Experiments are useful and reasonable and the experimental results are promising and in the favor of the paper. The paper is well written and clear. The incorrect Binary Operator example in Listing 2 does not seem to be a well justified bug.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>The authors address the important issue of exploration in reinforcement learning. In this case, they propose to use reward shaping to encourage joint actions whose outcomes deviate from the sequential counterpart. Although the proposed intrinsic reward is targeted at a particular family of two agent robotic tasks, one can imagine generalizing some of the ideas here to other multi agent learning tasks.<BRK>The paper proposes a novel algorithm for encouraging synergistic behavior in multi agent setups with an intrinsic reward that promotes the agents to work together to achieve states that they cannot achieve individually without cooperation. Some clarification is required here   did the extrinsic reward only baseline use the same skills as the proposed method? Empirical analysis shows that this intrinsic reward promotes synergetic behavior on two agent robotic manipulation tasks and achieves better performance that baselines and ablations.<BRK>The paper focuses on using intrinsic motivation to improve the exploration process of reinforcement learning agents in tasks with sparse reward and that require multi agent to achieve. The authors proposed to encourage the agents toward the actions which changed the world in the ways that "would not be achieved if the agents were acting alone". In this paper, it is presented by two types of intrinsic rewards: compositional prediction error and prediction disparity.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>This paper proposes a method to summarize a given graph based on the algebraic multigrid and optimal transport, which can be further used for the downstream ML tasks such as graph classification. Although the problem of graph summarization is a relevant task, there are a number of unclear points in this paper listed below:  In Section 3.1, the coarsening method has been proposed, which is said to be achieved by finding S such that A_C   S^T A S.     However, A_C is usually not binary for S \in R^{n x m}, hence how to get the coarse graph G_C from A_C is not clear. In experiments, how is the proposed method used for graph classification? It seems that it is not used in Algorithm 1.<BRK>The paper proposes a differentiable coarsening approach for graph neural network (GNNs). GNNs is indeed an interesting line of research. However, there are some major downsides. Moreover, if you check the paper above, they report much better results for PatchySan on MUTAG, better results on Protein for graph kernels, better results on IMDB B using a hierarchical GNN approach, based on ideas of higher order WL. Nevertheless, indeed, the present paper shows that a differentiable pooling using WL kind of ideas is competitive to existing pooling approach. This is nice, but in the light of the work above, the novelty is unclear.<BRK>This paper proposes an unsupervised hierarchical approach for learning graph representations. The proposed architecture is constructed by unrolling k steps of a parametrized algebraic multigrid approach for minimizing the Wasserstein metric between the graph and its representation. The approach is compared against 6 other state of the art approaches on 5 graph classification tasks, showing significant improvements 4 of them. It looks like the main point is  that this architecture is trying to emulate iterative coarsened residual optimization of the Wasserstein metric between a graph and its representation. The empirical results are quite intriguing.
Reject. rating score: 1. rating score: 1. rating score: 3. <BRK>The authors propose a variant of sequence to sequence models that operates on the fixed segments (waves). The paper contains significant flaws both in its writing and its experimental setup. I believe that this statement is completely irrelevant to the paper.<BRK>In this paper, the authors propose modifications to baseline seq to seq systems for wave to wave translation. To handle possibly long inputs and outputs, as well as significant length differences, they propose to use sliding windows. I would reject this paper because it largely ignores the litterature on speech recognition, text to speech synthesis and speech to speech translation (e.g.Jia et al.Direct speech to speech translation with a sequence to sequence model). The contributions of the paper are unfortunately minimal.<BRK>How many humans were involved in rating and what were they asked to do? Overall, given the quality of writing and lack of methodological novelty this paper is not ready for publication. Strenghts:+ application on activity translation and evaluation by human raters is interesting+ the proposed work is a nice application of an encoder decoder architecture in case of multivariate time seriesWeaknesses:  there is no methodological novelty. The proposed network uses a standard architecture and the authors use straightforward partitioning of the signal in equal sized windows.
Reject. rating score: 1. rating score: 1. rating score: 1. <BRK>The motivation of this paper is to use the idea of Transformer based NLP models in image data, which is appreciated. However, this seems to be a far unfinished paper. Moreover, the network structure in Figure 2 is not explained. The experimental part is very brief, and unconvincing.<BRK>This paper attempts unsupervised representation learning, via a patch prediction task on ImageNet. I understand the code for CPC++ might not be released yet, but the authors could at least implement their best approximation of it, and also find older works (which CPC compared against in their paper), to fill out the results and make a convincing argument. The paper barely includes any evaluation. Also, the method does not appear to be very novel: I recommend the authors look at and compare against "Unsupervised Visual Representation Learning by Context Prediction" (ICCV 2015), which is conceptually very similar.<BRK>After pre training on unlabeled imageNet datasets the proposed approach is competitive with these algorithms with roughly similar results. The paper could improve on its experimental evaluation bycomparing on multiple datasets, showing error bars when averaging across multiple samplings (eg for getting the 1% label set from the entire imageNet dataset) and also comparing with other approaches even when they dont directly aim to learn representation from unlabeled data (eg Image Transformers by Parmar et al). In addition the description is very high level and does not provide enough details for experimental reproducibility. For example the reviewer had to actually guess at some of specifics of the overall end to end architecture since it was not fully described precisely eg in a diagram.
Reject. rating score: 1. rating score: 1. rating score: 6. <BRK>This paper proposes to use an additional component to the commonly used encoder decoder approach for summarization, which is referred to as the recoder, which is an RNN syle component that takes the output of the decoder. The intuition offered in the paper is that a good summary should produce itself via the recoder network, and in training it together with the original encoder decoder it should improve its performance as it would be able to capture more than what the word level loss does. I have the following objections to this paper:  I can t see why this extra component should improve the quality of the summary produced. If say our encoder decoder architecture models the training data perfectly, then a recoder that does not do anything would be the right choice. Sure it has flaws, if there is something better why not use it for evaluation? Finally, showing the reference summary creates another bias, since equally good summaries can disagree on what content to include.<BRK>This paper introduces an encoder decoder as a differentiable loss function for sequential autoregressive generation tasks and more specifically for summarization. This is done by adding a recorder network that that takes the decoded sequence from the summarizer as input and is trained to output the reference summary. * But for training (original seq2seq + recorder) authors backpropagate the NLL loss (which is fully differentiable) of the recorder on reference summaries through the softmax probabilities of outputs from the seq2seq model. >> This whole architecture can be seen as a traditional end to end seq2seq model with non linearity and normalization (softmax) in the middle.<BRK>This paper proposed an encoder decoder based summarization network as a loss function within a similar encoder decoder based summarization framework to demonstrate that the proposed model obtains better automatic and human evaluation scores compared to the baseline model of See et al.(2017) with just traditional loss functions. Overall, the paper is well written and the presented results, analyses, and comparisons appear to be reasonable. Few comments:  "A presents either a word ...."  > this sentence is not clear. It would be great if you could provide more details on the selection criteria/qualifications of the mechanical turk workers.
Accept (Poster). rating score: 6. rating score: 6. rating score: 3. <BRK>This paper studies the theoretical property of neural network s loss surface. The main contribution is to prove that the loss surface of every neural network (with arbitrary depth) with piecewise linear activations has infinite spurious local minima.<BRK>This paper focus on how activation functions’ nonlinearities shape the loss surface of neural networks. Secondly, the authors prove one theorem to show four properties of the loss surfaces of nonlinear neural networks. The authors assert that “the loss surface of *every* neural network has infinite spurious local minima” in the abstract, while in chapter 3 line 2, authors mention, “We find that *almost all* practical neural networks have infinitely many spurious local minima.” Which one is correct? It could be feasible when training a stacked network with particular limitations.<BRK>Summary: This paper studies the landscape of deep neural networks with piecewise linear activation functions. The paper showed that under very mild assumptions, the loss surface admits infinite spurious local minima. If the network is two layer with two piece linear activations, it is proved that within each cell every local minimum is global. (a) The main message of Thm 2 is the partition of the surface into multiple pieces, and each piece has good property. Theorem 2 mainly describes the property of each region separately for 2 layer network, which is weaker than [R1]. (b) Theorem 2 seems easy to prove. The 2nd property “local analogous convexity” was given a 2 page proof in the paper. If not, what is the difficulty?
Reject. rating score: 1. rating score: 1. <BRK>  This paper introduces a structured consistency loss for semantic segmentation under the semi supervised learning paradigm. The only contribution seems to be the ‘first study that employs semi supervised learning and achieves state of the art performance in semantic segmentation using the Cityscapes’. Which is the difference with French et al.(2019) and Liu et al.(2019)?Both seem to be using CutMix for semantic segmentation.<BRK>Summary:  key problem: semi supervised semantic segmentation;  contributions: 1) combine the CutMix data augmentation of Yun et al 2019 with the standard consistency loss of  and the  structured consistency loss of Liu et al 2019, 2) state of the art results on Cityscapes.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>The paper proposes the conditional normalizing flow for structured prediction. The idea is to use conditioning variables as additional inputs to the flow parameter forming networks. The model was demonstrated on image superresolution and vessel segmentation. I find the contribution of this paper minimal. The idea of conditioning has extensively been used during recent years because it is the most natural thing to do (e.g., [1], [2] and numerous other papers). Their s nothing new about the flows used in this paper. The results in table 2 are not convincing; I see no benefit of using the proposed flow model for image super resolution instead of the SOTA super resolution methods. This also applies to other experiments.<BRK>The paper is well written overall and easy to follow. Basically the conditional prior z|x   z f_{\phi}(y,x), where x is the conditioning random variable, and we apply the change of variable formula to get the density of y|x . image.To sample from the models authors propose to use f^{ 1}_{\phi}(z;x). The conditional modules are natural extensions of invertible blocks used in the literature (coupling layers, split priors, conditional coupling, 1x1 conv), where the conditioning is done on some hidden representations of the conditioning variable x (i.e one or multiple layers of NN). Authors propose a dequantization for binary random variables (useful for segmentation applications), where they give an implicit model for the dequantizer (obtain a continuous variable from a discrete binary variable). Minor comments :   Formatting the bibliography is messed up and needs some cleaning , Figure 5 is also making formatting issues of the paper. Figure 1 for sampling it should be f^ 1_{\phi } and not f_{\phi}Review:   Figure 2 is hard to get any idea of the sample quality would be good also to put the low resolution input to the algorithm . can the model be just overfitting? The conditioning for the vessel implementation on x is on two layers , would be great to put all architectures of the models in details , and to show both sampling and training paths   It would be great to add the details of the skip connection used from the network processing x, and how ensure that the flow remains invertible. Overall this is a well written paper and a good addition to normalizing flows methods , some discussion of related works on conditional normalizing flows and more baselines with other competitive methods based on GANs for example would be helpful but not necessary.<BRK>This paper presented the conditional normalizing flows (CNFs) as a new kind of likelihood based learning objective. There are two keys in CNFs. The mapping function is invertible with x as a parameter. The output targe y is obtained with dependency on x and f_{\phi}. This study adopted the flow based model to estimate the conditional flow without using any generative model or adversarial method. 3.This paper proposed an useful solution to train continuous CNFs for binary problems. In particular, the property invertibility should be clarified. 2.Why the issues of mode collapse or training instability in flow are considerable in the experiments?
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>The authors study continual, lifelong learning. They suggest a new algorithm, named Adaptive Online Planning (AOP) that combines model based planning with model free learning. The main reason is that the experiments were only performed for 3 different seeds and are therefore not statistically relevant (see Henderson et al."Deep reinforcement learning that matters." 2018.).Besides the issue of significance of the results section, there are other concerns. Is this a reasonable assumption?<BRK>For achieving that, the authors propose an algorithm, Adaptive Online Planning (AOP) combining a model free policy learning method and a model based planner. The last comment is about the 3 environments that are not complex enough. The motivation is interesting to me, but the authors do not provide enough justification.<BRK>The paper presents an adaptive online planning(AOP) strategy in a model free policy setting, a reinforcement learning method aimed to solve catastrophic forgetting problem by combining model based planning and model free policy learning. While the improvement in computation is there, what I find lacking is the experiments demonstrating clear evidence of overcoming catastrophic forgetting problem.
Reject. rating score: 6. rating score: 6. rating score: 6. <BRK>The technique of replay is well established. You have added a selection criterion for what to replay. You show a modest improvement over a random sample. You choose to view this as proof of the criterion, I on the other hand see it as proof of a very small result. To me it seems more like a negative result. I believe negative results are as important as positives. So I recommend acceptance. You may want to expand the selection criterion you evaluate. You selected the most leverage on forgetting what happens as you select less and less leveraged cases?<BRK>*** SummaryThis paper proposes to formulate the continual learning problem as a meta learning problem where the multi tasking and forgetting can be addressed simutaneously. To assess the forgetting, this paper suggests using the anchor points learned in hindsight. Empirical results show that this formulation performs better than previous methods. The idea of using meta learning to deal with the forgetting issue is interesting. 2.The comparison with the previous shows that the proposed method performances consistently well on multiple tasks. I wonder if the authors have any intuition behind this. Basically, this result is not persuasive for the effectiveness of the proposed anchor point learning method. Also, I’m curious to see what would happen if you have oracle access to future tasks which means we don’t need to learn the anchor points in hindsight. There are several typos.<BRK>This paper proposes an approach for continual learning that improves existing memory / replay  based methods, by learning anchors for each previous task. The paper is well written, it is a novel and well explained idea, and the results are compelling. b) Does it always make sense to choose anchors that maximise forgetting on the current task? It would be interesting to visualize what anchors are found. Are they examples that tend to be visually close to other classes, or are they outliers? d) Given that anchors are already estimated and used to alleviate forgetting, what s the benefit of the additional episodic memory? An ablation is performed with different memory sizes, but what if *only* anchors are used (ie.a size of zero)? 2) On the two step optimisation (Eqn.5):a) It s not clear to me why this constitutes a meta learning process: there is no adaptation at test time, nor does this perform task inference or learn how to learn. In this case, the method just uses a single gradient step to compute the change in predictions at the anchor points. It would be good to clarify whether this is the case, and add further discussion and intuition as needed. The equivalent result for splitCIFAR in the iCARL paper (for 20 tasks x 5 classes) appears to be around 45 50%, so I think it is necessary to compare and evaluate the source of this large improvement in performance.
Accept (Poster). rating score: 6. rating score: 6. rating score: 3. <BRK>The authors present an algorithm CHOCO SGD to make use of communication compression in a decentralized setting. This is an interesting problem and the results are promising. Firstly they prove the convergence rate of the algorithm on non convex smooth functions, which shows a nearly linear speedup. Also, the paper is mostly nicely written.<BRK>This paper studies non convex decentralized optimization with arbitrary communication compression. It is well motivated and well written. The authors also show CHOCO SGD with momentum is effectiveness in practical. The experimental results on several benchmark datasets validate the algorithm achieves better performance than baselinesBoth of the theoretical and empirical results are convincing.<BRK>This paper studies the convergence of CHOCO SGD for nonconvex objectives and shows its linear speedup while the original paper of CHOCO SGD only provides analysis for convex objectives. The momemtum version of CHOCO SGD is also provided although no theoretical analysis is presented. Extensive empirical results are presented in this paper and the two use cases highlight some potential usage of the algorithm. First, the authors only provide analysis on CHOCO SGD but the comparison with baselines are based on their momemtum versions. Thus, the advantage of vanilla CHOCO SGD over other alternatives is not convincing. However, no evaluation of the consensus is presented and this leads to the following point. In this case, the obtained average loss can be even smaller than the optimal loss.
Reject. rating score: 6. rating score: 6. rating score: 8. <BRK>Summary of the Paper:  The authors claim the that i.i.d hypothesis that is often used in the prior when looking for the equivalence between neural networks and GP is not valid. Detailed comments:Overall I believe that the writing of the paper is very sloppy and difficult to read and follow. The same for non Gaussian variables. Therefore, I do not think that the GP interpretation of the NN is wrong simply for that. This simply shows that the i.i.d.prior may be suboptimal. Summing up, I think that this paper needs more work. The prior is subjective and can be chosen by the user. So if an i.i.d.prior is actually chosen, the corresponding Bayesian  neural network will converge to a GP. However, it can be used to interpret neural networks as GP. There is no problem with that. It is well known that the sum of random variables can also converge to a Gaussian distribution even though they are not independent. The witting of the paper needs to be improved. Z y in Eq.(9) should depend on l.It is not clear what is the distribution of a hidden layer (activations weights etc..). However, the authors give an expression for f_yl, which does not make sense.<BRK>Main contribution of the paper  The paper argues that the base assumption, the i.i.d.of the activated elements (activations) in the hidden layers, the existing methods (lee.et.al 2018) hold is not convincible. Methods  The author argues that the activation is not iid by empirically showing that the trained MLP (in most cases) does not un correlated. The author proposes a regularization term regarding layer/layer connection. They argue that the SGD training can be seen as a first order approximation of the inference of the hidden activations in MLP. Concerns  The main concern is that the reviewer cannot fully convince that i.i.d.assumption is wrong. supports the argument of the author, but the reviewer failed to clearly agree with the argument. As far as the author understands, the paper proposes a probabilistic (Bayesian) model for explaining MLP, but it seems that they just used SGD for training the model. The explanation using Gibbs distribution and PoE looks similar to RBM. However, the reviewer failed to fully agree on some steps in the process of the paper. Therefore, the reviewer temporary rates the paper as weak reject, but this can be adjusted after seeing the answers of the author. Inquiries  See the concerns parts.<BRK>The authors show that parameters of a DNN do not satisfy the i.i.d.prior assumption and that neural layer activations considered as i.i.d.are not valid assumptions for all hidden layers of the network. The authors suggest formulating the neurons per layer as energy functions thereby rendering a hidden layer as a Gibbs distribution and the connection between adjacent hidden layers as a PoE model. The paper is well written and well postulated. How would this have looked with the i.i.d.prior in place. > There are places in the paper where one must refer to the supplementary, for example sections H and J with the simulations. > One recurring thought I had when the authors bring up Bayesian Hierarchical model, is that most of the BHMs rely on i.i.d assumptions both in the prior space and with the observations. How would you stand by your claim of explaining a DNN s layers to be modelled as a BHM?
Accept (Spotlight). rating score: 8. rating score: 6. rating score: 6. <BRK>The paper proposes to improve upon GANs by considering to infer the distribution of realness instead of binary true/false labels in the discriminator side. The authors are encouraged to share their code and results to public.<BRK>Summary:This paper extends the discriminator of GAN to use a distributional output (multiple scalars) instead of a single scalar. The choice of anchor distributions A_0 and A_1 are not specified. While the authors provide some partial results in Table 2, it would be worthwhile to clarify the experimental details and justify them.<BRK>Does the method work if we remove it ? This paper propose a new GAN formulation where the Discriminator outputs a discrete probability distribution instead of a scalar for each inputs. The paper show that the proposed approach is a generalization of the standard GAN. In addition the paper propose two tricks 1) they include an additional term in the loss for the generator, such that the generator is also trying to minimize the KL between the discriminator distribution for a generated and the discriminator distribution for a real samples.
Reject. rating score: 1. rating score: 6. rating score: 6. <BRK>This paper is about training deep models with 8 bit floating point numbers. The authors use an enhanced loss scaling method and stochastic rounding method to stabilize training.<BRK>In this paper, the authors propose a method to train deep neural networks using 8 bit floating point representation for weights, activations, errors, and gradients. This should be clarified. For example, how much improvement can this work achieve when just using enhanced loss scaling method or a stochastic rounding technique?<BRK>Originality: The paper proposed a new scaling loss strategy for mixed precision (8 bit mainly) training and verified the importance of rounding (quantization) error issue for low precision training. The experiments are very clear and easy to follow. The enhanced loss scaling strategy is interesting but the method seems hand tuning. 2.The stochastic rounding method is very intuitive.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>This paper introduces a nonparametric score test to estimate the importance of network connections on the final output of Deep Neural Networks. I believe this paper is a borderline accept. It lacks baselines on more complex networks and could benefit from more empirical analysis of the theoretical benefits and properties of this approach. Cons:The empirical results could be clearer. It lacks baselines for larger models on Cifar10. The experimental setting is somewhat unclear. It would be interesting to visualize the importance of features at different depths in the deep convolutional networks.<BRK>The paper proposes a new way of evaluating the importance of neural connections which can be used for better model compression. The approach uses a non parametric statistical test to detect the three way interaction among the two nodes and final output. The approach seems interesting in the sense that, unlike existing techniques, it explicitly measures the three way interaction among the two nodes and the output. The paper is general clear and well written.<BRK>In this paper, the authors propose a new pruning technique that utilizes the statistical dependency between the corresponding nodes and outputs. Pruning is one of important problems for practical deep learning operations. This paper gives an interesting idea for the pruning techniques. I think the idea is novel. The numerical experiments are conducted in small datasets.
Accept (Talk). rating score: 8. rating score: 8. rating score: 8. <BRK># SummaryThe papers studies the effects of code level optimization on the performance of TRPO and PPO. Details, usually considered as implementation level particularities, are shown to be of crucial importance for the algorithms  performance. # DecisionThe paper makes an important point, it is written clearly, and the body of evidence is convincing. Therefore, I recommend this paper for publication. In Sec.2, there is a link to Appendix A.2 for a "full list", but the list in A.2 does not contain all points from Sec.2.For PPO M, it is said "implements only the core of the algorithm". What exactly does that mean? PPO NoClip is defined as "PPO without clipping".<BRK>This paper investigates the impact of implementation "details", with existing implementations of TRPO and PPO as examples. The clipping objective of PPO is also found to have no significant impact on its performance. This calls for more careful comparisons between algorithms (by minimizing implementation changes and more in depth ablation studies) than has typically been done until now in the RL research community. Although this paper is pretty straightforward and does not bring meaningful algorithmic improvements, I still believe it should be accepted as reproducibility and evaluation are a major issue in RL, and people need to be aware of these kinds of implementation differences that can affect the reported results. My only important concern is that I could not find a link to the code, which I believe is a must for such a paper focusing on implementation.<BRK>This paper identifies many "code level optimizations" that account for the differences between the popular TRPO and PPO deep policy gradient algorithms. The clear conclusion from the paper is that the touted algorithmic improvement of PPO over TRPO has negligible effect on performance, and any previously reported differences are due only to what were considered unimportant implementation details. I find the work included in this paper to be novel and a valuable contribution to the field. As demonstrated in Henderson et al.2017 (which is heavily cited in this paper), using such a small number of random seeds can have very misleading results. These are not simply implementation details as "code level optimizations" suggests, but are rather details that necessarily must be included in peer reviewed works.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>Note: The template used in this paper is of ICLR 2019, not ICLR 2020. This paper identifies the information space and nuisance space by thresholding the singular values of the network s jacobian and shows that generally the residuals projected to the information space can be effectively optimized to zero, thus leading to efficient optimization and good generalization. To summarize, this paper definitely contains some rigorous analysis which I appreciate, but it doesn t provide new insights into optimization and generalization for deep nets. [1] Arora, Sanjeev, et al."Fine grained analysis of optimization and generalization for over parameterized two layer neural networks." ****** Post rebuttal response ******Thanks to the authors  response.<BRK>The paper divides the space of weights and biases into the “information” and “nuisance” subspaces, spanned by the top largest and the remaining singular vectors of the Jacobian respectively. They use this division and its alignment with the low rank structure of the data to talk about convergence speed. While the paper seems interesting, I am not sure what its novel contribution is and how broad the claims made actually are in their applicability. For deep networks that are used on these big datasets, such a modelling assumptions would likely not be true. Point 3  Square loss vs softmaxYou are using the square loss |f(X)   y|^2 throughout your work. Do you know how this relates to your results?<BRK>This paper proposes new (data dependent) generalization guarantees based on the Jacobian of the model. The faster convergence of the model in the information space is not surprising and was observed by Jacot 2018. It is also formulated as a classification problem instead of a regression one. However, the setting considered by the authors to derive their theoretical contributions is too restrictive. The model exposed in section 1 is extremely simplified, as only W can be learned and V is fixed. As a result, the model is in essence completely linear: the goal is, for a given V, to learn a “good” hidden layer using a linear model and the loss L : h  > ||V phi(h)   y ||. The results uncovered are not surprising and predicted by Jacot 2018 (granted, it is interesting to see that the result holds for finite width and non continuous gradient flow). I think this paper in its current state is not good enough for two reasons. Nitpick:Page 2: “our results may shed light on the generalization capabilities of networks initialized with pre trained models commonly used in meta/transfer learning” seems like a bit of a stretch.
Accept (Talk). rating score: 8. rating score: 6. <BRK>This paper combines CapsuleNetworks and GCNNs with a novel formulation. Second they share the group equivarient convolution filters per all capsules of the lower layer. The discussion on ideal graph on page 5 is interesting. Reporting results by training on MNIST, testing on AFFNIST could shed light on this aspect of SOVNETs. I would advise reporting GCNNs for all the experiments in the main paper.<BRK>In this work, a method was proposed to train capsule network by projectively encoding the manifold of pose variations, termed the space of variation (SOV), for every capsule type of each layer. The proposed method is interesting and the initial results are promising. In the paper, the results are given for a general class of groups. If it is the latter, please provide the variance/standard deviation as well. > This is also a very general concept, which should be more precisely defined.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>This paper discusses a method that effectively incorporates a (large) pre trained LM, such as BERT and XMN, for improving the performance of NMT. The motivation of this paper is rather straightforward and not novel; many researchers can quickly think of such an idea of incorporating the power of the recent (rapid) development of pre training LMs into NMT. This paper provides a straightforward but smart way to incorporate pre trained LMs, which is not trivial in the community. Experimental results are mostly convincing; the authors conducted comprehensive and extensive experiments on many settings, such as supervised NMT with low  and hi resource settings, a semi supervised NMT setting by back translation, document level MT, and unsupervised NMT. 1, unclear explanationsThe writing can be much improved. 3, less discussion for the experimental resultsI found minimal discussions about the results.<BRK>The paper proposes an approach to incorporate BERT pretrained sentence representations within a NMT architecture. It shows that simply pretraining the encoder of a NMT model with BERT does not necessarily provide gains (and can even be detrimental) and proposes instead to add a new attention mechanism, both in the encoder and in the decoder. The modification is relatively simple, but provides significant improvements in supervised and unsupervised MT, although it makes the model slower and computationally more expensive.<BRK>This paper explores the use of BERT to improve Neural Machine Translation (NMT) both in supervised, semi supervised and unsupervised settings. Based on this finding, the authors propose a new approach to integrate BERT in NMT, named BERT fused NMT, which incorporates BERT representations from the input sequence into the encoder and decoder attention mechanisms. On the one hand, the paper presents a thorough experimental evaluation, with strong baselines (often outperforming their original implementation) and results that can be interesting from different angles, and the reported improvements are consistent.
Accept (Poster). rating score: 8. rating score: 6. rating score: 3. <BRK>It performs an empirical evaluation of six algorithms from the literature, k NN, FineTune, Prototypical Networks, Matching Networks, Relation Networks, and MAML. A new approach combining Prototypical Networks and first order MAML is shown to outperform those algorithms, but there is substantial room for improvement overall. This paper fills the need for a more challenging data set.<BRK>This paper proposed a really interesting direction for few shot and meta learning, the concept of a  meta dataset , which can be used for more realistic evaluation of algorithms. My concern about this paper in its current form is that the layout/structure of the paper needs to be improved, for example:Considering putting some of the key results in the appendix section in the main textRemoval of repeating results from the main text by shortening the early sections<BRK>The authors of this paper construct a new few shot learning dataset. After rebuttal:After reading the response, I think constructing a new benchmark is important and useful. The proposed dataset may useful in further meta learning research.
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>This paper proposes to use path planning on the tree structure for multivariate MAB problem. The idea is to model the hierarchical structure in the decision space, thus tree search idea can be applied to improve the efficiency of learning. However, the proposed method is a bit ad hoc and I don’t think the paper provides enough justification for it. However, this paper provides not analysis about such independence even in simulations.<BRK>In this paper, the authors address the curse of dimensionality in Multivariate Multi Armed Bandits by framing the problem as a sequential planning problem. The obtained results seem to support their original claim: the tree based approaches (e.g.FPF) perform better than the considered baselines. Generally, though several good ideas were presented, I felt that they were not properly motivated and that the paper generally lacks rigor and clarity. On the other hand, most of my concerns remain valid, and some were not addressed. Other remaining concerns are more generally the lack of justification and clarity of the proposed framework and implemented variants, and the inadequacy of the experiments with respect to the claim (using m 2 basically means only the first depth of the tree is useful). More importantly, the sensitivity of the Algorithm 1 to S is not evaluated.<BRK>This paper approaches the problem of exploding arms in multivariate multi armed bandits. They propose to versions of this path planning procedure and 2 version inspired from Hill climbing methods. Here are few questions:  The authors claim that the approach can be extended to categorical/numeric rewards. Can they give more details on how? The experiments are done only with D 3 and N 10.
Reject. rating score: 1. rating score: 1. rating score: 1. <BRK>The topic of the paper is a GAN framework to enhance PET images in industrial inspection, as far as I understand by transfer learning from a medical PET database. Unfortunately, I am unable assess the paper due to serious language problems. The text is incoherent and not understandable, it is impossible to decipher what is actually proposed. In may view that would be insufficient for a largely empirical application paper.<BRK>The basic idea seems interesting, but unfortunately in the present form he paper is very difficult to appreciate, as it lacks of important details concerning methodology, experimental results, and comparison with respect to the state of the art. Missing methodological details are grouped in the following parts of this review. In the same paragraph is written that features are extracted through convolution neural networks (CNN). Section 4.2 DatasetIn the first paragraph the authors cite a dataset of CT images, while the main focus of the paper is on PET images. The implementation details of the competing methods are not described so we cannot be sure about the fairness of the comparison. Other considerationsIntroduction, 4th paragraph: “imaging quality is higher” With respect to what? Introduction, 3rd to last paragraph: “We use the medical CT image ...”.<BRK>It s not allowed in ICLR submission that would review the identity of the authors. * Bad writing. For example, "In this paper, we propose adversarial networks of positron image memory module based on attention mechanism". The higher, the better? Besides, you need some analysis to illustrate the significance of your results. Considering these issues demonstrated in the paper, I recommend rejection.
Reject. rating score: 3. rating score: 3. rating score: 8. <BRK>This paper proposes a new framework for defining Boolean algebra over the space of tasks in goal conditioned reinforcement learning and thereby achieving composition of tasks, defined by boolean operators, in zero shot. The paper proves that with some assumptions made about a family of MDP’s, one can build Boolean algebra over the optimal Q functions of the individual MDP and these Q functions are equipped with all the mathematical operations that come with the Boolean algebra (e.g negation, conjunction). The paper verify their theoretical results by experiments in both the 4 room domain with standard Q learning and in a simple video game domain with high dimensional observation space and DQN. The proofs of all the theoretical results seem sound and the experiments support the theory. I enjoyed reading this paper as the paper is generally well written and the idea is quite neat. In the proposed framework, it seems that all of base tasks are required to be a well defined task which are already quite complex, so the utilities of composing them seems limited. Furthermore, [1] also considers task level composition with sparse reward but I think these compositions cannot be expressed by boolean algebra. Can the method proposed in this paper be used with actor critic style?<BRK>The paper assumes an undiscounted MDP with a 0 1 reward and a fixed absorbing set G, and considers a family of tasks defined by different reward functions. Each task defers only by the value of the reward function at the absorbing set G. These restrictions are quite severe but basically describes goal state reaching sparse reward tasks, which are quite general and valuable to study. The paper then defines a mapping onto a Boolean algebra for these tasks and shows how the mapping also allows re using optimal Q functions for each task to solve a Boolean composition of these tasks. This is demonstrated on the tabular four rooms environment and using deep Q learning for a 2D navigation task. The writing is relatively clear and the experiments support the claim in the paper that the framework allows learning compositions of skills. Both experiments show that after learning a set of base tasks, the method can solve a task in a zero shot manner by composing Q functions according to the specified task. This kind of reasoning is straightforward in the restricted case of MDPs considered in the paper and people can design their reward function directly without considering boolean algebra.<BRK>The paper proposes a method of combining value functions for a certain class of tasks, including shortest path problems, to solve composed tasks. By expressing tasks as a Boolean algebra, they can be combined using the negation, conjunction and disjunction operations. Analogous operations are available for the optimal value functions of the tasks, which allows the agent to have immediate access to the optimal policy of these composed tasks after solving the base tasks. The theoretical composition properties are confirmed empirically on the four rooms environment and with function approximation on a more complex domain. The paper is generally well written with a clear theoretical contribution and convincing experiments. My only concerns are in regards to the assumptions made in this formulation. 2) Concerning assumption 1, it seems that the assumption that the reward functions only differ on the absorbing states is fairly limiting.
Reject. rating score: 1. rating score: 6. rating score: 6. <BRK>The manuscript proposes SSE PT, a sequential recommendation model based on transformer and stochastic shared embedding (SST). Experiments on several datasets show that SSE PT outperforms a number of baseline methods. Some analytical results are also provided. The novelty of this work is limited. The difference is that this work adds user embedding in bottom layer and utilizes SSE for regularization as well as designs SSE PT++ by sampling. To me, there is little extension or novelty. The experiment results are not convincing. However, I checked the results in HGN paper and found HGN is much better than SASREC. In addition, I did not understand why the authors change evaluation metrics in Table 3, i.e., from NDCG/Recall@10 to NDCG/Recall@5. I did not see ablation study or discussion about this. Update: I have considered author rebuttal. I appreciate the extensive hyper parameter sensitivity and ablation study in the paper, while these cannot be a key factor in evaluating paper as most of them can be done easily.<BRK>In this paper, the authors study an important recommendation problem, i.e., sequential recommendation, and design a novel and improved model called SSE PT (Stochastic Shared Embedding   Personalized Transformer). Specifically, the authors mainly follow the previous works of the Transformer model and the stochastic shared embedding (SSE) regularization technique. For the part of the personalized transfer (PT), the authors introduce the user embedding for each user $i$, i.e., $u_i$, shown in Eq.(2) and illustrated in Figure 1. Extensive empirical studies on five datasets show the effectiveness of the proposed approach compared with other related methods. Overall, the paper is very well presented, in particular of the introduction and discussion about the related works, and the analysis of the experimental results. My major concern is that the technical novelty is somehow limited in terms of the two closely related works of Transformer and stochastic shared embedding (SSE). I thus recommend weak acceptance. Some suggestion: Some important baseline methods may be included to make the results more convincing, e.g., Fossil, MARank, and/or BERT4Rec.<BRK>The paper proposes SSE PT for sequential recommendation, which is an extension of previous work SASRec by adding user embedding with SSE  regularization [Wu et al.2019] .They further extend SSE PT to SSE PT++ to handle longer sequence. Experiments on five datasets show that the SSE PT and SSE PT++ outperform several baseline approaches. It could be better if the author could make clear what the major contribution of this paper is. 2)    In addition to SASRec, there are some other transformer based model (e.g., [1]) for sequential recommendation and the paper discuss how the proposed method differ from them.
Reject. rating score: 3. rating score: 6. rating score: 8. <BRK>I guess these would be mostly “a posteriori” explanations? This paper presents a classification model focused on interpretability. This is a new metric they are proposing. Overall, I’m not impressed with the models’ performances. The paper evaluates on this measure, which is included in the appendix, and the results are pretty disappointing compared to the existing models such as Lei et al’s initial baseline or Bastings et al.While the paper argues this method isn’t necessarily designed for this task unlike the other methods, I’m not sure this is necessarily the case. This goes back to my original point that their new measure of "concept accuracy" is vague. Is it for efficiency reason?<BRK>The paper introduces a new concept based interpretability method that lies in the family of self interpretable models (i.e.it s not a post hoc method). I have two main concerns with this work. It s very easy to assume the introduced training procedure to extract separable but meaningless concepts(i.e.the excerpts of a concept are separable from that of other concepts and are consistent with each other in the eyes of the network while they are not consistent with a concept in the eye of human rationale; both loss terms will be minimized but there is no human interpretability. My score will change accordingly as the authors address the raised issues. If the performance is robust, it would be interesting to see what happens for a large C?<BRK>The authors proposed a self explainable deep net architecture that could be used for text categorization. The main idea is to force the network to extract "excerpts", from the input text, each corresponds to a concept, which are also learned for interpretation. The idea sounds interesting and the experimental results support the usefulness of the proposed method on a variety of datasets. It has been discussed in the literature that many explanation methods suffer from this sensitivity issue.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>This paper targets the transfer learning problem. It assumes that when some auxiliary information is known, generalization bound can be given by only minimizing a reweighted loss of the biased source domain data. Thus, the practical use of this paper may be limited. The paper also lacks discussion with related theoretical work (such as generalization bound of PU learning). Moreover, such as result is already studied in Sugiyama et al.(2008).Thus, the novelty of this part is limited. The rebuttal is subjective (without enough support but expressions such as "we believe", "there is no point") and fails to address my concern.<BRK>Summary: This paper aims to show that we can estimate a density ratio for using the importance weighted ERM from the given sample and some auxiliary information on the population. Several learning bounds were proven to promote the use of importance weighted ERM. I think the writing in the experiment section can be improved. Comments:My impression is the novelty of this paper is modest.<BRK>The authors consider the problem of a mismatch between the distribution of the training observations and the test distribution (a transfer learning setup). The paper seems technically sound but it is not easy to read. I have a question: is it possible to extend your work considering Multiple Importance Sampling and Generalized  Multiple Importance Sampling  schemes?
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>The paper develops a method to augment deep neural networks with Spike Time Dependent Plasticity (STDP) aiming at improving noise robustness of the network learned features. The paper, however, fails to address the many works in the literature about adversarial perturbations ( attack ) and adversarial training ( defense ), starting by (Szegedy et al., 2013). Given the current state of the manuscript, the level of methodological novelty and the scope of input perturbations that can be made robust against both appear to be limited. The new network demonstrates improved noise robustness via improved classification accuracy on Cifar10 and ImageNet subset when input data have noise, on different network architectures.<BRK>The paper proposes a hybrid network architecture that can integrate features extracted via supervised training and unsupervised neuro inspired learning. The paper is well written and the experimental results seem sensible. The problem of image denoising is very well studied and very good methods have been proposed for image denoising under arbitrary noise using deep learning (see the works in CVPR, ICCV, ECCV etc.). Unfortunately, I am not in the position to judge the novelty wrt spiking neuron network literature. Nevertheless, as far as computer vision or general applications is concerned the proposed pipeline would not be among the methods of choice. Hence, I am recommending weak reject for now, waiting for a more informed opinion to see if I will change my opinion.<BRK>The paper shows that replacing feature extraction layers by spiking convolution network can improve the performance under random noise. The results shows improved performance under some random noise. Although the idea is cute, I feel the paper fails to convince why spiking nets are more robust to random noise; the explanation using backprop rules in section 3 sounds interesting but does not fully convince me; for example, if we train a CNN by other approach instead of back propagation, can we also improve robustness to input noise? Also, I have some questions on the experiments: 1. I think it will be better if the algorithm can consistently improve over various kinds of noise distributions. 3.What s the training time of the proposed method?
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>The paper proposes a method to optimistically initialize Q values for unseen state actions for the case of Deep Q Networks (DQNs) with high dimensional state representations, in order to step closer towards the optimistic initializations in the tabular Q learning case which have proven guarantees of convergence. The paper shows that simple alternatives such as adding a bias to a DQN do not help as the generalization to novel states usually reduces the optimism of unvisited state actions. However, my confidence on this rating is low as I have not gone through the theorem in the appendix and I may be wrong in judging the amount of empirical evidence required for the approach.<BRK>The paper is well structured, building from intuition to theory to toy examples in DQN setting. Yes there is a regret bound, but this is not as good as some other methods... Although this algorithm is motivated by applications to *deep* RL, the key choice of the "count" (and thus the method for optimism bonus) is mostly sidestepped. It amounts to an essentially tabular bonus in the space of the hashing function... and it s not clear why this approach should work any better or worse than other similar approaches that the paper complains about. Overall I think this is a reasonable paper, and I expect it to improve during the review process.<BRK>#rebuttal responses I am pleased by the authors  responses. Thus I change the score to weak accept. #reviewThis paper presented OPIQ, a model free algorithm that does not rely on an optimistic initializationto ensure efficient exploration. OPIO is ensured with good sample efficiency in the tabular setting. The paper would be more clear if the authors add a motivating example in a tabular environment. But the experimental results are somewhat weak, as there are no comparison results on hard Atari games, such as freeway and Montezuma s revenge.
Reject. rating score: 1. rating score: 1. rating score: 1. <BRK>This paper takes the reference game setup of Lazaridou et al.(2018), as a means of enabling emergent communication, and adds an auxiliary task to demonstrate that this helps with language emergence. I hope that the authors can perhaps see that this submission would be better suited to a dedicated workshop on emergent communication (and even then it would need more experiments and analysis). The idea of adding an "empathy" auxiliary task to the reference game setup is an interesting one, and the approach is well motivated and described, including a background section.<BRK>This paper starts with a conceptual claim that incorporating a notion of “empathy” in language emergency would help agents learn faster. I encourage them to do this for a future submission, in addition to more extensive results, because I think the ideas are worthwhile. Define how h_S and h_L are parameterized, and how each is trained. Is this necessary / sufficient for empathy?<BRK>Strengths:  The concept is interesting and grounded in human communication. Empathy is a complex human state/emotion that should not be reduced to this. This paper is very preliminary. The experimental results are not convincing at all. There should also be experiments testing the effect of \alpha on performance. There is no analysis of how well the model is able to predict empathy, as well as ablation studies testing for various design decisions.
Reject. rating score: 1. rating score: 1. rating score: 1. <BRK>This paper proposes a new way of scheduling the learning rate in optimization algorithms such as SGD. to better motivate the approach, I would suggest the authors include different tasks, rather than different training settings.<BRK>The proposed learning rate adaptation procedure consists of a straightforward combination of learning rate halving/doubling and model checkpointing. The paper claims a primary advantage of the proposed learning rule to be that it requires no tuning as opposed to other rules such as SGD, Adam. This leads to the second issue with the paper: the experimental validation is not extensive wrt/ datasets which is significant given that the form of the evidence for the proposed method is almost entirely empirical. Line 23 could/should be an else statement. Finally, the paper is unfinished as some experimental runs were not complete at the time of submission. I don t agree with the statement in the related work section that this entails "additional computation of gradients." *In the sense that the rule should be straightforward to implement. Can the authors discuss the appropriateness of their assumption wrt/ this point?<BRK>This paper proposes an algorithm for automatically tuning the learning rate of SGD while training deep neural networks. Some questions that I would like the authors to answer:1.
Reject. rating score: 1. rating score: 3. rating score: 6. rating score: 6. <BRK>This work studies learning under independent MARL, and shows theoretically and experimentally that two independent MARL algorithms converge for games that can be solved by iterated dominance. The fact that standard MARL learning rules (e.g.independent Q learning) converge in games with iterated dominance solutions is a very well known result in Learning in Games (see [1], [2]). Question to the authors:  How does this work differ from the known results about convergence of naive learners in iterated dominance solvable games?<BRK>This paper studies independent multi agent reinforcement learning (MARL) in dominance solvable games. The main contribution of this paper is that the authors have proved the convergence to the iterated dominance solution for two RL algorithms: REINFORCE (Section 3.1, binary action case only) and Importance Weighted Monte Carlo Policy Improvement (IW MCPI, Section 3.2). 2) This paper only has *convergence* results, but does not have *convergence rate* results. In other words, the authors have not proved how fast the agents converge to the iterated dominance solution. Might the authors establish a convergence rate result such as a regret bound?<BRK>The main idea of this paper is to solve multi agent reinforcement learning problem in dominance solvable games. For example, for agent i “its possible actions are the strategies in S_i” (section 2); any action “a \in S_i” (section 2,1); for agent i “for all s_i \in S_l” (Algorithm 1 line 2). The main contribution of the paper is to prove that both REINFORCE in binary action case and Monte Carlo algorithms find the agents’ policies converging to the iterated dominance solution.<BRK>This paper studies reinforcement learning algorithms in a specific subset of multi agent environments that are  dominance solvable . The paper is quite well written and understandable. I did not check the proofs thoroughly. I appreciate that, while the main results in the paper are limited to normal form games (which are quite restricted), there are empirical results in the appendix showing the extension to Markov games with multiple timesteps, suggesting that the applicability of iterated dominance reward schemes extend beyond the simple two action case, where no temporally extended decisions need to be made. My personal curiosity about this paper revolves around scaling to real world applications.
Reject. rating score: 1. rating score: 1. rating score: 3. <BRK>####The paper translates the Leaky Integrate and Fire model of neural computation via spike trains into a discrete time RNN core similar to LSTM. The hard decision is made by thresholding. It s unclear that a spiking inductive bias is actually useful, even though event driven computation could in theory allow much less computation, the proposed method does not have that property.<BRK>Table 1 is incomplete. Why bothering defining a new variable Y if it is equal to F? Here the authors extend this approach by proposing two variations of the LIF model, called RLIF and LIF LSTM. However, the presentation of these models is not clear at all.<BRK>This paper proposes a brain inspired recurrent neural network architecture, named Recurrent Leaky Integrate and Fire (RLIF). The main advantage of the proposed computational model was not supported by evidence in the paper.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>I have an unresolved question: What do the learnable backward connections add beyond the perturbation estimator for the gradients? This paper proposes a perturbation based synthetic gradient estimator that does not rely on symmetric backward connections. I would appreciate more discussion of this key choice, or a direct comparison with only the perturbation based estimator (only) to understand the differences. The topic is important and the paper is well written.<BRK>Which of these two is the actual source of good results? would strengthen the claims. Minor comments:  can authors provide some error intervals for results in Table 1? Could the notation be unified so that when talking about comparing optimisers, authors state Adam and SGD (assuming that this is what is currently called backpropagation?) Overall I believe it is an interesting study, however, currently missing important baselines and ablations to be a good ICLR contribution.<BRK>Generally, this work is well placed and the method straightforward and novel. Due to the following issues, we think that the paper is not yet quite ready for acceptance. There seems to be a notation issue since it is our understanding that every layer should have its own estimated weights. The authors make the observation that "The number of neurons has an effect". This seems to indicate that the method would not scale well.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>This paper studies an important problem, evaluating the performance of existing neural architecture search algorithms against a random sampling algorithm fairly. The authors train random architectures fully before selecting the best one, which turns out to perform as well or better than the sophisticated neural architecture search methods. The paper also identifies that parameter sharing turns out to be a major reason why the sophisticated NAS methods do not really work well. The insights are obviously important and valuable. Another comment is it is a stretch to consider the evaluation done in the paper a new framework.<BRK>This paper studies the effectiveness of several Neural Architecture Search (NAS) methods comparing it with that of random policy search. The paper concludes that none of these methods for a CNN (trained using CIFAR 10) and RNN model (trained using PTB) are statistically significantly better than the random search. The authors suggest that this is due to the weight sharing used by the NAS algorithms to accelerate the network training. Before this paper, Li and Talwalkar, “Random Search and Reproducibility for Neural Architecture Search” have also compared some of the NAS methods with random search and reported similar concerns. It would be useful to have them in the list of NAS methods considered here.<BRK>This works studies the evaluation of search strategies for neural architecture search. (1) It pointed out some important issues in the evaluation of NAS methods: evaluating under different random seeds and fair comparison with random baseline. Weakness:(1) The problem that the search space is over optimized and constrained is not unnoticed before. There should be more discussions about such improvements in the rigorous evaluation of NAS. 2019.Typos:"based one their results on the downstream task." The paper pointed out an important issue, but it has also been noticed before. The insight on weight sharing is interesting, although more experiments are needed to testify the claim over state of the art NAS search space.
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>The visualization focuses on two aspects: (1) Temporal masking for identifying key frames and key segments and (2) GradCAM for spatial saliency. Both visualization techniques are illustrated on two public available video classification datasets. This work has some major issues:1. It does not validate any of the following cases: (1) if Conv3Ds are more powerful, one should use the same number of parameters and compare classification results, or (2), in order to achieve the same level of accuracy, one of the two models is more parameter efficient. It is not clear which argument Table 1 is validating against if there is any as both parameters and accuracies vary. This is most likely due to visualization techniques other than the choice of models. 3.The fundamental issue of this work is that it does not establish a hypothesis from the beginning and design experiments around it.<BRK>This paper presents a paradigm for generating saliency maps for video models, specifically, I3D (3D CNN) and C LSTM. It extends Fong & Vedaldi, 2017 to generate a temporal mask and introduces two types of "meaningful perturbations" for videos: freezing and reversing frames; they use Grad CAM (with no modifications) for generating spatial masks. The problem is well motivated, as saliency maps have been extensively studied for image classification models, but rarely for video classification. Quality of techniqueWhile the temporal masks are novel and qualitatively "make sense" (though this is subjective), the generation of the spatial masks is not novel, is unconnected to the temporal mask generation, and often doesn t make sense because of lack of temporal smoothness / cohesion, particularly for C LSTM, where the visualizations when the mask is on appear quite "jumpy" (see Fig 2, Seq 1). It would be great to see more innovation on the temporal mask generation to address some of these issues (one natural approach that comes to mind would be learn spatial masks as done in Fong & Vedaldi, 2017, possibly with a temporal smoothness term between spatial masks and possibly combining temporal + spatial masks for freezing operation, i.e., only freeze spatial pixels)   that said, I realize that this may be out of scope for a rebuttal. 3.Lack of discussion on limitations/benefits of technique + how to use/interpret technique* There are no baseline comparisons for the proposed temporal mask generation. Ideally, the authors would show that their temporal mask generation meets some desired criteria (as well as compare with baseline methods) to justify their approach. There s no discussion about whether this problem persists for this work. * More discussion can be added about how to interpret results / use the technique (i.e., what is this technique useful/not useful for?what do results mean?). Do they differ substantially when optimizing for different output classes?<BRK>The paper shows a way to compare what is learned by two very different networks trained for a video classification task. The two architectures are state of the art methods, one relying on 3d CNNs (time  one dimension), the other on conv LSTMs (time is treated sequentially, using hidden states to pass information). The idea of the authors is (i) to provide saliency maps for each of them, and (ii) to create interesting perturbations in order to measure the influence on the networks. The results indicate that these complex networks are usually focused on interesting features, and as we would imagine, LSTMs is more learning from temporal coherence than CNNs. Positive aspects:  A significant effort has been put to creating meaningful perturbations for this particular task, i.e.temporal dependance and coherence. The effort to compare as best as possible two different approaches is fruitful, and very useful for the community as this is a real question to be raised. What do you mean by  The TV norm penalizes masks that are not coherent ? ...the mask is defined as a vector of values between [0,1]  : I understood that it was a real value between 0 and 1, but I think you meant more  a binary vector ? Have you looked at the importance of the sub sampling in the CNN framework? i.e., since the LSTM framework does not have that, maybe the differences in activation also depend on the length of the sequence. Small remarks:   3D CNNs instead instead convolve    As outlined in section 2  when we are in the introduction   (Mahdisoltani et al.(2018) contains... .
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>This paper introduces a novel parametric activation function, called the Pade Activation Unit (PAU), for use in general deep neural networks. Since one of the suggested properties is that a function using a given activation function be a universal function approximator, the authors provide a sketch of a proof that PAUs do allow that.<BRK>Table I seems to claim that the PADE based neural network satisfies (i), but there is no formal proof. The paper is well written, and the experiment results look reasonable. 1) as the authors stated, a "good" activation function should maintain the universal approximation property of the neural network. Perhaps there should be more discussion on this   preferably some theoretical supports.<BRK>The authors introduce an activation function based on learnable Padé approximations. The numerator and denominator of the learnable activation function are polynomials of m and n, respectively. The authors also propose a randomized a version of these functions that add noise to the coefficients of the polynomials in order to regularize the network.
Reject. rating score: 6. rating score: 6. rating score: 6. <BRK>This is a nice piece of incremental work on top of previously published GAN imputation methods. At least give some motivation for why certain imputations problems couldn’t be feasibly solved by modeling the missing values in a probabilistic programming framework. Given that the described method resembles GAIN, is it really much simpler?<BRK>The uncertainty of having a missing value is investigated on the prediction by not assigning a single imputed value but N different values generated via an imputer network (based on GAIN). Overall, this paper raises an interesting point about missing data imputation via generative models, and well written; however, there are number of concerns:1 	The predictor is trained on different version of imputed samples (imputed via the generator); this equates to making noisy version of the real samples, where noise is applied to the missing variables. 4 	In justification for claim 1, it is said “This is equivalent to training models using noisy labels”. This is not accurate: in noisy label prediction, we have one (noisy) y corresponding to each x, in your case there are multiple ys for one sample.<BRK>This paper proposes a method to impute missing features using a generative model and train a predictive model on top of imputed dataset to improve classification results. But I do feel it is a bit incremental over the GAIN approach. Does stochastic averaging benefit more in this case?
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>This paper suggests a measure for the inherent difficulty of datasets: DIME. While the idea of using Fano s inequality to give a complexity score for datasets is interesting, this paper does not provide what appears to be a close measure of this conditional entropy.<BRK>The paper proposes a measure of difficulty for datasets. There is definitely quite a lot of good ideas in this paper and it might just be a matter of bulking up with more analysis at this point as suggested by other reviewers.<BRK>So this paper is interesting. Inductive bias must play a part in this, and some datasets "difficulty" is intimately connected to the class of functions we optimize our classifiers over.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>Overall I like the approach in the paper. It proposes a nice 2 pronged method for exploiting exploration via intrinsic rewards for multi agent systems. The ability to ask other agents in the world about there preferences and novelty of states appears to be a strong assumption, especially in a multi agent robotics problem. While the authors note that the intrinsic rewards used in this work are not comprehensive it would be good to note how comprehensive they are. Task 2 seems a bit contrived.<BRK>Summary:The paper proposes a method for coordinating the exploration efforts of agents in a multi agent reinforcement learning setting. Experiments done on grid world and VizDoom environment for three different tasks demonstrate that, on most tasks, the proposed approach performs at least as well as separately trained individual intrinsic rewards. However, this would require the exploration strategy to be changed in the middle of an episode which is not supported.<BRK>For each pair of reward and agent, they learn a policy and a value through actor critic method, and then a meta policy choses at the beginning of each episode which intrinsic rewards to use, meaning that the policy used by the agents corresponds to the one that maximizes the reward chosen. However, the experiments are conducted only with a very limited number of agents (only 2 in the non toy environment of vizdoom). Given this limitation the scope of the work basically reduces to the exploration of a fixed environment when the action space can be factored into different agents.
Accept (Poster). rating score: 8. rating score: 8. rating score: 6. <BRK>The paper proposes a new approach for generating multilingual sparse representations. This is demonstrated using experiments on QVEC CCA (for interpretability analysis), NLI, cross lingual document classification, and dependency parsing (downstream tasks). Minor   I did not understand the benefit of MAMUS being "stable" across languages, as argued from Fig 1? The use of the word "cognitively" in the statement "representations determined by MAMUS behave in a cognitively more plausible manner" also seems a stretch to me. One issue that the authors should discuss is whether such representations hold any extra value over contextual representations like multilingual Elmo, BERT etc.<BRK>This paper proposes a method to generate sparse multilingual embeddings. Things got clear from the equations, but will be good to fix. Since I am less aware of work in this area, I cannot comment on whether the evaluation is complete. A few more suggestions:1.<BRK>This paper describes a method to build sparse multilingual word vectors that is designed to scale easily to many languages. It would be nice to provide an explanation for why (beyond the obvious efficiency gains) one couldn’t just do the necessary language pairs with bilingual methods for these experiments. I also wonder how relevant bilingual word embeddings are in a world of multilingual BERT and similar approaches. It would be interesting to know how cross lingual embedding in context methods would do on the extrinsic evaluations in this paper, though I also acknowledge that this could be considered beyond the scope of the paper.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>In practice (as showed in the paper) using blurred images leads to comparable results. For a given image, the method generates a bunch of decoys images, and then a given saliency extractor is applied to not only the original image but all generated decoy images. The resulting saliency maps are aggregated to output the final saliency map.<BRK>It might be better to explain your proof for Proposition 1 as an observation and use it as the motivation on how you have defined Z. The additional computational cost of your proposed method needs to be compared to other methods that are not data driven. For example, how does your computational cost compare with the references above? Several recent methods on saliency maps have not been considered, for example: 1. Certifiably robust interpretation in deep learning 2. Strategy for choosing a good initial value for c (in the penalty term) and how to increase it is not explained well. This information needs to be reported.<BRK>I SummaryThis paper has two major contributions:  A method to infer robust saliency maps using distribution preserving decoys (generated perturbated images that resemble the intermediate representation of the original image in the neural network)  A decoy enhanced saliency score which compensates for gradient saturation and takes into account joint activation patternsThe authors show the performance of their methods on three different saliency methods, quantitatively and qualitatively, but also when it is submitted to adversarial perturbations. ContentThe paper is very clear and easy to read, I would like to point out how well structured it is. The method yields very interesting results, the whole work is very complete experimentally (saliency methods used, adversarial perturbations, models etc) and the process coherent.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>The paper explores how focal loss can be used to improve calibration for classifiers. Somewhat surprisingly, this tends to improve the calibration of the model.<BRK>The authors provide a theoretical explanation to the superior results of the focal loss for calibration. Since the choice of gamma seems to be leading consistent results also on tinyIN, I find it less concerning. Positive aspects:   The paper is well written. could specify what MMCE means  clean the bibliographyI ve read the other reviews and authors  responses.<BRK>The paper describes how the use of the now standard focal loss can lead to improved calibration results when used to fit deep models. The approach is extremely simple to implement, the theoretical justifications are believable, and the calibration/accuracy performances seem to be good   for this reasons, I think that the paper should be accepted.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>UPDATE: I appreciated the authors  discussion. To do this, the authors define a generative model, GENESIS, that uses an autoregressive prior over mask variables. The visual appearance of the objects are generated conditioned on the component variables. The authors apply GENESIS to three datasets with monochromatic objects and show that GENESIS qualitatively generates coherent scenes and infers coherent scene components. Strengths:  The paper is well written and executed.<BRK>But, I m not sure what would happen if K is set to a large number to deal with this. The contribution of the proposed method from previous works is the introduction of an autoregressive prior on the component latents. In the experiments, the authors compare GENESIS with MONet and VAEs qualitatively and quantitatively and show that the model outperforms the baseline in terms of both scene decomposition and generation.<BRK>The paper proposes a generative model for images. While the results on factoring scenes do appear to be good, there s no quantitative evaluation of this (although the abstract promises it). I realize that coming up with metrics is hard, but I think the burden is on the authors to find the metrics to show their conclusions quantitatively. The results are good looking, and the method seems well explained. This may help some readers.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>The authors propose the general formulation of recent meta learning methods and propose a good library to use. Cons:The paper lacks technical novelty. I understand the goal of this paper is to build a library. However, the paper only describes a general formulation for recent meta learning methods (e.g., MAML) and implement the formulation. Advances in Neural Information Processing Systems. ICLR (2016).<BRK>This work presented a general formulation of a wide class of existing meta learning approaches, and proved the requirements that must be satisfied for such approaches to be possible. Half of the work is focused on describing the unnamedlib library, which extends PyTorch to enable the easyand natural implementation of such meta learning approaches. The early sections are interesting, especially section 2, which gives some great insights to the existing inner loop pattern in meta learning. However, from section 3, the paper has turned to examples and related works, where I was hoping the author would give more detailed analysis of the pattern. So http://www.jmlr.org/mloss/ might be a more suitable place for publication.<BRK>Yes, but also nesting this in an outer loop is fairly trivial in the sense	that it is a well known approach. The parameters $\varphi^\text{loss}$ are somehow part of the loss used fortraining in the inner loop. The parameters $\varphi^\text{opt}$ do not occur in the loss but in theoptimizer step. The authors also assume the meta learning loss to be sufficient smooth in $\varphi$such that a gradient based optimization can even be used for meta learning toa local optimum. Recommendation:I propose to reject the paper. There is no new insight provided on the software engineering level either asfar as I can see.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>Unfortunately, while the paper is technically well executed, I have fundamental issues with novelty. Given this "Similarly, applying DEMON to momentum SGD rivals momentum SGD with learning rate decay" is not surprising, and "and in many cases leads to improved performance" warrarnts a bit of scepticism. can be already found in [1]. Similarly, [2] already suggests decreasing momentum.<BRK>This paper proposed a new decaying momentum rule to further improve neural network training. The authors also extend this idea on to Adam and show that it improved upon the vanilla Adam. This question is not answered in the paper. I would suggest the authors to check the parameter settings and make sure all the hyperparameters for baseline methods are fully tuned. Aside from SGD with momentum, the experiments part also lacks several important baselines.<BRK>In this paper, the author propose a decaying momentum rule to improve algorithm. Furthermore, he apply this rule in momentum SGD and Adam, then use experiment to prove the algorithm. In the experiment, it training on many different dataset and compare with many baseline. The algorithm with decaying momentum rule get much better result than all other algorithm. Even the algorithm get a good performance, the intuition of the algorithm is not clear.
Accept (Poster). rating score: 8. rating score: 8. rating score: 1. <BRK>The paper studies transfer learning from the point of view of adversarial robustness. The goal is, given a robust deep neural network classifier for a source domain, learn a robust classifier for a target domain as efficiently and with as few samples as possible. The authors perform a diverse set of experiments from which I identified the following individual contributions:a) Retraining the last layer of the model on natural examples preserves robustness. Robustness degrades smoothly when pre training progressively more layers. This is an interesting contribution providing evidence that robust models do learn in fact robust input representations/features. Overall, the paper contains an experimental study that, in my opinion, is thorough, presents interesting findings, and contains the necessary ablations. I believe that this paper would be of interest to the adversarial ML community and I hence recommend acceptance.<BRK>Paper summary: This paper explores the problem of robustly transfer learning using only standard training (as opposed to adversarial training (AT)) on the target domain. The authors perform a nice exploration of the thesis that robust models have robust representations, and how this connects to transfer learning. ii.In Table 2, it would also be interesting to see the performance when the source domain is CIFAR10 and the target domain is CIFAR100. The approach proposed in Section 6 seems interesting, but more as an approach to improve the *overall* performance of the model. Overall, the exploration in the paper seems novel and could be useful to the community. Thus, I recommend acceptance.<BRK>Summary This paper addresses the problem of performing robust transfer learning. A first contribution of the paper is to robust and classic training with respect to usual validation accuracy and robustness to adversarial attacks on the CIFAR task. Overall The paper presents  a study of robust transfer learning that can be interesting for practitioners to know the type of results that can be obtained by robust transfer learning. Then, if the contribution of the paper is to propose to focus on robust transfer learning including a Learning without Forgetting strategy, the authors should then focus more on this part and analyze better the behavior of learning. If we restrict to the part related to experimental comparisons made, they are restricted to particular trainings and datasets with specific PGD attacks. The contribution would have been stronger is different types of adversarial attacks with different parameters have been studied and analyzed.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>The different models are combined to form an ensemble model. 6 layers seems very small given the size of the training set. I feel that the results are a bit disappointing given the scale of the experiments. What would be the performance of an ensemble of 10 models trained with the regular 20M parallel sentence pairs? It is true that  "every time we encounter a new domain, we have to retrain the model", but I think this is still a more viable approach than pretraining on the full 40B sentences. Although it is critical to work with cleaned data in NLP (especially in the context of generation), dataset cleaning is not really addressed in the paper. Overall, the experimental setup is impressive, but the improvements in terms of BLEU are relatively small, and the technical contributions seem quite thin to me for a ML conference.<BRK>This paper investigates the effectiveness of a massively large parallel corpus in NMT training, which consists of more than 40 billion En Zh parallel sentences. For preventing long training time, this paper proposes a practical data split and utilization method, which the authors call “dynamic data split.”The key idea of their method is to dynamically assign training instances to different model components and update different components according to the assigned instances. This paper reports the BLEU score of WMT17 Chinese English dataset for 32.3, which significantly outperformed the best score, and improved the performance of existing state of the art results. The main concern of this paper is the reproducibility of the experiments. Their main focus is to investigate the effectiveness of 40B massive parallel data.<BRK>This work conducts a large scale study on pretraining for neural machine translation. Overall, this work makes good contributions to the community, but the experiments need improvements. Pros: 	1.The data scale is huge, with 40 billion sentence pairs. Cons:	1.It is pity that the trained model is only evaluated on one test set and experiments are conducted on one language pair. Thus, it is not clear to me whether the improvement is general across datasets and language pairs. For example, I d like to see the results on WMT 2019 Chinese >English translation dataset.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>Wouldn`t it better to actually learn everything end to end, which is already done in paper and evaluate? The reason that I am asking these, is results looks like too well and I suspect overfitting to a points, which are suitable for estimation (small) homography, not general purpose points.<BRK># ContributionsThe paper contributes a self supervised method of jointly learning 2D keypoint locations, descriptors, and scores given an input RGB image. I would give this a 5 if the website allowed me to.<BRK>I had some concerns about the clarity of the paper, and would be willing to raise my rating if addressed. My understanding is that the proposed work is a somewhat incremental improvement over Unsuperpoint.
Reject. rating score: 1. rating score: 1. rating score: 6. <BRK>This paper proposes domain adverarial approaches modified to address covariate shift even in the case of shifting label distributions. The paper is interesting and the authorsare looking at an important problem, but the paper suffers several major misconceptionsand the exposition is full of errors. The paper proposes a method called “self training” to “estimate and align” the  target label distributionand a “prototype based method” for conditional alignment. They confuse the term “label shift” and the colloquial “shifting label distribution”. The proposed method leverages a “similarity classifier”The thing that the authors call a similarity based classifierisn’t well explained. I encourage the authors to give the paper a gut rewriteand do not believe that it can be published while resembling its current form. Note that you can have a shift in label distribution 	even under the covariate shift assumption.<BRK>In this work, the authors proposed a method to address the covariate shift and label shift problems simultaneously. 4).There is an issue in the label distribution by self training. The main concern of this work is its shift assumption. The novelty of the paper is limited.<BRK>The paper deals with covariate and label shift in commonevaluated on some standard benchmark data. I would like to see additional experiments on similar text data  > reuters  self training is a concept from semi supervised learning and not particular well supported  in the community   how do you make sure that the result remain valid  how do you make sure that the adaptation of the labels, the covariate shift and the classifier training  are not in facting cheating the result to an optimum within the optimized cost function?
Accept (Poster). rating score: 8. rating score: 8. rating score: 6. <BRK>Review: The paper proposes a technique for anomaly detection. It presents a novel method that unifies the current classification based approaches to overcome generalization issues and outperforms the state of the art.<BRK>This paper proposes a novel approach to classification based anomaly detection for general data. The proposed method substantially outperforms SOT on all datasets. The stability is not improved, it is just that the performance trend is stable. The paper provides comparison to SOT methods for both Cifar10 and 4 non image datasets.<BRK>on image data [3, 4]. I appreciate the clarifications, additional experiments, and overall improvements made to the paper. ####################This paper proposes a deep method for anomaly detection (AD) that unifies recent deep one class classification [6] and transformation based classification [3, 4] approaches.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>This paper presents a new discriminator metric for adversarial attack s detection by deriving the different properties of l th neuron network layer on different adv/benign samples.<BRK>This paper proposes an adversarial detection method via Fourier coefficients. The proposed method seems promising, and empirical evaluations are reasonable. However, I find that the proposed MBF detection metric is much more complicated to calculate than any of its baselines, e.g., LID or K density.<BRK>This paper proposes an approach to adversarial detection. The approach first computes a representation of the activation layers using the Benford Fourier coefficients.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>Summary:This paper presents a family of architectural variants for the recurrent part of an RL controller. An increase in training speed and stability, apparently without any major caveats, would be of great interest to any practitioner of Deep Reinforcement Learning.<BRK>Overall it is an interesting paper in the sense that the introduced aggregation layer is so simple but effective in noisy RL. The explanation using arguments of gradient decay and SNR decay seems to be convincing.<BRK>UPDATE: The response helped address my questions. LSTMs are sensitive to noise: Is there an explanation for this observation? This paper studies reinforcement learning for settings where the observations contain noise and where observations have long range dependencies with the past. The experimental results look convincing to me.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. rating score: 3. <BRK>Later I noticed that you always index S with {1,\dots,|S|}, but using i \in S in combination with 1< j< |S| was a bit confusing. 3.The approximation theorem is useful and clean, and the empirical results are intriguing. Because the properties of UE and contractibility were not used, it may be more appropriate to use this space to introduce more of the literature on neural nets as feature embeddings stuff. This paper could be improved by generalizing to a few other choice models  in particular the CDM (https://arxiv.org/abs/1902.03266) may be a good candidate for your method.<BRK>The authors propose parametrizing PCMCs with neural networks to fix these issues. Pros:  Although I was previously unfamiliar with the PCMC model, using a neural network parametrization seems novel and well motivated.<BRK>The method relies on training a neural network. PCMC Net bakes the definition of PCMC into the neural net structure and therefore satisfies the theoretical properties of contractability and uniform expansion, which are desired properties of choice modelsMoreover, since choice probabilities are a function of choice candidates’ features (and features of an individual making the choice), this method allows for new (unseen) choice candidates at test time, which was not possible with previously proposed maximum likelihood (ML) inference. I recommend REJECTing this paper. This paper tackles the problem of efficient inference and test time generalization (to unseen choice alternatives) for choice modelling, and the proposed approach is interesting, seems to be theoretically sound, and outperforms evaluated baselines.<BRK>This paper presents an approach for choice modeling that leverages neural network features in a continuous time Markov Chain whose stationary distribution represents the choice distribution. The experimental section is too limited, with results on only one dataset and no comparison of different architectural choices for how to incorporate neural networks into PCMC models, or analysis pointing toward what the features are learning that allows them to improve over earlier approaches. The text was also confusing in a number of places (possibly due to my lack of knowledge in choice modeling), and there’s no discussion of related work incorporating neural networks into ranking based models.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>However, I believe it is not strong enough for me to recommend acceptance at this point. then, is HIB the proper baseline in figure 6 and 7?<BRK>Please, list the differences with this prior work and provide experimental comparison if possible. The method is an extension of Prototypical Networks (PN, [1]) with Gaussian embeddings. Advances in Neural Information Processing Systems.<BRK>The intersection sampling seems a bit interesting in the sense that the sampler focuses on the intersection of the input distribution and the class distribution and it is more sample efficient.
Reject. rating score: 1. rating score: 1. rating score: 3. <BRK>Therefore this paper has no valuable contribution in its current form and I vote for rejection.<BRK>The paper has no real experimental analysis, it doesn t seem to propose anything new or make any clear contribution, and overall, is quite unclear on what it is trying to do.<BRK>Summary:This paper introduces convolutional neural networks to encode video sequences. The used autoencoder and autoregressive techniques are promising for video encoding.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>This paper provides a novel off policy objective to solve imitation learning. The new algorithm is simple but efficient, and can handle off policy settings. However, the first half of the paper focuses on deriving an off policy objective for imitation learning.<BRK>This paper presents an algorithm for adversarial imitation that uses off policy data in a principled manner, unlike prior work. Can this be corrected? The paper then shows how the auxiliary variable (critic) added to the optimization is a value function that maximizes the corresponding induced reward in AIL methods, thus unifying the objectives for policy optimization and reward learning. And overall, is the optimization of the ValueDICE objective easy?.<BRK>The primary contribution of this paper is a principled algorithm for off policy imitation learning. For the method proposed in this paper, it would not be straightforward to do so.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>The paper argues for the use of attractive networks (AN) for the tasks that involve learning from noisy data. Update after rebuttal: I agree with the other reviewers that the paper is not ready for publication. Ablation studies for the activation choice and the loss choice need to be analyzed in more detail.<BRK>This paper presents an attractor network (AN) approach for pattern interpretation and completion. It was not clear to me how the proposed approach uses recurrent networks. In supervised MNIST experiments, it was claimed that it achieved the state of the art results. Interpretation was emphasized in the paper, but it was not clear to me what induce interpretability in the model and how to interpret experimental results.<BRK>Similarly, the experiments on MNIST are not very informative and you might want to push them to appendices. While the authors claim superior performance against other recent attractor networks, no quantitative comparison was found in the paper. Overall, I am concerned that the experimental  part of  this paper does not warrant the conclusions of superiority. The  bipartite  structure is not clear.
Reject. rating score: 3. rating score: 3. rating score: 8. <BRK>This paper defines a set of learnable basis functions and a joint learning algorithm to estimate them. However, this premise is not accurate and many learning algorithms operate just in the actual time domain (even in speech). The paper advocates for a special group of strictly increasing transformations of the basis functions. Unfortunately the authors do not report runtime numbers in the experiments. First, the results in Tables 1 and 2 do not seem to be statistically significant and Table 3 does not have the intervals. Overall, the key message out of the experiments is that if you project the data to a parameterized basis set and constrain the parameters, you will get better generalization, which is not very novel.<BRK>On the contrary, the STFT has a lack of localisation (and thus the "precision" is not constant along frequencies). Overall, I think that re thinking the way a Wavelet Transform is designed, is an interesting direction of research, but I think some of the theoretical tools developed in this paper are not dedicated to achieve this purpose. In particular, the group/representation properties seem to not be used, and the authors could simply consider a specific subset of invertible mapping on $\mathbb{R}^2$ which would be applied on the mother wavelet and lead to a Wavelet Transform. In which case, this experiment would not be meaningful.<BRK>In the LGT, a more flexible transform that just scaling and shifting is applied to the shape of the mother wavelet, which is piece wise linearly stretched. *Supporting arguments* What I like about this paper is that the idea is a straightforward generalization of the wavelet transform through the lens of group theory. Experimentally, I think there was a nice selection of toy and harder examples. *Smaller questions/notes for the authors*  The explanation of what a group is is quite high level and I think if you did not know what it was beforehand, it would be hard to understand what one is. I really liked the connection drawn between the group transform and time warping. This is an aspect I personally had never considered.
Reject. rating score: 3. rating score: 3. rating score: 8. <BRK>This work proposed a fully stochastic RL method and demonstrated significantly improved performance on multiple tasks. Pros:1.The presentation is very clear and easy to read. As discussed in the related work, this work can be seen as complementary to many related works such as Igl 18, but the novelty of the idea is rather limited. 2.The claims and the real benefit of the method may not be consistent. It seems that the benefit of the method is rather from such particular latent space design rather than the stochastic vs deterministic. But there are many works such as the KVAE that are stochastic and models sequential information.<BRK>This paper proposes an actor critic method that tries to aid learning good policies via learning a good representation of the state space (via a latent variable model). The key argument is that learning policies in the latent space is more efficient, as it is possible to learn good representations in the latent space. It is not clear from the text. Most importantly, there are quite a few claims made in the paper which are not properly justified, that makes the overall contribution and novelty of the paper rather limited. Why should this approach even be adapted or what is the significance of it? I think overall the contribution of the paper is rather limited.<BRK>The authors propose SLAC, an important extension of the recently introduced soft actor critic (SAC) algorthm, which operates on a learned latent state, rather than an observed one, and therefore aims to jointly learn to represent high dimensional inputs and execute continuous control based on this representation. Overall:A strong paper, that brings together and generalizes existing work, with strong experimentation and SOTA results. Limitations: While the most important ablation, the role of making the primary latent variable stochastic, is investigated, a deeper investigation of what makes the model more effective than existing techniques would be insightful, and further strengthen the paper.
Accept (Poster). rating score: 6. rating score: 6. rating score: 3. <BRK>Contributions:This paper develops an algorithm for verifying the robustness of transformers with self attention layers when the inputs for one input word embedding are perturbed. Unlike previous work the present work can deal with cross nonlinearity and cross position dependency and the lower bounds derived in the paper are much tighter than the Interval Boundary Propagation (IBP) method which uses backward propagation. The core contribution is expounded by developing bounds for multiplication (xy) and division (x/y) and using this to compute tight bounds on self attention layer computations. In particular in Table 3, the second example shows that the method identifiews "a", "the" "our" etc, which at least do not appear to be most salient to this reviewer.<BRK>Summary:This paper builds upon the CROWN framework (Zhang et al 2018) to provide robustness verification for transformers. The  CROWN framework is based upon the idea of propagating linear bounds and has been applied to architectures like MLP, CNNs and RNNs. A major contribution of this paper is to use forward propagation of bounds in self attention layers along with the usual back propagation of bounds in all other layers. Although the fully forward propagation leads to loose bounds, the mixed approach (forward backward) presented in this work provides bounds which are as tight as fully backward method. If the math is correct, then this paper can be it. Questions:The set up in the paper assumes only one position in the input sequence is perturbed for simplicity. I have not verified the math to see if they indeed compute a lower bound.<BRK>MILP is a powerful verification technique that can deal with cross position dependency, which can be potentially applied to transformers. The paper solves these key challenges which are not traceable for previous methods. Although it is the first one who does robustness verification on transformers, the linear relaxation is similar to previous work just deal with different nonlinearity. The author needs to add experiments of multi layer transformers.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>The experiments are sufficient. Therefore, what is the difference between this paper and others?<BRK>Overall, it is unclear what is the major novel contribution in this paper.<BRK>The paper focuses on training image classification networks without batch normalization.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>This paper proposes a simple method for imitation learning that is competitive with GAIL. Because SQIL is off policy, it can utilize replay buffers to accelerate sample efficiency. The authors really play up the "surprising" connection of SQIL to a regularized behavioral cloning. But this isn t really that surprising in the general sense (although I applaud the authors for rigorously defining the connection).<BRK>This paper proposes an imitation learning approach via reinforcement learning. This encourages the agent to return to "known" states from out of distribution states and alleviates the problem of compounding errors. The authors derive an interpretation of their approach as regularized behavior cloning. I think this is a good paper which shows strong empirical results based on simple but effective idea. deserve to be discussed earlier in the paper (introduction?) and make it to the experimental results.<BRK>Summary The authors propose SQUIL, an off policy imitation learning (IL) algorithm which attempts to overcome the classic drift problems of behavioral cloning (BC). The idea is to reduce IL to a standard RL problem with a reward that incentivizes the agent to take expert actions in states observed in the demonstrations. Comments Overcoming the limitations of BC algorithms is a relevant problem and this work presents a simple and interesting solution. 1.The considered settings (e.g., MDPs, IL/IRL problems) are never formalized in the paper (which directly starts by describing the method in Section 2). 2.Though the approach solves one of the main problems of many BC/non IRL algorithms, it still has some of the other limitations. Have I misunderstood something?
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>This paper provides an empirical comparison between several existing graph classification algorithms, aimed at providing a fair comparison among them, as well as proposing a simple baseline that does not take into account graph structural information. As a disclaimer, I would like to mention that I am more familiar with graph node classification methods, as opposed to whole graph classification (which is the focus of this paper), so I cannot assess very well the authors’ choice of which models to compare, and which datasets they were tested on. As mentioned above, I believe there are insufficient details about the baselines. For instance: a) The authors point out that the performance on the NCI1 dataset is different than all the others (it is the only dataset where the baseline is not the best). This could provide interesting insights for future work. If the authors clarify some of the issues above, especially about the results discussion part, I believe this paper may indeed be of value to the graph classification community.<BRK>This type of benchmarking paper is long overdue for graph classification with deep neural networks. The paper would ve been strongly if it had the following:1. Considered more structural features than simple node degree and clustering coefficient. Prior work [1] has looked at such features and answered questions like: How do structural features improve classification performance?And, which structural features are the most useful? 2.Investigated which graph neural network performs better for which graph structures (preferential attachment, small world, regular, etc) and for how much homophily. 3.Investigated the robustness of graph neural networks on classification as the structure of graphs become more random (e.g., by rewiring edges while maintaining degree distribution).<BRK>********** Post Rebuttal Update **********I appreciate that authors provided comments on all the raised concerns and updated the paper accordingly. That is not true. ********** Summary ********** The paper conducts an empirical study of 5 recently proposed graph neural networks (GNN). + it is shown that on some datasets, the results of a simple baseline   only operating on the node features, can achieve similar results to the elaborate GNNs. + some of the results in table 4 contradicts the corresponding papers which can be informative for the practitioners of the field. + the reproducibility and replicability problems, that is the motivation of this work, are important concerns of the field. It is also true that this is an important concern in machine learning research. Even if it’s assumed the 5 GNN methods , under this paper’s scrutiny, are representative of GNN classification, GNNs are used well beyond graph classification.
Reject. rating score: 1. rating score: 6. <BRK>1.Paper summaryThis paper develops a novel filtration for the analysis of based on theidea of *covers* of data sets. The paper lacks this structure at present and for a conference  submission, all main contributions should also be a part of the main  text. These stable paths are then shown to be useful for thecreation of  gentler  transitions for recommendation systems, as wellas the development of explainable supervised machine learning models. However, I recommend rejecting the paper in its current form due to thefollowing issues:A.<BRK>The paper presents an interesting filtration method to find staple maps, which proves effective in the recommendation system and explainable machine learning. The new framework is built upon a new concept termed cover filtration based on the generalized Steinhaus distance derived from Jaccard distance. This is not very clear at the beginning; instead, most of the introduction is related to TDA and mapper, which may confuse people not from this particular field. * The method introduced in this paper is intuitive and demonstrates with meaningful outcomes.
Accept (Talk). rating score: 8. rating score: 8. rating score: 6. <BRK>This paper proposes Meta Q Learning (MQL), an algorithm for efficient off policy meta learning. Please also augment captions to make figures as stand alone as possible. One important but somewhat orthogonal contribution of the paper is to highlight the importance of context in meta learning and fast adaptation. Concretely, the authors show that a simple actor critic algorithm (TD3), whose policy and value are conditioned on a context variable derived from a recurrent network performs surprisingly well in comparison to SoTA meta learning algorithms like PEARL. I have mixed opinions on this paper. This either highlights the strength of multi task learning, or the inadequacies of current meta RL benchmarks: either of which will be of interest to the community.<BRK>Summary The authors propose meta Q learning, an algorithm for off policy meta RL. The proposed approach is evaluated on standard Mujoco benchmarks and compared to other relevant meta rl algorithms. This work proposes interesting ideas and overall it constitutes an nice contribution. In particular, I found interesting (and at the same time worrying) that a simple q learning algorithm with hidden contexts compares favorably to state of art meta rl approaches in standard benchmarks. Could they be done at the same time by setting to 1 the importance weights of the new trajectories and sampling from the whole experience (new and old)? 3.Note that the ESS estimator (13) diverges to infinity when all weights are close to zero. I think an experiment of this kind would be valuable to improve the paper.<BRK>The authors investigate meta learning in reinforcement learning with respect to sample efficiency and the necessity of meta learning an adaptation scheme. Based on their findings, they propose a new algorithm  MQL  (Meta Q Learning) that is off policy and has a fixed adaptation scheme but is still competitive on meta RL benchmarks (a distribution of environments that differ slightly in their reward functions). **The authors make the following contributions:**1. The new method leverages data during meta testing that was collected during meta training using importance weights for increased sample efficiency**Overall, we believe the contributions are significant and sufficiently empirically justified. This is a significant result and supports the new method developed in this paper. The reuse of experience from meta training during meta testing by employing importance weights is also an interesting contribution. In contrast, we are not satisfied with the presentation of their new approach as a meta learning approach.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>The paper is relatively well written, based on intuitive ideas and including clear figures. I think there is not a theory that justifies this approach. It is not clear how the theoretical results (Theorem 1) helps to support the proposed method. I cannot agree with the author’s claim that “KANets significantly outperform the previous state of the art compact models”. o	The experimental results about memory and time used by regular attention operator compared with KAOs is obvious and not relevant because their theoretical complexities are well known. The only advantage seems to be a slight reduction in number of operations which is marginal.<BRK>Recommendation  Attention has been shown to provide improvements over convolutions but can indeed incur significant memory costs. The proposed method is sound and simple and may achieve significant speedups over regular self attention. Can the authors report results on such a baseline? The rest of the architecture isn t an external factor to ignore. These methods should also be cited as related work and potentially use as baselines (Squeeze and Excitation for example). The probabilistic analysis does not convincingly motivate the Kronecker Attention Operator. The theoretical motivation for the method is not convincing.<BRK>The main theorem provides a way to efficiently construct feature maps satisfying this covariance structure. I find this paper difficult to follow. I think I got it in the end, but I believe the analysis could be better motivated/presented and the consequences of Theorem 1 on design choices or implementation could be clarified. Similarly, the description of the architecture in Sections 3.1 and 3.2 is sometimes given without much motivation, letting the reader wonder there are particular reasons for the choices made on the architecture. I am not very confident in my assessment but I have the feeling that the paper could be greatly improved by some restructuring and giving more insights and motivations. after Eq.(3) I don t think the notation [cross in diamond] has been introduced.
Reject. rating score: 3. rating score: 3. rating score: 3. rating score: 6. <BRK>Specifically, they focus on the noisy robust (NR) variant of the action robust framework proposed in [1]. The authors propose to combine SGLD with DDPG, to maintain a distribution over deterministic policies (essentially a mixed strategy)   hence overcoming these issues. Review:Overall this seems like the first approach of using Bayesian learning in order to reach mixed Nash equilibrium in RL. This is super important, since many problems can be formulated as zero sum games for which the solution is not necessarily a pure strategy. However, in my opinion, it is not there yet and is thus not ready for ICLR. I feel that such work needs to be more convincing.<BRK>The authors report practical improvements compared to pure strategies computed as proposed by Tessler et al.DecisionThe idea of using randomized strategies for two player reinforcement learning is interesting and natural. However, as the authors note, mixed strategies are classical in game theory. In my opinion, this paper should only be accepted if it provides very convincing numerical experiments, which I am not qualified to assess. I happy to increase my score if the experimental results are deemed strong by the reviewers with more expertise in practical reinforcement learning. Does this refer to the algorithm that is used in the numerical experiments?<BRK>This paper approaches two player zero sum Markov game by using mixed Nash equilibrium by sampling from randomized policies. The authors propose that the optimization is done using Stochastic Gradient Langevin Dynamics iterations. In my opinion, the use of SGLD to this problem is potentially useful   as partially proved by this work. However, this application is obvious and does not have enough novelty merits to be accepted to this ICLR. The experiment make senses but is not rigorous enough to assure the practitioners on the improvement over baseline.<BRK>THE NR MDPs can be thought of as an agent learning in an adversarial environment. Most of the theory comes from the "Finding mixed nash equilibria of generative adversarial networks." But, this seems to be the first time SGLD has been applied to such a problem. The authors compare on the MuJoCo benchmark with common but not identical instances to "Action robust reinforcement learning and applications in continuous control", which also provides the baseline algorithm used for comparison. It is infact mentioned as a failure case.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>The paper tackles the problem of online learning for GMMs, in the context of high dimensional data. Specifically, the authors limit the scope to SGD like approaches and EM like optimization. I feel that this work is largely incremental, but more importantly indicating the authors  lack of understanding of the very long history of (online) EM. (In fact, their max approx is of this type.) Why not use hierarchical priors instead? In Sec.3.4, additional smoothing is accomplished using a subspace approach, which requires QR decomposition. I am mostly concerned about the evaluation.<BRK>The paper describes in detail a proper implementation of SGD for learning GMMs. The paper is overall clear and well written. The main contributions are an effective learning of GMMs from random initialization that is competitive (in terms of final loss) to EM training with K means initialization. The authors present experiments to show the effectiveness of it to avoid single component solutions that may arise from random initialization, which is an interesting point of the paper. So the practical advantage of the method (which probably exists) would benefit from more comparisons. While the authors discuss some way to train low rank models, the only successful results seem to be with diagonal covariance matrices, which seems much easier.<BRK>The paper proposes a new method based on Stochastic Gradient Descent to train Gaussian Mixture Models, and studies this method especially in the context of high dimension. what fraction of the data was used? (which covariance matrix?there are K such matrices). Section 3.3: The first sentence is wrong   EM can also suffer from the problem of local minima. is not a local minimum. The change of regularization during the training process seems like a heuristic that worked well for the authors, but it is thus unclear what optimization problem is the optimization solving. I didn t see a definition I don t understand the local principal directions covariance structure. The authors write  a diagonal covariance matrix of S < D entries). But what about the other D S coordinates?
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>In the second approach, the authors propose to dynamically switch between mixed operations and half precision operations during training. The authors claim that this second approach can match SOTA results while using half precision arithmetic for more than 94% of training. However, I have a number of concerns about the paper, which explains my score. While the authors have included a hyperparameter sensititivity analysis, I find the experiment to be unconvincing. While I appreciate the added experiment and realize that 10 days is too short a time to put in a proper sensitivity analysis, based on the current draft of the paper, I cannot recommend accepting this paper.<BRK>The author(s) propose to accelerate the training of deep neural networks while also maintain the performance of the trained model by switching between fully half precision computation and mixed precision computation. The proposed method simply switches between two existing training strategies, i.e., the mixed precision training and half precision training. K can be tuned so that the proportion of BF16FMA is close to those in Table 1. 5.From Table 1, there still exists a large performance gap in terms of accuracy (1.56% for ResNet 50) between the model trained by the proposed method and the model trained by state of the art MP. 6.The organization of this paper can be improved.<BRK>Observed that relying purely on half precision arithmetic results in lower accuracy, the authors developed a method to dynamically switch between mixed precision arithmetic (MP) and half precision arithmetic (BF16 FMA). Empirical results show that the dynamic approach can achieve similar accuracy as MP and FP32 algorithms. Specifically, what is the key factor that influences the sensitivity of a neural network towards precision? The dynamic approach could mean a lot of things while training DNNs and one cannot tell what the paper is about simply relying on the title.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>Thank the authors for the response. The major novelty of this paper is encoding the objective as a logical expression and the experiment part is limited. I am happy to change my score based on the reviews from other reviewers.<BRK>As a result, the experimental evaluation should be much more thorough. They argue, via simulation and toy examples, that the proposed model is able to generalize to logical formulas of the multidimensional rewards that has not observed during training. As a result, I do not support acceptance. The authors should more clearly explain this.<BRK>I wonder whether the model is still generalizable for larger problems. Even in the case of 20x20 grids, we can notice the gap between the baseline and the proposed method. More specifically, the problems of the paper are,( ) The scalability issue. Is it possible that we can relax this assumption?
Accept (Poster). rating score: 6. rating score: 6. rating score: 1. <BRK>I think the work does a decent job at looking at different number of components in the ensemble and analyzing the proposed method, but maybe not enough comparing and exploring other mechanism proposed as a defense for adversarial attacks. It proposes to use ensembles of full precision and low precision models in order to boost up robustness to adversarial attacks. I think the premise of the paper is quite clear, and the results seem to be intuitive.<BRK>The authors propose an ensemble of low precision networks as a solution to providing a neural network with solid adversarial robustness whilst also providing good accuracy. I found the paper easy to read with a high quality introduction and background, the results are very convincing and the idea is simple but intriguing. I could not work out from the paper whether the adversarial attacks on the low precision networks were performed at full precision.<BRK>This paper suggests using ensemble of both full precision and low bits precision models to defense adversarial examples. So I don t think the methodology contribution of this paper is enough for publication. Considering the weakness of the paper both in methodology development and empirical justification, this work does not merit publication from my point of view.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>This paper presents local ensembles, a method for detecting underdetermination when extrapolating to test points. This is central to the work of the paper and a more full treatment of the proof here could help illuminate some intuition about the connection to perturbations and variance of predictions. In the final experiment the authors demonstrate the use of local ensembles in active learning.<BRK>The paper focusses on underdetermination as being key to extrapolation. What are the implications of the method in the case of finetuning models especially is the training data available for fine tuning is low. A comparison with larger test set and models trained on deeper architecture such as ResNet and the like will be interesting to see.<BRK>The idea of estimating "ensemble subspace" is interesting and computationally effective. Please include much of the discussion in the paper or appendix. The reason that these methods are not compared to is insufficient.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>The authors consider the relation between Frechet distance of training and test distribution and the generalization gap. Overall I feel that the contribution may be quite weak, and I lean on the negative side. 2) In the proof of Theorem 1, it is quite hard to follow with the current notation, for the integral in (i), (ii) as well as in the proof using the intermediate value theorem, which variables are used? What we have in Theorem 1 is the lower bound only?<BRK>The authors try to capture it with Frechet distance, but I struggle to understand what is new in this work. First, there are a lot of assumptions in the computation of the Frechet distance:   1. Most importantly, they do not relate the Frechet distance to the lower bound in Theorem 1. There is no estimation on how the learned changes across distributions in the gradient norm term. The authors should make the connection of the bound and its computation clear, with proper connections to the experiments.<BRK>This paper considers the problem of how the mismatch between distributions of training data and test data would affect the generalization gap in machine learning tasks. The paper took a step in relating the change in the performance of the learned function to the Frechet distance (FD), also known as 2 Wasserstein distance, between the input and output distributions and proved that the former is lower bounded by the latter multiplied by a term related to the sensitivity of learning algorithm to distribution shift. I also find the statement about the generalization gap a bit misleading. Generally, the generalization gap refers to the gap between the expected error and the empirical error. But the experiments are mostly presenting the performance on the test data. Overall, I don t think the paper meets the standard for publication at ICLR.
Accept (Talk). rating score: 8. rating score: 8. rating score: 6. <BRK>This paper attempts to learn discrete speech units in a hierarchical (phone and word) fashion by incorporating multiple vector quantization layers into the audio encoder branch of a model that visually grounds speech segments with accompanying images. The model has been tested and compared against two algorithms and implementations that set the SOTA on the Zero Speech 2019 challenge (further improving one of them in the process, it seems), and outperforms these significantly using the ABX metric, so the proposed method seems to perform well (the model is using additional supervision, though). The paper is a pleasure to read and provides a rich set of results and analyses. One is adding the discretization to a pre trained model, the other is training from the start?<BRK>Strengths:The paper is extremely well written with a clear motivation (Section 1). The approach is novel. But I think the paper s biggest strength is in its very thorough experimental investigation. Their approach is compared to other very recent speech discretization methods on the same data using the same (ABX) evaluation metric. But the work goes further in that it systematically attempts to actually understand what types of structures are captured in the intermediate discrete layers, and it is able to answer this question convincingly. Finally, very good results on standard benchmarks are achieved.<BRK>Pretty interesting paper attempting to learn discrete linguistic units via vector quantization of visually grounded, speech related features. I think this is a worthwhile contribution. Reading the work, this seems to be the triplet loss described in Section 3.5. Is that the novel objective? I fear that essential and interesting point is somewhat diluted in the detailed exposition of results.
Reject. rating score: 1. rating score: 6. rating score: 6. <BRK>Based on this result, the authors claim that projecting the latent samples onto the surface of a hypersphere would make GAN less sensitive to the choice of the prior distribution. This paper is hard to follow and requires substantial improvements in terms of writing, owing to several grammatical and semantic issues. I can therefore not recommend acceptance. An important claim in this paper is that the proposed approach “alleviates variational inference in VAE”. Consider revising the paper to improve its writing.<BRK>This paper proposed an interesting idea that by regularizing the structure of the latent space into a sphere, we can free VAE from variantional inference framework. 2. the image quality of VAE (CelebA) is not that bad in other VAE papers, maybe tuning the \beta VAE can also achieve the same quantitative and qualitative results. 3.Can you visualize the latent space (z) for the CelebA dataset, also comparing with the results from VAE?<BRK>This paper proposes a novel autoencoder algorithm, named Spherical AutoEncoder (SAE). Compared with using von Mises Fisher distribution in the vanilla VAE, the advantage of the proposed method is not clear. To leverage the properties, proposed algorithm centerizes latent variables and projects them onto unit sphere. In this paper, the authors argue that the sphere structure has good properties in high dimensional.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>This paper takes the idea of Population Based Augmentation (PBA) and extends it to knowledge distillation (KD). Overall, there aren’t that many experiments. As for Figure 3, I don’t know if there is anything intuitive we can glean from this. This would be interesting to add.<BRK>However, I found a few problems with the paper:In the author’s methods, there seem to be multiple steps:1. 2.Train the student with PBA, using a subset of the data and then using the teacher to learn the augmentation policy (stage beta). 3.Additionally in Section 5.2 (experiments), the authors propose the combined inter/intra distillation loss, which is named ‘II KD’. Same for AlexNet on CIFAR 100. The novelty in the paper seems to be:a) Applying PBA to a Distillation setting.<BRK>More concretely, the paper proposes to use an evolutionary algorithm for data augmentation (PBA, already published) to train the teacher and student networks. The key aspect of the proposed method is that the teacher and the student use different augmentation schedules. The augmentation schedules improve results on both the teacher and student networks. The datasets used in the experiments are CIFAR 10 and CIFAR 100. The results show that it’s better to use a specific data augmentation schedule for the student network. However, the improvements of their method over the baseline (II KD) seem marginal there. A similar table to Table 3 should be included in this section. Score: Borderline accept, but I will increase the score if the authors address my concerns and provide better evidence that the hypothesis is confirmed.
Accept (Talk). rating score: 8. rating score: 8. rating score: 8. <BRK>Notes:While this is a good paper, I think the impact of the paper could be magnified if the authors were a bit more ambitious with their empirical evaluations. This paper extends the standard variance analysis to consider the hypernet case by investigating what the choice of hypernet initialization should be if one still wishes to maintain the well behaved activations/gradients in the main model. The axes should be labeled.<BRK>The paper presents an extension of Glorot/He weight variance initiazation formula for the hypernetworks. They show that proposed method allows  hypernet training when the standard ways don`t. Questions:    In standard NNs, initialization issues are mostly solved after introduction of BatchNorm. Wouldn`t it be the case for hypernetwork as well: to just add BN layers between main net layers?<BRK>Their method may be able to make Hypernetworks accessible to many more researchers and practitioners, the way classifical init techniques have made neural net training more accessible. There are a few things that could improve the paper (and get an improvement score from me). (For the record, if this was a 1 10 scale, I would have liked my score to be a 7).
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>The submission proposes an autoencoder architecture which combines two recent GAN based architectural innovations, namely the progressive growing of the decoder architecture (as well as the encoder architecture in this case) and the use of the encoded representation to modulate the decoder via a feature wise transformation mechanism. A learned representation for artistic style. I also have concerns with its characterization of the literature. Large scale adversarial representation learning. What do the authors mean by “disentangled representation”? Section 3.2 uses some notation for the encoder without introducing it first. The submission presents model samples, but as far as I can tell the procedure for sampling is not provided. How are samples obtained from the trained model?<BRK>Deep Automodulators introduces a generative autoencoder architecture that replaces the canonical encoder decoder autoencoder architecture with one inspired by StyleGAN. The paper trains this architecture with the loss framework of the Adversarial Generator–Encoder (AGE) and utilizes the progressive growing trick originally introduced in Progressive GAN which is also adapted by the Pioneer models, recent followups to AGE. The use of AdaIN conditioning across multiple layers and multiple scales (like StyleGAN) and the ability to directly compute latent codes via the encoder allows the authors introduce a disentanglement objective L_j and also an invariance objective L_inv to help encourage these properties in the models via consistency objectives The paper shows results demonstrating StyleGAN style coarse/fine visual transfer on two high quality face datasets (importantly this is demonstrated on real inputs rather than samples as in StyleGAN) as well as respectable sample quality on LSUN Bedrooms and the LSUN Cars dataset. Overall, I think the paper is promising and shows a nice combination of efficient latent inference and controllable generation but the authors do not include ablations to validate some of their core contributions such as the L_j objective. 1) The StyleGAN inspired architecture 2) the disentangling objective L_j and 3) using the loss function dρ of Barron 2019. Additional Comments:Each subsection of 3 could be improved by providing a brief introduction to the motivation for and aim of each contribution before launching directly into how it is implemented / achieved.<BRK>The paper makes the following contribution:  using the AdaIn architecture proposed by Karras et al., 2019 with the autoencoding architecture of AGE/PIONEER;  a cyclic loss to enforce disentangling between different layers;  a method to enforce invariances at specific layers. The adaptation of the AdaIn architecture in an autoencoding fashion (a la AGE/PIONEER) is sensible and well motivated, combining state of the art generator while allowing inference in a compact setting (i.e.not requiring an additional discriminator). The other contribution are harder to read and the writing should be improved. I will also assume that d_cos is the cosine loss as defined by the PIONEER paper. This should be mentioned as well. While the authors introduce F as a "known invariance", it is unclear what role it plays in the cost function. Is F an invariant on which we measure this reconstruction loss d? It is unclear what was the contribution of the layer specific loss metric to allow that feature transfer. It seems from Figure 5 the invariance objective has been roughly satisfied but at the cost of a significant drop in image quality. The two other contributions are unclear, both in their explanation and in what they contribute: the layer specific loss not compared to an architecture just trained in an AGE way, and the enforcing of invariance, although filling its objective, might deteriorate other desirable properties of the model (e.g.sample quality).
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>The model is learnt by maximizing a lower bound on the mutual information between the latent states and their successor observations (instead of the classical sequential ELBO). The authors argue that the latter objective function yield robustness to distraction in visual scenes. Overall I did not find the paper particularly clear and easy to read. The method is only introduced in the 5th page and no ablation study is conducted. It is still not obvious to me why maximizing the MI in the objective function would reduce the influence of potential distractors.` Furthermore, the paper overlooks a good part of the related work on extending VAEs to sequence data, published in the last 3 years and does not draw links to similar architectures. The experiments are in my opinion not convincing, as the approach is only experimented on 2 non trivial  yet not particularly challenging  environments (Finger and Half Cheetah).<BRK>########### Post rebuttal summary ############The proposed method relies on the fact that the distractors have highly unpredictable movements such that a mutual information objective between frames of a sequence learns to ignore them. In real scenes the behavior of distractors likely lies somewhere in between these extremes: they will likely not be fully deterministic but certainly not have frequent moments of purely random direction changes. Due to this fundamental concern about the method I cannot recommend acceptance of the submission. ########################################## Paper SummaryThis paper combines a mutual information maximisation objective a la CPC with objectives for dynamics and reward prediction to learn a representation for downstream planning / skill learning that is more robust to visual distractors than comparable representations learned with reconstruction based objectives a la VAE. The authors show improved robustness of their representation to visual distractors over a baseline with pixel reconstruction based representation learning (PlaNet). As a result they are able to achieve better performance when model predictive control is used on top fo the learned representation to perform control on simulated DM Control Suite tasks with added simple visual distractors. In order to justify that the MI objective is helpful for learning the representation I would suggest to run an ablation experiment that trains using *only* the reward prediction objective and compare performance.<BRK>The authors propose a latent dynamics model that is learned by maximizing a bound on mutual information between image embeddings and the latent state h time steps later. The model is evaluated on four standard visual control tasks that are solved by online planning. Strengths:  The paper addresses an important open problem with latent dynamics models. However, I cannot find anything about the method that would make the learned features more task relevant than reconstruction. What value for h is used? It would be interesting which of the design choices about the model contribute to its success. It is unclear why information about the reward should be penalized. Is the objective summed across time steps? How is the data sampled that the model trains on? Comments:  The paper claims in the introduction that reconstruction based approaches cannot discard low level information.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>This paper tries to control the variance of advantage function by utilizing the independence property between current action and future states. The practical approach they are using is to learn a dependency model of reward function as a control variate to lower the variance. It is similar to many of the control variate technique papers (e.g.Liu et al.(2017)), which learn a model to decrease the variance in a certain way. I don t see from the paper for the advantage of applying control variate over advantage function compared to previous methods. The minor concern is for the clarity. I encourage the authors to do more surveys on control variate technique in policy optimization and highlight the novelty of why controlling the variance of the advantage function can help to boost the performance of policy optimization.<BRK>This paper proposes a novel advantage estimate for reinforcement learning based on estimating the extent to which past actions impact the current state. More precisely, the authors train a classifier to predict the action taken k steps ago from the state at time t, the state at t k and the time gap k. The idea is that when it is not possible to accurately predict the action, the action choice had no impact on the current state, and thus should not be assigned credit for the current reward, they refer to this as the "independence property" between current action and future states. Based on this idea, the authors introduce a "dependency factor", using the ratio P(s_{t+k},a_{t+k}|s_t,a_t)/P(s_{t+k},a_{t+k}|s_t). In particular, given the use of function approximation in practice instead of actually sampling 3 trajectories the validity of the control variate method applied is questionable. This is something I feel would be worthwhile to explore more in future work. However, the variance can actually be higher, due to the importance sampling ratio used, when future rewards are highly dependent on the current action. They also provide a simple demonstration where their advantage estimator is shown to improve sample efficiency in a control problem. What measure is this variance supposed to be computed with respect to?<BRK>This paper proposes a new advantage estimator in reinforcement learning based on importance sampling. This form allows for a significantly lower variance estimator for situations where the current action "stops mattering" to the future state. A control variate, as in Grathwohl et al., is used to combine the importance sampling estimator with the "standard" estimator in a way that is always unbiased and attempts to minimize the overall variance. The overall setting makes sense. But of course your estimator does not rely on actual *independence* (C   0); it can take advantage of only "weak dependence" (and moreover this dependence need not be pre specified). This does raise an issue: a policy which *ever* deterministically avoids an action, i.e.$\pi(a_t \mid s_t)$ in (13) is 0, will break the method. But a bad choice of parameters in your $C^\pi$ estimator *would* bias your estimates. Similarly, $V_{w_1}(s_t)$ of (7) isn t really a value function; it s the difference between the value function and the sum of discounted control variates. Also, $C_\phi$ doesn t estimate $C^\pi$: it estimates $C^\pi + 1$, so it might make more sense notationally to just subtract one from the definition of $C_\phi$. Overall: I think the idea in this paper is sensible, the derivations fairly clear, and it seems to help empirically.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>This paper proposed to improve the regular batch normalization by reducing the skewness of the hidden features. To this end, the authors introduce a non linear function to reduce the skewness. However, the analysis and experiments are too weak to support the authors  claim.<BRK>3.Based on “for ... X with zero mean and unit variance, there is a high probability that ... lies in the interval ( 1, 1)”, the paper introduces φ_p(x), where p > 1, to decrease the skewness of the feature map x. However, there are about 32% elements of X that their absolute values are larger than 1, for a standard normal distribution. 4.The results on CIFAR 100 and Tiny ImageNet are not convincing enough in my opinion.<BRK>The paper proposes to add an extra nonlinearity function in batch normalization, between the normalization and affine scaling. The intuition behind is reducing skewness of activations, and the modification is evaluated on CIFAR and tiny ImageNet datasets.
Reject. rating score: 1. rating score: 3. rating score: 3. rating score: 3. <BRK>This paper claims that convolutional filters in CNNs are not the result of fitting to the input data distribution but they are the optimal solution to a spectral decomposition of the convolutional operator. The work is unfinished without a thorough analysis and discussion of these crucial aspects. This prior work greatly reduces the impact of this contribution, unfortunately.<BRK>This short, interesting paper provides a theoretical analysis to explain why we may expect to see bandpass oriented filters arise as a result of the convolutional structure of deep networks. The explanation boils down to the fact that the eigenfunctions of convolutions correspond to bandpass filters. 2.Some light shed on 3D filters in higher layers of the network.<BRK>Contribution: This paper proposes an explanation in terms of the structure of convolutional networks themselves: Given thattheir convolutional layers necessarily operate within the space of convolutions, learning oriented bandpass filters provides the system with the potential to span possible input, even while preserving a notion of locality in the signal domain. Question: What is possible implication and applications of this  explanation in practice.<BRK>This paper proposed a hypothesis on why neural network learns oriented bandpass filters. The mathematical observations are interesting, and the paper hypothesizes that this mathematical property encourages neural networks to learn oriented bandpass filters. I understand the paper is proposing a hypothesis, but drawing a more solid conclusion is important. I am not recommending acceptance of this paper in the main conference, but it may be a good paper in a certain workshop.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>This paper tackles the problem of developing agents to solve interactive fiction (IF) games. The authors propose an agent that builds a dynamic knowledge graph of each state from the textual observation provided by the games, while choosing actions from a template based action space. In general, it would be nice to have some more analysis on all the models across the different games rather than just Zork1. 2.Empirical results are good and presented on real IF games.<BRK>This paper considers the problem of interactive fiction games in which an agent interacts with the world purely through natural language. The paper is very well written, especially the introduction section, demonstrating novelty in the context of fictional games literature, and showing good empirical results. However, I don t have any background in fictional games but dialog modeling. So it is hard for me to fairly assess how novel this work is. Though, it can be effective. Authors argue that action space is super large even if generating sentences of length upto 5.<BRK>This paper proposes a knowledge graph advantage actor critic (KG A2C) model to allow an agent to do reinforcement learning in the interactive fiction game. Under the general framework of A2C, the core contribution of the paper is to apply a graph attention network on the knowledge graph to help learn better representation of the game state and reduce the action space. Authors do make good progress along this line. 2, The paper is well written and the design of the proposed new model seems technically reasonable. Why?Most of my concerns are addressed by the authors  response. I increased my score.
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>This paper proposes a theoretical framework for post processing methods of word embeddings. While the paper reflects thorough and substantial work   both in the theoretical framework and in the experimental part, I have serious concerns about its clarity and about the experimental results and also some concerns about comparison with previous work. All these, unfortunately, make me recommend a reject decision. Below, are more details:1. But this is a much broader issue   the author suggest very little motivation to how the post processing method should work, what improvements it should provide and why we should expect such improvements. Only on the beginning of section 3 I learned the fundamentals of that framework and basic concepts such as the Gram matrix. Finally, it was hard for me to determine where the survey of previous work ends and the contribution of this work begins. 2.Experimental analysis:First, the authors describe their evaluation tasks very briefly and only in the appendix. (2014).Retrofitting word vectors to semantic lexicons.<BRK>This would also offer additional space for more experiments. I would suggest the authors to cite that work and ideally even compare to it on their set of intrinsic tasks (e.g., word similarity, word analogy), and then discuss the difference in results and their approach to unsupervised post processing. Do we talk about true similarity or relatedness or both? However, in the context of the paper post processing actually refers to some unsupervised post training steps on the input space without injecting any external information. However, the summary is not self contained as it is not clear what \mathcal{L}  refers to (and the reader must search through the derivations again to find its meaning). It is a pity that the method is not evaluated on more distant language pairs, as I believe that the method might have much more effect there than on the already saturated EN to ES/FR/IT bilingual lexicon induction tasks.<BRK>To find the optimal Gram matrix, they adopt the shrink method to make Gram matrix K  to target matrix T on semi Riemannian space. Strengths* This paper provides a novel post processing method that can relieve isotropy condition and shows experimental support that solving isotropy condition on word embedding vectors can improve its performance. * Large set of experiments on various word embedding benchmark tasks. Weaknesses* It would be nice if the authors show the performance of the post processed word vectors on other NLP benchmark: text classification, NER, ... etc.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>This paper presents a new method computing the importance of features in time series, called Feed Forward Counterfactual (FFC). However, previous counterfactual based methods do not carefully consider appropriate conditional distribution and generate out of distribution counterfactuals. FFC is evaluated on simulated and real datasets and shows that it is better at localizing important observations over time compared to the other baselines. Although the experiment shows successes of the proposed method on several datasets, the major weakness of this paper is the lack of technical novelty and detailed analysis of the proposed method. For example,If the time series is non stationary, this could incur a different amount of the change in the model output and proposed time importance might not work. Did the authors consider trying out with varying size of training data or generator model?<BRK>Technically, it is in the category of saliency maps, only with possibly larger perturbations defined by the generative model. Thus, it most likely should inherit the same properties as the saliency maps. The authors experiment on both synthetic and real world datasets. Given the similarity to the saliency maps, the authors should have tested the proposed method in the sanity checks in [1]. Despite sampling from a generative model, because of the univariate nature of the counterfactuals used in this paper, the process might create invalid data points. However, this method does not account for the correlation among the features. The authors should have compared the run time speed of the algorithms in the experiment section, too.<BRK>  Overall  This paper proposes a method for evaluating the influence of individual observations on the output of a time series prediction model by replacing each (discrete time) observation with its conditional expectation given the other observations. I reviewed this paper for NeurIPS and was happy to see that the authors have made substantial improvements to the presentation and evaluation of the method. I recommend using a toy example to make this point. For example, the authors demonstrate the sensitivity analysis fails on the synthetic data, but never explain why. Is this picking up on a specific condition and if so what condition? Is it possible that the frequency of measurements affects which features are selected as important? 6.I thought GHG experiment was *much* better and clearer in this version of the paper. I don t think a reader should have to reference another document to follow notation. Pg.3 "The magnitude of our...": I call the authors  definition of feature importance absolute not relative.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>The paper describes a new dual method for graph convolutional networks that combines the features from the graph and it s dual, in two pipelines. The paper builds on the architecture as in GCN and in addition to the dual pipelines, one from the graph and other it s dual, employs KL divergence to achieve the final prediction.<BRK>The model is composed of two GCNs, one on the primal graph and one on the dual graph. The novelty and contribution of the paper are rather limited.<BRK>I decided to give a weak reject to this paper for the following shortcomings:1. Novelty is not enough.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>The paper proposes to learn the step size for a Runge Kutta numerical integrator for solving ordinary differential equations initial value problems. The authors frame the stepsize control problem as a learning problem, based on different performance measures, on ODE dependent inputs and on a LSTM for predicting the next step coefficient. The construction of the training and test sets should be better explained. The graphics also show that the local error is smaller for the proposed method than for the baselines which is in contradiction with the global error behavior. The baseline is not defined in the text so that it is difficult to judge the performance.<BRK>Summary: This paper casts the problem of step size tuning in the Runge Kutta method as a meta learning problem. The paper gives a review of the existing approaches to step size control in RK method. Deriving knowledge from these approaches the paper reasons about appropriate features and loss functions to use in the meta learning update. The paper shows that the proposed approach is able to generalize sufficiently enough to obtain better performance than a baseline.<BRK>## Summary ##The authors present a method for learning a step size adaptation strategy for Runge Kutta methods. They define a loss function that better captures global performance of the controller, rather than just local behavior. While the premise of the paper is very promising, I don t think it is ready to be accepted to ICLR at this time. I think the paper would benefit from a clearer description of the RK step size selection problem. This estimation is critical to step size adaptation.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>For this purpose, the authors propose to use a flow based model for p(z), and regularize the AE objective (i.e., MSE) with a cross entropy between q(z)   1/N \sum_n E(x_n) and p(z). The main disadvantage of the paper is its language. But besides that, the main ideas are well explained. Remarks  The language in the paper is a bit off. I find it confusing.<BRK>Summary:The authors propose a model that combines a simple Auto Encoder (AE) together with a Normalizing Flow (NF) model, such that to derive a generative model. In particular, the AE is used to learn a low dimensional representation of the given data in a latent space. However, in the proposed idea I have the feeling that there is a strong overfiting issue.<BRK>The paper proposes a new model combining an auto encoder (AE) and a normalising flow (NF). The model, Generative Latent Flow (GLF), uses the AE to map the inputs to a latent space, which is then transformed using the NF. The authors compare the performance of GLF to a large number of competing methods, showing very competitive results.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>This paper proposes a new feature selection method by integrating the knockoff procedure and generative models. However, I have the following concerns:  The motivation is not clear. The advantage of the knockoff procedure is that it can find relevant features (variables) with statistical guarantees such as FDRs, which is clearly discussed in the paper. However, the objective of this paper is to design a better feature selection method for prediction, where the statistical guarantee is usually not important. Hence the advantage of using the knockoff procedure is not clear. In addition to the above issue, the empirical performance of the proposed method is not convincing. Since the proposed method is based on the knockoff procedure, it would be interesting if there is some statistical guarantee for the selected features.<BRK>This paper presents an interesting use of a knockoff framework similar to that of model X knockoffs (Candes et al., 2018) in generative models like VAE and GPLVM for feature selection in supervised learning. In particular, why are z and x_n conditionally independent given x_{ n}, as reflected in their zero covariance value? Page 2: The authors say that "they must be independent from the labels to be predicted".<BRK>This paper proposes a way of employing modern generative models like VAEs and GPLVMs within the recently popular “knockoff” framework for variable/feature selection. Under certain assumptions, fitting a model on top of both original and knocked off features and observing the difference between the fitted coefficients for the true and the knockoff features can then be used for variable selection with guaranteed false discovery rate. The paper concludes with an empirical study which shows that their algorithm is competitive with existing feature selections methods in terms of post selection accuracy of the fitted model. In particular, mu_{z | x} tends to be a function of the whole vector x including x_n. Relatedly, have you tested whether starting from different seeds results in the same subset of variables selected (e.g., when using VAEs)?
Reject. rating score: 1. rating score: 1. rating score: 1. <BRK>This paper introduces a strategy to prune a convolutional neural network during training. Furthermore, the robustness of the resulting pruned networks to adversarial attacks is investigated. The study of robustness to adversarial attacks, while interesting, is also not novel per se, as the idea of performing such a study was proposed in Wang et al.,  2018. However, there are no explanations for this different behavior. The experiments demonstrate that the method is effective at pruning, but do not provide any timings to evaluate the resulting speedups.<BRK>Specifically, it proposes concentrating all pruning during an early "era" of training (the first 20 50 epochs out of 100 total). The appendices should contain material that is nonessential for making sense of the paper. It also explores hybrids between sparse pruning and structured pruning. 3) To reduce the cost of training neural networks in general by pruning them during training? There are no clear takeaways from the results of these experiments. This paper has no clear motivation and makes no tangible contributions to the literature and, therefore, I recommend a rejection. CONTRIBUTIONS 1) A study of the appropriate window ("pruning era") for pruning Resnet 50 on ImageNet and TinyImageNet2) A study of the tradeoffs between various forms of structured and unstructured pruning. 3) An analysis of the adversarial robustness of the pruned networks. The paper would be stronger if content on adversarial robustness was removed entirely.<BRK>The paper investigates methods to train neural networks so the final network has sparse weights, both in convolutional layers and in fully connected layers. In particular, the paper focuses on modifying the training so that the network is first trained without sparsification for a certain number of epochs, then trained to be increasingly sparse, and then fine tuned with a fixed sparsity pattern at the end. While I find the overall approach of the paper interesting, currently the experiments are not systematic enough to derive clear insights from the paper. What happens if the "pruning era" is made longer, started substantially earlier, or started substantially later? In addition, I have the following suggestions:  The authors may want to remove or enhance the adversarial robustness evaluation.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>This paper aims to apply the model of Wang 2019 to the new NDH task of Thomason  19. Both of these datasets are built on the same room to room environment and both are for natural language instruction following. Thomason s work extends the R2R paradigm to include a dialogue history which is collapsed into a single instruction. The contribution of this paper is to build a single model which alternatingly samples trajectories from each of the two datasets to train a more general actor and the authors also believe that the presence of an environment classifier assists in generalization. The claims of the paper focus on being "environment agnostic" and notions of generality. As hinted by the authors in their future work, to properly show this would probably require two different environments or tasks (e.g.Touchdown), not training on two tasks that use the same environments and pre computed visual features. Am I incorrect that the only difference between the NDH and VLN formulation is the structure of the sentences? Figure 2 mostly leads me to believe that we have a simple data augmentation situation which makes the bump in performance somewhat predictable. Minor: Is there any reason why in Table 1 we can t simply run the VLN models on NDH and NDH on VLN?<BRK>Therefore, the authors propose two key ideas to tackle this issue and incorporate them in the reinforced cross modal matching (RCM) model (Wang et al, 2019). Moreover, by training on both tasks the effective size of training data is increased significantly. Second, they propose an environment agnostic learning technique in order to learn invariant representations that are still efficient for navigation. The contribution of this paper is combining and incorporating these two key ideas in the RCM framework and verifying it on VLN and NDH tasks. They demonstrate that their technique outperforms state of the art methods on unseen data on some evaluation metrics. Therefore, I would recommend accepting this paper if some issues in delivery and clarity are addressed. In particular, Section 3, where the authors introduce the novelty of the paper in more detail, could be better explained and a cleaner line should be drawn between prior results from other papers and novel results proposed by this paper. Is there a particular explanation for this?<BRK>Summary:There have been two recent related tasks proposed in vision langauge settings: vision langauge navigation (VLN) where natural language turn by turn instructions must be decoded by an agent in an indoor environment to reach the goal location and Navigation from Dialog History (NDH) where dialog between two humans trying to reach a goal is input to an agent to try to reach a goal location. This paper uses these two tasks  data in a multi task manner to try to generalize better between indoor environments especially unseen environments which are not in the training set of the agent. Comments:  The paper is well written and easy to understand! Experiments are thorough and has all the ablations one would ask for. Why not try more sophisticated methods of multi task learning like  MetaLearning  by Finn et al 2017 (MAML). The setting is already such that one has a natural oracle (which the authors are already using via BC in the objective) which is the shortest path planner during training time. Then combined with MAML one can do Meta IL as in  One Shot Imitation Learning via Meta Learning  Finn et al 2017.
Reject. rating score: 1. rating score: 1. rating score: 3. <BRK>(2) The content in the Introduction does not make a note of many algorithms proposed for exploration in Deep RL   UBE [1], Bootstrap DQN [2], Randomized prior for Bootstrap DQN [3], Parameter noise[4]. After that, are some concrete questions to clarify the contents of the paper. This is possibly a typo, or something deeper is left unexplained here. (3) DDQN has been shown to be reducing the overestimation bias prevalent in DQN and therefore was the framework BDQN was built on. "Randomized prior functions for deep reinforcement learning." (4) Are the benefits of adaptive sigma present if the base algorithm is changed to DDQN? It does not have to outperform DDQN, but even a comparative study empirically would be an insightful and comprehensive contribution.<BRK>This paper introduces a deep learning based adaptation for the RLVSI algorithm, where the agent uses the representation learned by the deep neural network based RL agent (DQN). However, they do not provide any baselines or comparisons with this approach. 2) Lacking comparisons in general The results on Atari are compared with vanilla DQN (with epsilon greedy). Non standard experimentsIt is not clear why the authors did not use the standard n chain task but rather used the modified version. They also should use a few of the standard experiments so that it gives the reader more insight into where their algorithms excel. Things to improve the paper that did not impact the score:Figure 3 is too small to read. The section on Likelihood matching is not clear: in motivation and impact. Deep exploration via bootstrapped DQN. Randomized value functions via multiplicative normalizing flows. "Randomized prior functions for deep reinforcement learning."<BRK>Deep Randomized Least Squares Value Iteration This paper proposes a method for exploration via randomized value functions in Deep RL. One nice thing is that it requires only relatively minor changes to the DQN algorithm. The general flow of the paper and structured progression is nice. However, there are some other places the work could be improved:  I think that the name "Deep RLSVI" is a little imprecise... actually RLSVI could already be a "deep" algorithm as defined by the JMLR paper: http://jmlr.org/papers/volume20/18 339/18 339.pdf (Algorithm 4). It would be good to compare these methods more explicitly, particularly on the domains designed specifically for testing exploration. However, I do have some concerns about the treatment/comparison to related work and I think without this it s not ready for publication.
Accept (Spotlight). rating score: 8. rating score: 6. rating score: 6. rating score: 6. <BRK>This paper introduces an approach to learning compositional koopman operators to efficiently model the dynamics of non linear systems, consisting of an unspecified number of objects with repetitive dynamics. The key contribution of this work is the use of a graph neural network that allows the koopman operator to be learned for systems of  multiple objects, and the incorporation of blockwise structure in the koopman gain and control matrices that improves parameter estimation process and is shown to reduce over fitting. Nevertheless, this is a useful demonstration of learning for soft robot systems, and the idea of using koopman embeddings is likely to be of value to the ICLR community. As I understand it, the proposed approach is able to exploit this natural blockwise structure due to the assumption that the same physical dynamics are followed by each block (although objects can also be labelled as rigid/moving). Why was this the case?<BRK>A physical system is a represented as a graph; graph neural network is used to encode the current state to an object centric embedding where the dynamics are assumed to be linear (Koopman operator theory) and modeled as a transition matrix. The key contribution is to recognize that similar physical interactions can be modeled using same parameters which constraints the transition matrix to be block wise with shared parameters. Furthermore, the model is extended to add a control matrix to model external control. The efficiency of the proposed algorithm compared to prior work makes is much practically useful. This paper and several related works are all evaluated on different problems; it would be useful to evaluate on similar tasks; for instance, strings [Battaglia 2016].<BRK>This paper proposes to learn compositional Koopman operators using graph neural networks to encode the state into object centric embeddings and using a block wise linear transition matrix to regularize the shared structure across objects. The combination of deep Koopman operator with graph neural nets is very novel and interesting. In conclusion, I think this work can inspire more wok into modeling larger and more complex systems by integrating the power of the Koopman theory and the expressiveness of neural networks.<BRK>The paper proposes a novel method for modelling dynamical systems over graphs. I think this is very important from the reader perspective. The GNN encodes the input graph to what the authors call "object centric embedding", whose concatenation over all objects is defacto the approximate Koopman embedding of the system. One of the key contributions is the reduction in parameters, by assuming that the interactions between different objects in the Koopman space are limited to some fixed number of types, or in other words given the object centric embedding the Koopman matrix is a block matrix, where each block can only be one of K matrices. In addition to the dynamical modelling the paper adds an extra linear "control" input in the Koopman embedding space which to affect the dynamics of the system and allow for modelling systems where there is external control being applied. I personally like the main idea of the paper, which is to use previous results from approximating the Koopman operator and combining it with GNNs for more accurate physical modelling of object object interactions. Comments on the experiments:1. 2.The block diagonal structure approach in general has been presented as working with multiple types of interactions.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>This paper proposed a new method for unsupervised domain adaptation. I think their method is interesting and motivation is important. However, their experimental results are not convincing enough. I would say that the method does not have to outperform state of the art methods for these datasets, but they need to show how the method works on this dataset with respect to stability and interpretability. "Energy based generative adversarial network."<BRK>This is achieved by designing an adversarial reconstruction network. The proposed MDAT stabilizes the gradient by replacing the domain classifier with a reconstruction network. ### Novelty ###The model proposed in this paper is extended from the domain adversarial training approach. This idea is interesting and provides some novelty. ###Pros###1) The paper proposes a Max margin based approach to tackle domain adaptation. 2) The experimental results on digit benchmark demonstrate the effectiveness of the proposed method over other baselines including the most state of the art ones. ###Cons###1) The experimental part of this paper is weak.<BRK>This work proposes Adversarial Reconstruction Network (ARN), a network architecture, and Max margin Domain Adversarial Training (MDAT), an objective and training procedure for unsupervised domain adaptation. The method is very similar to some of the existing works in the literature. Experiment results on the standard digit datasets and the WiFi gesture recognition dataset show that the proposed method outperforms other alternatives. Its novelty is limited. D_s should be \mathcal{D}_s to match previous notation. It would be better if the paper includes proper discussion about the contrastive loss from the literature and distinguish the particularities between MDAT and SiGAN. Overall, I think the proposed method shows some prosperity thus I have increased my score accordingly.
Accept (Talk). rating score: 8. rating score: 8. rating score: 8. <BRK>The paper proposes an original approach to predict the function of groups of neurons in the V1 cortex based on their invariance to well designed rotation invariant CNN filters. The design of these features is funded by the observation that specific ganglion cell types have rotation and scale invariant responses to visual stimuli.<BRK>It would be important to control for this potential artifact by running the procedure on an unstructured synthetic dataset. > this sentence is misleading, since no evidence for functional clusters is provided.<BRK>The paper is well postulated.
Reject. rating score: 1. rating score: 1. rating score: 3. <BRK>I consider this work to be widely irrelevant. The results show some effect   but not a relevant one. And there is not much more to say.<BRK>The algorithm is an extension of a previous one.<BRK>The proposed algorithm seems to be a straightforward modification of the randomized SVD algorithm, so that the contribution of this paper would be incremental.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>The paper presents an algorithm for optimizing an function f under the constraints that the square matrix variable x represents "metric". In this context, this means that we have also observed a graph G with n vertices, and x is of size n by n, x(i, j) < x(i, e) + x(e, j) if i ~ e and j ~ e are adjacent: this is a generalized for of triangle inequality. The Project subroutine itself is a projection onto a convex set according to a Bregman divergence, which is not trivial. The algorithm stacks multiple subroutines which are not necessarily very light. It seems to be a "list of hyperplanes" according to the previous text, but it is unclear to me how to build it algorithmically The notation L is confusing in Algo 1 MetricViolation: wasn t L the matrix defining the metric?<BRK>This paper proposes a new method for solving the metric constrained problem based on projections on cutting planes. Its main contribution comes from the "forgetting" part, where unnecessary constraints (that are inactive) are removed in order to keep the number of constraints manageable. Pros: The methods seem practically useful as verified in the experiments. Cons: Most importantly, the paper is out of format and there exist some critical typos that need to be fixed. It needs to be reformatted and verified to be under 10 pages limit. However, I think this point is not crucial given the empirical usefulness of the algorithm. See [1] for an example.<BRK>The paper considers the problem of optimizing convex functions under metric constraints. The main challenge is that expressing all metric constraints on n points requiries O(n^3) constraints. The paper proposes a “project and forget” approach which is essentially is based on cyclic Bregman projections but with a twist that some of the constraints are forgotten.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>This paper introduces a new loss function for training deep neural networks, which show good performance with respect to well calibrated, trustworthy probabilities for samples after a domain shift. I have the following major concerns with the paper:1. Presentation: The paper s presentation is very weak. The introduction is more like realted work with less focus on what they are trying to pitch in the paper. 2.While I appreciate the use of reliability diagrams and the loss function inspired from it, I do not completely understand what are the entities in equations 1 and 2 or how they are used later. I believe this is not the case; hence, the authors should make it more general and divert the specific details to experiments. I believe the authors have constructed a new loss function by adding a new term to it. Again a presentation issue. However, I have reservations regarding the presentation of this paper at this moment.<BRK>This paper proposed FALCON, a simple method to produce well calibrated uncertainty estimation. The idea is to introduce two additional terms, one that directly encourage lower confidence for all negative classes of all data points, and another one that optimizes the ECE for adversarial samples. The line style is not consistent in the figures. For example, what do you mean by ‘non misleading evidence’ when describing L_{adv}? For example, it would help to state that L_S operate only on negative predictions.<BRK>The paper presents a method for calibrating neural networks on in  and out of distribution data using two additional loss terms: entropy encouraging loss term which maximizes softmax probabilities for wrong classes and adversarial calibration loss term which pushes confidences to match accuracy on adversarial examples. The idea of using adversarial calibration training is interesting and promising, however, the clarity of the paper needs significant improvement and there are several issues which need to be addressed; for this reason, I recommend a weak reject for the current version. The predictive entropy loss term essentially maximizes the probabilities of wrong classes with a lower coefficient. How would you support the claim that the loss surface is unchanged? Is the entropy loss needed at all? How does performance change if we only have standard and adversarial loss?
Reject. rating score: 1. rating score: 3. rating score: 8. <BRK>The authors propose a mean field analysis of recurrent networks in this paper. The recursive structure is the most complicated part of the recurrent networks, and also its major difference from feedforward networks. In current networks, the hidden states become (or even heavily) dependent on the weight due to recursion. When making such an assumption, the recurrent networks just become similar to feedforward networks. The authors  claim that "the untied weights assumption actually has long history of yielding correct prediction" is not ungrounded and questionable. (2) The paper is not well written. They are placed in the text without any highlight. Some theoretical statements are claimed without any rigorous proof. (3) The experiments only consider the MNIST and CIFAR10 datasets. Even though the authors might like their experiments, for the sake of the main stream users of recurrent networks. I cannot believe such weak results can be used to make meaningful justifications.<BRK>This paper touches the signal processing/long term propagation problem in gated recurrent neural networks from the mean field theory. including myself, find the paper hard to read for the general machine learning audience. And even though the authors mention that they will fix the text in the future, they do not change any text of the paper. I think writing is also important besides presenting interesting research ideas. The paper is interesting but more details could be added to both theories and experiments. However, I think all of the reviewers. 4.This initialization only helps at the beginning of the training. Do you train/tune all the different initializations in the same way? It is hard to believe LSTM did poorly on sequential MNIST unless giving more details since LSTM has been proved to perform okay on sequential MNIST in a bunch of papers[1]. I agree with Reviewer 2 that the paper provide some insight from Physics and can be an interesting contribution to the community.<BRK>The aim of this paper is to suggest randomized initializations for the various weights of a recurrent neural network (GRUs and various LSTMs are covered), such that training these networks gets to a successful start, when the model is trained on long sequences. Instead of being heuristic, their approach follows first principles of analyzing signal propagation through time, using ideas from statistical thermodynamics (mean field approximations). I am quite intrigued by this paper. While the results in practice are still not too convincing, I am strongly in favour of giving this approach the benefit of doubt, as it could lead to practically very useful downstream work. The main direction of improvement for this paper (given that experiments are what they are   somewhat limited to toy situations right now) is to better explain the methodology to researchers not familiar with mean field methods. Most importantly, it is not explained in the main text how hyperparameters are really chosen in the end. Please do at least comment on real world applications, and whether (and how) the ideas here would apply  Discussion: "there is no clear principled way...": Well, but practitioners need something. This creates a disconnect between the very nice (and seemingly useful) theory and its implications (they are not really well spelled out). First, such assumptions are indeed pretty common in such statistical mech analyses of learning methods. Second, you have to distinguish between weights after (random) initialization and after training. If I was the AC for this paper, I d ask somebody with at least some background in statistical mech to provide some additional opinions, as the reviewers (including myself) are not fully qualified. Under their assumption, these critical conditions can be computed depending on the hyperparameters. As a direction for future work, this would be very important. Try making it more crisp.
Reject. rating score: 3. rating score: 3. rating score: 6. rating score: 6. <BRK>This paper proposes a new type of adversarial attack setting for graphs, namely graph rewiring operation, which deletes an edge in the graph and adds a new edge between one node of the first edge and one of its 2 hop neighbors. This new attack is proposed to make the perturbations unnoticeable compared with adding or deleting arbitrary edges. To solve this problem, a reinforcement learning based approach is proposed to learn the attack strategy in the black box manner. The writing is clear. The authors could explain more on the results. The authors should clearly introduce the novelty of the proposed method as well as the contributions.<BRK>This paper proposes the ReWatt method to attack graph classification models by making unnoticeable perturbations on graph. Reinforcement learning was leveraged to find a rewiring operation a   (v1; v2; v3) at each step, which is a set of 3 nodes. In the first step, an existing edge (v1, v2) in the original graph is selected and removed. Pros1.The rewiring operation is more unnoticeable. 2.The proposed ReWatt method is effective in attacking the graph classification algorithm, facilitated by the policy network to pick the edges. Can it be applied to such problems as well? 3.In addition to RL S2V, it will be helpful to compare with Nettack (Z¨ugner et.al, 2018). So it is still not clear whether rewiring leads to less noticeable changes. However, for those predicted incorrectly on the rewiring operation set, the success rate should not be counted.<BRK>In this paper, the authors studied the adversarial attack problem for graph classification problem with graph convolutional networks. Further, the authors propose an RL based learning method to learn the policy of doing rewiring operation. Experiments show that the proposed method can make more successful attack on social network data than baselines and previous methods. The proposed RL based method where the search space is constraint also can solve the problem. However, I have a few concerns on the experiments. 1.In figure 3, the authors also show that the proposed method can make less noticeable changes on eigenvalue. But are these changes still noticeable compared to original one? 2.2% data for testing is too few for me. The authors should increase these number.<BRK>The paper addresses a real problem. This paper argues that if one rewires the graph (instead of adding/deleting nodes/edges) such that the top eigenvalues of the Laplacian matrix are only slightly perturbed then the attacker can go undetected. The paper should address the following issues:1. There is no discussion on tracking the path capacity of the graph as measured by the largest eigenvalue of the adjacency matrix and the eigengaps between the largest in module eigenvalues of the adjacency matrix . Rewiring often affects the path capacity even if one makes sure the degree distribution is the same and restricts the rewiring to 2 hop neighbors. The paper will be stronger if it included how the proposed method performs under various random graph models   e.g., Gnp random graph, preferential attachment, and small world. Miscellaneous notes:  The captions for the figures should be more informative.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>From this perspective I would say this is a classical approach to partially observed reinforcement learning with advanced models for transition matrix and value and policy functions. The work combines together variational recurrent neural network (VRNN) and soft actor critic (SAC) models into a rather advanced system for reinforcement learning. The method achieves improved performance in several (simpler) benchmark problems in comparison to strong baselines. This learning of the state transition model is actually similar to classical model based RL.<BRK>For instance, the authors argue it is better to keep 2 models (the "first impression" and "keep learning" model) and show an ablation study in appendix C.  Now, one could wonder if the proposed method would still perform better than the baselines if with, say, the just using a single VRM. The improvement compared to SAC LSTM is not very large except in a few cases, so possibly just using the VRM would perform no better. Figure 1 is too  complicated for an illustrative figure  and the presentation and clarity needs to be improved. What is the scalability, such as wall clock time and #parameters  of the approach compared to the baselines?<BRK>The paper proposes that for partially observable reinforcement learning tasks it might be simpler to decompose the problem in two parts: a recurrent world model and a feedforward agent, as opposed to using just a recurrent agent. For the world model the paper proposes using a variational recurrent state transition model, which is essentially a VRNN which also conditions on the actions. That said the incompleteness of the experimental results is my only reservation against accepting this paper.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>The authors propose to tackle the problem of neural inductive program synthesis using a combination of REINFORCE, imitation learning, and MCTS. They test their method on a set of input output sequences provided by automatically generated x86 programs, and a small set of manually designed programs. Is there a finite set of IO tasks defined for all the experiments?<BRK>[Summary] This paper addresses the problem of synthesizing programs (x86 assembly code) from input/output (I/O) pairs. Leveraging a learned policy network and value network for improving the efficiency of the MCTS seems effective. *ablation study*Ablation studies are comprehensive. While the proposed hybrid objective is very similar to the one proposed in [2, 3, 4], the revision does not mention this. The authors acknowledged that they did not know about [6] that works on program synthesis for an assembly language. Yet, this paper is still missing from the paper. Or how about search based program synthesis baselines?<BRK>This paper tackles the problem of program synthesis in a subset of x86 machine code from input output examples. First, the paper uses a random code generation policy to generate many programs and executes them with random inputs to obtain I/O and program pairs.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>Instead of sampling the nodes or edges across GCN layers,  this paper proposes to sample the training graph to improve training efficiency and accuracy. It is a good work.<BRK>The paper is well written and the fact that code is published is valuable.<BRK>Overall, this idea is interesting and well presented.
Reject. rating score: 1. rating score: 1. rating score: 6. <BRK>I should note, however, that this technicality is not my main issue with the paper and will not influence my judgement. I still find the motivation obscure and the experiments weak.<BRK>The paper would be more convincing if the authors empirically compare with other sensible baselines and justify why we should use MIM as opposed to A MIM in representation learning. Methods that encourage mutual information maximization under the latent variable generative modeling framework would be more suited for comparison. Unless we sample z | x from the conditional distribution of \mathcal{M}_s as proposed by the authors, it is unclear why we need this symmetry in representation learning; it seems slower to sample from the MIM distribution though (see motivation for A MIM).<BRK>This paper defines a new learning objective of an autoencoder framework for learning joint distributions over observations and latent states, where the objective is the joint entropy of  M_s, an equally weighted mixture of the encoding and decoding distributions.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>It is an interesting idea about how to enforce the Lipsthitz constrain in WGAN by using virtual adversarial training. The connection between virtual adversarial and this paper method   ALR is quite simple and clear. In the experiments, the FID score in the table is not complete which can not clearly compare the ability of the Lipschitz regularization to other regularization methods. This paper did not provide the reason about why this method can not work better than GP method in high dimensional setting. Cons:1.The comparison of the experiments was not complete. Might have some inference about the effect of BN in regularization term.<BRK>Inspired by this, the paper proposes a Lipschitz regularization technique that tries to ensure that the function being regularized doesn’t change a lot in virtual adversarial directions. This method is shown to be effective in training Wasserstein GANs. Motivation and placement in literature: Being able to effectively enforce the Lipschitz constraint on neural networks has wide ranging applications. Writing: The paper is well written and easy to understand. Other, lesser important points of improvement:1. According to which metric is this optimal? Therefore, it is perhaps not too surprising that the LDS term from Miyato et.<BRK>But my major concerns have been addressed by the authors in their response and changes to the paper. I was requested as an emergency reviewer for this paper. Due to a concern over correctness of some empirical results and issues with the presented derivations I have opted to reject this paper. There is older work studying the generalization properties of Lipschitz neural networks which is not mentioned in this section. I do not consider this a huge issue, but it should be discussed in the main paper. I believe that this would be a highly valuable addition to the paper and would help distinguish this method from other training stabilization proposals.
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>The paper reported the experimental results on Omniglot and Market1501. A simple combination of two existing techniques (clustering followed by few shot learning) without any in depth analysis cannot be justified as a reasonable contribution for an ICLR paper. The authors need to present more evidence or practical application scenarios to support the practical value of this problem setting. More challenging datasets such as ImageNet or at least its easier subsets (e.g., miniImageNet, tiredImageNet) should be considered. Unsupervised learning via meta learning. Update after rebuttal:Thanks for the new experiments on miniImageNet! In addition, the new results on miniImageNet is not very encouraging (it is necessary to provide a fair comparison).<BRK>Nevertheless, this does not seem to be an issue, at least with these datasets. One main claim of the paper is that the iterative nature of this process is key to the success of the algorithm. (3.2) The word "concurrently" suggests that the clustering and the training are performed simultaneously. I would have preferred to see a comparison to non episodic training. (1.2) While the algorithm has been demonstrated on real images in the Market1501 dataset, it would have been much more convincing to see it demonstrated on a more widely used dataset for few shot learning such as Mini ImageNet.<BRK>In this paper, the authors have investigated the unsupervised few shot learning problem. They have proposed a method to learn an unsupervised few shot learner via self supervised training (UFLST), which consists of two alternate processes, progressive clustering and episodic training. Overall, I think it is an interesting scenario and have the following comments. (1) The first one the about the method. The authors have tried to describe their methods in a concrete way. I suggest the authors to express as accurately as possible. For example, in the abstract, the authors state that ‘However, current few shot learners are mostly supervised and rely heavily on a large amount of labeled examples.’ I do not agree with this statement since in few shot learning, there are only limited exemplars.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>This paper proposes the Composite Q learning algorithm, which combines the algorithmic ideas of using compositional TD methods to truncate the horizon of the return, as well as shift a return in time. They claim that this approach will improve the method s data efficiency relative to standard Q learning. I do believe the algorithm has promise for the reasons teased apart in our discussion, and encourage the authors to improve their paper with these results. Based on this, I am recommending rejection of the paper. An intuition for why is because the accuracy of the shifted action values depends on the accuracy of the standard TD estimate, and the TD errors can be shown to exactly decompose that of standard TD. 3) The results in the tabular setting seem to contradict what I described in Issue 2, because compositional Q learning as presented did converge quicker than standard Q learning.<BRK>SummaryThis paper introduces a new Q learning formalism that helps reduce the bias of single step bootstrapping in Q learning by learning multiple single step bootstrapping Q functions in parallel. By choosing to fix meta parameters based on the defaults of a competitor, this could be harmfully biasing the proposed algorithm by preventing it from choosing a better stepsize. Edit after discussion and rebuttal phase:I read the in depth discussion between the authors and R3 and looked at the edits to the draft. During the initial review, I found the ideas of the paper interesting enough to largely out weigh the importance of a careful meta parameter study. I still strongly believe there is a place in the literature for this paper, so I hope to see this paper again at the next conference.<BRK>Main Contributions:    An algorithm, Composite Q learning, which decomposes the value function into a short term truncated portion and a long term shifted portion. *Review*  The paper is generally well written (some suggestions for improved readability can be found below), and provides some nice algorithms for the community. Overall, I am recommending this paper for a weak accept as I have some concerns over the experimental results that I would like clarified. S3: It might be interesting to look at the value of the shifted Q function for this domain. This is an important detail to include, even if you believe they are well accepted in the field. I would urge the authors to soften this claim, and instead say you provide evidence of composite q learning s data efficiency as compared to other methods.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>This paper formulates a connection between the Fisher information matrix (FIM) and the spectral radius of the input output Jacobian in neural networks. This results derive the eigenvalues  bound to theoretically study the convergence of several networks. After addressing the following remarks, I can adjust my reviews. 1.There are some typos, such as see[?] in page 7, the main theorem on page 6 should be written mathematically with a remark. 2.What is the major technical difference between this paper and Karakida et al., 2018? 3.Here the model is given by conditional probability is defined by a neural network. The author may also be interested in implicit models, such as normalization flows and generative networks.<BRK>This paper analyzes the connection between the spectrum of the layer to layer or input output Jacobian matrices and the spectrum of the Fisher information matrix / Neural Tangent Kernel. By bounding the maximum eigenvalue of the Fisher in terms of the maximum squared singular value of the input output Jacobian, this paper provides a partial explanation for the successful initialization procedures obeying "dynamical isometry". By additionally investigating optimization on the orthogonal weight manifold, this paper sheds light on the important of maintaining spectral uniformity throughout training. For these reasons I recommend this paper for acceptance. It seems like the main arguments only depend on the maximum eigenvalues. Second, it should be noted that the the networks trained in the experiments are likely in a regime that is well outside the NTK regime, in two important ways: the dataset is large compared to the width and the optimal learning rates may be large as well.<BRK>They suggest projections to the manifold of orthogonal weights during training and provide analysis. Their main result seems to be a bound on the eigen values of the Fisher information matrix for wide networks (Theorem on pg 6). In their experiments they train Stiefel and Oblique networks as examples of manifold constrained networks and claim they converge faster than unconstrained networks. There are claims in the paper for providing explanations by making connections to Neural Tangent Kernel but it is mentioned only in the discussion section and they reiterate previously known results. Fig 3: is the training plot for cifar10 in this figure the one in figure1? The writing has improved a lot and most of my concerns are addressed. It would be nice if authors could incorporate the timing plots in the appendix.
Reject. rating score: 3. rating score: 8. rating score: 8. <BRK>The paper has a very weak relation to causality; one could replace "causal" with "translation invariant", and very little would change. But do() does not amount to much here. It reduces to mere conditioning here, as the do is always applied to a root node without parents. This paper refers but fails to say how similar they are. But some of the translation invariance seems to be due to just using a generative model (the VAE), as it occurs without any fine tuning.<BRK>I would actually expect the model to work still well with q(m|x,y). This is an extremely elegant property, which is also proven in the experiments to be very effective. Being able to learn previously unseen types of manipulations only by proper application of causal inference tools is a very important news for the adversarial robustness community.<BRK>The author further elaborately devises experiment on the standard dataset and achieve good results. Strong point:(1)	The paper is well written and the idea is motivated. Weak point:(1)	Please provide the deducing process of the ELBO, such as how the ELBO is deduced in the training mode and the prediction process should be elaborated detailedly. Do they belong to the domain information?
Reject. rating score: 1. rating score: 1. rating score: 3. <BRK>Update: I thank authors for the rebuttal. I agree that direction of exploring personalization in FL is interesting. The main contribution of this paper is to notice the connection between Federated Averaging (FedAvg) and Model Agnostic Meta Learning algorithms (MAML). Perhaps, it is indeed more interesting and challenging, demanding more advanced methodology.<BRK>The paper claims not only their proposed method can lead to fast convergence time but also provide a solid initial model per device/client and results in a better personalized model. 3) Also, the paper mentioned that this method can work even if there is no local data available on some of the devices/clients. Wouldn t a device/client just use the global model?<BRK>Pros.+ The motivation of the paper is clear and indeed these methods seems similar, and meta learning can help with federated learning. I am not convinced that some more minor modification of Reptile could not already do well on this paper.
Accept (Poster). rating score: 8. rating score: 6. rating score: 3. <BRK>These networks might need to be trained in an HPC environment, but most can be deployed on laptops (not an HPC environment). I have a some criticism of the paper, but before I get lost in the details, let me say that I like the overall paper.<BRK>The coreset seems to require the activation function to be non negative, which will possibly limit the scope of application of the proposed theory.<BRK>The goal of the paper is to reduce the number of neurons. If it was not incorrect labeling in the figure, it would be good to add some analyses about this result.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>This paper proposes the multigrid memory networks which combine multigrid convolutional layers with LSTMs and evaluates its performance on a reinforcement learning based navigation task and two algorithmic tasks of priority sorting and associative recall. Moreover, in all the experiments, the DNC baseline has memory sizes that are much smaller than the multigrid memory networks.<BRK>The method extends the convolutional LSTM with bigger memory capacity in forms of multigrid CNNs. * The experiments are not very satisfactory for the “generality” claim that the paper makes.<BRK>Overall, this architecture, while not groundbreaking, is novel in this context and the results show empirical gains. The paper is fairly well written. This work proposes an architecture inspired by an approach used in the computer vision literature, a multi scale CNN.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>This paper introduces a bio inspired locally sensitive hashing method called BioHash, inspired by FlyHash. Questions:  Novelty of the algorithm?<BRK>This paper studies a new model of locally sensitive hashing (LSH) that is inspired by the fruit fly Drosophila s olfactory circuit. With improved discussion of prior work, the paper places its contributions in the right context. Moreover, the empirical results in the paper demonstrate the utility of the proposed method on (small scale) real world data. Overall, I think that this paper makes interesting and novel contributions.<BRK>This paper introduces a variant of FlyHash for similarity search in vector space. This leads to the bio inspired hashing algorithm (BioHash). Second, the evaluation is mostly done on toy datasets in terms of scale. Another minor issue of this paper is that the citation format does not seem to comply with ICLR format.
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>This paper considers the problem of changing environments for LQR. The authors model this through the use of a decoder that maps an incoming context (C,D) to the LQR matrices (A,B). 1.The results of this paper were not contrasted with other papers in this area. For example, if C,D are constant, and \Theta_* is a Block diagonal matrix with A,B on the diagonal   then the contextual case reduces to the standard LQR problem. It s unclear how the results given compare to past results in this setting, for example those of Abbasi Yadkori/Szepesvari 2011. 2.I did not fully understand the UCB nature of the algorithm. 3.Building on (1), it is hard to understand the results as given since there are no lower bounds given nor is there a discussion of the problem dependent parameters that arise. 3.I struggled to understand the setup of the experiments   as described the algorithm given was not used at all, rather \Theta^(k) was approximated and beta^k was set to be a constant.<BRK>The problem itself is introduced in this paper and is similar in spirit to CMDPs, with the difference that instead of learning a mapping from context to transition matrix, a mapping from context to matrices [A, B] figuring in the system dynamics of LQR is learned. A toy experiment with a 2D moving mass is presented to illustrate the theory. # DecisionAlthough the problem setting is interesting and it is encouraging to have a guarantee, several important unclear points in the paper and a missing comparison to a straightforward baseline stop me from recommending it for publication in its present form. I can see a straightforward algorithm that can learn the linear mapping \theta from context to [A, B] as follows. >  A comparison to such a basic approach should be definitely included in the paper, in my opinion. In more detail,          Eq.(9) is not solved exactly but by random sampling. More importantly, the UCB bound \beta in Eq.(11) is not used at all in the experiments. If it is not used, how should one judge the resulting algorithm? 3) This is a concern regarding clarity. As R4 pointed out, some clarifications on the side of the algorithm are also required.<BRK>Leveraging the theoretical analysis of LQR, the authors extended the analysis to the setting of output feedback with particular structures of decoder matrices (C,D) sampled from decoder \mu. The algorithm proposed is quite standard in the output feedback LQR literature (in control or RL). But the work is still interesting because to my knowledge I am not aware of general theoretical analysis of this setting (while most analysis is based on the full state feedback). I haven t checked the proofs very carefully in the appendix, but from the description in the main paper it seems the analysis of contextual transfer learning performance is sound, and under certain regularity assumptions the authors did provide a high probability regret bound for this contextual transfer learning problem. I also have some difficulties understanding all the dots in figure 2. Another comment is about the current title, currently by looking at it I have no idea that is about contextual transfer learning and LQR.
Reject. rating score: 1. rating score: 1. rating score: 3. <BRK>The paper attempts to tackle unseen object attribute recognition in still images. A collection of losses (some regularisation and some distance in embedding space) are proposed. For the images belonging to the same pair, we use the recognitions for all images to vote a pair label to be the final attribute object pair recognition." In my interpretation, the authors are taking all test images that are labeled using the same pair (e.g.sliced apple    assuming this is an unseen pair). If my interpretation is correct, this is A MAJOR FLAW in the approach.<BRK>This paper tries to handle the unseen attribute object pairs recognition, which asks a model to simultaneously recognize the attribute type and the object type of a given image while this attribute object pair is not included in the training set. Even for the two picked dataset, the improvement is not consistent, this is not enough to show the effectiveness of attractor network. The authors could design some visualization/metrics to show what the attractor networks have learned, i.e., the visualization of the nodes.<BRK>This paper studies the so called “unseen attribute object pair recognition”,which asks a model to simultaneously recognize the attribute type and theobject type of a given image. 4) The experiments are pretty weak: Only on two small datasets. 2) the whole framework is a two pathway encoder decoder networks. In general, there is lack of discussion why the attractor networks are novel, and significant.
Accept (Poster). rating score: 6. rating score: 6. rating score: 3. <BRK>This paper provides extensive experiments that demonstrate the effectiveness of the proposed method. The performance gap compared to the existing distillation approaches seem to be significant. So I think the compatibility between the proposed and exisiting methods should be checked. However, in this paper, only Table 4 shows the compatibility with KD (CRD+KD). I think detailed verfication should be provided in the paper.<BRK>This paper combines a contrastive objective measuring the mutual information between the representations learned by a teacher and a student networks for model distillation. When combined with the popular KL divergence between the predictions of the two networks, the proposed model shows consistently improvement over existing alternatives on three distillation tasks. This is a solid work – it is based on sound principles and provides both rigorous theoretical analysis and extensive empirical evidence. I only have two minor suggestions.<BRK>Comparing with original distillation method (KD) I m not sure how significant the improvement is. Sure it is a more involved distance metric, however it is in the spirit of what the distillation work is all about and I do not see this as being fundamentally different, or at least not different enough for an ICLR paper. The experimental results also suggest only a marginal improvement compared to other methods. It would be helpful to also include the variance of each experiment i.e., it was mentioned that the results were averaged by repeating 5 experiments to make sure the proposed method consistently better than others.
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>The paper proposes models for link prediction task in a generalized knowledge graph setting that can contain n aryrelationships. Experimental results show the proposed models, outperform the baselines by good margin (with some exceptions). This is a very obvious generalization from binary to n array relations, but the work is very incremental and does not provide any good motivations. It is well known that hypergraphs can be approximated with graphs using clique and star expansions but I do not see any discussion regarding this.<BRK>This paper extends SimplE, a previous embedding model, from modeling binary knowledge graphs to knowledge hypergraphs, where n ary relations may show up. 3.Empirical results comparing with existing methods are proposed. The major contribution of this paper is to propose two new architectures for hypergraph embedding. 1.The paper proposes to use 1d convolutions to separate entity positions and entity embeddings (HypE) and claim this strategy is better than just rotating the entity embeddings (HsimplE) because one can introduce additional parameters through the convolution filters. So probably HypE is not the most efficient way to use parameters. 2.The second thing that I feel confused about is the fair comparison with other methods to handle hypergraphs. For example, t SimplE performs badly on all metrics, including Hit@t and MRR in Table 1. However, in Table 3 it does much better than the rest methods for binary relations (0.478 vs others). For example, by converting non binary relations into cliques? I think the paper makes some contribution to the existing literature, but it should at least clarify its contribution with more evidence and better comparison criterions.<BRK>This paper proposes two new embedding strategies for the task of knowledge graph completion, with special attention on generalizations that support hypergraphs. The first method, HSimplE, learns an embedding for entities that directly contains multiple positional representations; these are shifted depending on the relation they re used in. The second method, HypE, disentangles entity embeddings and positional convolutional filters, allowing stronger positional generalization. Experiments on standard benchmarks demonstrate that the approaches work well. I think this paper should be accepted. I think this is work that needs to be done, so I favor accepting it. * The paper is well written and well situated in the literature.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>This paper shows empirically that rotational invariance and l infinity robustness are orthogonal to each other in the training procedure. However, the reviewer has the following concerns,It is already shown in (Engstrom et al., 2017) that models hardened against l infinity bounded perturbations are still vulnerable to even small, perceptually minor departures from this family, such as small rotations and translations. The experiments are only on MNIST and CIFAR 10. Training on a larger dataset  like imagenet would make the experiments more convincing.<BRK>This paper examines the interplay between the related ideas of invariance and robustness in deep neural network models. Invariance is the notion that small perturbations to an input image (such as rotations or translations) should not change the classification of that image. Robustness is usually taken to be the idea that small perturbations to input images (e.g.noise, whether white or adversarial) should not significantly affect the model s performance. In the context of this paper, robustness is mostly considered in terms of adversarial perturbations that are imperceptible to humans and created to intentionally disrupt a model s accuracy. The results of this investigation suggests that these ideas are mostly unrelated: equivariant models (with architectures designed to encourage the learning of invariances) that are trained with data augmentation whereby input images are given random rotations do not seem to offer any additional adversarial robustness, and similarly using adversarial training to combat adversarial noise does not seem to confer any additional help for learning rotational invariance. (In some cases, these types of training on the one hand seem to make invariance to the other type of perturbations even worse.)<BRK>This paper analyzes the behaviour of DNN trained with rotated images and adversarial examples. The paper has several technical issues that need to be resolved before drawing any conclusions:1) “invariance”: this term is not used in the correct way. What this paper is evaluation is robustness to rotation vs robustness to adversarial perturbations. 2) It is unclear that Figure 3 is saying that adversarial training does not affect the rotation invariance because there is a general drop of accuracy. So, for all tested cases in the paper, there could be a perturbation that damaged the model much more than the ones found, which could change the conclusions of the analysis. There could be a network dependency.
Reject. rating score: 3. rating score: 3. rating score: 6. rating score: 6. rating score: 8. <BRK>This is an interesting paper that proposes the use of few shot regression to predict complicated experimental measurements such as protein ligand binding affinity from very small, noisy real world datasets. Moreover, there is a large body of work in the drug discovery literature that uses sparse experimental data on the interactions of multiple target proteins and multiple ligands to build models that predict the outcome of biological assays for held out protein targets, where this problem is known as drug target interaction prediction, but these papers are not referenced in this work (e.g.reviewed in Chen et al.Molecules 23(9):1 15, 2018, Ezzat et al.2017, 2018, 2019). In addition, it is hard to understand the results of the experiments that the authors carry out in this paper using data from BindingDB and PubChem. I don t understand the scaling that is applied to the MSE metric for the binding or antibacterial datasets. It would be useful for the authors to visualize performance for the Binding and Antibacterial tasks   for example how different are the different protein targets?<BRK>To tackle data scarcity issue in biological assay modeling, this paper proposes a method to episodically train Deep Kernel Learning models such that at meta test time the models requires less examples. Section 5 lacks details. How each meta train episode is formed? Presentation Issues:  Section 2 (line 76) "We extended it (Deep Kernel Learning) to few shot learning and discuss its advantages over the metric learning framework" This sounds like the author developed a brand new framework, while the rest of paper is about proposing a specific realization of few shot learning: Few shot Deep Kernel Learning, which meta learn through a differentialble kernel learning process (with the task kernel adaptation network novelty). If Bertinetto et al.categorize their method as part of a deep network then I think so should this work. What is the other benchmarks the authors are comparing with? Are they generic benchmarks for all types few shot regression tasks/applications beyond biological assays (e.g.computer vision tasks like: object detection).<BRK>The authors of this work are attempting to solve the problem of few shot regression for drug discovery problems. In particular, the authors propose a new method, adaptive deep kernel learning to help improve task specific learning. ADKL is claimed to improve over FSDKL since it helps learn a task specific kernel function. The authors also incorporate some unlabeled data during training to improve on representation learning. In the experimental section, the authors compare ADKL against a number of past low data learning methods. The experiments having to do with active learning in section 6.2 are interesting. I m also not sure that this paper is a clear fit for ICLR.<BRK>This paper presents a new framework for solving few shot regression problems. The authors introduced adaptive deep kernel learning, which learns kernel for multiple task collection and computes the correct kernel for a task in a data driven manner. The method is evaluated on three tasks collections — Sinusoids (synthetic dataset), Binding (real dataset of 5717 task where each task represents a binding affinity of small molecules against a given protein) and Antibacterial (real dataset of 3255 tasks where each task represents antimicrobial activity against given bacterium). 2.The experimental results in Tables 1 3 show only marginal improvement for real datasets. Also, it’s not clear if the numbers in the Tables 1 3 are on the original scale or on the transformed scale. To estimate how well the models perform it’s useful to transform the targets back to the original scale. 3.Overall the paper is written in a somehow confusing manner and some details in the description of the experiments important for understanding are omitted.<BRK>The main contributions are:    A few shot learning algorithm combining several ideas and features:      Combining metric learning (shared across tasks) and kernel regression within each task      Learning a task representation by maximizing an estimate of the mutual information between the train (support) and valid (query) sets of a task      The addition of learned, synthetic "pseudo examples"    Two datasets for few shot regression, from real life biological assaysThe proposed algorithm outperforms (or is competitive with) mainstream few shot learning methods on a synthetic 1D regression dataset, as well as the two proposed datasets. OverviewThe overall problem is clearly stated, as well as its main challenges: noisiness of the data, different behaviors of the same input across tasks. Is that only because there is a closed form solution for the optimal regressor? What does "correlations > 0.8" mean exactly? (l. 258, 263)    In the "Binding" dataset, is it possible that the same protein is used in different bio assays? I m not sure how to improve it though, maybe letters instead of numbers?
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>In this paper the authors adopt prior work in image inpainting to the problem of 2d fluid velocity field inpainting by extending the network architecture and using additional loss functions. * It is not clear that that the effect of the additional L1 losses is truly cumulative. I am specifically not convinced about the practical applicability of the results. The novelty of the approach also seems quite limited, and the findings do not seem particularly surprising or insightful (i.e.that extending the vanilla U net architecture and adding losses that directly bias the network towards physically meaningful solutions is better than the baseline). Since all training and testing data was generated from simulation, it is unclear how well the networks would cope with real world measurement noise. It is surprising that this could be a problem to a level where it could impact evaluations. Questions & suggestions for improvements:* Has the impact of different weight combinations in A.2. been investigated? * What are the Reynolds numbers used in the simulations?<BRK>Most notably, the loss functions are motivated by fluid dynamics, which forces the network to remain more consistent with the governing laws. Decision:I found the paper and the idea very exciting. 8?Isn t approach (b) the approach which is most  physics aware  and correct from a physics point of view? Once trained, can it work on grids smaller/larger than 128x96? If not, what do you recommend to do in practice? The description of the experimental protocol does not specify whether the method was evaluated on independent test data. While quite exciting, I am not confident the contribution is original enough from an ML point of view for ICLR, although it is certainly novel for fluid dynamics. It would have made the experiments much stronger if uncertainties were also reported and discussed. This would have been quite helpful to better tell them apart. Given my comments above, I am confident an 8th page could be put to good use.<BRK>I am not an expert in recent Navier Stokes approaches, but note that there is a lot of recent work in physics aware modeling. With respects to the DL part it looks like it’s mainly minor modifications to the known U net architecture. The authors argue that “the synthetic velocity field data has discretisation errors and it is not truly divergence free. Therefore, the approach with a single stream function branch cannot capture the divergent modes present on the original data”. * I guess the inpainting works decently well, as is expected from previous image inpainting literature and the problem is essentially treated as image completion. Again, this ties back to my previous component about lack of clarity of the improvement of the introduced individual terms. Also their paper ends before the 8 page limit. I think the authors could have used the remaining space more efficiently. I generally like the idea of including physical consistency when training to train a neural network for a respective task where this matters.
Reject. rating score: 3. rating score: 3. rating score: 8. <BRK>This paper investigates an SGD variant (PowerSGD) where the stochastic gradient is raised to a power of $\gamma \in [0,1]$. The authors introduce PowerSGD and PowerSGD with momentum (PowerSGDM). I consider this assumption unrealistic.<BRK>Overall, this is a clearly written paper with comprehensive experiments. The proposed method PowerSGD is an extension of the method in Yuan et al.(extended to handle stochastic gradient and momentum).<BRK>The rates in the theoretical analysis are competitive with those for standard SGD, and the empirical results argue that PowerSGD algorithms are competitive with widely used adaptive methods such as Adam and RMSProp, suggesting that PowerSGD may be a useful addition to the armory of adaptive SGD algorithms. Overall I recommend acceptance of this paper, although I think there may be a couple of places where the authors overclaim a bit on the theoretical side.
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>The authors spend quite a of space on ablation studies to investigate the contribution of different factors, and on cross domain transfers. It would be better if they could show it for other tasks on the benchmark as well. Overall I think this work is somewhat incremental, and falls below the acceptance threshold.<BRK>Furthermore, the mixed results shown in Table 3 do not justify the proposed method well enough. Although the authors provide extensive empirical studies, I do not think they can justify the claims in this paper. I do not agree that the proposed method is less elaborate than previous methods.<BRK>This is not experimentally explained, but I suspect there are optimization benefits that are hard to pin down exactly. Including this in the results would be even better. However, I do argue for its acceptance, because it does a thorough job and presents many interesting findings that can benefit the community. Comparison with prior work:The submission focuses on comparison with Sun et al.and Sanh.These comparisons are important, but not the most compelling part of the paper.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>Experiments are done on a single dataset for a single task, which seems insufficient to support the generality of the approach and claims in the submission. Learning to adapt and optimize receptive fields successfully would be a great fundamental improvement to CNN architectures. It seems that early layers would make sense too, as it is where most of the downsampling happens.<BRK>In this paper, the authors proposed a semi structured composition of free form filters and structured Gaussian filters to learn the deep representations. The idea is interesting and somewhat reasonable but I still have several concerns. However, I still have several concerns:1. The authors proposed to compose the free form filters and structured filters with a two step convolution.<BRK>This paper proposes semi structured neural filter composed of structured Gaussian filters and the usual structure agnostic free form filters found in neural networks. They are optimized using end to end training. Large improvement in seen on naive / sub optimal architectures for segmentation. ?2.Table 4 shows that the networks with reduced depth when integrated with composed filters can perform as well as large networks. How the results prunes out when included at the lower as well as at the intermediate layers ? Please include a plot of accuracy vs depth (at which it is included).
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>This allows understanding of both efficacy of multiplicative interaction (i.e., MI vs MLP), and the common between multiplicative type models (e.g., hypernetworks, FiLM, gating,  attention etc). Weaknesses:* I suggest a better explanation how the suggested models compare to state of the art models. For instance, proposed model alternate existing baselines, such as PopArt, or is completely novel? * Although mentioned, it s not the focus of this work, the paper should have discussed attention models more. To conclude, multiplicative interactions are extremely important, and I find the paper exploration useful.<BRK>Multiplicative interactions can be viewed as an effective way of integrating contextual information in a network. Through a series of thorough empirical experiments, this paper demonstrates superior performance on a variety of tasks (RL, sequence modeling) when a such multiplicative interaction module is incorporated. And the paper hypothesizes that multiplicative interactions can help introduce desirable inductive biases, therefore leading to improved generalization performance. However, the theoretical intuition and justification for such hypothesis is missing, which weakens the contribution of the paper.<BRK>This paper takes a component of neural networks that is sometimes, but not always used — multiplicative interactions — and goes into depth in analyzing and discussing the different ways in which computed features may interact multiplicatively. The analysis and math are clear, and the main points are made with neither too many nor too few equations. Decision: weak accept. Pros:   I can imagine any researcher getting into the field and interested in this sort of thing reading this paper as a canonical, concise, and moderately thorough intro to the concept. Finally, LSTMs already have multiplicative interactions in them (via gating, as mentioned in the paper). Would the proposed form of multiplicative interaction obviate the need for LSTM gating all together?
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>3.The paper is clearly not written well with many typos.<BRK>The paper is very well written and easy to follow.<BRK>This paper analyzes the performance of sign gradient descent as a function of the “geometry” of the objective. It is already known that the choice of a norm can have a significant impact on the speed of steepest descent but practically, the performance depends on quantities that are unknown such as the norm of the gradient over the specific trajectory of the algorithm.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>It provides results on image classification and detection using popular network architectures. Based on these results, the paper claims an accuracy drop of 10 to 16%. In itself, it is valuable work, but it is not clear if the contribution is important enough for ICLR. I do not specifically have issues with "more stringent robustness metric" but it should not be used to claim incredible results (like an accuracy drop of 10 to 16% instead of 3% for previous work (Real et al.2017)).There is one thing for sure: using "accuracy drop" in this context is just misleading. Same thing in Table 2, which even provides a "delta" between two unrelated metrics. Keeping that in mind, these are the actual conclusions we can make from the paper:1) Human reviewers removed or changed about 20% of the frames2) This resulted in a relative accuracy improvement of about 4% for the reference frame (Table 4, column Original). The improvement for the perturbed frames are not actually provided.<BRK>This paper targets on the evaluation of model robustness on similar video frames. The authors build two carefully labeled video datasets, and extensive experiments are conducted to show that the state of the art classification and detection models are not robust enough when dealing with very similar video frames. The results are similar to my intuitive feelings. Overall, the contribution is limited.<BRK>Overall I think the paper adds an interesting contribution, with the datasets themselves which can be used for image similarity tasks for exampleAlthough the contribution of the paper is important, it seems limited for the conference with no novel method proposed. Three detection models are also evaluated and show that not only classification models are sensitive to these perturbations, but that it also yields to localization errors. The authors present two novel datasets grouped in sets of perceptibly similar images and answer to the following hypothesis: Can the perturbations occurring naturally in videos be a realistic robustness challenge?
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>** Post Rebuttal ResponseI d like to thank the authors for clarifying some points in their response. They optimize the parameters with respect to an entropy minimization objective. As such, I maintain my original rating.<BRK>This paper focused on the problem of semantic segmentation. I would like to see the relative improvements introduced by the proposed method over a stronger baseline. The proposed method is evaluated on the PASCAL VOC dataset with the DLA segmentation backbone.<BRK>The authors propose a method to dynamically adapt some structural features of a semantic image segmentation model at inference time based on the entropy of the predictions. Wouldn’t simply multiplying \theta_{score} by a large number decrease the entropy of the predictions?
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>Apart from a few issues (mentioned below), the paper is well written. The authors have provided a detailed overview of their data collection/verification pipeline and related model/experiments. This paper is about a dataset (TABFACT) aimed at promoting research for fact verification using semi structured data as evidence. To tackle this, the authors suggest two approaches as baselines on the dataset   one uses off the shelf BERT model for NLI; the other one focuses on symbolic reasoning and is based on program execution   which primarily uses lexical matching and a set of predefined operations (like count/max/min) to construct a program.<BRK>This paper proposes a new dataset for table based fact verification and introduces a couple of methods for the task. However I have some concerns on its construction. writing: "the model is expected to excel... but to fall short", "we follow the human subject research protocols" (which ones?), "in case of obvious stylistic patterns" (which ones). The two models discussed are OK as baselines, but not particularly interesting or appropriate.<BRK>Specifically, the authors created a new dataset TabFact and evaluated two baseline models with different variations. Both showed reasonable accuracy (~68%), but still below human performance (92.1%) on a held out test set. I would like to see the paper accepted because:(1) it proposes an interesting task (table fact verification) with a clean dataset, and the experiments evaluated the ability of the current neural network models, such as BERT, or hybrid models, such as the LPA baseline, to perform (symbolic) reasoning;(2) special care is done to ensure the dataset doesn t contain simple cues or patterns, which is a common pitfall in dataset collection, and the dataset is also validated through two reasonable baseline models. This helps point out where the difficulty come from, for example, whether the difficulty is language understanding or symbolic reasoning.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>* Summarize what the paper claims to do/contribute. This paper claims to extend existing image translation works, like CycleGAN, to domain pairs that are not similar in shape. It is proposed to do so by using a VGG network trained on classification (I assume on Imagenet), extracting features from the two domains and learn 5 CycleGANs to translate for each level of the feature hierarchy. At each level of the hierarchy the translation from the previous level is used to condition the translation for the current level. Major reasons:  The problem itself, as stated in the introduction, seems ill posed to me.<BRK>The paper proposes a new method for image to image translation. The authors address this by performing the translation in a cascaded fashion starting from a semantic (deep) level (fifth layer of VGG). The results of the proposed method are superior. The proposed method is simple. 1.I like the idea of applying the cycle consistency to the deeper layers rather than at the pixel level. 3.Would it be possible to not use pretrained feature from VGG 19 ? In general, I think the paper clearly explains what it does, and it also shows cases that it performs better than state of the art. The paper could be much improved in its analysis of the reasons for its better performance, analyzing key aspects of its design like cycle GAN on features, pretrained VGG features and the use of cascaded generation of the final image.<BRK>This paper proposes a new cascaded image to image translation method to address the I2I tasks where the domains have exhibit significantly different shapes. The proposed method train cycle GAN on different levels of feature extracted by pre trained VGG and combine the futures with the AdaIN layer to keep the correct shape from the deep features. 2.The idea of cascaded translators sounds simple and reasonable which can probably benefit other related tasks. The domain specific knowledge may help to improve the results and alleviate the limitations presented in the paper, e.g.background of the object is not preserved, missing small instances or parts of the object due to invertible VGG 19.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>########Updated Review ###########I would like to thank the author(s) for their reply, which I have carefully read and it partly addresses my original concerns. Still, as agreed by all three reviewers, this paper might not be a significant step up compared with [1]. ###############################This paper tries to address the problem of non parametric maximal likelihood estimation via matching the score function wrt data. Additionally, the proposed model does not outperform that from [1] (see Table 1). Section 2.2 is particularly problematic. [1] Y Song, S Ermon. NeurIPS 2019.<BRK>This paper presents a method of learning of energy based models using denoising score matching. I don’t feel like there is a lot of difference between the proposed model and (Song & Ermon, 19) when it comes to supplying noise information. + I think Section 2 does a good job at illustrating challenges in training energy based models using denoising score matching with a single noise scale.<BRK>The main contribution of the paper is to show that denoising score matching can be trained on a range of noise scales concurrently using a small modification to the loss. Overall I think the paper is well motivated and written, experiments are sound with encouraging results that will be useful for further progress in training energy based models. [Song & Ermon].
Reject. rating score: 3. rating score: 3. rating score: 8. <BRK>The manuscript proposes an evaluation methodology to obtain deeper insights regarding the strength and weaknesses of different methods on different datasets. As such, in my opinion, the "interpretable" tag associate to the proposed method is somewhat out of place. Having said that, I would recommend removing the "interpretable" tag and stress the contribution of this manuscript as an evaluation protocol. The goal of this manuscript is to propose a general evaluation protocol for NLP tasks. However, it seems to be somewhat tailored to the NER task.<BRK>The goal is to give a better understanding of the strengths and weaknesses of an algorithm on a specific dataset according to the attributes, as shown on Fig4. 3 TaskSection is too small to be a level 1 title4 Attributesfigure 2 : where are the links to levels ? Is it more interesting than a learning curve ? The paper is 17 pages long with the annex : it would better fit a journal publication or the author should select some of the main results to present them in a conference paper.<BRK>The authors have constructed a series of experiments to make their case. The paper is well written and easy to understand, albeit some of the related work seems a little unrelated to the task at hand. Furthermore, there is only one problem setting considered (i.e.NER), and for the paper is make claim to more general settings, I would expect evaluations on atleast one more problem setting. I would suggest the authors modify the claims accordingly. This is not to diminish from their contributions in the NER. While some of the claims made (e.g.regarding dataset biases) probably require further and deeper analysis, this is a good first step that should foster further research and discussion.
Accept (Poster). rating score: 6. rating score: 6. rating score: 3. <BRK>This is an interesting paper about use of Finite State Transducers to model semantic and tactic history in dialogues. Why not compare w.r.t.HMMs as you mention it as a choice in the intro? I have some basic questions. Why is human evaluation performed only w.r.t.HED and its variant but not Sequicity?<BRK>This paper proposed a framework for non collaborative dialog systems. To track the history better, the authors propose to apply two pre trained finite state transducers (FSTs) to take the sequence of dialog acts or strategies as inputs and output sequences of state embeddings for the hierarchical encoder decoder (HED) part as inputs. The authors test their model on two tasks, a bargain task and a persuasion task. So I think this is a good work. This shows the success of the FST framework.<BRK>This work presents two FST models to explicitly incorporate semantic and strategic/tactic information into dialog systems. Experiments on two datasets from prior work show the advantage of this model.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>This paper studies the learning of over parameterized neural networks in the student teacher setting. I would like to see clearer properties of the critical points learned by student network rather than some intermediate results. The title is not consistent with the content of the paper. From the title of this paper looks like a characterization on the student network trained by SGD. I believe the authors should provide a more detailed explanation. The observations regarding the alignment between teacher and student networks are indeed interesting. Therefore I would like to keep my score.<BRK>Since ReLU networks are somewhat linear, it would be interesting to compare the results on the dynamics to plain linear networks, as in Saxe et al (e.g.https://arxiv.org/abs/1710.03667 ). The result on the overlap and the "specialisation" of the teacher to the student presented in the paper is rigorous (though I did not completely checked the proof), and seems general enough, but it seems a bit trivial: of course if I have no or little error on all my data points, I have overlap with the teacher, and since I m over parameterised and it s a ReLU network, then the alignment will be many to one. What do they look like?<BRK>The paper studies the role of over parametrization in the student teacher multilayer ReLU networks. Cambridge University Press, 2001, there is a very detailed account of many results on the setting from 80s and 90s. But presenting only one side of the results is not helping. In related works:** Paragraph on "Teacher student/realizable setting": The recent line of works is interesting, but the authors should be clearer about this being a very classical setting dating back several decades.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>In general, the paper is well organized but it is not easy to follow. In summary, the proposed method is interesting and results seem to be encouraging, however, there are parts of the proposed method that are not clear to me.<BRK>The new version of the paper is clearer and the new baseline experiments are a good addition.<BRK>What are the most important hyper parameters for this model, and how to tune? Extensive experimental results demonstrate the superiority of the proposed model over baselines. My main concern on the paper is its generalization.
Reject. rating score: 3. rating score: 3. rating score: 8. <BRK>The paper describes a deep multiple instance learning method. The authors experimentally show the performance of their proposedmethod on several datasets and compare against other state of the artmethods.<BRK>Hence, I don t see much novelty here except that there is a Gaussian normalization layer after the instance weighting in the MIL framework. However, I see significant issues in terms of evaluation which makes hard to accept this paper.<BRK>The paper proposes a new approach to weighting in multiple instance learning scenario. I still believe that the paper is interesting and important for the MIL community.
Reject. rating score: 3. rating score: 6. rating score: 8. <BRK>This paper proposes a new way of finding the Granger temporal causal network based on attention mechanism on the predictions obtained by individual time series. There is a major theoretical and conceptual issue in this paper: the proposed attention vector depends on all of the time series. "Attention is not explanation". The authors should expand the motivation for the prototypical design. Also, this model is super complex. A key reason for popularity of the Granger causality is the simplicity of the underlying VAR model.<BRK>The paper proposes a novel way of reconstructing Granger causal structures using a differentiable neural network architecture that contains attention modules that are proportional to the Granger causality of the input layers. A possible downside is the relative lack of novelty, since the method seems like a reasonable extension of the existing work. However, I think this counterbalanced by the excellent results on the causal discovery task and the extensive nature of the experiments.<BRK>This paper investigates the important problem of inferring Granger casual structures from multi variate time series data, and propose the Granger casual structure reconstruction (GASER) framework with prototypical Granger causal attention. The proposed attention mechanism is also  intuitive. Have enough strong baseline algorithms been included? (1) It seems that GASER outperforms state of the art prediction algorithm IMV LSTM by a large margin (Table 5) even if it is not designed for the prediction task. (1) Is there any trade off in the design? However, adding prototype learning increases the number of parameters to be learnt, i.e., $[p_1, … p_K]$.
Accept (Poster). rating score: 8. rating score: 6. <BRK>The paper aims to characterize for different activation functions the minimum eigenvalue of a certain gram matrix that is crucial to the convergence rate for training over parameterized neural networks in the lazy regime (small learning rate). The authors experimentally validate the observations on synthetic data. The paper does a thorough theoretical study of the behavior of the eigenvalues of the matrix corresponding to NTK which is crucial to the NTK analysis.<BRK>Summary: The authors of the paper examine how different activation functions affect training of overparametrized neural networks. The main point of their analysis is that they examine a matrix called the G matrix which is described in equation (2), and this (positive semi definite) G matrix can determine the rate of convergence to zero of the training error.
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>The paper proposes adaptive gradient approaches where the step size is not determined on the per coordinate basis but rather for blocks of coordinates. The empirical results are not substantially superior. The claimed superiority of block wise adaptivity in the theory relies heavily on an assumption relying on tightness and closeness of  upper bounds on gradient magnitude /  gradient second moment in each block.<BRK>theoretical and experimental results are given. However, I did not find this paper very compelling. Postscript:I still feel that the theoretical analysis provides little to no evidence of in practice value of the method. What about the exploration goal of local search or mcmc? In the absence of meaningful theory, the empirical results are what matter.<BRK>In this paper, the authors propose a generalization of AdaGrad, called BAG, that operates on blocks of parameters instead of each individual parameter. The authors also propose a momentum version of BAG called BAGM. Some of the other authors have expressed a number of concerns about this paper s theoretical and empirical contributions, and I am not raising my score. a) While Proposition 1 is interesting, is it relevant for the BAG algorithm since it considers a layer wise training process.
Accept (Poster). rating score: 6. rating score: 6. rating score: 3. <BRK>This paper introduces few shot learning for graph classification. The authors propose a pre training >fine tuning approach to handle graph classes unseen at training time (and in only a few shots at test time). They demonstrate that the proposed method makes significant improvements over baselines.<BRK>Experiments on two datasets demonstrate that the proposed model outperforms a number of baseline methods. It is interesting for the authors to introduce few shot graph classification problem which is meaningful. To me, the novelty is incremental.<BRK>This paper proposed a few shot graph classification algorithm based on graph neural networks. I vote for rejecting this submission for the following concerns. The learning process constitutes of the following steps.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>Summary: This paper proposes an approach to identifying important waypoint states in RL domains in an unsupervised fashion, and then for using these states within a hierarchical RL approach. I looked at the provided code hoping it would help to clarify some of the implementation details, but the code is not at all a complete collection of routines that could re create the experiments. I d be curious if the authors are able to clarify any of these points during their rebuttal.<BRK>The paper proposes an interesting method to construct a world graph of helpful exploration nodes to provide “structured exploration”. This graph is used in an HRL structure based on the feudal net structure. It is also important to include more analysis of the amount of data needed to train the VAE and create the graph. Similar for adding edges. These act as waypoints in planning. Could this method not be used to also construct a more sparse waypoint graph to use such as what is described in this work? This paper should be discussed in more detail in the related work.<BRK>One concept I really like in the paper is using the reconstruction error as the reward for the RL agent, which has some flavors of adversarial representation learning. Further, I also really like the idea of doing structured exploration in the world graph and I believe doing so can help efficiently solve difficult tasks. My main concerns are the following:    1. 2.The proposed method for learning the graph does not have to be a VAE at all. This assumption is quite strong. It seems to me some pruning criteria were used unless the model converged within small number of iterations?
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>While three head network is presented by a prior work [1] and is learned via supervised learning on a fixed dataset, this paper mainly applies it to AlphaZero training for the game of Hex 9x9 and shows preliminary results. However, the additional change makes the story a bit more convoluted. This bring about a question: is the performance difference due to unfavorable hyper parameters on 2HNN (or other factors)? In my opinion, the paper can be better rewritten as a paper that shows strong performance in Hex, compared to previous works, plus many ablation analysis. Minor: The term “iteration” seems to be defined twice with different meanings. I believe each dot in Fig.2 is “iteration” in the AlphaGo Zero sense. Finally, although many hardware information is revealed in the appendix, maybe it would be better if the authors could reveal more details about their AlphaZero style training, e.g., how long does it take for each move and for each self play game?<BRK>The paper applies three head neural network (3HNN) architecture in AlphaZero learning paradigm. 4.Nothing is said about the architecture of NNs. The approach is demonstrated on the game of Hex. Results are presented on two test datasets: positions drawn from a strong agent’s games and random positions. They could be united in one figure. I tend to reject the paper, because the demonstrated results suggest that the models were not tuned well enough. Indeed, the paper claims that the parameters were not tuned. 8.Please provide error bounds in table 2. However, the best model in the experiment is the one with the parameter equals zero. Probably, this condition could potentially be an additional loss term. 2.Also, it would be interesting to see how the condition between p and q holds. •	Figure 3, right. 2.Supmat reveals, that some of the models are in fact learned using the different loss than it is said in the paper. The influence of this term is itself interesting, as it is one of the reasons 3HNN is learning q function at all.<BRK>This paper applies the three head neural network architecture as well as the corresponding training loss proposed in (Gao et al., 2018b) to alphazero style learning of the Hex game. The paper is mainly an empirical study, and shows that the architecture leads to faster and better learning results for Hex. Without these explanations, the significance of the paper would be largely limited to coding and engineering efforts (which are also valuable but not that much in the research sense). The authors may want to explain clearly how the training scheme is different, and clearly state what the detailed neural network architecture (at least in the appendix) used is, and how they are different from the original alphazero paper and (Gao et al., 2018b).
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>The submission proposes a method for extracting "knowledge consistency" in neural networks and using that toward analyzing different aspects of them, eg understanding the representations, explaining knowledge distillation, and analyzing network compression. I recommend acceptance.<BRK>This paper presents a method to disentangle intermediate features between two different deep neural networks. The authors design a simple yet effective algorithm for extracting knowledge consistency. Thus, I vote for weak acceptance. Does p_(k+1) significantly improve the performance or negligible?<BRK>The goal of this paper is to analyze knowledge consistency between pretrained deep neural nets. In order to do so the paper trains neural networks to predict a hidden layer of one DNN using a hidden layer of another DNN. Similarly the authors analyze model compression and distillation with their technique.
Accept (Spotlight). rating score: 8. rating score: 6. rating score: 6. <BRK>The paper empirically analyzed the wide existence of "early bird tickets", e.g., the "lottery tickets" emerging and stabilizing in very early training stage. It would have been interesting to see. Does it imply the training might not be stable?<BRK>They demonstrate that the sparsity pattern corresponding to a lottery ticket for a given initialization can be uncovered via low cost training. The paper is well written and enjoyable. On the other hand, the experiments are well conducted (especially 4.3) and even if the original idea is simple, it is of interest to see it tested as clearly. All in all, I found this paper convincing and worth reading, and I think it should be accepted.<BRK>The main contribution is a method to quickly identify winning lottery tickets (denoted early bird, or EB by the authors), without running the model to convergence. This paper addresses an under explored, but very important problem in AI: the increasing cost of training models. The experiments presented in Figures 1 and 3 are convincing and will be of interest to the community. In Figure 1, it seems that the extracted subnetworks are doing very well even after 0 epochs. or is it pruned after training for 1 epoch? 3.Do the authors have any intuition as to the sharp decrease in the 70% graph in Figures 1 and 2 around epoch 50?
Accept (Poster). rating score: 8. rating score: 8. rating score: 6. rating score: 3. <BRK>The paper studies convergence & non divergence of TD(0) with value function estimates from the class of ReLU deep neural nets (optionally with residual connections). This includes determining if results, whether theoretical or empirical, are correct and if they are scientifically rigorous. The paper takes a first step in bridging the gap between existing analyses of TD(0): convergence with linear function approximators, and convergence in reversible MRPs. The second result connects a notion of reversibility of an MRP and the condition number of the neural tangent kernel, saying that better conditioning can make up for the lack of reversibility. Clearly state your decision (accept or reject) with one or two key reasons for this choice. The paper is well written, with a clear story and accessible explanations. Provide additional feedback with the aim to improve the paper.<BRK>####D0.My main critique is that the results are somewhat disparate. ####The paper characterises the convergence of Temporal Difference learning for on policy value estimation with nonlinear function approximators. This topic is important for improving the theoretical understanding of Deep RL. D3.Can the paper make it more clear to a Deep RL audience in the intro or discussion what the holy grail of this research direction would be? When a particular class of function approximators known as homogenous functions (e.g.Deep ReLU networks) is used, the error on the state value function can be bounded. 2.It is known that TD(0) converges with linear function approximators and arbitrary environments. It is also known that TD(0) converges with arbitrary function approximators when the environment is fully reversible. This paper shows that there is in fact a tradeoff between how well the function approximator is conditioned and how reversible the environment is (for particular definitions of well conditionedness and the "extent" to which an environment is reversible). That s a nice insight. 4.There is a classic counterexample for TD(0) with a nonlinear function approximator diverging. This work contributes to the understanding of Deep RL and could eventually lead to actionable theory which lets us design more robust RL systems (with insights about the coupling between learning algorithm, function approximator, and environment). ####D. Provide additional feedback with the aim to improve the paper.<BRK>The paper analyses the convergence of TD learning in a simplified setup (on policy, infinitesimally small steps leading to an ODE). Several new results are proposed:  convergence of TD learning for a new class of approximators (the h homogenous functions)  convergence of TD learning for residual homegenous functions and a bound on the distance form optimum  a relaxation of the Markov chain reversibility to a reversibility coefficient and convergence proof that relates the reversibility coefficient to the conditioning number of grad_V grad_V^T. While the theory applies to the ideal case, t provides some practical conclusions:  TD learning with k step returns  converges better because the resulting Markov chain is more reversible  convergence can be attained by overparmeterized function approximators, which can still generalize better than tabular value functions.<BRK>This paper establishes a theoretical insight into Temporal Difference (TD) learning for policy evaluation, on the convergence issue with nonlinear function approximation. We prove global convergence to the true value function when the environment is “morereversible” than the function approximator is “poorly conditioned”. How does the behavior that the TD update is absorbed into the “neighborhood” of the true value function? I think a missing experiment is the showcase for the divergence examples the case of “homogeneous” function, such as the square function and the neural networks (as claimed in the paper, these are “homogenous” functions). >>not clear what this means until here. Why not use V? The first is when V is linear and the second when the MRP is reversible so that A is symmetric.
Accept (Poster). rating score: 8. rating score: 8. rating score: 6. <BRK>The authors chose 10 for all experiments, why is this number chosen, what would be the effect of choosing a smaller one ? This is a key parameter as it defines the structure of the projection subspace. * The paper is well written and the math is clearly laid out.<BRK>This paper is well written overall. Presentation is clear and it is easy to follow. The proposed approach is a simple combination of existing approaches. The proposed method has the number of parameters including \lambda_1, \lambda_2, and parameters in neural networks.<BRK>The matrix A and the parameters of the AE are trained jointly. The paper claims to generalize the existing RSR framework to the nonlinear case.
Reject. rating score: 1. rating score: 1. <BRK>This paper describes a sensor placement strategy based on information gain on an unknown quantity of interest, which already exists in the active learning literature. The paper is also missing several important technical details and clarity of presentation is poor. The authors have performed some simple synthetic experiments to elucidate the behavior and performance of their proposed strategy. Can the authors explain this phenomena?<BRK>Summary:This paper addresses the issue of how to optimize sensor placement. The authors propose a framework for sensor placement called Two step Uncertainty Network (TUN) based on the idea of information gain maximization. Experimental results on the synthetic data clearly show that TUN outperforms current state of the art methods, such as random sampling strategy and Gaussian Process based strategy. If I understand correctly, on page 3 in Sect. However, my major concern is about the novelty of this work, given the fact that the theoretical contribution is quite limited.
Reject. rating score: 1. rating score: 3. rating score: 3. rating score: 6. <BRK>This paper proposes a conditioning approach for CNF and explore speed up by tuning error tolerance of the ODE solvers. Is it possible to make the problem more clear? It seems that the first time when the authors mentioned error tolerance is in contribution 2, but I didn t see the definition of the error tolerance.<BRK>This inefficiency problem has been a weak point in the existing conditional normalizing flow models. This paper has a novel contribution, outperforms the baseline (CCNF: CNF (Chen et al.) I agree to accept this paper, but I vote for ‘weak accept’ because of the following weaknesses:1. For the second contribution, the authors’ way is quite similar to Wang et al.(SkipNet). It looks like learning tolerance increases NFE in large epochs, and the timing seems to depend on the batch size. I cannot see any explanation about this claim.<BRK>This paper examines the problem of extending continuous normalizing flows (CNFs) to conditional modeling. InfoCNF relies on the accuracy of ODE solvers, so the paper also proposes a method that learns optimal error tolerances of these solvers. And the approach to learning error tolerances is a good idea. The main drawback of this paper is the lack of clarity. It is poorly written and the presented model is not clearly motivated. Below are some examples of this lack of clarity:  When motivating Conditional CNF (CCNF), the details for training the model are unclear. The paper compares InfoCNF to a single baseline (CCNF). The paper goes over these approaches in Section 5 and discusses their differences with InfoCNF, but these are never experimented with. Even comparing with these models without CNFs would have been interesting.<BRK>This paper proposed a conditional CNF based on a similar intuition of the InfoGAN that partitions the latent space into a class specific supervised code and an unsupervised code shared among all classes. To improve speed, the paper further proposed to employ gating networks to learn the error tolerance of its ODE solver. Do you have any explanations?
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>Motivated by the fact that the attention mechanism in transformers is symmetric which might not be able to disambiguate different orders, this work proposes to use a subject vector (in addition to query, key states) for each attention head, and multiply it elementwise with the context vector for each head before merging the heads. 2.The clustering of the subject vectors gives some insights into model s behavior . Cons:1.In terms of experiments, the proposed approach adds a few million parameters to normal transformer (table 1), but in terms of interpolation it only improves 3% (extrapolation improves 0.5%) at 700k steps. The comparison would be fairer if the normal transformer can be given more parameters. It would be nice if experiments on other tasks are shown in addition to the math dataset. 3.In terms of motivation, the claim that there re ambiguities introduced by multiple layers of  regular attention needs to be supported by evidence. I think (which authors also pointed out) the feedforward network and non linearties can disambiguate as well. While this work shows superior performance on the mathematics dataset, I have a few concerns about the generalizability of this proposed architectural change to other problems, as well as the fairness of comparison to baseline. Therefore, I am inclined to reject this paper. updates after reading rebuttal Thanks for adding the new NMT experiment in Appendix A3. My concern is that the proposed TP Transformer is not very effective on NMT.<BRK>This paper illustrates the TP Transformer architecture on the challenging mathematics dataset. The TP Transformer combines the transformer architecture with tensor product representations. Moreover, the paper also explains the reason why the TP Transformer can learn the structural position and relation to other symbols with a detailed math proof. Overall, this paper is nice as it makes a milestone for math problem solving from unique perspectives. Illustrate in fundamental math that why TP Transformer can learn the structural position and relation, and solve the binding problems of stacked attention layers. Here are a few minor questions that may further improve the paper:1. The conclusion states that TP Transformer beats the previously published SOTA by 8.24%. However, it does not match to the experiment results (see section 4). 2.In figure 5, there are 4 tasks in the bottom with accuracies lower than 0.5. It would be nice to provide more insights on this.<BRK>By creating an attention mechanism called TP Attention, they explicitly encode the relations between each Transformer cell and the other cells, whose values are retrieved by attention. By introducing tensor products, the proposed algorithm can empirically perform well for noncommutative operations with multiple arguments, such as division. The authors trained models with the proposed algorithm on the Mathematics Dataset and compared the performances with two baselines (simple LSTM and the original Transformer). At last, several model snapshots are provided to help interpret several key elements of the model: the learned roles, the attention maps, the TP transformer columns and so on. The experimental results generally support the high level intuition behind the introduction of tensor product representation. I would recommend accepting this paper. It was claimed in the Conclusion section that the performance of the proposed algorithm beats the previously published state of the art by 8.24%. I guess the number comes from the 2nd and the last row of interpolation accuracy in Table 1. Is it a fair comparison? If the proposed algorithm is also trained for 500k steps, the improvement is around 2.3%. 2.Why is the extrapolation accuracy results for TP Transformer missing in Table 1?
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>In this paper, the authors proposed the algorithm to introduce model free reinforcement learning (RL) to model predictive control~(MPC), which is a representative algorithm in model based RL, to overcome the finite horizon issue in the existing MPC. The authors evaluated the algorithm on three environments and demonstrated the outperformance comparing to the model predictive path integral (MPPI) and soft Q learning. 1, The major issue of this paper is its novelty. The proposed algorithm is a straightforward extension of MPPI [1], which adds a Q function to the finite accumulated reward to predict the future rewards to infinite horizon. Without more comprehensive comparison  on other MuJoCo environments, the empirical experiment is not convincing. The first term should be negative. There are already plenty of work solving the entropy regularized MDP online [2, 3, 4] and achieving good empirical performance. There is no evidence that the entropy regularization will reduce the mode bias. Information theoretic mpc for model based reinforcement learning. Bridging the gap between value and policy based reinforcement learning. "SBEED: Convergent reinforcement learning with nonlinear function approximation."<BRK>This paper builds a connection between information theoretical MPC and entropy regularized RL and also develops a novel Q learning algorithm (Model Predictive Q Learning). Experiments show that the proposed MBQ algorithm outperforms MPPI and soft Q learning in practice. The paper is well written. For experiments, I d like to see some results on more complex environments (e.g., continuous control tasks in OpenAI Gym) and more comparison with recent model based RL work.<BRK>The main contribution of this paper is a model based control algorithm that uses n step lookahead planning and estimates the value of the last state with the prediction from a learned, soft Q value. The proposed algorithm is evaluated on three continuous control tasks. I do think that this paper is tackling an important problem, and am excited to see work in this area. I would consider increasing my review if the paper were revised to include a comparison to a state of the art MBRL method, if it included experiments on more complex task, and if the proposed method were shown to consistently outperform most baselines on most tasks. In Equation 17, why can the RHS not be computed directly?
Reject. rating score: 1. rating score: 3. rating score: 3. rating score: 6. <BRK>This paper presents an approach where the regularisation is used to optimise whether each layer of a DNN is binary or ternary. The paper seems to contain an idea which might have merit. However, the idea just does not seem to have been developed enough. 2) Equations are not discussed in enough detail, nor are the parameters defined. 6) Figures 3 and 4 are difficult to interpret.<BRK>This paper studies mixed precision quantization in deep networks where each layer can be either binarized or ternarized. Experiments are performed on small scale image classification data sets MNIST and CIFAR 10. The proposed regularization method is simple and straightforward. However, many details are not stated clearly enough for reproduction. Thus it is hard to tell if the proposed method also works for larger networks or data sets? Yet another concern is that many recent methods that can train mixed precision networks are not compared.<BRK>The Paper talks about the Smart Ternary Quantization method that improves the quantization over binary and ternary quantizations by specifying an adaptive quantization. The proposed regularization function is covered in detail and the results are evaluated on MNIST and CIFAR10 datasetsThe authors can improve the submission by 1. evaluating more modern networks with bigger datasets, as opposed to the ones demonstrated.<BRK>Past methods such as Binary Connect and Binary Weights Network have shown that you can train a network efficiently with 1 bit quantization, and methods such as Ternary Weights Network demonstrate 2 bit quantization with weights taking one of { 1, 0, 1} * mu, with mu being a scale computed per weight tensor. In addition to that, the regularization also includes a prior to make the layers prefer binary weights by default. This is done by adding a cost that penalizes the choice of ternary weights for each layer. Overall, the paper is well written and explained, with supporting experiments to show on MNIST and on CIFAR10 that this method performs quite competitively compared to an all binary or all ternary weights network. Although the experiments cover MNIST and CIFAR10, it s not clear how mixed precision low bit methods perform on models more prevalent in the real world. Experiments on CIFAR10 strongly show improved accuracy and higher compression ratio compared to ternary weights network. The regularizer introduces more hyper parameters to tweak and it s not clear how sensitive these are to the choice of the architecture. Minor comments:  In equation (3), the term under argmin should be mu and not alpha.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>SummaryThis paper proposes an approach to make the model free state of the art soft actor critic (SAC) algorithm for proprioceptive state spaces sample efficient in higher dimensional visual state spaces. To this end, an encoder decoder structure to minimize image reconstruction loss is added to SAC s learning objectives. The approach is evaluated on six tasks from the DeepMind control suite and compared against proprioceptive SAC, pixel based SAC, D4PG as well as to the model based baselines PlaNet and SLAC. The proposed method seems to achieve results competitive with the model based baselines and significantly improves over raw pixel based SAC. The former work combines Q value learning with auxiliary losses for learning an environment model end to end (with a reconstruction loss for the next state) in the domain of Atari. UpdateI read the other reviews and the authors  response. I still feel that the novelty of the work is very limited and the authors  response to lacking novelty does not convince me.<BRK>The paper aims to tackle the problem of improving sample efficiency of model free, off policy reinforcement learning in an image based environment. They do so by taking SAC and adding a deterministic autoencoder, trained end to end with the actor and critic, with the actor and critic trained on top of the learned latent space z. They call this SAC AE. The predictors are learned on top of the encoder output, and in SAC+AE we would expect task information to be encoded in the learned z. The case for SAC+AE seems much stronger from the reward curves, rather than these plots. * The paper argues that their approach is stable and sample efficient, but when looking at the reward curves, it looked about as stable as SAC.<BRK>The method is evaluated a variety of control tasks, and shows strong performance when compared to a number of state of the art model based and model free methods for RL with image observations. The paper is well written and provides a very clear description of the method. RL from images remains a very challenging problem, and the approach outlined in this work could have a significant impact on the community. While the overall novelty is a bit limited, this could be a case where details matter, and insights provided by this work can be valuable for the community. There is mention of SLAC as a model based algorithm.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>This paper considers the problem of understanding the impact of deep neural networks (DNN) model architecture on the convergence rate of gradient descent dynamics. 3) The authors may want to add citations to [2] (which is a concurrent work with [25] on essentially the same topic) and [3] (which is a predecessor work of neural ODE). The paper then claims that the convergence rate is characterized by the minimum eigenvalue of H, and analyzes this H through a straightforward path based formula obtained by chain rules. In particular, the authors try to explain the effect of width, depth and number of paths on the convergence rate, and validated these through a few numerical experiments. Admittedly, the idea of this paper is interesting. 1.On the novelty side, characterizing the convergence via the H matrix is not new, and most of the discussions in Section 4 have appeared in exactly the same form in the previous works [13] (two layer) and [25] (general), which are also cited in this paper. 1) The notation is not very consistent.<BRK>This paper studies the training dynamics of a neural network model as a dynamical system. The authors proposed a path based approach to compute the derivatives that would appear in the H matrix which governs the learning dynamics. They further utilized this formulation to (1) simplify the analysis of convergence rate of 2 layer neural networks w.r.t.width; and (2) presented an argument for the similarity between added depth in the network and momentum based optimization; and (3) also argued about the importance of the number of paths for fast convergence. The path gradient is quite intuitive, but I’m a bit surprised there’s no prior work (at least not discussed in this paper) studying the relationship between gradients and the paths in the network. It is a bit hard for me to judge the significance of this work because of my lack of context. The second part tried to draw a relationship between added depth in a network and momentum based optimization, which I found to be a bit hand wavy. Overall I found this paper presented some interesting ideas, but may need a bit more work to be ready to be published. Happy to change my judgement however, if other more experienced reviewers can comment better on the significance of this work.<BRK>This paper presents a simple and intuitive interpretation of the dynamics of gradient descent between labels and predictions rewritten in terms of all possible paths from inputs to outputs in FC networks. The coefficient matrix H of the system is known to determine the convergence properties, and this can be rewritten with respect to path wise sums of gradients through the chain rule (Theorem 4.1). 2) the  depth  of FC network affects the convergence like momentum (section 5.2). 3) the number of paths compared to the number of nodes has a predominant impact on the convergence (section 5.3). I would suggest that emphasizing the fact 4.1 as an already discussed fact makes easy for readers to follow the results and focus more on the paper s contribution.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>This paper is relatively easy to follow and the ideas are simple and effective.<BRK>In the end empirical analysis is performed to analyze the characteristics of DKs. I appreciate the effort to give a background on ERFs and describe (local and global) DKs, but in my opinion, technical sections of the paper partly very obscure.<BRK>I do not have much background in this field, but I found the ideas of DKs very interesting and novel (assuming this is the first work to make the filter data dependent and learnable.) In this paper, the authors propose an approach known as DKs (deformation kernels) to overcome such issues.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>This paper presents a learned image compression method that is able to be robust under a variety of tasks. The results presented do NOT show that this method is better than the best hand engineered approach, despite what they claim.<BRK>Summary of the paper  This work proposes a new deep learning based method to replace the lossy compression techniques of images., jpg. The work investigates the role of codec and shows that the proposed complex photo dissemination channels optimizes the codec related traits on images.<BRK>The paper describes a pipeline for image compression which allows to reliably detect specific manipulation patterns in compressed images. A comparative study which relates a new system to a current state of the art is required to claim that a proposed approach is better.
Accept (Poster). rating score: 8. rating score: 3. <BRK>This paper proposes a new sequential model free Q learning methodology for POMDPs that relies on variational autoencoders to represent the hidden state. The idea is to create a joint model for optimizing the hidden state inference and planning jointly.<BRK>The paper proposes SVQN, an algorithm for POMDPs based on the soft Q learning framework which uses recurrent neural networks to capture historical information for the latent state inference. The authors evaluate the final algorithm on a set of ALE and DoomViz tasks.
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>Specifically, they use the Stein s unbiased risk estimator for the problem when the noise is gaussian. 2.Experimental focus of the paper is to analyze biomedical datasets   HCP, EDX and the authors compared their method to *only* one baseline. I suggest that they perform some more comparisons on natural images like http://vllab.ucmerced.edu/wlai24/cvpr16_deblur_study/<BRK>This paper proposed a piecewise linear close form expression for the Stein’s unbiased risk estimator and use this formulation to construct a new Encoder decoder convolutional neural network.<BRK>They show that for CNN autoencoders this can be efficiently computed. So how do you reconcile this with undersampled MRI and EDX data? 2.Decision and argumentsUnfortunately this paper is outside my expertise so I can’t evaluate the novelty of the theoretical accomplishments.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>This leads to the final insight, feature manipulation is easier in robust networks. The paper demonstrates that robust optimization enforces a prior on the representation learned by neural networks that results in high correspondence between the high level features of an image and its representation in the network, i.e., similar images share similar representations. The paper does not introduce any new algorithm or shows any theoretical results, but it is a great source of insight and intuition about robust optimization and deep learning. Comments and Questions  There is still a major question that the paper does not directly address, but that is very relevant to robust optimization. Given that robust optimization seems to result in better behaved and semantically meaningful representations, as evidenced by the findings in the paper, why is it that the performance of the resulting networks, in terms of classification accuracy, is lower than the performance of standard networks (trained with standard optimization)?<BRK>The paper proposes robustness to small adversarial perturbations as a prior when learning representations. I would agree with the authors that this paper does go into more detail for feature visualization. This is definitely interesting, but still very related to the feature painting result. #### Author s Position 2They disagreed that feature inversion (this paper) is similar to image generation (NeurIPS paper). (Perhaps the two papers could have been one single paper). If I understand correctly, all of these examples exist because the robustly learned representation relies on the salient parts of the input and not on the non robust features. In its current form, I feel that the two papers are too similar to recommend acceptance. Moreover, they argued that even if we consider NeurIPS paper to be prior work, feature visualization is explored in much more detail in this paper.<BRK>Summary:The paper shows that the learnt representations of robustly trained models align more closely with features that the human perceive as meaningful. They propose that robust optimization can be viewed as inducing a human prior over learnt features. The paper indicate adversarial robustness as a promising avenue for improving learned representations in from several aspects. It is well written and contains extension experimental results. I d suggest accepting the paper. Some symbols seem to be used somewhat interchangeably.
Reject. rating score: 3. rating score: 6. rating score: 8. <BRK>The paper proposes a method for few shot object detection (FSOD), a variant of few shot learning (FSL) where using a support set of few training images for novel categories (usually 1 or 5) not only the correct category labels are predicted on the query images, but also the object instances from the novel categories are localized and their bounding boxes are predicted. RPN and found as matching to the few provided box annotations on the support images. The method is tested on a split of PASCAL VOC07 into two sets of 10 categories, one for meta training and the other for meta testing. Some important details are missing from the description. It should be evaluated for a fair comparison. 4.Although they don t strictly have to compare to it, I am wondering if the authors would be willing to relate to a similar approach that was proposed for the upcoming ICCV 19: "Meta R CNN : Towards General Solver for Instance level Low shot Learning", by Yan et al.Their approach is more similar to RepMet in a sense that the meta learning is done in the classifier head,and better results are reported on VOC07 benchmark (and except for 1 shot, higher results are reported for the 3 and 5 shot FRCNN fine tuning).<BRK>In this paper, authors propose a meta learning based approach for low shot object detection. Specifically, they use prototype in the support set as attention guidance, and learn the category specific representation for each query image. The idea is somewhat novel, in terms of meta learning based low shot detection framework. My main concern is about experiment. First, the data setting is branch new. How to make it in a meta learning way? Please clarify the implementation details for all other related works in the comparison.<BRK>This paper is about the task of object detection in the setting of few shots dataset. The problem is addressed in the learning scheme of meta learning paradigm: the proposed meta rcnn trains the popular faster rcnn on several tasks of few shots object detection while the RPN and the object classification networks are meta learned among the tasks. Compared to previous work the paper introduces the meta learning framework and several changes to the faster rcnn detector. As a result I recommend this paper to be accepted. Minor issues:  in caption of Fig1: avialable  > available  in 4.1: “Compared to other variants...” please add a reference to the specific methods you are comparing to.
Accept (Poster). rating score: 6. rating score: 6. rating score: 3. <BRK>*Summary*This paper describes DiffSim, a differentiable programming system for learning with physical simulation. Overall, I m optimistic about this paper, and would tend to vote for acceptance. I lack the background to comment constructively about expectations for these simulations or the fidelity of the methods in this paper.<BRK>This paper introduces DiffSim, a programming language for high performance differentiable physics simulations. Update after rebuttal Thank you for the revision of the paper and the additional comparisons with Jax. The revised version reads much better.<BRK>This paper presents a programming language for building differentiable physics simulators. The system presented by the authors is certainly impressive. The latter also provides a compiler backend to produce GPU code with gradients, and as such seems very closely related to the proposed language. The core of the proposed work, the programming language seems to be quite powerful.
Reject. rating score: 1. rating score: 3. rating score: 3. rating score: 6. <BRK>The contribution of the paper is marginal, as the principle of imposing Gaussians on the network to perform Bayes is not new. The Laplace based approximation is half baked and certainly much better techniques for Bayes exist in the recent literature; furthermore, it s selection is not substantiated enough, and, of course, it represents no novelty. The experimental results are not convincing, as both the considered scenarios are limited and the comparisons are too poor (no consideration of state of the art alternatives).<BRK>Or I guess you use a different D in eq(13) from the D in eq(10) ? The paper shows that the proposed method has smaller Frobenius approximate errors compared to K FAC and EK FAC. Beyond that, the adversarial attack experiment and the mis classification uncertainty experiment in Ritter et al (2018) seem to be good choices as well. Firstly, for the MNIST experiments, it is better to use the same architecture as in Ritter et al (2018) for direct comparisons. Interestingly, the paper shows that this corrections doesn t add too much computations. However, the proposed low rank approximation doesn t seem necessary. With the diagonal correction approximating the Fisher better, the paper shows the computation can still be conducted in the scale of W, which is similar to K FAC. # Writing The paper s notations are messy, which requires a lot of intellectual guesses to understand the conveyed idea. 4) The paragraph below Corollary 1 says the author can prove the proposed method also has closer approximations in terms of the Fisher inverse. # Low rank Approximation1) It is not clear why the low rank approximation is necessary.<BRK>The proposed diagonal correction is shown to have a smaller residual error in F norm. Experiments are given to show that the proposed Laplace approximation makes more accurate uncertainty estimations. The paper makes a certain contribution to existing Laplace approximations for the task in terms of accuracy and scalability. However, it is incremental and the novelty is a bit low, compared to many recent closely related works, for example,Optimizing Neural Networks with Kronecker factored Approximate Curvature. 2018A scalable Laplace approximation for neural networks.<BRK>The submitted paper presents a method of approximating the posterior distribution over the DNN parameters based on a Laplace Approximation scheme. It extends on the previous work by adding a diagonal correction term to the Kronecker factored eigenbasis and also suggests a low rank representation of Kronecker factored eigendecomposition. The main idea of the paper is convincing and well motivated. In that sense, I am slightly concerned that its novelty is limited. The experiments are not comprehensive. For the toy regression problem, a comparison to Hamiltonian Monte Carlo would be more informative. Moreover, it would be helpful to report the comparison with factorized variational methods (e.g.Graves, 2011) and experiment on modern architectures. Also, in Lemma 4, shouldn’t there be a hat on I_{efb} and I_{kfac}?
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>The paper proposes a method to address a known problem for unsupervised disentangling methods that penalises total correlation, namely that while the total correlation of the samples from q(z) (denoted TC(z)) are encouraged to be small, the total correlation of the means of q(z|x) (denoted TC(mu)), used as the disentangled representation in practice, is not necessarily small and can increase with regularisation strength. I like the simplicity of the idea, however the analysis is lacking in rigour. This should be explicitly stated so that one can understand the results in Figure 1. Also the at the bottom of page 5 is a Gaussian with a correlated covariance matrix, and it’s claimed that its TC can be arbitrarily large, but surely this is fixed? The experimental results are very weak and sparse, that is nowhere near enough to give a convincing case for the newly proposed method. The method has only been trained on dsprites and 3d shapes, with three choices of beta and a single value of eta, and only estimates of TC(mu) and TC(z) are reported, with no evaluation of disentanglement performance. The experiments should cover a larger range of datasets, with evaluation on how different disentanglement metrics, TC(mu) and TC(z) change for different values of beta and eta, along with a comparison with other disentangling methods, especially DIP VAE 1, that directly penalises correlation in mu (for an open source library that facilitates this, see e.g.github.com/google research/disentanglement_lib). Even the authors acknowledge that “the scale of our experiments is limited”, and it is clear that the paper is not yet ready for publication.<BRK>Proving a theorem that a family of distributions of sample representations with a bounded total correlation can have a mean representation of arbitrarily large total correlation, the authors propose RTC VAE, which additionally penalizes total covariance of sampled latent variables. However, I still think that the paper  has room for improvement in justifying the method, explaining the choice of hyperparameter and so on. The proposed method, RTC VAE, is based on a simple idea and its performance in experiments is promising. The covariance term in RTC VAE of Eq.(4), is indirectly related to mean representation.<BRK>The novelty of this paper is adding an extra regularization term to the objective of beta TCVAE (a VAE that regularizes total correlation), based on the discovery that low TC(z) does not necessarily mean low TC(mu). The added term enforces sample and mean representations stay close. The authors  idea is understandable at a coarse resolution. For example in Theorem 1, what is "j"? In Section 4, the simplification of notations lead to more difficulties to understand the formulas. The notations of variables are also confusing. However, the authors should show some generated examples through latent variable traversal to qualitatively demonstrate the potential advantages of the proposed improvement.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>This work suggests a host of  improvements and simplifications to the meta learning approach of Andrychowicz et. al.The authors have carefully analyzed weaknesses in previous work and I think their experiments do suggest that they have improved on them.<BRK>This paper presents several improvements over the existing learning to learn models including Andrychowicz et al.(2016) and Lv et al.(2017).Specifically, this paper analyzes the issues in the original learning to learn paradigm (L2L), including instability during training and bias term issues in the RNN. It proposes a new loss based on weighted difference for improving the meta optimizer in the later stage of optimization. Cons1.The novelty is not good enough and the method does not seem to be solid enough. It would be interesting to know that if the bias term of the two baseline model are removed, how is the performance difference compared to the method proposed by the authors? How does the number of parameters of the meta optimizer scales with the problem size?<BRK>In this paper, the authors build on the  learning to learn  work, that aims to leverage deep learning models with optimization algorithms, most commonly with recurrent networks. The paper is overall well written, and several experiments are presentedBuilding on previous work, the authors propose some variations to the meta learning schemes and architecture. I comment on these below. This is supported by a set of experiments in Fig 3a (but with only one learning rate?). This experiment shows an extraordinary difference in accuracy between including and not including the RNN bias.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>How to smartly share parameters and how to control the number of parameters will be an interesting direction to explore. The current writing is not easy to follow. The explanation is missing in this paper. 4     Lack of references. What are your contributions and differences in terms of the neural symbolic architecture design?<BRK>This paper builds an interesting connection between Datalog rules and temporal point processes. Since these arguments affect the partition of the number of node blocks, it would be more clear to illustrate how to design the node blocks as the number of arguments increases (say beyond 2 arguments).<BRK>However, I tend to favor rejection becausewhile the ideas are very interesting (and potentially impactful),validation of the claims is weak. Weaknesses:There are a few major points to criticize about this paper. First, there is no clear learning or prediction benefit.
Accept (Poster). rating score: 6. rating score: 6. rating score: 1. <BRK>The paper presents evidence that even a tiny bit of supervision over the factors of variation in a dataset presented in the form of semi supervised training labels or for unsupervised model selection, can result in models that learn disentangled representations. The authors perform a thorough sweep over multiple datasets, different models classes and ways to provide labeled information. Overall, this work is a well executed and rigorous empirical study on the state of disentangled representation learning. Comments1) Would it be possible to use the few labeled factors of variation in a meta learning setup rather than as a regularizer? It is certainly hard to discuss all the thousands of experimental observations, but the paper can benefit from some more fine grained analysis.<BRK>This paper considers the challenge of learning disentangled representations i.e.learning representations of data points x, r(x), that capture the factors of variation in an underlying latent variable z that controls the generating process of x and studies two approaches for integrated a small number of data points manually labeled with z (or noisier variants thereof): one using these to perform model selection, and another incorporating them into unsupervised representation learning via an additional supervised loss term. The paper poses its overall goal as making this injection of inductive biases explicit via a small number (~100 even) of (potentially noisy) labels, and reports on exhaustive experiments on four datasets. However, I believe in the context of (a) making more explicit a practical (and theoretically) necessary step in the pipeline of learning representations, and (b) contributing a comprehensive empirical study, this is a worthwhile contribution.<BRK>After rebuttal edit:No clarifications were made, so I keep my score as is. This paper needs a substantial rewrite to make clear what specific contributions are from the multitude of experiments run in this study. As is, the two contributions stated in the introduction are both obvious and not particularly significant   that having some labels of the type of disentanglement desired helps when used as a validation set and as a small number of labels for learning a disentangled representation space. There are no obviously stated conclusions about which types of labels are better than others (4.2). Section 3.2 seems to have some interesting findings that small scale supervision can help significantly and fine grained labeling is not necessarily needed, but I don t understand why that finding is presented there when Fig.4 seems to perform a similar experiment on types of labels with no conclusion based on its results.
Reject. rating score: 1. rating score: 1. rating score: 3. <BRK>This paper lacks of research motivation and solid experimental validation. The authors claim "it is the fastest domain adaptation algorithm in terms of computational complexity", which is not very convinced. This paper written is a little poor, and the novelty of NBP is not clearly claimed. The experimental effectiveness is weak and have no improvement compared with BT 2018 in image dataset.<BRK>In this work, the authors improve the work (Raab & Schleif, 2018) by (1) reducing the computational complexity, (2) neglecting the sample size requirement, and (3) achieving a low rank projection through Nystrom approximation. Experimental studies on three datasets have been done. Here are some detailed comments:(1)	A lot of recent deep domain adaptation methods are missing. With this, eq.(13) is incorrect as X should be L_X*S_X*R_X^T, but not L_s*S_s*R_s^T. I do not find contents stating the low rank property of the proposed algorithm in the main technical sections. The improvements of NBT to BT are very marginal, 0.6.<BRK>The novelty seems to be too limited. The Datasets used in the experiments are not representative. Besides, there is no comparsion between the proposed methods and the state of the art deep learning based methods.The experimental results seems unconvincing.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>This paper proposes an efficient sparse matrix based representation for symbolic knowledge bases. This representation enables fully differentiable neural modules to model multi hop inferences, which is designed to be scalable to handle realistically large knowledge bases. However, considering the readability, I would like to recommend a weak accept for this paper.<BRK>The paper provides a way to represent symbolic KBs called sparse matrix reified. Relations and entities  types are modelled using sparse matrices. A neural model is used to manage these matrices. The proposed approach seems promising, however, I feel that the paper is not ready for publication. After reading the paper I have the feeling that it was written in a bit of a hurry, without working on the details.<BRK>The paper proposes sparse matrix KB representation for end to end KB reasoning tasks. They demonstrate that their algorithm is scalable to large knowledge graphs which is the central contribution of the paper. They apply this to a bunch of tasks such as KB Completion and KBQA. The notations are overly complex. The paper, in my view, requires  considerable rewriting. The paper needs considerable rewriting and therefore I cannot recommend this paper for acceptance at this stage.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>This paper deals with the problem of how to enable the generalization of discrete action policies to solve the task using unseen sets of actions. The challenge is to extract the action s characteristics from a dataset. This paper presents the HVAE to extract these characteristics and formulates the generalization for policy as the risk minimization. This paper shows us how to represent the characteristics of the action using the a hierarchical VAE. 2.From the provided videos, we can directly observe the results of this model applied to different tasks. In the paper, the authors mentioned that they proposed the regularization metrics. It is important to develop the proposed method in theoretical style. 2.Analyzing the regularization metrics should be careful in the experiments.<BRK>This paper addresses the very interesting problem of generalising to new actions after only training on a subset of all possible actions. Having identified the context, it is used in the policy which therefore has knowledge of which actions are available to it. While the experiments are sufficiently varied, it worries me that only 3 or 2 seeds were used. In some cases, such as NN and VAE in the CREATE experiments show large variances in performance. Perfects a few more seeds would have been nice to see. This is the key reason why I chose a  Weak Accept  instead of an  Accept . Minor issues: 1) In Figure 3, I am not clear about what  im  and  gt  settings are. 2) In Figure 3, it would have been nice to have consistent colors for the different settings. 3) It would have been nice to see the pseudocode of the algorithm used.<BRK>This paper studies the problem of generalization of reinforcement learning policies to unseen spaces of actions. This paper could be improved in the following aspects:1. The novelty of the proposed model is somewhat incremental, which combines some existing methods, especially the unsupervised learning for action representation part that just combines methods such as VAE, temporal skip connections…2. 4.Some datasets are not sufficient enough for sake of statistical sufficiency, such as recommendation data with only 1000 action space.
Reject. rating score: 1. rating score: 1. rating score: 1. <BRK>To attain this goal, the authors propose a new regularization scheme that encourages convolutional kernels to be smoother. The authors augment standard loss functions with the proposed regularization scheme and study the effect on adversarial robustness, as well as perceptual alignment of model gradients. Overall, I think there are significant issues with the paper, especially in the empirical evaluation section. Thus, I recommend rejection. In particular, in Table 1 (also Figures 7 9 in the Appendix):1. The numbers suggest that FGSM is more successful as an attack than PGD. 2.At a higher level, the numbers that the authors highlight in the table are the best performance over attacks. This is not the correct way to evaluate robustness, which must always be reported as the *worst case performance* of the model and hence the lowest accuracy over attacks. If one takes this into consideration, it is clear that the proposed regularization does not really improve robustness. 3.Furthermore, the authors state they use default parameters from Foolbox to evaluate their models. 4.The eps that are used for the CIFAR 10 and ImageNet experiments are extremely large, and not standard in the literature.<BRK>The authors propose a method for learning smoother convolutional kernels with the goal of improving robustness and human alignment. They evaluate the impact of their method on the adversarial robustness of various models and class visualization methods. However, the experimental evidence presented is either unreliable or not sufficient to demonstrate the merit of the approach. The authors perform a number of off the shelf attacks using the foolbox library without accounting for fundamental differences between these attacks or basic principles of adversarial evaluation. Hence, most of the columns of Table 1 are unreliable and cannot be taken into account when evaluating the models  robustness. Furthermore, the evidence in favor of human alignment is relatively weak. While the method does have some effect for the case of simple models (MNIST and Fashion MNIST), for the case of complex models (for which visualization is actually a challenging problem) the improvement is virtually non existent. However, I find this confusing. There exist several works by now performing visualization using adversarial models and I have never encountered such a failure before. Overall, while the high level idea of the paper is interesting, the experimental evidence presented is either weak or unreliable. I will thus recommend rejection.<BRK>1.Please number the equations for better readability. The contribution in terms of designing R(w) and the logit pair loss function is trivial. The authors mentioned about robustness without any justification. The usage of Pinsker’s inequality to get upper bound is meaningful but that doesn’t prove the robustness. Please explain, also why not state this as a theorem. I suggest prove the robustness in a concrete manner, maybe using influence functions. supposed to be? What can we get from Table 1? Also please justify the choices of hyperparameters used. 14.The regularization seems not that useful, to me this work tries to justify using a regularization which by the choice of experiments is not well grounded.
Accept (Spotlight). rating score: 8. rating score: 6. <BRK>Here are the claims I could find in the intro:"Given a query input to a black box, we aim at explaining the outcome by providing plausible and progressive variations to the query that can result in a change to the output" > This is well supported as the model generates these and it is very reasonable that it can. "the counterfactually generated samples are realistic looking"> The images seem to support this. "the method can be used to detect bias in training of the predictor"> Section 4.4 makes it really clear that, at least in the described setting, it works. The general concept of exaggerating a feature that represented a class seems novel and exciting. M_z seems to just be a bottleneck but the writing makes it seem like it is more.<BRK>The paper presents a method for explaining the output of black box classification of images. The rationale is that, by looking at these, humans can interpret the classification mechanics. The presentation is clear. One question that is not addressed is how efficient is this method, in terms of computational cost. If not, it is an approximation, and it should be presented and reasoned as such (with a discussion of limitations and caveats, for instance).
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>All the primitives are competing with each other on a given state to take an action. The paper performs extensive experiments to show that this scheme improves over both flat and hierarchical policies in terms of generalization. This paper is well written. I enjoyed reading it. Did you think about other simple methods, e.g., decompose the policy using linear combination work? It seems you want p(z|s) to be as close to a unit Gaussian as possible? • Figure 4 does not show a clear cluster structure.<BRK>This paper is about a policy design, where the policy is expressed as a mixture of policies called primitives. Each primitive is made of an encoder and a decoder, mapping state to actions, rather than temporally extended actions (or options in RL). The primitives compete with each other to be selected in each state and thus do away with the need for a meta policy to select the primitives. It is helpful for me to have equation (3) in mind before reading about the explanation on the tradeoff between the reward and information, but this is a minor point. My concern is that by scaling the reward in proportion to L_k redistributes the rewards in a way that is not reflective of the underlying reward structure of the MDP.<BRK>The paper draws upon the idea of information bottleneck to do task decomposition so as to learn policy primitives similar to hierarchical reinforcement learning that combine together in a competitive manner to specialize in different parts of the task s domain. These policy primitives don t need a higher level meta policy to stitch them together. The paper seems to build on the idea of decomposing the task primitives that specialize in different parts of the state space. There are other issues with the paper as well. Decision making is not exactly "decentralized"? Continuous control tasks required pretraining. Overall the experiments seem a little underwhelming. I like the idea of a competitive ensemble figuring out a useful task decomposition and using an information bottleneck like approach makes sense.
Accept (Poster). rating score: 6. rating score: 6. rating score: 3. <BRK>This work is expressed clearly and well written. The authors propose a new method to learn graph matching. It contributes in two aspects: 1) a new edge embedding strategy and 2) Hungarian attention incorporating with the loss function. A set of experiments as well as ablation studies have been conducted to show the effectiveness of the method.<BRK>The authors proposed a new way to train graph siamese networks for the graph matching problem. The overall framework of this paper is somehow similar to [1] and [2], except for the final Hungarian attention module, which is the key contribution of this paper. Is it possible for the module to only using geometric features as [1] and [2]?<BRK>This paper studies the graph matching problem in the context of vision. As it is written, this paper seems more appropriate for a conference in vision. My understanding is that features are extracted from images and used to construct a graph. Although I am familiar with the graph matching problem, I have much less experience regarding its application in vision.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>Summary: this paper claims to design an unsupervised meta learning algorithm that does automatically design a task distribution for the target task. Detailed comments:	• It would benefit a lot if you can clearly define the original meta learning procedure and then compare that with the one proposed in this paper. I would think p(z) is also “hand specified”. Again, why p(z) is not “hand designed”	• Why compare with the original meta RL algorithm on p(z) is not fair? • The “controlled MDP” setting is actually much easier: perhaps you just need to learn the probability distribution.<BRK>The paper develops a meta learning approach for improving sample efficiency of learning different tasks in the same environment. The paper is interesting.<BRK>I am still confused on why we suddenly should use meta RL. The statement of Lemma should be made more clear. 4.The key ingredient is missing   the learning procedure f, which was mentioned in eq.(1) and Algorithm 1, but the details are never specified. It is impossible to reproduce the algorithm based on the description in the paper.
Accept (Talk). rating score: 8. rating score: 8. rating score: 8. <BRK>[Summary]This paper studies the problem of non convex optimization for Dictionary Learning (DL) in the situation when the underlying dictionary is over complete (more basis vectors m than the dimension n). A similar result is proved for convolutional dictionary learning. [Pros]The theoretical results in this paper provides a solid improvement over the prior understandings on overcomplete DL, a setting that is practically important yet theoretically more challenging than standard orthogonal/complete DL. The analysis contains novel technicalities and can be of general interest for understanding the landscape of non convex problems.<BRK>The authors consider two problems: Overcomplete dictionary learning (ODL)and convolution dictionary learning (CDL). The authors show that under a given set of assumptions local nonconvexoptimization can be used to find globally relevant solutions. The authors show (assuming p \to \infty) that the optimization nonconvexlandscape (constrained to the sphere) does not contain any stationary pointswithout negative curvature. I am recommending to accept based on the high quality of the work. But I am not confident as to the accessibility of the paper to the wideaudience of ICLR as it is rather technical.<BRK>This paper studies the dictionary learning problem for two popular settings involving sparsely used over complete dictionaries and convolutional dictionaries. Interestingly, the paper shows that when $A$ is unit norm tight frame and incoherent the optimization landscape of the aforementioned non convex objective has strict saddle points that can be escaped by along negative curvature. The reviewer believes that this paper presents many interesting and novel results that extend our understanding of provable methods for dictionary learning. As claimed in the paper, this the first global characterization for the non convex optimization landscape for over complete dictionary learning. Besides, the paper provides the first provable guarantees for convolution dictionary learning.
Reject. rating score: 1. rating score: 1. rating score: 3. <BRK>The paper describes a dataset an a hybrid machine learning + rule based approach for event extraction from Amharic Text. Although there has been a lot of work on event extraction for other languages, including morphologically rich ones, this paper states there has not been prior work on event extraction in Amharic. The authors describe a new event extraction dataset, text for which they scraped from the news websites. I think the paper in its current form should be rejected from ICLR. The paper is not clearly written. My suggestion is to submit to another venue such as LREC, focus on the new resource and include linguistic insight into the language specific challenges, and also include machine learned and rule based baselines.<BRK>This paper deals with the important issue of information extraction from less resourced languages. In its current form, the paper has two main weaknesses:  it is poorly written & organized  it was a fairly weak empirical evaluationIn order to address the first issue:  the authors should significantly improve the quality of the prose, which can be confusing & difficult to undersrand  the introduction needs to be significantly crisper: in its current form, it is far too general and does NOT describe the rest of the paper; the authors should explain ...   1) what is the problem they are working on (currently present, but far too long)    2) what is the proposed approach & why is it novel (missing)     3) what are the main results & their significance (also missing)In order to address the second issue:  3.1 needs more details; it is this reviewer s understanding that the current corpus consists of 1065 documents (which is extremely small in size); how many sentences are there in these documents? in the current form, it is also unclear whether the on/off event detection is performed at sentence or document level   4: what is the value of k in k fold CV? Last but not least, the authors could use the work below as inspiration on how to improve the overall quality of the paperhttps://pqdtopen.proquest.com/doc/2025917601.html?FMT ABS<BRK>The paper studies extracting events from unstructured text, specifically on the low resource language Amharic. The paper proposes to combine rule based based with a learning based approach. As well as a hybrid versus a rule based approach. The paper claims “Amharic presents sophisticated language specific issues” but does not evaluate how the proposed approach handles those specific challenges. The authors note it is the same dataset. 3.3.What is the large unlabeled corpus used for? The paper misses comparisons to prior work for event extraction and misses to include ablations which show the value of the introduced rules and design decisions made. As clarity and experimental evaluation are also major concerns of the other reviewers and it is unclear if and how they will be addressed in a revision I do not recommend accepting the paper.
Reject. rating score: 1. rating score: 1. <BRK>The paper proposes a horse dataset to study transfer learning or so called out of domain pose estimation. They also study which model is a better initialization model for pose estimation, and how to utilize transfer learning to get a better estimation model. There are several questions from the paper:1. why are they not using human pose estimation datasets, as there are already lots of them and that will be easier to compare with other models: MPII, COCO, AI challenge, CrowdPose, etc. In terms of out domain, authors can use pose pre trained models to analysis horse pose prediction. 2.The analysis is good and with lots of experiments, however, the key part is that they do not provide a way to improve the overall performance for out of domain pose estimation.<BRK>  Summary This paper analyzes the effect of ImageNet pretraining on out of domain visual recognition. The paper presents a new horse pose estimation dataset and extensive experimental analysis to demonstrate the benefit of ImageNet pretraining. DecisionI would recommend to reject this submission mainly due to the shortcomings of the proposed dataset, which make the analysis and conclusion of the paper unconvincing. It only contains 8K horse profiles images, each of which contains only a single horse, and only 30 horses of the same species appear in the images. Furthermore, since the dataset are sampled from video sequences, images of the same horse ID could be too similar in terms of appearance. Images of 10 horse IDs are considered as the "within domain" dataset while the others as "out of domain" dataset, and a subset of the within domain dataset is used for training or finetuning the pose estimation networks. If this is not a big issue, I rather would like to recommend to exploit existing human pose datasets (e.g., MPII) since they are larger enough in size, and guarantee a larger variety of poses and person appearances than the proposed horse dataset.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>In summary, the scope of experiments and presentation of results would need to be significantly improved in order forthis work to reach the quality bar of ICLR.<BRK>This paper investigates an interesting problem of building a program execution engine with neural networks.<BRK>his paper deals with the problem of designing neural network architectures that can learn and implement general programs. The main contribution seems to be adding the self attention mask that is learned, along with execution traces that have been used in previous work. Therefore it seems to me that the contribution of this paper is limited in terms of technical contribution.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>This paper proposes a universal approximation theorem for functions invariant and equivariant to finite group actions. It proves a bound on the number of parameters in the build equivariant model. The proof structure uses a decompostion of G equivariant functions into Stab(1) invariant functions, which are represented by a particular network. I think it is necessary to do a more in depth comparison with respect to the existing work of (Keriven & Peyré 2019). I still believe the approach may have merits, however I do not recommend acceptance of the paper at its current state.<BRK>*Paper summary* The authors develop a universal approximation theorem for neural networks that are symmetric with respect to the symmetric group (permutations). They also formally show that the number of free parameters is to train an equivariant network is smaller that the number in a non equivariant network, leading to better sample complexity. It would be nice if these differences were spelled out for me. *Supporting arguments and questions for the authors* The paper is clearly written by people who have a firm grasp of their subject.<BRK>The paper proposes a universal approximator for functions equivariant to finite group action. While this is an important topic and the paper   to the extent that I could follow   seems to be technically sound, I found the paper very hard to read in part due to numerous grammatical errors. Also is there a setting in which this setup leads to a practical architecture?
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>One of the key points of the old adversarial attacks was that the attack image was indistinguishable from the true image by a human. It would also be good to see the actual VAE values. The key claim of the paper is that an attacker has to attack all layers at the same time to attack the reconstruction in eq (12). This looks more like the algorithm did not manage to find a suitable direction.<BRK>This paper examines adversarial attacks to a VAE. Then the authors evaluate the robustness of reconstructions under various output attacks. Overall, this section feels as if it is too hastily written, many results put into appendix without much discussion. The organization can be much more improved. Overall, the paper is quite promising but I feel that one more iteration maybe needed.<BRK>The authors of this paper propose a new VAE model called seatbelt VAE and investigate its robustness to output and latent adversarial attacks. Robustness to adversarial attacks is the focus in experiments.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>This paper proposes a notion of feature robustness which is invariant with respect to rescaling the weight. The authors discuss the relationship of this notion to generalization. There are many relevant work in this area that connect feature or weight robustness to generalization look at [1,2,3,4] for some examples. Instead they end up decomposing the test error to the sum of their robustness measure and the gap between robustness and test error which is trivial. I suggest authors to look at the literature on PAC Bayesian and compression based bounds to connect their suggested measure to generalization. When varying other things, the measure is not really correlated. [1] Dziugaite and Roy. ****************************After author rebuttals:Author have added discussion of related work which was missing in the original submission (thanks!).<BRK>The notion of feature robustness, which is a notion the paper proposes, connects the flatness measure to generalization error. One of the most relevant work will be [1]. It appears that the Fisher Rao norm [1] has several advantages over the proposed measure in the submitted paper. It is strongly encouraged to discuss the connections and comparisons with the Fisher Rao norm. However, the theoretical result is limited, and I do not think it provides clear connections of flatness and the local loss landscape. I think this paper is not ready for publication, and I keep my score.<BRK>I would encourage the authors to try and identify another model in which the flatness generalization relationship exists (even empirical evidence would suffice for now). The authors combine their notion of feature robustness with epsilon representativeness of a function to connect flatness to generalization. Atleast on CIFAR10 and MNIST it is possible to achieve training loss <1e 4 so am not sure if the networks that the authors are testing are minima at all (It is important for them to be minima since the flatness measure is only defined at minima). I am not so convinced about the theoretical justification that they claim to provide and thus do not recommend acceptance.
Reject. rating score: 1. rating score: 6. rating score: 6. <BRK>The main idea is to apply a bernoulli distribution on top of the regression values to convert them to work with binary classification problems. The inference can be done using numerical approximation and learning using variational methods and is still untracktable. The paper is incremental and doesn t really provide improvements to learning parameters (or at least there is no theory showing this in the paper). The experiments do not seem satisfactory as discussed below. It is not very clear when the GCRFBCb model would be better than the GCRFBCnb. b) The datasets (music classification and gene classification) don t seem to be good datasets for structured predictions i.e.the interaction needed between the nodes is not clear. c) There should be more thorough fine tuning of other models, for e.g.in the ski lifts experiment, the CRF does much worse than logistic regression in the results. This is most likely because the parameters were not initialized properly using normal tricks like using logistic regression. It would really help to make this paper stronger by showing the new modeling technique does better than CRFs (that are tuned properly) on better structured datasets. It would be good to have a discussion on when this model would do worse than the other structured models and why.<BRK>TITLEGaussian Conditional Random Fields for ClassificationREVIEW SUMMARYA well justified approach to structured classification with demonstrated good performance. Methods for inference and parameter learning are presented both for a "Bayesian" and maximum likelihood version. The method is demonstrated on several data sets. CLARITYThe paper could be improved by a careful revision with focus on improving grammar, but as it stands the paper is easy to follow. It is not clear to me exactly how the numbers in Table 1 were computed. Is this based on 10 fold crossvalidation as in the following tables? ORIGINALITYI am not familiar enough with the field to assess the novelty of the contribution. It would be great if the paper provided a better overview of competing structured classification methods.<BRK>The authors provide a method to modify GRFs to be used for classification. The idea is simple and easy to get through, the writing is clean. The method boils down to using a latent variable that acts as a "pseudo regressor" that is passed through a sigmoid for classification. The authors then discuss learning and inference in the proposed model, and propose two different variants that differ on scalability and a bit on performance as well. The idea of using the \xi transformation for the lower bound of the sigmoid was interesting to me   since I have not seen it before, its possible its commonly used in the field and hopefully the other reviewers can talk more about the novelty here. The empirical results are very promising, which is the main reason I vote for weak acceptance. I think the paper has value, albeit I would say its a bit weak on novelty, and I am not 100% convinced about the this conference being the right fit for this paper. The authors augment MRFs for classification and evaluate and present the results well.
Reject. rating score: 1. rating score: 3. rating score: 6. rating score: 6. <BRK>This paper proposes a method to capture patterns of “off” neurons using a newly proposed metric.<BRK>This manuscript introduces a novel method to explain activities of ReLU based deep networks by constructing a linear subnetwork which only contains neurons activated by the input. Overall, the proposed methodology is intuitive and distinctive to the state of the art interpretability methods.<BRK>This is not a small claim and is definitely in need of more evidence. The main drawback of the paper, however, is whether the contributions are enough for this venue. Anyhow, the experiment where they prove the usefulness of the method by adding background noise is interesting.<BRK>The question of interpretation seems rather thorny. Review: This paper proposes to improve the interpretation of relu based networks by considering the "inactive network" which could potentially become activated by local perturbations instead of just considering the active part of the network (which is locally linear).
Reject. rating score: 1. rating score: 3. <BRK>Authors suggest a method to solve multi objective optimization. The submission is interesting; however, its novelty is not even clear since authors did not discuss majority of the existing related work. Finally, more extensive experiments on existing problems comparing with existing baselines is needed. Hence, this is not the first of such approaches.<BRK>Learning weights for each objective by keeping the order as Pareto dominance is an interesting idea to me. Weaknesses  The lack of experiments. SummaryThis paper presents a new approach for single objective reinforcement learning by preferencing multi objective reinforcement learning.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>In this paper, the authors present an iterative approach for feature selection which selects features based both on the relevance and redundancy of each feature. both among the different methods and among the different folds for the same method. The Section 2 headers all have an unnecessary “0” in them (e.g., “2.0.1”). Table 1 should include the standard deviations. Major commentsThe paper does not include relevant, recent work on using autoencoders for feature selection, such as [Han et al., ICASSP 2018; Balın et al., ICML 2019], among others. Thus, it is difficult to discern how this paper either theoretically or empirically advances the state of the art. However, there is no theoretical justification for the approach. Thus, I would expect a thorough empirical analysis. The paper is not well written. However, the authors do not address these issues. If there are some implicit assumptions that the ranker model is a neural network, this should be made explicit; if not, the discussion should be revised (and, of course, non neural models should be used in the experiments). It would be interesting to explore more deeply how autoencoders with more capacity impact the results. Clearly, the relevance and redundancy scores could be weighted unequally when selecting the feature to remove. Including forward feature selection approaches would add useful context for how the proposed approach compares to other strategies.<BRK>The authors argue that it is important to consider the relevance of features for the considered supervised ML problem and redundancy of features. They propose the wrapper feature selection method based on this paradigm and report the results of the experimental comparison of the method with some approaches from the literature. The ranking of features based on the sensitivity of some supervised ML model with respect to the particular feature. 2.The ranking of features with respect to their individual impact on the accuracy of the autoencoder trained on the features of the training data set. The scores obtained on these 2 steps are added and the algorithm iteratively removes features with the lowest total score. I should note that the proposed approach is very general, but the paper gives very few details on the actual implementation. For example, one can use training or validation sets for that but the authors choose the training set without motivation. To sum up, I think that while the motivation behind the paper is very natural, I am not convinced with experimental results and the overall applicability of the approach.<BRK>This paper proposes a wrapper feature selection method AMBER to use a single ranker model along with autoencoders to perform greedy backward elimination of features. Experimental results on various datasets show that their criterion outperforms other baseline methods. Instead of selecting features with AMBER explicitly, a more straightforward way is using all features as input and solving the downstream task with deep learning model. Feature selection will be automatically conducted during the learning process. Is there any specific reason for including d 1 hidden neurons. It will be better if the author can give some theoretical analysis of it. Third, the author calculates the redundancy score and relevance score independently and combine them together to obtain the saliency score. For example, a feature can be both relevant and redundant. Should we eliminate it? How the proposed method solve this case?
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>The paper analyzed the adversarial examples from the Bayes optimal view. However, there are some drawbacks: 1. The motivation of this paper is not clear to me. I am not fully convinced by the presentation of the paper. 3.One minor point, it appears somewhat strange that “observations” were proved. However, CNN is a totally different model compared with the Bayes model (one is a discriminative model and the other is a generative model). For discriminative models, the decision boundary is related to local information.<BRK>The paper studies the adversarial robustness of the Bayes optimal classifier (i.e., optimal for the standard "benign" risk). To do so, the authors construct various synthetic distributions and show that in some cases the Bayes optimal classifier is also adversarially robust, while in other cases it is not. In the main experiment, the authors construct two high dimensional synthetic distributions of human faces via a generative model. In one of the distributions, even the Bayes optimal classifier is vulnerable to adversarial examples. Overall I find the experiment in the paper interesting, but it is unclear how representative the experiments are for adversarial robustness on real data. Hence I unfortunately recommend to reject the paper at this point and encourage the authors to deepen their experimental investigation. Is the probability given in (9) exact?<BRK>This paper proposes studying adversarial examples from the perspective of Bayes optimal classifiers. They construct a pair of synthetic but somewhat realistic datasets—in one case, the Bayes optimal classifier is *not* robust, demonstrating that the Bayes optimal classifier may not be robust for real world datasets. The contribution of the two datasets (the symmetric and asymetric CelebA) is, in my opinion, an extremely important contribution in studying adversarial robustness and on their own these datasets warrant further study. Previously, all studies of this sort had to be done with small scale classifiers and simplistic datasets such as Gaussians. While I think the datasets presented in this work are much more interesting and certainly more realistic, this work should be put in context. I believe a more measured conclusion (perhaps that we *need* more regularization methods, but even then we may not be able to get perfect robustness and accuracy) would better fit the strong results presented in the paper. CNN vs Linear SVM: I am confused about why we would expect a CNN to be able to learn the Bayes optimal decision boundary but not the Linear SVM.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>The proposed method is evaluated on guided content transfer, out of domain manipulation, attribute removal, sequential content transfer, sequential attribute removal and content addition, weakly supervised segmentation of the domain specific content. This work relates to the problem of content transfer between images. This last decoder also outputs a mask that focuses the attention of the model to the specific part. Ablation studies reported in the paper nicely show the contribution of each loss.<BRK>This work proposed a mask based approach for instance level unsupervised content transfer, which is an extension of the disentanglement work in (Press et al., 2019) and the attention guided translation (Chen et al., 2018, Mejjati et al., 2018). On the other hand, the proposed method extends the attention guided translation from the domain level to the instance level which allows more specific and diverse translations. It is really nice that the authors also considered the situation of generalization to out of domain images. I do not think this is the case. It would be good to show the sensitivity of the lambdas in the overall loss.<BRK>This paper proposes a method for unpaired image to image translation, where the target domain explicitly contains some additional information than the source domain. The authors empirically show the proposed method can be used for image translation, attribute editing. networkss  > networksIt is a published paper at ICCV, not just on arxiv.
Reject. rating score: 3. rating score: 3. rating score: 3. rating score: 6. <BRK>The authors present a randomization defense in the black box threat model, where bounded l_2 norm perturbations are allowed. I would check to make sure that the attacks are applied correctly here. In the presented scheme, the defender adds Gaussian noise to every coordinate of the output probability vector before returning an inference result. BAND performs worse than QL on the undefended classifier in Table 1, which should not occur.<BRK>This paper proposes to introduce randomness in a classifier’s predictions to mitigate black box attacks that rely on gradient estimation through finite differences. Because Figure 2 shows that the defense does not provide robustness in the white box setting, this suggests that other forms of black box attacks that either (a) rely on transferability or (b) are label based only would still evade the model.<BRK>This paper proposes applying randomization to the output layer of a DNN to defend against query based attacks based on finite difference estimates.<BRK>This paper presents a method for defending black box (in particular, finite difference based loss) adversary attacks by randomisation of the output of the network. A natural question that would be particularly interesting to me is how does such defence compare against the defence by  randomizing the input and the model. How would this differ if other types of distributions are considered, e.g.non Gaussian distributions? Regarding the novelty of this paper, I was based on my judgement and experience of reading a few papers, not I never published papers on adversary attacks or defence.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>This paper addresses security of distributed optimization algorithm under Byzantine failures. Focusing on the asynchronous SGD algorithm implemented with a parameter server, the authors propose to use stochastic line search ideas to detect whether the gradients are good descent directions or not. In the proof of Theorem 1, line 6, it is not clear to me why the gradient norm ||g||^2 is replaced by || grad f_s (x_tau) ||^2. Clearly the g comes from any worker which can be very different to grad f_s (x_tau). Therefore, I recommend the authors check the proof of both theorem 1 and 2 more carefully. However, this scenario is very limited to validate all imaginable Byzantine failures that this paper would like to address.<BRK>Summary:This paper investigates the security of distributed asynchronous SGD. Authors propose Zeno++, worker server asynchronous implementation of SGD which is robust to Byzantine failures. To ensure that the gradients sent by the workers are correct, Zeno++ server scores each worker gradients using a “reference” gradient computed on a “secret” validation set. If the score is under a given threshold, then the worker gradient is discarded. Authors provide convergence guarantee for the Zeno++ optimizer for non convex function. In addition, they provide an empirical evaluation of Zeno++ on the CIFAR10 datasets and compare with various baselines.<BRK>This paper proposes an approach to Byzantine fault tolerance in asynchronous distributed SGD. Theoretical convergence guarantees are provided, and an empirical evaluation illustrates very promising results. I realize that validation samples are never used explicitly for stochastic gradient updates, but the algorithm does ensure that the stochastic gradients used are similar to gradients of validation samples. The paper claims that the computational overhead of Zeno+ is too great to evaluate for comparison with Zeno++. Also, I was wondering, given that a gradient has been computed on the parameter server s validation set, which is assumed to be "clean", why not take a step using this gradient when the test in line 7 fails?
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>The ASRs being used for generating hypotheses can be either a model trained with the supervised data or the student model, and can switch between the two during training. In the experiments, ASR models are pre trained with the subset of Librispeech data and use the rest of Librispeech data as unsupervised data, and the LM is trained with Librispeech LM data. The paper relates their method to self supervised learning, yet I find it having stronger correlation with existing distillation approaches, and can be better understood through the distillation perspective.<BRK>This paper propose local prior matching to leverage a language model to use unlabeled speech data to improve an ASR system. This is a worthy goal. The details of the proposal were a bit hard for me to understand. I encourage the authors to condense 2.2 and make it clearer what, exactly, Local Prior Matching is. The paper presents extensive, interesting results.<BRK>Overview:This paper is dedicated to proposing a self supervised objective, local prior matching (LMP), for speech recognition. The motivation that the source of indirect supervision on processing unlabeled speech comes from prior knowledge about the world and the context of the speech makes sense to me. The author combines the Bayesian method to build the model which is aligned with the motivation. The paper only evaluates their method on LibriSpeech dataset. Although this dataset is popular, one or two more datasets will be more convincing. 3.For the experiment between the amount of unlabelled data for self supervision and final performance, it would be better the author can provide a curve with more results. The proposed approach is useful. This is a weak accept.
Reject. rating score: 3. rating score: 3. rating score: 3. rating score: 6. <BRK>This paper proposes a low rank training method targeting for edge devices. The main contribution is an algorithm called Streaming Kronecker Sum Approximation. However, I found they are not that accessible and hard to understand. (2) The novelty of the algorithm is limited. For such a paper concerning training on edge devices, I would expect to see some experiments on real edge devices.<BRK>This paper proposes a low rank training schema that helps mitigate some of the critical challenges that occur during training models on NVM memory based edge devices. +ves:+ Training on an edge device is a relevant setting, where there is very little work so far, and this is a useful objective. POST REBUTTAL COMMENTS I thank the authors for the rebuttal. The paper does not talk about this.<BRK>This paper proposes a low rank training method called the Streaming Kronecker Sum approximation (SKS algorithm) for training low precision models on edge devices. The main weakness of the paper seems to me limited experimental results   they mainly show improvements for CNNs on MNIST. Overall, I recommend acceptance based on the thoroughness of the work and the authors open sourcing their code which would additionally help with reproducibility of their results.<BRK>This work presents a new online training scheme which is amenable to non volatile memories and particularly applicable to smart edge devices. Disclaimer: I am far from an expert on this domain, so my review is not very well calibrated or informative. The new contributions of this paper are to use a running estimate of Q_L, Q_R and weightings using modified Gram Schmidt. Experiments seem to show the proposed benefits but are done with artificial models/simulations. Would it be easy to implement this on chip and try it on actual hardware?
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>Overall, the paper presents a well designed system for handling multi hop queries and the explicit recurrent state is a nice contribution and addition to the IR model proposed in Godbole et al., 2019. The paper mentions that it studies the interplay between the retriever and reader.<BRK>The paper is proposing a multi hop machine reading method tested on hotpotqa in the Full Wikipedia setting and squad open datasets.<BRK>Summary This paper introduces a graph based recurrent retrieval model for retrieving evidence documents in a multi hop reasoning question answering task. Is it the question? Overall Comments The paper is an interesting, but incremental, improvement to the area of question answering. The main idea is that (1) the graph formed by Wikipedia links between passages can be used as constraint for constructing reasoning chains, and (2) the joint encoding of the question and current passage can be used to retrieve a subsequent passage in the reasoning chain.
Reject. rating score: 6. rating score: 6. rating score: 6. <BRK>This paper introduces MissDeepCausal method to address the problem of treatment effect estimation with incomplete covariates matrix (missing values at random   MAR). It makes use of Variational AutoEncoders (VAE) to learn the latent confounders from incomplete covariates. This also helps encoding complex non linear relationships in the data, a capability that is missing in the work of Kallus et al.(2018)   the work which this paper extends. In summary, I am not convinced that the contribution of this paper is enough, nor of its novelty. However, I will read the rebuttal carefully and am willing to increase the score if the authors address this concern. 2, last line: state of the art method”s”	  Page 3, under Unconfoundedness par., line  7: [...] for each observation “comma” treatment assignment [...]	  Page 3, Figure 1: According to ICLR’s formatting guidelines, the figure number and caption must always appear after the figure. Mattei, P. A., & Frellsen, J.<BRK>I recommend the authors to elaborate on this point in the camera ready version. But having matched an existing baseline (the MF method) that deals with confounders on real data and showing superior synthetic results and authors clarifying and toning down their theoretical claims, I am inclined to increase the score to Weak accept. In this paper, the authors want to consider general non linear relationships between Z and X with the same MAR (missing at random assumption) for missing entries. For missing entries, they just replace those entries by a constant and do the usual VAE fit. There is no reason to suppose Z s used in eq (9) from the VAE satisfy ignorability even in the asymptotic limit. In this light, the paper in essence just estimates Z s from some latent model that is fit and then use those latents to regress Y and then computes ATE. I would be willing to increase my scores if the authors could convince me on this point. So the only demonstrated benefit is for the synthetic experiments for Fig 5 and Fig 3 (I agree that it is considerable particularly with large fraction of missing values in Fig 3) in whose settings we dont know about how unbiased it is in the limit. Does variance go down or the bias itself changes with B    This would be a useful insight to have. What does this mean ?<BRK>This contribution considers deep latent factor models for causal inference  inferring the effect of a treatment  in the presence of missing values. As a consequence, it requires the missing at random assumption to control for the impact of imputation. Given that the confounders are not directly assumed, a first approach estimates their effect via an estimate of P(Z|X*)  (probability of confounder given observed data), which is then plugged in the doubly robust estimator in a multiple imputation strategy. I do not have many comments. This is to be contrasted with other approaches compared to. How was the specific architecture and learning strategy of the VAE selected? The simulation settings are somewhat artificial.
Accept (Talk). rating score: 8. rating score: 8. rating score: 6. <BRK>The detailed comparison with baselines on the full Atari suite is sufficient to back the claims in the paper that the strengths of BMI and SFs do complement each other. Decision:I vote for accept as this paper proposes a novel technique to combine mutual information based intrinsic control objectives with successor features, which allow for combining the benefits of both in a complementary way.<BRK>The proposed paper ameliorates the need of defining the reward function as linear in some grounded feature space by resorting to variational autoencoder arguments. This is a valuable contribution to the field.<BRK>To address this specific setting, the authors propose to use the successor feature representation of policies and combine it with methods that estimate policies in the unsupervised setting (without a reward function) by maximizing the mutual information of a policy conditioning variable and the agent behaviour. Clarity:I think this is one of the weaknesses of the paper. Novelty:The proposed approach is novel up to my knowledge. This work would benefit from similar simpler and easier to understand synthetic environments (unlike ATARI). Significance:The proposed contribution seems significant as illustrated by the experimental results and the novel methodological contributions. Therefore, I have decided to update my rating and vote for acceptance.
Reject. rating score: 1. rating score: 1. rating score: 3. <BRK>The authors propose to use the final features produced in the last feature extractor layer of DNN as features for KNN and choose K such that the performance of KNN is closest to the performance of DNN. Below  are some other minor problems:The introduction/title of the paper claims this is a general approach for any model but the authors  focus is only on DNN. This should be corrected.<BRK>First, the contributions are not enough for this venue. I vote for rejection of this paper mainly because of two reasons. All data points contribute value to the feature learning part and the approximation simply ignores this crucial fact. The valuation methods serve as valuation methods which the introduced method, although providing " a valuation method", is not providing an unbiased estimate of the equitable Shapley value valuation method.<BRK>In this paper, the authors have developed an algorithm to estimate Shapley value with complexity independent of the model size, based on the KNN classifier. The authors argue that it is both fair and decomposable (linear in U).
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>The topic addressed by the paper is domain adaptation and transfer learning in the text context of deep reinforcement learning, in particular the “sim2real” problem, where a policy is learned in simulation and should be transferred to a physical agent in a real world scenario. The evaluation is unfortunately not convincing. In Pinto et al., this is addressed by learning an actor taking as input observations, and a critic which has access to the state. Another downside is that, although sim2real is used as a motivation for this paper (since this is the most typical scenario where states are available during training but not during testing), the experiments have not been performed using physical agents. Testing is performed on degraded simulated agents. The problem is that the state is very different from the observations, which are images. The Walker 2D environment is described as “modified”, but how exactly, and why? Here, the authors claim that the observation module itself is asymmetric … but how can something by asymmetric if it contains only an actor?<BRK>The paper operates in a settings where the policy to be transferred only has access to observations   images, etc   and not the complete underlying state of a (simulated) environment. The authors generally do a good job of motivating the proposed approach by leveraging access to privileged information in the environment / simulation / renderer during training to get more robust observation policies to transfer to novel settings. The proposed approach is presented after appropriately grounding the problem setting and preliminaries and the authors clearly state and evaluate on the axes of research questions they care about. This, combined with the fact that major gains have only been demonstrated over the specified continuous control domains (ignoring the Atari results), makes me slightly concerned about the scalability of the proposed approach in terms of more real world + applicable domain transfer scenarios. Can the authors comment on this? I’m curious how important is it for the state based attention to be sparse? I would be curious to see how well does APRiL compare to such approaches in a setting where both are applicable   say the MultiRoomNXSY set of experiments in InfoBot (pointed above).<BRK>As well, the work talks about how this method can be used to accelerate learning for transfer to real robotic systems but does not have an example of this. This is a very simple method and appears to accomplish the goals for the authors. How would this method work on the walker 3d where there is even more partial observation? It is not very clear. I do not see this. Where do the segmentation maps come from? Is it just more objects in the scene? There does not appear to be a significant improvement? Can you show more of a qualitative improvement via videos of the policy performance? Where do you get the compressed state information? Can you describe specifically how this experiment is designed? How do the distractors compare to the other objects in the scene? How many are there?
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>The paper introduces a model trained for video prediction hierarchically: a series of significant frames called “keyframes” in the paper are first predicted and then intermediate frames between keyframes couples are generated. The probabilistic model (section 3.1) is relatively clear, even if it could be improved. The proposed model is new and the authors introduce some clever ideas in order to train it.<BRK>The problem is interesting and well motivated, but I have some concerns with the proposed approach and experiments. Is it guaranteed that all of the needed keyframes will actually be within the first T timesteps? The authors do not compare their method to any strong keyframe prediction baselines. Why does the model trained to learn a fixed number of timesteps for the intermediate frames? If they tried that approach and it failed, maybe that should be mentioned in the paper (with an explanation as to why it fails).<BRK>Starting with the kinds of data that have been used recently in video prediction, the authors aim at learning a sequence of keyframes (i.e., subsets of frames forming the overall sequence) that in a suitable sense "summarize" the overall trace. The technical approach is to pose the problem as one of inferring the temporal location of each of these key frames and then to interpolate with a model to generate intermediate frames. I feel the paper is taking on the right kinds of questions, looking for ways to inject the right kind of structure. I do have some concerns about the overall formulation:1. In realistic images it is likely that the total number of keyframes selected by such an algorithm is much larger due to extraneous events. The paper would really be much stronger if these were addressed.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>The authors propose a way to anneal the truncation of the inner iteration, and investigate a quantity to represent the suboptimality of the truncation. Strengths:  (From Table 3), the method is competitive with adversarial training (PGD; Madry et al.(2017)) as well as an improved method for adversarial robustness (FOSC; Wang et al.(2019)), while requiring half the computation time. The writing is very clear. It is unrelated to the optimal control formulation. Some experimental details are missing. How was the number of iterations for the PGD attack (40) selected? Why was the iteration count of the PGD attack not varied?<BRK>This paper proposed an annealing mechanism for PGD adversarial training in Madry et al.This mechanism gradually reduces the step size and increases the number of iterations of PGD maximization. The authors choose to fix the total step length of PGD. Is this a heuristics? I like the optimal control formulation in 2.2 and 2.3.<BRK>This paper proposes a simple modification for adversarial training in order to improve the robustness of the algorithms. This paper proposes a simple modification to the PGD that is being used in the inner loop. The proposed modification involves the increasing the number of adversarial training steps and decreasing the adversarial training step size gradually as the training proceeds. Significant improvements in terms of training times. This field is still new not every reader might be familiar with the optimal control theory or the common notation that is being used there. Experiments are only on small scale toy datasets like CIFAR10 and MNIST.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>There have been several works using deep generative models to temporal data, and the proposed method is a simple combination of well established existing works without problem specific adaptation.<BRK>The paper proposes a new intensity free model for temporal point processes based on continuous normalizing flows and VAEs. However, I found the presentation of the new framework and the associated contributions somewhat insufficient. The proposed approach seems to consist mostly of applications of existing techniques and of only few technical contributions. While each of these points on its own would not be very severe, I found that the combination of all of them is problematic in the current version of the paper. [1] Xiao et al: Wasserstein Learning of deep generative point process models, 2017.<BRK>The authors propose a method for learning models for discrete events happening in continuous time by modelling the process as a temporal point process. To further increase the expressive power of the normalizing flow, they propose using a VAE to learn the underlying input to the "Flow Module". The writers have put their contributions in context well and the presentation of the paper itself is very clear.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>The topic of the paper is the inductive bias of neural networks. The authors study a simple model, namely a perceptron with no bias term viewed as a mapping from {0,1}^n >{0,1}. They also exhibit empirical evidence that by adding a bias term, or by using multiple layers, this tendency towards low entropy appears to increase. Finally, they prove a result that suggests that for ReLU networks with infinite widths the bias towards low entropy function does indeed increase with depth. My main concern regarding this paper is that the claim in the title and the statement of Theorem 4.1 seem to rely crucially on the fact that the functions are viewed with input as {0,1}^n. If one switches to a symmetric domain, for example { 1,1}, the effect in this setting completely disappears. However, this to me suggests that Theorem 4.1 is not capturing any significant aspect of neural networks (in fact, the statement is a property of how linear hyperplanes to separate {0,1}^n, not neural networks). Another concern is related to Theorem 5.5. This might be a more substantial result, but it is difficult to interpret and its implications are not discussed. The paper is well written but not always very clear. * Definition 3.6: some context or references for this definition could be useful. Assuming the distribution of w/|w| is uniform on the sphere, a more precise description of  P(f) seems possible* Section 4.3: what is the "rank" in this setting?<BRK>This paper studies the a priori bias of a feed forward neural network when the weights are initialised uniformly at random and independent of the network architecture. The paper claims that this initialisation leads to biases towards low entropy functions when the input and output are binary values. The proposed approach seems rigorous, but I have a hard time to follow the paper as many of the important results are presented in appendix. In addition, the analysis is based on a feed forward neural network with binary inputs and a single binary output, it is not clear whether these results can be generalised to architectures of practical importance such as convolutional/recurrent neural networks. Overall an interesting piece of work that contributes to the understanding of deep neural networks.<BRK>The authors study the behavior of simple neural networks at initializations. Further, the authors show that how such conclusion would be reached with or without a bias term, with different number of hidden layers, with change of activation functions. The work is fairly interesting, yet the motivation is less clear. Despite that neural networks at initializations are biased towards low entropy functions, it’s not clear with training on a dataset with an optimizer, how much we can conclude about the generalization power. Below are some more detailed comments:1) In the Introduction and the first paragraph of Section 2, the authors motivate by describing how important it is to understand the inductive biases. 2) In Figure 3(a), 4(b,c,d), there is a spike at the mid point of t. Though not as high as the extreme points, this is contradictory to the main conclusion.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>This paper studied the problem of universal adversarial attack which is an input agnostic perturbation. The paper is generally well written and easy to follow. I would suggest the authors to compare with several mentioned baselines in the paper to show the superiority of the proposed method. Also regarding the choice of \delta, it seems that \delta is different for different x? Directly applying the Theorems seems to get \epsilon / (\gamma) only?<BRK>I would suggest using tables to give a clearer comparison. The idea of this paper is intuitive but I feel that it is highly related to the one in Khrulkov & Oseledets (2018). "Defense against universal adversarial perturbations."<BRK>It is not clear to me how the authors build the matrix corresponding to the universal invariant perturbations in sec 6. The paper gives a theoretical justification of their method using matrix concentration inequalities and spectral perturbation bounds. I also like the observation and the generality, simplicity, and theoretical proof of the proposed universal attack algorithm SVD Universal.
Reject. rating score: 3. rating score: 3. rating score: 3. rating score: 6. <BRK>The paper adds an interesting new perspective to equivariant neural nets. However, the actual construction looks equivalent to steerable neural nets to me (see the papers by Cohen and Welling). The authors mention that Z^{\times G} is not the only possible lifting space. I believe that the general case would be Z^V where V is a representation of G. Many of the earlier papers on equivariant nets were written in the language of representation theory. Consequently, I would expect all the experimental results to be identical. What would make this paper really valuable for didactic purposes is if these connections were carefully mapped out and presented with intuitive diagrams and examples.<BRK>In this paper, the authors propose a method for making a neural network equivariant. Their method also can be applied to make each layer equivariant too. The novelty of the work is questionable. While the development is different, the final example for equivarification of a neural network is very similar to the existing works by Cohen and Welling. There are other works on equivarification that are missed by this paper. The layer wise equivariant method does have extra computational overheads. The fact that we have to specify the groups that we want to make the network equivariant with respect to is a limitation. The promise of capsule networks, in contrast, is to "ideally" learn the pose (variation) vectors in a data driven way.<BRK>Motivated by group action theory, this paper proposes a method to obtain ‘equivariant’ neural nets given trained one, where ‘equivariant’ refers to a network that gives identical output if certain symmetry of the dataset is performed on the input (for example, if we rotate a sample the predicted class should not change). Could the authors elaborate on this? After reading this section, I don’t understand the proposed fine tuning procedure (pre train, finetune and test): (1) what is the accuracy of the pre trained network that was started from? page 8, conclusion: The authors claim that the proposed approach yields a ‘significant reduction in the design and training complexity’. After reading the paper I don’t understand how such a network can be implemented and whether it works.<BRK>In this work, the authors employ concepts from group theory to turn an arbitrary feed forward neural network into an equivariant one, i.e.a network whose output transforms in a way that is consistent with the transformation of the input. Should it be ‘a map from X to ..’? Based on these shortcomings, I recommend rejecting the paper but I would be willing to increase the score if these points were addressed in sufficient detail. The authors briefly comment on this point with one sentence in the third paragraph of the introduction. Is this by construction? 3) LimitationsAs indicated in the second paragraph of Sec.4, this approach is limited to finite groups and the authors only consider image rotations w.r.t.the cyclic group of degree 4.
Reject. rating score: 3. rating score: 6. rating score: 8. <BRK>Statistical tests are presented to check the stationarity of the gradient updates. Another procedure for how to decrease the learning rate is proposed using a stochastic line search. Indeed quadratic forms are good local approximations for any general function. Typos: "Pflug also a devised"  > "Pflug also devised". The current version is significantly over length (by more than 1 page).<BRK>The authors explore how stationarity tests can be leveraged to automatically tune the learning rate during training. Their algorithm also add a robust line search algorithm, to reduce the need to tune the initial learning rate.<BRK>This paper proposes a new way of automatically scheduling the learning rate in stochastic optimization algorithms: Stochastic Approximation with Line search and Statistical Adaptation (SALSA). By first introducing a necessary condition for stationarity, the authors use this condition to make a simple statistical test for non stationarity. At this stage, the learning rate is assumed to be optimally initialized for the objective function considered. Second, it manages to relax the dependence of SASA algorithms on their optimal initial learning rate by introducing a Smoothed Stochastic Line Search (SSLS) algorithm that is responsible for finding such an optimal initial learning rate.
Reject. rating score: 3. rating score: 3. rating score: 8. <BRK>This paper proposes a modification of RNN that does not suffer from vanishing and exploding gradient problems. The proposed model, GATO partitions the RNN hidden state into two channels, and both are updated by the previous state. This model ensures that the state in one of the parts is time independent by using residual connections. However, the paper itself is not ready to be published.<BRK>In this paper, the authors propose a novel recurrent architecture called GATO. Empirical results show GATO can outperform LSTM and RNN in both synthetic datasets and real datasets. The key insight of the proposed model is that only part of the hidden states is recurrently updated. GATO summarizes the hidden states r_t by recurrently adding (transformed) r_t to s_t. This limits the novelty of the paper and thus make the contribution marginal. As for the experimental studies, the authors only provide comparisons with LSTM and GRU. It would be more convincing if the authors could include these models into comparison.<BRK>The paper proposes a new RNN architecture designed to overcome vanishing/exploding gradient problems and to improve long term memory for sequence modelling. The main ideas are (i) to split the hidden state into two parts, one of which does not influence the recurrence relation, and can therefore not blow up or contract by self feedback; and (ii) to use periodic functions, in particular the cosine, as non linearity in the decoder, so that the output is bounded but does not saturate. So there are in fact no empirical results, not even on toy data, for the general case that the paper claims to introduce. While the numbers clearly support GATO, it would have been nice to look a bit closer and pinpoint what makes the difference. In fact, it could even be that the task is just simple, so that more restricted model with fewer parameters generally perform better   I do not claim this is the case, but the experiments do not rule it out and, hence, do not confirm that the clever GATO recurrence makes the difference. This is one of the more convincing RNN papers I have recently read.
Accept (Spotlight). rating score: 8. rating score: 6. rating score: 6. <BRK>This paper examines head direction representations in a RNN. The RNN was trained to report current head direction using initial head direction and angular velocity information as inputs. The authors compare the representations in the RNN to the representations found in the head direction systems of mice and flies. They find that the representations and connectivity matrices of the RNN recapitulate many aspects of the real brains’ head direction systems. These cells tile the space in a functional torus structure, as revealed by t SNE, which resembles the structures seen in real brains. In my opinion, it also suggests that information about the structure of brains could inform strong priors for ANNs. I think this is a great paper. It should be accepted in my opinion. Fig S8 isn’t that much bigger, why not just make it Fig.3?<BRK>## OverviewThis paper studies whether a recurrent neural network trained to solve a particular task (integration of angular velocity to generate head direction). However, my understanding is that many biological neurons have tuning properties that are hard to classify, perhaps the discarded neurons could map on to these previously uncharacterized neurons? It would be even more compelling if, wherever possible, these comparisons were made to be quantitative. However, since the labels extend across many panels, it looks as if the panels themselves are organized according to angular velocity and head direction, which doesn t make sense.<BRK>They then investigate the tuning properties of the units in the RNN, and the connectivity between units, and make comparisons to the corresponding systems in the fly and rodent. Shifter cells are also observed, that integrate angular velocity cues and "shift" the representation of head direction: these show an intuitive asymmetric connectivity profile. I can t quite decide what to make of this paper. One the one hand, the recapitulation of the biological circuit in the RNN is fairly compelling. I have a few specific suggestions:1) It would be useful as a comparison to duplicate the analysis of unit tuning, connectivity, etc., in untrained networks. Is it all of them? Based on some previous work with feedforward nets (arXiv:1803.06959 [stat.ML]), I d guess that the function could be seriously degraded by removing nonselective units.
Reject. rating score: 6. rating score: 6. rating score: 6. <BRK>I understand that a big benefit is that test time training does not need to see the entire distribution (unlike standard domain adaptation approaches). My rating edit comes from the realization that the performance improvements obtained are almost entirely from the "online" version, which gets to see the test distribution. b) The discussion in Appendix A seems a bit speculative and opinionated. How were those chosen?<BRK>Accordingly, the title of the paper inaccurately reflects of the claim of the paper and is misleading, this paper is not on learning with out of distribution instances. The other important point is about catastrophic forgetting phenomena in online setting of their approach, which was not addressed thoroughly in the paper. How not to forget what the model has previously learnt a test time training? The main idea is fundamentally simple, but it is still difficult to get it from the text. ** Update ** I read other reviews and comments. The answer of the authors to my comments are somehow satisfactory, especially the point of changing from "out of distribution" to "domain shift", which avoid some confusion.<BRK>The paper proposes test time training, a method that uses an auxiliary task to provide a kind of loose supervision during test time. I would be more so inclined if the authors could provide a reasonable categorization of tasks where this method is expected to be applicable. I m not sure I totally believe that this is a method of out of distribution generalization, but rather it helps adjust for corruptions and modest dataset shifts which is an important problem itself. My main problem with this paper is that the more fine tuned labels get (like the density of a tumor), the harder it gets to create auxiliary tasks.
Reject. rating score: 1. rating score: 1. rating score: 3. <BRK>This paper proposed to use KL and reversed KL as its new objective function for text generation GAN training. However, this paper missed a lot important references. Also, KL + reversed KL training method for GAN framework is first proposed in Symmetric VAE (https://arxiv.org/abs/1709.01846), and the Proposition 2 basically are the same as the Symmetric VAE paper.<BRK>This paper introduces a GAN based text generation approach, where the authors propose to directly optimize a weighted version of JSD replacing p_data with its empirical distribution. How does it control the balance between forward and reverse KL? 3.Is there evidence that \pi is controlling the tradeoff between quality and diversity? Given that both the theory and the empirical results are not solid in the current version, I intend to reject the submission.<BRK>This paper provides a method (loss function) for training GAN model for generation of discrete text token generation. The aim of this loss method to control the trade off between quality vs diversity while generating the text data.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>In this paper, the authors propose a strategy for neural architecture search. To be clear, the authors  method is clearly an instantiation of model based optimization. However, much of the paper is arguably written as though this needs to be invented from first principles. Much of the discussion contrasting arbitrary action spaces with handcrafted ones are somewhat lost in the actual experimental setup: For example, the ConvNet 60K and LSTM 10K datasets have well specified parameter spaces. The use of tree models for model based optimization have been considered before (e.g., SMAC), although the MCTS acquisition with a single tree surrogate is novel as far as I am aware.<BRK>The paper proposes LaNAS which is based on an MCTS algorithm to partition the search space into tree nodes by the performance in the tree structure. The performance of the method is shown in the NASBench 101 dataset and Cifar 10 open domain search. However, as far as I know, the MCTS approach for the NAS problem is not a standard solution for NAS (which is not proved to be practically useful in other people’s papers) which diminishes the contribution of the improvements of MCTS in NAS. For the motivation of the proposed method, the authors mention the drawbacks of other NAS methods used fixed action space in their RL or MCTS module. However, the authors only show that using a learned action space in MCTS is better than a fixed MCTS algorithm in the experiments. Some important explanation of the methods is missing. Otherwise, people cannot use it.<BRK>The paper describes a new neural architecture search method based on monte carlo tree search that dynamically adapts the action space. Those two stages are iterated with new incoming data. The paper proposes an interesting approach which achieves competitive results compared to state of the art methods. However,  I haven t fully understood  how the model space is divided at different nodes. Further comments:  Figure 4 a and b seemed to be flipped? Could you also include other Bayesian optimization methods, such as SMAC or TPE, which should competitive performance on NASBench101 and do not suffer from a cubic scalingpost rebuttal I thank the authors for performing additional experiments and clarifying my questions.
Reject. rating score: 1. rating score: 1. rating score: 3. <BRK>This paper suggests that the logits cary more information than the maximum softmax probability for OOD detection. They suggest this with scatterplots and develop techniques to support this claim. The authors should include an evaluation on CIFAR 100 for completeness. Small comments:Table 3 is a comment about featurization. Does this hold when taking the log of the softmax probabilities (not the same as logits)? The information should be contained in one location.<BRK>SummaryThis paper showed that out of distribution and adversarial samples can be detected effectively if we utilize logits (without softmax activations). It would be better if the authors can provide the reason why softmax activation hinders the novelty detection. The logit based detectors proposed in the paper are simple variants of existing methods.<BRK>The paper is mostly empirical following this specific observation, and uses a number of examples on MNIST and CIFAR to show the improvement in performance by using unnormalized logits instead of softmax. While interesting, it is to be noted that methods such as ODIN and temperature scaling specifically include a temperature to exactly overcome this same issue with softmax. The lack of comparison to such baselines makes this paper quite incomplete, especially as it is an empirical paper itself.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>This paper proposed another graph embedding method. It focuses on directed graphs, and it embedded the graph nodes into exponential power distributions, which include the Gaussian distribution as a special case. The method is implemented by optimizing with respect to the free distributions on a statistical manifold so as to achieve the minimum distortion between the input/output distances. For example, page 3, what is "a good proposal function"? Theorem 1 (2), mention the Fisher information matrix is wrt the coordinate system (\sigma^1, \cdots,\sigma^k, \mu^1, \cdots, \mu^k)Ideally, the experiments can include an undirected graph and show for example that the advantages of the proposed method become smaller in this case.<BRK>This paper proposes an unsupervised method for learning node embeddings of directed graphs into statistical manifolds. They also introduce a natural gradient correction to the gradient descent algorithm in this setting. The paper appears to bring a valuable method for directed graph embedding. Moreover, I suggest that the authors work on an improved version of the manuscript, as it contains many grammatical and spelling mistakes, some of which listed under. Could the authors provide a more principled validation approach to their experiments, e.g.using cross validation?<BRK>In this paper, the authors proposed an embedding method for directed graphs. A scalable algorithm is designed. Behaviormetrika 14.21 (1987): 81 96.” This method represents each node in a directed graph as an embedding vector with a radius and proposed a Hausdorff like distance. b) The recent work in [35]. This method also embeds nodes by elliptical distributions, but the distance is measured in the Wasserstein space. Besides the classic statistical measurements, I would like to see a down stream application of the proposed method, e.g., node classification/clustering.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>This paper presents a general approach for upper bounding the Lipschitz constant of a neural network by relaxing the problem to a polynomial optimization problem. And the authors extend the method to fully make use of the sparse connections in the network so that the problem can be decomposed into a series of much smaller problems, saving large amount of computations and memory. This paper also compares the proposed LiPopt method with another solution derived from a quadratically constrained quadratic program reformulation. I also like that the authors present results on networks trained on real world dataset (MNIST).<BRK>The authors study the problem of estimating the Lipschitz constant of a deep neural network with ELO activation function. The computational results are clearly not sufficient to apply this approach to real world neural networks, but are still respectable. The authors could cite, e.g., JB Lasserre: Convergent SDP relaxations in polynomial optimization with sparsity (SIAM Journal on Optimization, 2006), as one of the early proponents of the exploitation of sparsity. In Section 7:  The claim "We observed clear improvement of the Lipschitz bound obtained, compared to the SDP method" is not supported by the results the authors present. The authors do not present the run time. This needs to be included, considering they imply that the key improvement over the traditional SDP is that this works with smaller variables and should be faster. The presentation of the experimental results should be improved, so as to follow the NIPS reproducibility checklist, or at least have error bars at one standard deviation and standard deviation in the table. Other than that, the paper is well written (modulo Section missing in "Section 5" at the top of Section 7), and I would recommend its acceptance.<BRK>In this paper, the authors introduce a framework for computing upper bounds on the Lipschitz constant for neural nets. Through experiments, the authors show that the proposed algorithm computes tighter Lipschitz bounds compared to baselines. The approach proposed in the paper looks interesting. I found the proposed algorithm and the discussions in Section 2 and 3 interesting, although I am not familiar enough with the literature on polynomial optimization to evaluate whether there is any significantly new idea presented in these sections. I found section 4 very interesting too, and very important towards making the algorithm actually computationally tractable. I have a couple of concerns with the rest of the paper however, which `I describe below:1. It is nice that upper bounds for the local Lipschitz constant can be incorporated easily into the formulation. I would have liked to see some experiments on evaluating local Lipschitz constants though, and how they compare with other methods, since this is a very popular setting in which such techniques are used nowadays. 2.The paper overall I think would benefit from a better experimental evaluation. It would also be interesting to see how the bound degrades as the network grows bigger, and in particular as the depth increases.
Reject. rating score: 1. rating score: 3. rating score: 3. rating score: 3. <BRK>This paper proposes a categorization of inner layer weights to be linearly or non linearly correlated with the output. The motivation on why this is important is somewhat weak in the paper. The experiments are not convincing. But I did not see that happening here. Happy to be proved wrong by the authors or other reviewers if I am missing something here.<BRK>Summary: This paper proposes a novel architecture that is able to separate different types of features learned at each layer of a neural network through a gating structure   features that are sufficiently passed through the network are immediately sent to the final output layer. As an example, in the SENN paper, they utilize breast cancer and COMPAS but these were not tested on this architecture.<BRK>This paper proposes a feature leveling technique to improve the self explaining of deep fully connected neural networks.<BRK>This paper proposed a neural network architecture to separate low level features and high level features. The model can be interpreted by the weights associated with each of those k th level features in the final GLM layer.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>This paper study the problem of editing sequences, such as natural language or code source, by copying large spans of the original sequence. This method can be improved by adding a copying mechanism, based on pointer networks, to copy tokens from the input. The problem studied in the paper   copying spans from the input   is interesting, and has applications in NLP or code generation. I think that the the proposed solution is technically sound. However, I have some concerns regarding the paper. The body of work on iterative refinement for sequence generation is also probably relevant to this paper [5,6].<BRK>In this work, the authors tackle the problem of span based copying in sequence based neural models. which only allow for single token copy actions. Their span based copy mechanism allows for multiple tokens to be copied at a time during decoding via a recursive formulation that defines the output sequence distribution as a marginal over the complete set of action combinations that result in the sequence being produced. The authors evaluate their model on four tasks: code repair, grammar error correction, editing wikipedia, and editing code. They also show that the efficacy of their proposed beam decoding mechanism and do some simple quantitative analysis that the model learns to copy spans longer than a single token. In general, I found this paper to be very clearly written with very good motivation for the proposed solution. For example, the model consistently outperforms simple copy seq2seq baselines as well as the baselines in which the benchmark datasets were proposed (Tufano et.al, Yin et. al.)However, it does not seem the span based copying method is state of the art. I would like to see a more formal treatment of the run time of the training marginalization operation. 2) It would be nice to see a quantitative analysis for distribution of sequence lengths copied over (like some sort of histogram) for the datasets.<BRK>This paper proposes a new decoding mechanism that allows  span copying which can be viewed as a generalisation ofpointer networks. one advantage of this proposed model is that it doesn t need to copy word by word to update sequences which need minor changes, rather than the seq2seq model with copy actions which due to the way we train those models using NLL loss will likely assign high probabilities to the non modified input. Cons:   One of the drawbacks of this method is the decoding strategy although authors present a motivated solution for that. Experiments could have been more thorough, especially in terms of architectures.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>Contributions:The main contribution of this paper lies in the proposed Residual Energy based Model (EBM) for text generation. a) One of the main results is Table 1, which reports all the PPL numbers. Strengths:(1) Writing & Clarity: This paper is well written, easy to follow, and clearly presented.<BRK>I suggest to polish the main text incorporating these clarifications. Residual EBMs are defined and trained using NCE. The first version of the paper clearly lacks in this respect.<BRK>As mentioned in Section 5, this approach heavily depends on a strong pretrained language model. This should be mentioned in Theorem 1. Based on other reviews and the authors  response (especially review #3), I reduced my rating to  Weak accept . To compute the perplexity, they have given an upperbound and lowerboud for the partition function based on number samples in Theorem 2, but I haven t checked the correction of the bounds.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>In this paper, the authors tried several metrics, from which they pinpoint one as the indicator to select a pretrained model without practically fine tuning. Therefore, the proposed metric(s) and settings in the current shape are not that practical. Pros: 	In this work, the authors focused on an important problem – selecting the best pretrained model from a zoo of models without finetuning all of them in a brute force manner. The idea of applying the metric(s) to select a layer from which the consecutive layers are truncated is intriguing, for the sake of model compression. The experiments are not comprehensive, so that the conclusions drawn are weak and untenable. The writing with many grammatical errors and typos definitely needs polishing. This is paradox, in my opinion.<BRK>This paper aims to speed up finetuning of pretrained deep image classification networks by predicting the success rate of the process without running it. The authors suggest running samples from the target task on the (trained) source model, and computing a few sensible measures from the final output layer which indicate how well the trained features are separating the target images. However, neither did this paper.<BRK>The authors propose several metrics to evaluate the transferability of pretrained CNN models for a target task without actually fine tuning the networks to accelerate fine tuning. The paper has done some interesting empirical studies on how to predict the transferability of a neural network. In this perspective, the paper is novel. First, there is no clear relationship between the six evaluation metrics and the fine tuning performance. Second, some of the proposed metrics (S1/S2) are actually closely related with weight norms.
Accept (Poster). rating score: 6. rating score: 6. rating score: 3. <BRK>The two key insights of the proposed method is 1) to learn the weights of a t shaped kernel when performing novel view synthesis, and 2) to estimate and use adaptive dilations on those kernels. “demonstrate”  p. 2 “is open known to be a much more complex problem”: I think the authors meant either “is known to be a much more complex problem” or “is still an open problem”?<BRK>I therefore recommend acceptance of this paper. I would like to emphasize that while I work in deep learning, I don t work on view synthesis and therefore it is difficult for me to evaluate the novelty of the proposed approach as well as the difficulty of the problem.<BRK>The t shaped network architecture here is largely presented as only appropriate to handing image panning. A specially crafted convolutional architecture is shown to be well suited to this problem. That is, simulated images of the scene from translated viewpoints. The method is clear and straightforward to implement either on its own, or as a module/architecture within a larger pipeline.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>In the paper, the authors propose a general form that covers most stochastic gradient methods so far, e.g.stochastic gradient descent, Adam,  or adaptive probabilities methods. If we divide both sides by T, the right side of the inequality is still upper bounded by \sqrt{T}, it is not convergent. 3) The same question in Corollary 2.1 about the convergence result. e.g.,  [1][2][3] for adaptive methods, and [4] adaptive sampling methods.<BRK>The toy experiments in section 6.1 were illustrative but seem to only consider adaptive probabilities without the adaptive moments? I would recommend that the authors explore combinations of enabling balance correction in the baseline methods (possibly through reweighting the loss according to the balance statistics) or requiring DASGrad to compute the optimal probabilities through the adaptive moments as suggested throughout the rest of the paper. Additionally, could you provide a citation for the optimal adaptive probabilities and clearly state under which conditions these adaptive probabilities are optimal?<BRK>The convergence of the proposed method is analyzed in terms of regret bound and is compared to similar results for ADAM. al.” is this a reference?
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>Instead of learning asingle latent representation, the paper proposes learning charts, whichserve as local latent representations. Experiments demonstrate that thelocal representations perform favourably in terms of approximating  theunderlying manifold. I appreciate the useof concepts from differential topology in deep learning and agree withthe paper that such a perspective is required to increase ourunderstanding of complicated manifold data sets. 3.The experiments do not showcase the *conceptual* improvements of the   proposed technique. This makes some of the claims in the paper hard to assess. How do we know that we have a sufficient number of charts? Why is  the structure destroyed? I see that the reconstruction error for MNIST goes down but there arealso significantly more (!) The ideas of the sampling or interpolation experimentsgo in the right direction, but in their present version, they are notentirely convincing.<BRK>In general the paper is ok written and tries to present the idea and the theoretical background in a nice way. Moreover, there is some work where multiple generators are used in order to model the data [5]. Probably comparisons with other models that use multiple generators or even latent spaces that respect the topology of the data manifold could be included. I do not see how the proposed model can tackle this issue. This needs clarification. However, I have the feeling that the proposed approach is quite debateable.<BRK>Notes:    Goal is to learn autoencoders which can capture disconnected manifolds by employing multiple discrete charts. The circle example in the introduction is illuminating and I enjoyed it. It s somewhat subjective, but I feel that autoencoders are becoming less widely used, so the paper might have more impact if it had targeted models like ALI/BiGAN which do reconstruction but purely with adversarial objectives. For 5.2, I d prefer the use of a dataset other than MNIST, since we don t strictly know that the digits require different charts (for example I m pretty sure there s a smooth mapping between "1" and "7"). I slightly lean for acceptance but am very borderline, especially as the results on "real data" are very weak.
Reject. rating score: 6. rating score: 6. rating score: 8. <BRK>This paper proposes a meta learning framework for learning adaptive kernels using a meta learner. Furthermore, to plug the kernel learning into the meta learning framework, they let the variational feature posterior to condition on the current support set for adapting and to use a modified LSTM network for accumulating information. They also illustrate that their adaptively learnt Fourier feature outperforms the standard variational Fourier features. Strengths, 1, The idea of learning kernels in meta learning is interesting. In particular, Figure 5 shows how the performance changes when the test shot and test way are varied. Weakness,1, The notations in the paper are not well presented. Because $w^{1:t 1}$ are random variables, they cannot be observed and cannot be conditioned on. 2, The paper doesn t introduce what is the likelihood $log p(y| x, S, w)$. It is unclear how the kernel regression is adopted in classification. 3, The meta prior $p(w| x, S)$ depends on the feature of the query point, which doesn t seem to be a common practice in variational inference. It would be beneficial if the authors could explain this and probably validate it empirically. 4, The motivations of the modified LSTM should be clarified more. However, the settings for the baselines should be better presented. For example, it is strange that the numbers of SNAIL are different with the numbers in their paper. And SNAIL on Omniglot is not reported.<BRK>This paper studies meta learning problem with few shot learning settings. The author proposes a learn each task predictive function via the form of random Fourier features, where the kernel is jointly learned from all tasks. The novel part is the parametrization of inference network using LSTM such that the random feature samples of t th task conditional depending on all previous task 1,...,t 1, which is an interesting way of modeling kernel spectral distribution. The experiment results show improvement of the proposed methods compared to SoTA meta learning algorithms. In general, the writing of the paper is clear, and the proposed method is interesting and novel. However, there are parts missing in the experiment setting. I would love to increase my score if the author could address the following questions/comments:(1) How do you choose the meta prior distribution? It should be a basic kernel family such as RBF Gaussian or mixture of RBF? (2) In Table 1 and Table 2, the benefit of using LSTM only gives very marginal improvement over w/o LSTM. Are the results statistically significant? (3) The experiment missed the simple kernel learning baseline, such as kernel alignment [1] and its variants [2]. If using these task independent way to do kernel learning, what’s their performance compared to you proposed method? (4) When learning the RFF spectral distribution using LSTM over a sequence of tasks, does the order of task matter? [1] Learning kernels with random features, NIPS 2016.<BRK>The paper focuses on the topic of meta learning for few shot learning and explores kernel approximation with random fourier features for this problem. The authors propose to learn adaptive kernels by meta variational random features, and evaluate their approach on different few shot learning tasks, comparing it against recent meta learning algorithms. The paper is well motivated and well written. On page 8, the authors mention related works that were not included for comparison because they rely on pre trained embeddings or large scale deep architectures. It would have been interesting to see the difference in performance.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>Overview:The paper tackles the representation learning problem where the aim is to learn a generic representation that is useful for a variety of downstream tasks. I consider the theoretical guarantees associated with the proposed approach a welcome and valuable contribution to this field that has recently been relying primarily on limited empirical work to assess any method. The empirical results presented in the paper do not sufficiently support the claims of sample efficiency. This does not help make conclusions about the sample efficiency of the proposed method on new tasks. The paper notes that these are some preliminary experiments.<BRK>(I bid on the paper thinking that bi level optimisation would play a major role in the paper.Unfortunately, it does not, so my expertise in bi level optimisation is not much use, I am afraid.) They call this the "representatition learning for imitation learning". The results are plausible, given the assumptions. The empirical results involve only benchmarks of the authors own coinage, and hence are hard to evaluate. It seems plausible, again, however, that the approach may work in some cases.<BRK>This paper theoretically explores reinforcement/imitation learning via representation learning. f. Theorem 4.1, perhaps use some other notation for c, which is defined as the cost/reward in the RL setting. Also, note that there is a bearing of the bound on the trajectory length H (Theorem 4.1, and 5.1). While, the current paper uses bilevel optimization setting in an RL context, it is not clear to me if this (bilevel + RL) setting has any significant bearing against the theoretical results furnished by Maurer 2016.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>It would be great to see at least one or two other areas where this could be applied to, since I doubt the general ICLR audience is well versed in nano porous templates. Unfortunately, I cannot comment on the overall scientific contribution of the paper, as I do not possess the expertise to judge it accurately. My expertise is so outside of this field that I will rely on the judgement of the other reviewers, whom I hope will have more experience and will better know the literature. In practice, would one want to wait longer to get a better quality result, or are the numbers obtained with the proposed approach usable?<BRK>Nevertheless the paper is a little lacking of novelty in the sense that it brings together many existing ideas and provides an analysis of the effect of bringing them together but none of the theory significantly improves over the existing theory. Hermite learning which directly approximates the error on the gradient as well as the function evaluation. Nevertheless the bounds achieved do not look much worse than the non error counterparts and are easy to implement. The Langevin process requires a derivative of the gradient.<BRK>As a non domain expert I cannot evaluate the importance of the contributions or the complexity of the tasks. However, given the well written and clearly structured presentation, the theoretical proofs and the generality of the constraint solver (with learned approximated gradients), I would vote for accepting the paper. Open questions:  How does the approach relate to "multi objective Bayesian optimization". The authors note that their approach is closely related to Shen et al.(2019).However, there is no algorithmic comparison in the experiments. What were the input and output dimensions.
Reject. rating score: 3. rating score: 3. rating score: 6. rating score: 8. <BRK>This paper introduces a mutual information term into the training objective of message passing graph neural networks. A variational lower bound on the mutual information is used in training. Postscript:  I have been swayed by the complaints of reviewer 1 and reduced my score to weak reject.<BRK>This paper proposed an auxiliary loss based on mutual information for graph neural network. Such loss is to maximize the mutual information between edge representation and corresponding edge feature in GNN ‘message passing’ function.<BRK>This paper proposed a new graph neural network to utilize the edge features. In particular, it proposes the Edge Information maximized Graph Neural Network (EIGNN) that maximizes the Mutual Information (MI) between edge features and message passing channels. 2.The writing is clear. 3.Extensive experiments are done to verify the performance of the proposed method.<BRK>In this paper, the authors proposed a new kind of graph neural network that can use continuous edge features. Specifically, a variational lower bound is proposed for mutual information and integrated into the GNN model so that MI between edge features and the message passing channel is maximized. Utilizing continuous edge features in GNN is an important and difficult task. To conclude, I think the paper will be a good addition to the conference.
Reject. rating score: 1. rating score: 6. rating score: 6. rating score: 8. <BRK>https://openreview.net/pdf?id SkxaueHFPBThe paper has some interesting ideas but I don’t think any of them are fully fleshed out. I am not making the argument that the authors ought to demonstrate SOTA results, however they should at least present results which are consistent with the published results of their chosen baseline. The authors then make this statement:“Thus, its superior performance supports the claim that ICR is the appropriate form of regularization for GANs. We emphasize that in our experiments we did not perform any architecture or hyperparameter tuning, and instead use a model intended to be used with WGAN gradient penalty”This does not hold, since the numbers reported are far below the actual baseline. Besides this major point, I am unconvinced by some of the mathematical statements in the paper. Much of the mathematical details are deferred to the original CGD paper. Concretely my concerns refer to the main discussion of the effect of the CGD as a regularizer:The authors state:“If some of the singular values of Dxy are very large, this amounts to approximately restricting the update to the orthogonal complement of the corresponding singular vectors” I don’t see how this is the case. The terms Dxy/Dyx aren’t really introduced or defined anywhere in this work. Assuming is the transpose of the other (?) So we have a term which is being affected by the smallest singular values of S and a term which is the orthogonal projection of grad_y onto Dxy, alternatively the ridge regression fit of grad_y on Dxy which would attenuate directions corresponding to the *small* singular values (as is well known from the theory of ridge regularizers). I feel like there is much more to say here than what is discussed in the paper in very vague terms. In practise I would assume the smaller SVs of Dxy to be difficult to estimate or the matrix to be rank deficient in which case they would simply be unity in the inverse whereas the directions corresponding to large singular values would be attenuated. First it is not at all clear to me what “smoothly varying singular vectors” are. Finally, figure 3 is quite bizarre to me. None of the quantities have been rigorously defined and so it seems like the relative effect of each of the arrows and the manifold have been drawn arbitrarily in order to fit the story, rather than to actually illuminate the true behaviour in an intuitive manner.<BRK>The paper presents a new way of regularization in Generative Adversarial Network (GAN). It is well known that a naive training of GAN can fail to converge. Although GAN is relatively a new concept, many papers tried to introduce a good way of stabilizing GAN training. I believe that this paper is addressing the stability issues in the most fundamental and effective ways. The intuition is that both players should predict what their opponent is going to do. The performance of the new method was demonstrated on CIFAR10. If this method works as well as the authors claim, it can significantly improve the practicality of GAN. The paper is very readable and understandable but many small typos and grammar errors can be found in the text. This can be easily corrected by the authors. However, the contribution of this paper is questionable. The original CGD paper already applies it to train a GAN. I would also appreciate if the method is tested on multiple other data sets. Overall, the paper is well written, technically correct and interesting enough for the venue. However, as I pointed out above, the contribution should be more clearly stated.<BRK>The paper presents a novel training methodology for GANs to improve stability. The resulting regularization, termed implicit competitive regularization, updates the parameters of both the generator and the discriminator to be robust to one another. A framework for practical application of this approach is described   this is done by a local Taylor approximation of the loss and updating each model’s parameters to this approximate model’s nash equilibrium. The method is shown to prevent overfitting and produce high performing models with consistent training. The results are interesting in terms of describing the ICR property and demonstrating its performance. The paper gives background and intuition to solidifying the CGD update. This I believe would help solidify the paper and build beyond CGD. Some additional results that could clarify the benefits:  A primary contribution of the training approach is training consistency. Clearly due to the additional gradient calls the approach is computationally slower, as shown in Figure 4. One may expect that the update may result in more conservative updates and thus potentially lower performing policies in the limit. If there iterations were instead log scale to show performance in high training iterations, is there any loss of performance in top performing runs? This may also be a stable training procedure as well with less conservatism. The paper should be proofread, there are several minor typos throughout, e.g.:  “generators producing that produce good”  > generators that produce good  “This game is very similar similar”  > repeated word  “GAN trainin.”<BRK>The paper analyzes instability in training GANs, relates it to Nash equilibria, and proposes a novel training set up based on competitive nashless games. The solution is related to other recently proposed work, but the paper brings additional insights into understanding it. The analysis on conditions that lead to divergence or convergence, and of the proposed solution, are interesting. I recommend accepting. I have some basic knowledge of GANs but am not deeply familiar with the field. The paper was accessible to me on a high level. Especially compelling to me were sections 2 and 3. The empirical study also seemed to yield positive results. Suggestions for improvement:  Additional proofreading would be beneficial. The scale of the axes in figure 1 is not clear, making it a little less compelling. Inception score is used as the only evaluation metric for the generators. Perhaps this is standard in the field, although human ratings would seem more reliable to me.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>In this paper, the authors study Neural Architecture Search, which aims to automate design of neural network models. Major concern:1/ I did not find the proof of Theorem 3.2 in the main paper and in the appendix, so I do not buy it. 3/ The key idea of the algorithm is not well explained.<BRK>4   Does m 1000 in your experiments satisfies theorem 3.2? As such, this work is an application of recent progress in the field of compressive sensing to One shot neural architecture search. To this regard, the only novelty that was the framing of One shot NAS as a recovery of boolean functions from their sparse Fourier expansions is not new either. ClarityOverall, the paper is well motivated and the technical content is good.<BRK>This paper proposes a new algorithm for one shot neural architecture search (NAS) via compressive sensing. How did you tune the p in the Bernoulli distribution during the one shot weight updates. In ICLR, 2019. Overall, I think the proposed algorithm is interesting and of practical usefulness.
Accept (Talk). rating score: 8. rating score: 8. rating score: 8. rating score: 6. <BRK>This paper introduces an end to end method to predict the secondary structure of RNA, by mapping the nucleotide sequence to a binary affinity matrix. An innovation is to express this post processing as an unrolled sequence of proximal gradient descent steps, which are fully differentiable, and allow the full combination of (i)+(ii) to be trained end to end. The proposed approach appears to provide a novel, convincing and non obvious solution to RNA secondary structure prediction, and subject to suggestions below, would represent a valuable contribution to ICLR. The principal area for improvement would be to include additional detail (perhaps in appendix) on the model hyperparameter configurations that were used in the experiments.<BRK>The authors proposed an end to end method (E2Efold) to predict RNA secondary structure. The score network is a deep learning model with transformer and convolution layers, and the post process network is solving a constrained optimization problem with an T step unrolled algorithm. Experimental results demonstrate that the proposed approach outperforms other RNA secondary structure estimation approaches. Overall I found the paper interesting. Training details and implementation details are missing; these hinder the reproducibility of the proposed approach. This performance was computed on the dataset (RNAStralign) on which E2Efold was trained. On this data, E2Efold has F1 score 0.686 versus 0.638 for CONTRAfold.<BRK>RNA Secondary Structure Prediction by Learning Unrolled AlgorithmsThis paper proposes E2Efold, which is an RNA secondary structure prediction algorithm based on an unrolled algorithm. Previous methods rely on dynamic programming (which does not work for molecular configurations that do not factorize) or rely on energy based models (which require a minimization step, e.g.by using MCMC to traverse the energy landscape and find minima). The method presented here is novel, shows strong SOTA performance, and would be of interest to the wider deep learning community.<BRK>*Summary*The authors perform RNA secondary prediction using deep learning. The paper also considers an application domain that will be unfamiliar to many ICLR readers interested in deep structured prediction, and may serve as a call to arms for the community engaging with additional problems in this field. There are a number of technical details, such as the loss function in (8) that will be of general interest. I advocate for acceptance. How sensitive is performance to the number of optimizer iterations?
Accept (Poster). rating score: 8. rating score: 3. rating score: 3. <BRK>However, such maps are in general discontinuous. Since deep neural networks can only represent continuous maps, this brings two problems: mode collapse and mode mixture. Their method basically avoids representing discontinuous maps by the generator. I think the idea of the paper is nice, and an interesting perspective  on GANs is presented. Nevertheless, I have some comments below. 1) Although this paper brings a new perspective, based on optimal transport theory, as far as I can understand this paper does not establish formal new results. Thus I think some strong claims about providing deep theoretical explanation should be more moderate. I think in some parts a lighter notation and a more intuitive explanation could help. 3) After Eq.(5) in the Appendix the authors mention Newton s method, and Thm 3 is also specific to Newton s method. This is confusing. In the negative case, why not?<BRK>This paper proposes a new problem in GAN distribution mapping: the concavity of support problem. 3.Empirical results show the effectiveness of the proposed method. Since OT will be aware of all modes in \nu, singular points can be detected by checking the angle between "shards" and those points that are around the "ridge" should be rejected. Thus, the proposed method could handle both the concave support problem and the mode collapse problem. Fit an auto encoder just as you did in the paper and get an empirical distribution \nu. Step 2.Fit a Gaussian mixture model on \nu and do model selection over # clusters. Since this method relies on a high quality auto encoder model, it is hard to say this paper makes progress in fixing the GAN s mode collapsed problem. Besides, the paper does not involve an adversarial training module.<BRK>This paper deals with an important problem of mode collapse and mode mixture. The illustration in Fig.3, and implicit in all the explanation charts is the fact that discontinuity can be found by a linear separation. Singular set detection seems to be the most tricky part in this paper, which should have been explained further. The Simplex projection assumption, renders this part not that tricky, but that is where I feel the biggest doubt about this paper lies. Also, the method does not have any adversarial training and hence, it studies the GAN idea from only fixing the generator point of view.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>Generally speaking, I agree that it is always good to be more efficient. The paper presents a new approach, SMOE scale, to extract saliency maps from a neural network. Overall, in my opinion, being efficient at generating saliency maps is a nice to have, but not much more. Being efficient is also a nice to have. However, the comparison to other approaches does not show a clear advantage, and the related work (and experiments) lacks recent techniques. For the first element, we have to consider the paper as the combination of two things. For instance, Fig.4 caption tells that "SMOE Scale differentiates itself the most early on in the network", but it is actually only for the very first scale layer. Overall, while SMOE is indeed novel, it is not highly convincing. It does seem to have an edge on KAR score, but not by a huge amount. Finally, a note about efficiency.<BRK>I SummaryThe authors present a method that computes a saliency map after each scale block of a CNN and combines them according to the weights of the prior layers in a final saliency map. The paper gives two main contributions: SMOE, which captures the informativeness of the corresponding layers of the scale block and LOVI, a heatmap based on HSV, giving information of the region of interest according to the corresponding scale blocks. The method is interesting as it does not require multiple backward passes such as other gradient based method and thus prove to be more time efficient. Figure 5: "Higher accuracy values are better results for it"  > yield better resultsThe phrasing with"one" as in "if one would like to etc" is used a lot through the paper, it can be a little redundant at times. Overall the results of the obtained maps are not very convincing compared to existing methods. The conclusion and discussion are short and could be filled a little more (some captions could be shortened in order to give more space). Edit: The authors have answered most of my concerns and I am happy to re evaluate my score to weak accept.<BRK>This paper presents a method for creating saliency maps reflecting what a network deems important while also proposing an interesting method for visualizing this. The central premise for the method of characterizing relative importance of information represented by the network is based on an information theoretic measure. I find that the proposed method appears to be theoretically sound and is interesting in revealing differences to other information theoretic methods especially in the early layers. Moreover, the LOVI scheme for visualization is interesting in itself and I found this aspect of the work to be thought provoking with respect to how such methods are examined from a qualitative perspective.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>The goal of the paper is clear. But the authors failed to propose a novel method and the results are not convincing. Hence, I recommend rejection.<BRK>  Post Rebuttal  No rebuttal was provided and all reviewers have raised issues. The issue is that standard decision trees, by independently picking the split feature(s), virtually discard the structure of the input features (if any). This patch will respect locality in a similar way to the proposed MORF’s bounding boxes. more importantly, it is not mentioned how these hp are optimized for the different baselines as well as the proposed method. the bounding box sampling seems biased as presented.<BRK>This paper proposed a new method called manifold forest to improve decision forest (DF) classification results. It is motivated by that, natural data is often in some manifold but not randomly distributed. It showed how to use the 2D spatial structures of natural images by constructing structured atoms. 1.In image classification, we definitely need 2D structure information. It is rare to use the pixel values as the features directly for classification. In this case, the benefit of the proposed method is very weak.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>The paper presents a compression algorithm for neural networks. The method is simple yet it shows strong performance of a variety of compression benchmarks. I appreciate that the authors fit the paper into the recommended 8 pages. Section 2.1, How are the weights grouped for coding? Assessment:While the idea is not groundbreaking, it is very well presented and evaluated and shows strong performance.<BRK>The paper introduces an end to end method for the neural network compression, which is based on compressing reparametrized forms of model parameters (weights and biases). During optimization, several tricks are applied. It provides good compression while retaining a significant portion of accuracy. Also, I wonder whether under the same compression rate the proposed method outperforms DeepCompression (Han et al., 2015) in terms of accuracy?<BRK>When trained on natural images, CNN filters are typically "smooth" (see any visualization thereof) and this smoothness translates as a prior of sorts on $\Phi_{w}$. This insight was previously explored in [1, 2] for purposes of compressing CNNs. Can assignments be reliably made by simply looking at the architecture? Minor Comments:    The general notation of the paper is cumbersome at times, can $\phi$ to be changed to, e.g., $\tilde{\theta}$? Consider trying to order things "chronologically" such that training comes before compression? [1] "Compressing convolutional neural networks in the frequency domain", Chen et al.2016[2] "CNNpack: Packing convolutional neural networks in the frequency domain", Wang et al.2016
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>The study direction itself is interesting and very useful for the interpretation and adversarial attack community. However, this paper can be improved a lot as follows. It is not clear on the definition of "hidden" in terms of  "interpretability".<BRK>But a better summary of this observation is that "robustness of interpretability implies robustness of classification", which is not surprising, and is in fact a trivial corollary of the fact that the metric on interpretations dominates the classification error metric (an observation which is made in the paper).<BRK>#StrengthThe paper is well written and structured, with a clear demonstration of technical details. #PresentationGood coverage of the literature in both adversarial robustness and model interpretation.
Reject. rating score: 1. rating score: 1. rating score: 3. <BRK>Theorem 2 and its proof are plagiarised: they are rephrased and reorganized formulation and proof of Theorem 1 of [1], while being presented as authors  own work. Demystifying MMD GANs.<BRK>The writing of the paper is poor. Moreover, as mentioned by reviewer #1,  theorem 2 and its proof are plagiarised. Overall, I think the paper is a clear reject.<BRK>Does the proposed Random Forest MMD GAN also has that property? Instead of using Gaussian kernel on the top of the learned embeddings from the discriminator, it combines existing deep forests kernels. It would be interesting to see which parameterization is better in this space. Could you discuss it with Theorem 2?
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>This paper addresses the problem of training small models to mimic large models but, in constrast to knowledge distillation, minimize the reverse KL between the teacher and the model instead of the forward KL. However, the authors argue that minimizing the reverse KL makes more sense: to only include tokens in the students that are present in the teacher.<BRK>The experiments in this paper may be thought insufficient. However, I have a little concern that the contribution is relatively limited since it is known that KL divergence is not symmetric and the proposed KA (KL divergence in the reverse order) may be thought a little straightforward. Language models are unsupervised multitask learners.<BRK>This is also a bit counter intuitive. 3.The authors performed the experiments on the translation tasks showing that the proposed KA strategy outperforms both KL and JS strategy in terms of the generation performance. When only the top few tokens are used to transfer the knowledge from teacher model to student model, KA focus on the precision of a small subspace, which tends to have few modes.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>I also find the experiment lacking as comparison with fast approximation method such as [*] that incorporate local information is not included. This is further coupled with armortized inference for better scalability. Post Rebuttal Update  Thank you for the rebuttal & I have read it in detail. Please note that I am not disputing the potential use of this VI form here, which could have been the only way to encode a different (directional) type of information. For encoding KNN information, however, it only seems to create more troubles than it solves. [C] Complexity: The complexity analysis is too informal and lacking fine grained information.<BRK>In this paper, the authors propose a family of variational distributions in which the variational covariance matrix is parameterized as RR , with R_ij being nonzero only when j is a neighbor of i as defined by prior covariance. This results in a sparse factor of the covariance matrix which can be used for efficient computation. However, I have a few concerns about the execution. 3 7 are not sufficiently motivated, and are essential to the method as they allow for stochastic optimization.<BRK>1) SummaryThe manuscript proposes a k nearest neighbor (KNN) Gaussian process (GP) approximate inference scheme to render computations more scalable. There are some typos and some glitches in the notation. There are some open issues regarding the KNN computations. The modification is rather marginal and the empirical evaluation makes it hard to judge the relative merit of the proposal. However, there is no code for the experiments, which makes the results slightly tricky to exactly reproduce. 7) EvaluationThe evaluation does not consider simple baselines like dense GPs or sparse approximations such as FITC and VFE.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>The paper is concerned with embedding a supervised feature selection within a classification setting. Suggestion, you might compare with the L_0 inspired regularization setting used for unsupervised feature selection in Agnostic Feature Selection, Doquet et al, 2019. I am mildly convinced by the paper:* Out of the four contributions listed p. 2, STG is the most convincing one; still, the description thereof is not cristal clear: the reparametrization trick is not due to the authors.<BRK>The authors propose a feature selection method for high dimensional datasets that attempts to fit a model while selecting relevant features. They relax the discrete variables using a continuous relaxation and provide a simple unbiased estimator for the gradient of the relaxation. The current methods do which suggests that the continuous relaxation is useful. For e.g.the median rank is better shown with box plots (as in the Chen et al 2018 paper cited by the authors).<BRK>***The paper considers the problem of embedded feature selection for supervised learning with nonlinear functions. Sparsity in the feature selection is enforced via a relaxation of l0 regularization. A variety of experiments in several supervised learning tasks demonstrates that the proposed method has superior performance to other embedded and wrapper methods.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>The paper proposes to use low rank matrix decomposition for embedding compression, with relu in the reconstruction layer to gain non linearity. Detailed comments:1)	The technical contribution seems to be a bit limited. Also, not much insight is provided on why such approach works better than other baselines. b.How does the time complexity and running time of the proposed method compared to the baselines? The experiments would be more convincing if evaluated on more tasks as well.<BRK>This paper proposes a method for compressing embedding matrices of both encoder/decoder embeddings. We need to note that the memory requirement of the proposed method during training will increase. As pointed out by the authors, this seems to be the first success of reducing the embedding matrix with a tied embedding setting. However, according to Tables 1, 2, and 3, it seems that the performance gain is marginal compared with similar methods. Besides, the authors should perform a statistically significant test if they say “our method outperforms existing state of the art methods.”  2I am a bit confused about the following inconsistency;The authors say that “Compressing embedding matrices without sacrificing model performance is essential for successful commercial edge deployment” in the abstract. By this fact, compressing embedding matrices seems not essential for successful commercial edge deployment.<BRK>The authors propose to use a variant of SVD (which can be viewed as 2 linear transformation, with a middle dimension that represents an embedding), where the first transformation is linear with a ReLu, and the second is linear. It is not clear to me why using a surrogate L2 loss within the model should give better predictive performance than a fully end to end trained neural network. Without this comparison, I do not think the proposed experiments are conclusive enough.
Reject. rating score: 1. rating score: 1. rating score: 3. <BRK>It includes the construction of a data set and some experiments with regression models. This paper aims to predict typical “common sense” values of quantities using word embeddings. These models are standard existing techniques, and given the relatively low performance I would have liked more development of the models and more analysis of the performance.<BRK>My second issue with the paper is that it is not possible to conclude if the experimental results support or refute the hypothesis (ignoring the issue with the dataset):1. To verify this hypotheses, the authors have created a dataset through a crowd sourcing service which represents "numerical common sense". Using this dataset, the authors examine the predict abilities of regressors trained on learned word embeddings and the aforementioned crowd sourced dataset.<BRK>This paper describes the collection and analysis of a numerical common sense dataset.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>(post rebuttal) I appreciate the authors for detailed rebuttal. How you sample depends on the problem assumption. In the original paper, they used a heuristic based on edit distance from ground truth, but in theirs they did not have assumption that you can evaluate correctness (as used in external filter). In this paper s context, the sampling naturally comes down to rejection sampling. The paper proposes an iterative data augmentation approach based self generation and filtering with success criteria. The authors justify the algorithm as an EM procedure of maximizing \log p^*(y|x), where p^*(y|x) \propto p(y|x) * p(c 1|x,y).<BRK>This paper proposes a training scheme to enhance the optimization process where the outputs are required to meet certain constraints. The authors propose to insert an additional target augmentation phase after the regular training. For each datapoint, the algorithm samples candidate outputs until it find a valid output according the an external filter. The model is further fine tuned on the augmented dataset.<BRK>This paper proposes a data augmentation strategy for a class of problems that the amount of labelled data is limited while the evaluation procedure is easier. Specifically, they are able to incorporate some of the model’s output into training data to guide the training procedure. The idea is quite simple and effective according to empirical results. Also, it’s not tied to specific neural architectureSection 4 provide an interpretation from view of EM algorithm, which is quite interesting. In molecular optimization task, i suggest authors to add more details on setup. Have you tried the strategy that incorporate all the augmented data?
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>This encoding enables SAT solvers to reason about the underlying variables and query existential or counting clauses. The main contribution of this paper is the analysis of the architectural design choices of the BNN and modifications of the training procedure in order to improve the efficiency of SAT solvers. The modifications are simple but effective.<BRK>While binarized neural networks are not my area of expertise, I am familiar with a number of verification papers on full neural networks. As such, it is my opinion that to be a strong paper, they must show this property holds for larger networks and more significant datasets. Consequently, they are able to demonstrate that SAT solvers can find adversarial examples much more quickly with their new architectural alterations. This would provide some breaks in the text so as to provide ease of reading.<BRK>The purpose of the new design is to make the network easier to analyze using the existing Boolean satisfiability (SAT) solvers. An easier analysis is preferable since the SAT solver can be used to infer existing fragility in the network, e.g., adversarial attacks. I like how the authors tried to address various aspects of the networks for easy analysis of SAT solver, i.e., neuron, block, and network levels even though they only focused on changing the architecture in neuron level perspective.
Reject. rating score: 1. rating score: 1. rating score: 3. <BRK>The paper trains a GAN on univariate time series data and uses reconstruction errors in combination with the critic s output to predict anomalous subsequences. are used to predict the subsequence(s) containing an anomaly. I acknowledge that I have read the authors  response, but it doesn t change my assessment that several major revisions are needed:  further motivating the design choices and comparing them to the state of the art;  formalizing (ideally providing a model for) the sort of anomalies that the proposed method aims to detect;  discussing limitations of the proposed approach.<BRK>Summary:  The paper propose a cycle gan variants combined with RNN for time series anomaly detection. 1.It is not clear the advantage of using GANs in anomaly detection of the proposed algorithm, and it is questionable if using GANs is really useful. I m wondering if the analysis can be extended to here.<BRK>This paper proposes a GAN model with cycle consistent loss function for anomaly detection on timeseries. * no comparison to State of the art GAN models for anomaly detection, such as AnoGAN and ADGAN. The novelty is not very high as the main architecture is from CycleGAN and the proposed similarity measures for the reconstruction error are not really novel.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>This paper proposes a new method of scaling multi agent reinforcement learning to a larger number of agents using evolution. Overall, I think this is a good paper and I recommend acceptance. This is motivated by the intuition that agents that perform best in small groups may not be the ones that perform best in larger groups. The proposed method is simple, but it makes sense.<BRK>This paper proposes evolving curriculums of increasing populations of agents to improve multi agent reinforcement learning with large number of agents. The topic is of relevance to the ICLR community and the results are tending towards publishable contributions, but I have some concerns that I would like the authors to discuss in their rebuttal. Please provide evidence that this is a fair comparison. Overall, this is an interesting approach with promising initial results. It would improve the paper to justify why this choice was made.<BRK>The paper proposes a kind of curriculum for large scale multi agent learning. However, the authors do not compare with ANY of this work (either in terms of algorithm design or performance). In more detail, the paper combines RL, multi agent learning and evolution. Improving on the baselines is a useful sanity check. After reading the rebuttal and other reviews and comments, I ve modified my score to weak accept. The paper makes an interesting contribution that is distinct from other approaches.
Accept (Poster). rating score: 8. rating score: 8. rating score: 3. <BRK>Their idea is "multi exit networks" with inference that adapts based on the input. Particularly, their proposed "Robust Dynamic Inference Networks" allows each input    clean or adversarial   to choose adaptively one of the multiple output layers to output its prediction. This way, they can do an investigation to new variations of adversarial attacks and adversarial defenses. + First time adversarial attacks and defenses are studied in a multi output model. Overall, I believe that this is an interesting, novel paper, which could be of high interest in the ICLR community, and I would vote for its acceptance.<BRK>The paper exploited input adaptive multiple early exits, an idea drawn from the efficient CNN inference, to the field of adversarial attack and defense. Overall, this paper presents an interesting perspective, with strong results. Since no literature has discussed the attacks for a multi exit network, the authors constructed three attack forms, and then utilized adversarial training to defend correspondingly. The authors presented three groups of experiments, from relatively heavy networks (ResNet38), to very compact ones (MobileNet V2). Several points that could be addressed to potentially improve the paper:  The authors want to make it clearer that: their "triple win" is not about constructing a light weight model that is both accurate and robust.<BRK>This paper proposes a framework coined as ‘Robust Dynamic Inference Networks (RDI Nets)’. The goal is concurrently achieving accuracy, robustness and efficiency via ‘input adaptive inference’ and ‘multi loss flexibility’  on a multi output architecture. The observation is that in a deep architecture, the representations in earlier layers can also be used for solving a specific downstream classification task. The paper is not very well written. The authors provide a large experimental section, however the key problem with the paper is that it blurs the evaluation issue. But given the thresholds the final decision is just a function of the entire network   as it should be.
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>The authors propose to use VAEs to model fixed policy opponents in a reinforcement learning setting. All the techniques presented in the paper are standard and the way they are put together is not particularly original.<BRK>The authors propose a variational autoencoding (VAE) framework for agent/opponent modeling in multi agent games. Also, having baselines that do not use opponent embeddings on the charts of Fig.4 would help understand the contribution of opponent modeling. However, I believe that while estimating accurate embeddings of the opponent behavior from the agent s observations only is interesting, the approach has limitations, and I feel those are not studied in depth enough (e.g., as a reader, I would like to understand if and when I should use the proposed approach and expect it to work).<BRK>This paper proposes a reasonable and natural way of modelingopponents in multi agent systems by learning a latent spacewith a VAE. My one concern with this modeling approach is that it will startbreaking down if the opponents are *not* fixed as thispotentially makes the agent more exploitable. [1] Ganzfried, S., & Sandholm, T. Game theory based opponent modeling in large imperfect information games.
Reject. rating score: 1. rating score: 3. rating score: 3. rating score: 3. <BRK>This paper presents a method for financial sentiment analysis based on the texts obtained from news. Although the results may be of interest to communities working in this area, there are no or little novel contributions. By reading section 2 (only one page), which describes the method used, I have the impression that the authors took the method BERT and then applied this to the TRC2 financial dataset and then reported the results and also discussed some parameter choices in the BERT method. Apart from this, there are no other contributions or insights to the methods/problems. In addition, section 2 is over brief and very unclear, and it only contains a brief summary of the BERT method.<BRK>This paper proposes a domain adaptation type of task via proposing fine tuning of pre trained models such as BERT on data from financial domains. However, there is not much novelty in this paper. 1)The authors do not propose any new model architectures. Even if we were to argue the novelty is in terms of their empirical work, there are some flaws/missing details in the experiments. 3)Table 4 presents results that do not seem significant. On the whole I am very lukewarm on this paper.<BRK>This paper presents an analysis of the BERT language model on financial text. I find the phrasing "FinBERT is a language model based on BERT" misleading; I think FinBERT is BERT trained on financial text. There is no modification that is done to the original BERT model. FinBERT is compared to a few baselines such as LSTMs with ElMO embeddings and ULMfit. I find interesting that the model performs better on the subset of the dataset for which there is perfect agreement between the annotators. I also find the results on training on financial data interesting. The results seem to indicate that further training on financial text does not seem to result in additional improvement when compared to original BERT. While I find the analysis and the experiments presented in the paper interesting, the novelty of the paper is rather low. There is no new idea introduced in this paper, it contains a series of experiments with BERT on financial text and tasks.<BRK>This paper described the application of BERT in the field of financial sentiment analysis. Authors find that when fine tuned with in domain data, BERT outperforms the state of the art, demonstrating that language model pre training can transfer knowledge learned from unsupervised large corpus to new domain with minimum effort. I am in favor of rejecting this paper and my reasons are as follows:First, this paper may lack deeper innovation, although it demonstrates a good application of the BERT models in financial domain. Second, the dataset used in evaluation is of small size (for example, Financial PhraseBank test set has one 1K). The difference between FinBERT( domain) and ULMFit can be explicitly contrasted in the paper.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>The authors furthermore provide mathematical references and results to derive bounds for their approximation. The paper is well written and easy to follow. My major concern however is that the authors do not provide any reasoning as to why do we need the weighted automata machinery behind their approach? Effectively what they do can simply be seen as embedding of inherently periodic multiset elements using periodic functions, which are parameterized by non linear transformations of data.<BRK>This paper proposes generating feature representations for set elements using weighted multiset automata. The experimental results are difficult to interpret. Reading the paper it is not entirely clear what theoretical results are novel and which proofs are restatements of existing proofs.<BRK>Same goes for (#2 above) in the latter point. However I do find the motivation of this paper is a bit weak,  and I’m having a hard time finding the highlight of the paper. Here are some general comments:How is the multiset automata learnt? However, the experiments didn’t show much difference. e.g.set the transitions to be diagonal and directly optimize with gradient descent?
Reject. rating score: 1. rating score: 1. rating score: 1. <BRK>Continuing from the previous point, it seems it is not easy to distinguish the main idea of this work and the work of NPI. The story is confusing.<BRK>Are the "runs" mentioned training runs? The controller is trained by a variant of REINFORCE. My main concern with this paper is that there is zero experimental comparison against previous neural program induction approaches.<BRK>The paper provides a good comparison between the proposed architectures and other related works. The idea to compose modules is reasonable. Table 2 presents a bunch of success rates without comparison to other methods.
Accept (Poster). rating score: 8. rating score: 6. rating score: 3. <BRK>This paper uses NTK and techniques from deriving NTK to study asymptotic spectrum of Hessian both at initialization and during training. Is there a major block for the analysis given in the paper to extend beyond FC networks?<BRK>This paper discusses the behavior of the Hessian of the loss of NN during training. That being said, the paper is a nice and interesting contribution to the NTK regime, that is the subject of intense studies currently. I do not believe all these references are in the NTK regimes.<BRK>This paper uses the Neural Tangent Kernel (NTK) to presents an asymptotic analysis of the evolution of Hessian of the loss (w.r.t.model parameters) throughout training. What are the implications for generalization or for future training algorithms? There is a minor typo in the first equation of Sec.2.3 (i  > j).
Accept (Poster). rating score: 6. rating score: 6. rating score: 3. <BRK>This paper provides a novel approach to the problem of simplifying symbolic expressions without relying on human input and information. •	The most interesting figure provided is the rewrite rules discovered by the model. That said, this is not my area of expertise, so I cannot judge novelty or importance as well as other reviewers. Moreover, the paper does not seem to have been revised with many grammatical issues that make it hard to read.<BRK>This paper presents a method for symbolic superoptimization — the task of simplifying equations into equivalent expressions. The solution uses a reinforcement learning method for training a neural model that transforms an equation tree into a simpler but equivalent one. This is especially troublesome for a RL based model.<BRK>The authors present a framework for symbolic superoptimization using methods from deep learning. The approach avoids the exploitation of human generated equivalence pairs thus avoiding human interaction and corresponding bias. Instead, the approach is trained using random generated data. A corresponding discussion would be valuable here.
Reject. rating score: 3. rating score: 6. <BRK>The authors propose an automatic learning rate schedule based on an explore (always increase LR initially) and then exploit (more typical patience based decay) strategy. Finally, I found the remarks and analysis regarding width of the minima, and the stipulation that there are more narrow minimas, not substantiated and even contradicatory to some of the results in the literature. Could you please clarify what is the claim about the method? I think at least a discussion of (some) of these papers is very important. I think [5,8] should be cited here.<BRK>The paper proposes an automatic tuning scheme for learning rate while training neural networks. For example, in CIFAR/ResNet there are experiments showing that duration of `explore’ phase is important and choose 50 epochs. I think full automatic learning rates, if it can be done, will have great impact in neural network optimization.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>The LSTM training is also based on prior work in that domain. How well do they compare to the authors  approach and in what ways have they built further? Motion texture: a two level statistical model for character motion synthesis.<BRK>1.Summary:The paper proposed  composable semi parametric modeling  for generating long range diverse and distinctive behaviors to achieve a specific goal location. It seems that the authors again adopt reconstruction loss, how the loss penalize inconsistent predictions between clips is not well explained. (2) The overall presentation of this paper is hard to follow.<BRK>The paper tackles the problem of generating long range, diverse and natural looking motion sequence between initial and end states, and proposes to use a semi parametric approach consisting of local and global models. Also it might need to add more detail in the presentation.
Reject. rating score: 3. rating score: 3. rating score: 3. rating score: 6. <BRK>The paper proposes a methodology to overcome the problem of processing long sequences with a pre trained Transformer model, which suffers from high computational costs due to the complexity being quadratic in the length of the sequence. The authors also point out that BERT needs to be retrained from scratch if sequences longer than the specified maximum length (512) are to be processed. Their method (BERT AL) chunks the input text into segments of maximum length. I think your paper would benefit from exploring different options like that experimentally to better justify your model decisions. (2) The experimental evaluation is not convincing: The application scenarios are unrealistic, the dataset is not well chosen, and the results are not impressive. While the model is interesting, the individual design decisions are not well justified, e.g., why the LSTM is applied at each layer and why it needs to be a multi channel LSTM. If future pretrained models account for long sequences already during pre training, the motivation for this work is rather low. This is not a deal breaker by itself, but it makes it obvious that the paper needs substantial polishing before it should be published.<BRK>This paper proposed a BERT based document summary model that has the capability of modeling arbitrarily long documents. The advantage of this paper is that the time consuming training process of BERT can be avoided. The model looks bloated and the performance is not persuasive. The authors reproduced the baseline BERTSUM but the reproduced performance is significantly lower than performance in the original BERTSUM paper. As the main contribution in this paper is to understand the longer documents, the performance on long documents should be evaluated separated.<BRK>This paper proposed another variant of BERT, called BERT AL, which can deal with arbitrarily long inputs. Second: In the discussion of the experiment section, the authors claim that the proposed method BERT AL can be parallelized and runs faster than existing methods. The main part of the proposed method is to combine the segment wise BERT with the multi channel LSTM. Please explain more details of those results. For the fair evaluation of results, we need the information on the overall experimental environment.<BRK>The author proposes an extended version of the BERT architecture, BERTAL for text summarization. The experimental procedures as well as the choice of architectural design are well explained and designed in a logical way. However, it doesn’t compare the result of BERTAL to other text summarizers with arbitrary length text, which is not based on BERT.
Reject. rating score: 1. rating score: 3. rating score: 3. rating score: 6. <BRK>This paper studies the problem of finding sparse networks in a limited supervision setup. The main application seems to be extracting lottery tickets faster by downsampling the data however this aspect is again fairly obvious. In short, unfortunately, this paper doesn t cut it for ICLR. Main contribution is Section 4.1 where self supervision is investigated.<BRK>The experiments on cifar10 is lacked. And it is better to complete the figure with several random seed and plot the error bar to avoid randomness. But some experiment’s results and its setting are confusing, while also makes me concerned about the conclusion solidness. But the figures in this paper do not contain a zoom in details for each line, make me hard to distinguish the performance between each setting.<BRK>This paper empirically studies the lottery ticket hypothesis with limited or no supervision. Second, the authors show that finding "good" (reasonable) winning tickets can be accelerated by a factor 5 on ImageNet by using only a subset of the data. The authors also argue that using large datasets is important to study lottery tickets, since deep networks trained on CIFAR 10 are natually sparse, making conclusions potentially misleading. Overall, I found that the experimental results in this paper are solid and provide more understandings of the lottery ticket hypothesis. However, I feel that the novelty of this paper is limited, and do not provide much new insights. Therefore, it does not reach the bar of being published at ICLR, from my perspective.<BRK>In this paper, the authors try to provide empirical answers to several important open questions on winning tickets. They conduct most of experiments on ImageNet and results show that winning ticket is robust, and few data samples can also obtain good winning tickets. Generally, the paper has conducted extensive experiments on three open questions and results prove their assumptions. I’m wondering, whether there will be winning ticket for multi task learning with limited data each task? Will this be helpful in distilling the model?
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>I think the paper now reads better and like the new added experiment! **Original review**This paper presents a technique for learning of lattice valued embeddings. Since the resulting algorithm is hard to implement in high dimensions, the authors eventually replace the uniform noise with a small Gaussian noise.<BRK>This is different from other methods such as Gumbel trick in the sense that the quantization is done on lattices and the noise is uniform over primitive cells. Some details can be put in the appendix to make the paper shorter. It s not critical, but I wonder if the this argument could be more interested if better connected to lattices, ie the optimality of "hyperspheres" as a lattice representation.<BRK>This paper proposes a framework for gradient descent optimization of latent variable models where the latent code lies on a (n dimensional) lattice. I think that the authors should have at least illustrated the appeal of lattice representation learning on a toy example. Given the prominence of the term in the paper (and in the name of your proposed method) I think this warrants more attention.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>The performance of TPRU is validated with several NLP tasks such as POS tagging. So the paper is not self contained enough. However, the analysis is mainly performed in a qualitative way, and there is no quantitative analysis of it. However, the term "interpretability" is very vague and it is not properly defined in this paper. It looks, however, improper because there is no baseline and we cannot conclude that TPRU has better interpretability than others.<BRK>This paper proposes a novel model of recurrent unit for RNNs which is inspired from tensor product representation (TPR) introduced by Smolensky et al.in 1990.The authors claim that this allows one to better incorporate structural information into learning and easier interpretability for the learned representations. The proposed approach is motivated by a theoretical analysis showing that using TPR in this context acts as a sort of pre conditioner and stabilizes learning. I think this paper is not yet ready for publication: the proposed model is interesting and relevant but its validity could be better assessed and the paper needs some thorough proof reading.<BRK>The paper is difficult to read because it assumes the reader is an expert on Tensor Product Representations. Many important terms are not clearly defined, which makes difficult to follow. However, I think the contribution of the paper is important and presented experimental results, comparing the method against classical LSTM and GRU architectures, seem to be relevant for the field.
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>The reason for this are threefold. The paper is crowded with text and ends up to be hard to follow. The method compares to deep RL baselines. The paper does not compare to planners, which are tailored to solve the problem the paper adresses. I think that the authors need to reformulate what the contribution of their work is. That needs to be presented in a more abstract way, without focusing on the experimental setting prematurely. The experimental setup is ok if the method is restricted to robotic tasks, but too thin for the general setting of efficient planning with sparse costs.<BRK>  Summary  The paper introduces Curious Sample Planner (CSP) a long horizon motion planning method that combines task and motion planning with deep reinforcement learning in order to solve simulated robotic tasks with sparse rewards. Each vertex of the tree is assigned a curiosity score, which is used as an exploration bonus for PPO and to determine the probability with which each vertex is sampled from the tree for future exploration. The results show that CSP accomplishes each task while using significantly less samples. Although the ideas in the paper are presented clearly, the algorithms and methods are presented mostly at a very high level. Specifically, I think the paper should include this:  The hyper parameter settings for each different algorithm and an explanation about how they were selected.<BRK>This paper tackles the problem of enabling robots to learn long horizon, sparse reward tasks. CSP overcomes this limitation by planning in the space of macro actions in a way that is biased toward novelty. CSP is evaluated on a suite of simulated robotics tasks that require the robot to build simple machines from the objects in its environment, in order to achieve the specified objective. There is an ablation study, that compares against planning with uniform selection of macro actions and uniform selection of states to expand. The paper is clearly written and well motivated, and the evaluations are thorough. First, there are not enough details included for reproducibility (see list below). Finally, I m not convinced that this approach works well for transfer, and the evaluations seem inconclusive as well. Is it the batch of next states, S ?
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>The paper considers the label shift problem and investigates the role of the calibration in improving the results of two different domain adaptation solutions including EM and BBSE. They show with having better estimation of conditional distribution in the source domain the final label distribution obtained by EM and BBSE in the target domain is more accurate. Overall, I think the paper should be rejected as it suffers from not high enough level of novelty in proposed method. It would be better that the accuracy is reported for the baseline, EM,  BBSE Soft and BBSE hard at the same table with mean and std values. The tables some how should show the impact of using the calibration to improve significantly the final label shift accuracy. But in this way of reporting the results it is not clear how big calibration can improve the final accuracy.<BRK>This work conducted exhaustive experiments for a label shift problem with EM and BBSE over CIFAR10/100 and retinopathy detection datasets. As stated in the paper, the main contribution of this work is to explore the impact of calibration. However, it is still doubtful whether those empirical results can be generalized as there is no analytical and thoughtful discussions. Further, the label shift was simulated by means of dirichlet shift on both datasets.<BRK>This paper builds upon recent work on detecting and correcting for label shift. The paper is easy to follow an the authors should also be credited for releasing code anonymously with which we could reproduce their results. I have as few specific concerns/questions about the paper that I would like the authors to address:  * They consider JS divergence as a metric for evaluation. Overall this paper makes an interesting contribution in establishing the usefulness of the likelihood formulation (here optimized by EM) of label shift estimation and its apparent benefits over BBSE in some settings. I am happy to keep my score despite apparent disagreement from the other reviewers. Still, while this paper can be improved in some key ways, it does make an interesting contribution.
Accept (Poster). rating score: 6. rating score: 3. rating score: 3. <BRK>Theoretical analysis is also provided to support the effectiveness of the proposed methods. The experiments show good performance. In overall, I think this paper solves an important problem in federated learning, and I vote for acceptance. However, since my knowledge in fairness is very limitted, I think my review is an educated guess. In my opinion, the proposed algorithm highly relies on $L_q(w)$. It will be better if the authors can show some results where different estimations of L  is used, and compare these results to show the sensitivity to the estimation of L.<BRK>The problem of fairness in federated learning (FL) is important given the popularity of the topic and its immediate impact on the society. This paper proposes a new algorithm for federated learning to reduce variance in performance across clients. The inspiration for the algorithm comes from the problem of uniform  resource allocation in wireless networks. While the problem and the motivation for the algorithm are interesting on the high level, I think this paper does not deliver the key ideas in sufficient detail and clarity. Are the results for q 0 in the experiments reported for this run or is it repeated with the learned L? Further, this procedure suggests that the number of communication rounds is at least doubled for the end to end training. Tuning q, which seems to be necessary, may require even more communication rounds. While there are a lot of experiments in the paper (across main text and supplementary), none seem to be carried out sufficiently well.<BRK>[Summary]The authors propose a protocol to encourage a more fair distribution of the performance across devices in a federated setting. In contrast with previous work, which protects a specific attribute, this paper aims to achieve the uniformity of the accuracy distribution. The claims are well supported by theoretical analysis and experimental results. However, my main concern is that the paper offers an incremental improvement over the early work FedAvg (McMahan et al., 2017). [Details][Pro 1] This paper provides insights into fairness (a more uniform accuracy distribution) in federated learning, which appears to be well motivated. It is an interesting idea to choose dynamic step size depending on the global Lipschitz constants and fairness parameter q. [Pro 3] The evaluation fully considers various uniformity metrics, sampling strategies, and the chosen of q. Is it relevant to the parameter q?
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>####################This work makes a connection between recently introduced one class neural networks [8, 4] and the unsupervised approximation of the binary classifier risk under the hinge loss [1]. An explicit expression of this risk approximation is derived for the case that the prior class probabilities are known and that the class conditional distributions of classification scores are Gaussian. Anomaly detection using one class neural networks. Nevertheless make an assumption on the class prior? (1) and (2) into one equation. (ii) The technical derivations in the paper (and the appendix) are correct but rather straightforward.<BRK>They propose an extension to a one class based approach that can do anomaly detection in an unsupervised fashion. The main contribution is a modification of the target function for the training of one class NN. The experiments are not convincing and the modification doesn t seem to provide much inside into representation learning and anomaly detection area. Table 1: why compare a supervised method to an unsupervised one and don t compare to other methods?<BRK>Paper summary:This paper proposes an algorithm to train a binary classifier without supervision, simply relying on (i) class prior, (ii) the hypothesis that class conditional classifier scores are Gaussian distributed. It proposes a simple algorithm for unsupervised training of binary classifier. Overall, the approach is simple and it would be a good paper with the addition of baselines (mixture) and the clarification of the validation procedure.
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>C2.Experiments showing that, quantitatively, the Sparse Transformer out performs the standard Transformer on translation, language modeling, and image captioning. The proposal is admirably simple. The paper should clearly identify the differences between the proposed model and earlier models: it does not discuss this at all. Experimental demonstration that the proposed innovation actually remedies the identified deficiencies should be provided, but is not. In particular, no empirical results are given concerning the sensitivity of the reported successes to choosing the correct value for k. We are only told that “k is usually a small number such as 5 or 10” (Sec 3). The experimental details in the appendix do not even state the value of k used in the models reported. It is an interesting discovery that in the translation task, attention at the top layer of the standard Transformer is strongly focused on the end of the input.<BRK>The authors propose a sparse attention mechanism based on the top k selection where all attention values in a row are dropped if they are not higher than the k^{th} largest item in the row. The authors report results on machine translation, language modeling and image captioning. The motivation of this work seems to be the latter as the authors claim improvements in terms of performance over full attention. 3.Does the paper support the claims? The authors report good results on machine translation, showing that their sparse attention method improves performance on En De to 29.4 BLEU, on De En to 35.6 BLEU and on En Vi to 31.1 BLEU, improving on full attention baselines. The authors also do not report what choice of k is used for the top k operation and how they made their choice of the optimal k? It seems that if an index is not selected (i.e.it s attention value is smaller than top k) it s gradient is set to 0. [1] Generating Long Sequences with Sparse Transformers by Child et al (https://arxiv.org/abs/1904.10509)<BRK>The paper proposes "sparse self attention", where only top K activations are kept in the softmax. The resulting transformer model is applied to NMT, image caption generation and language modeling, where it outperformed a vanilla Transformer model. In general, the idea is quite simple and easy to implement. It doesn t add any computational or memory cost. The diverse experimental results show that it brings an improvement. However, there are quite many baselines are missing from the tables. The sota on De En is actually 35.7 by Fonollosa et.al. On enwik8, Transformer XL is not the best medium sized model as the authors claimed. Probably only true for a certain task.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>This paper presents a calibration based approach to measure long range discrepancies between a model distribution and the true distribution in terms of the difference between entropy rate and cross entropy, which is exactly the forward KL divergence. 1.The authors should read the Language GANs falling short paper, and conduct the experiments in the same way in that paper and compare their approach with temperature sweep method. If yes, please state in the paper, if not please state why? The log function is unbounded, so please be careful. and many language GANs paper.<BRK>This paper highlights and studies the problem of "entropy rate drift" for language models: the entropy rate of the language generated by a trained model is much higher than the entropy of ground truth sequences and this discrepancy worsen with the length of generation. The authors interestingly claim that the well known lack of coherence in long term model generations is due to this entropy rate drift. Do you have a way of quantifying whether this assumption reasonably holds ? Updated review:I thank the authors for their answer.<BRK>(emergency review)This paper demonstrates that a left to right language model suffers a high entropy rate when generating a long term sequence of words. Then the authors claim that this is because of entropy rate amplification, which could be mitigated by  calibration . The proposed technique (local entropy rate calibration) is straightforward to implement, and empirically shown to be effective.
Reject. rating score: 3. rating score: 3. rating score: 8. <BRK>The paper is concerned with biologically plausible models of learning. The key insight is that the updates in EP can be written as a telescoping sum over time points, eq (5). Making equilibrium propagation more biologically plausible is an interesting technical contribution. MNIST is an unusual dataset with a stark constrast between foreground and background that is far from biologically plausible. I know it has a long and important history in machine learning, but if you are interested in biologically plausible learning then it is simply the wrong dataset to start with from both an evolutionary and developmental perspective. Maybe not.<BRK>I think it is an intriguing paper, but unfortunately left me a bit confused. I have to admit is not a topic I m really versed in, so it might be that this affected my evaluation of the work. The paper introduces C EP, an extension of  a previously introduced algorithm EP, such that it becomes biologically plausible. My first issue is with the proof for the equivalence between EP and C EP. And W symmetric is also not biologically plausible.<BRK>Summary: this paper introduces a new variant of equilibrium propagation algorithm that continually updates the weights making it unnecessary to save steady states.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>This context is provided in the form of a support set of K pairs of pose/frame images for the video. The paper is also clearly written and easy to follow. For these reasons, I m personally leaning towards recommending to accept this submission.<BRK>In this paper, authors propose to address few shot video retargeting, where one should adapt a generic generative model of human actions to a specific person given a few samples of their appearance. However, the solution is not quite novel for me.<BRK>This paper proposes a novel and interesting task that learn to retarget human actions with few shot samples. Additionally, could the authors provide some visualizing results for different K number, which would be interesting for analysis. Though the proposed problem is novel and somewhat interesting, there are also several weaknesses of this work:  The novelty of methodology is somewhat limited.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>The paper presents a method of scaling up towards action spaces, that exhibit natural hierarchies (such as a controllable resolution of actions), throughout joint training of Q functions over these. Authors notice, and exploit a few interesting properties, such as inequalities that emerge when action spaces form strict subsets that lead to nice parametrisation of policies in a differential way. Ablations provided imply that this part is indeed crucial (as with independent Qs, called "Sep Q" learning flat lines). Could this ablation be also done on the toy ish tasks from experiment 1? How were the missing parent actions handled?<BRK>Based on the intuition that smaller action space should be easier to learn, the author proposes a curriculum learning approach which learns by gradually growing the action space. An agent using simpler action space can generate experiences to be used by all the agents with larger action spaces. The author presents experiments on simple domains and also on a challenging video game. In general, it is an interesting research work. I think the author can improve the paper in the following aspect. I think the author should include some discussions regarding large action spaces, since one goal of the proposed method is to handle such situation.<BRK>Summary: This paper proposes a method to progressively explore the action space for RL. The proposed method is called “growing action spaces”. This method effectively captures many RL settings, including multi agent learning. One effective approach is to apply the action hierarchy. Then the paper performs experiments on both simple toy examples and a more complicated one, the Starcraft game. The simple toy problems is “Acrobot” and “Mountain Car” with discretized spaces. The proposed method is novel and effective. • Using 3 level of hierarchy in the StarCraft game does not work well. • The training curriculum is still mysterious. Maybe training level by level is better? So you will have l different policies.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>Overall the paper is easy to read and I welcome that. I like the idea of using node level embedding instead of pairwise weights to learn a low rank weight representation. However, I am more skeptical about using this in a recurrent architecture and claiming that this is structure learning. The empirical results do not provide sufficient evidence that this performs structure learning. Can I use the proposed FNN with a similar number of parameters to learn the corresponding architecture for A and B respectively, without the need to figure out which is which? It would be interesting to try baselines that have roughly the same number of parameters as the proposed FNN. How were they chosen? Assuming that the same amount of computational resource is spent on searching through baseline architectures as well, could the results have been different from those in Table 1? There are interesting ideas in this work but in its present form I cannot yet recommend acceptance.<BRK>This paper proposes a new architecture based on attention model to replace the fully connected layers. In this architecture, each neuron is associated with an embedding vector, based on which the attention scores (between two consecutive layers) are calculated, and the computational flow through the layers are derived based on these attention scores. The experiments on MNIST and CIFAR demonstrate some degree of superiority over plan FC layers. 2.I donot believe FC is essential in modern computer vision (CV) tasks, so the better performance over a plain FFN on CV tasks are not that convincing (especially the two datasets are typically regarded as debugging dataset nowadays). I suggest the authors conduct more experiments on Transformer based tasks (e.g., machine translation), since in Transformer, the FFN is quite important. If the replace of FFN using the proposed FNN is successful for Transformer on some large scale task (e.g., WMT14 En De Translation), this work will be much stronger in terms of empirical performance. What is the embedding size d in the experiments?<BRK>This paper introduces a new neural network architecture, in which all neurons (called "floating neurons") are essentially endowed with "input" and "output" embedding vectors, the product of which defines the weight of the connection between any two neurons. In my opinion, this improved the paper and made some of its claims much better justified. Updated: The authors updated the text and addressed many of my questions. In Section 4.1, the authors compare FNN and DNN on MNIST and CIFAR10 datasets. and possibly even lower. I believe that these questions require additional discussion and empirical evidence. Just as an example, if it was possible to sample (potentially randomly) different DNN architectures (with a reasonable parameter prior) and compare them with FNNs on a 2D accuracy parameters plot (or using other important metrics), it would provide much more information to the reader. How important are these individual aspects? If I am not mistaken, FNN can also be "unrolled" and represented as a multi layer floating neural network with additional parameter sharing. This would imply that FNNs do not necessarily supersede multi layer floating neural networks, at least when the computational complexity is of importance. 4.There are a few minor misprints throughout the text. But additional empirical results for these architectures would, in my opinion, be much more convincing.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>The method proposes a method for continual learning. This method aims to find gradient updates which are perpendicular to the input vectors of previous tasks (resulting in less forgetting). However, the authors argue, that the learning of new tasks is happening in the solution space of the previous tasks, which might severely limit the ability to adapt to new tasks. The authors propose a ‘principal component’ based solution to this problem. The paper is not well positioned in related works. At least a comparison with the more related works PackNet and HAT should be included. For more recent method for task aware CL see also ‘Continual learning: A comparative study on how to defy forgetting in classification tasks’. And the proposed PCP solves this problem. Such an analysis of P_l^k as a function of the tasks (and for several layers) would be interesting to see, for example for EMNIST 47(10 tasks).<BRK>This paper introduces Principal Components Projection, a method that computes the principal components of input vectors, using them to train on a transformed input space and to project gradient updates. Experiments show improved results over OWM (the method that this paper builds on) and EWC. If I understand correctly (which I think may not be the case), the principal component vectors are computed after the first forward/backward pass of each task, for the inputs to each layer (C_l^k). I also do not understand Equation 1. What is \grad{W}? The experiments seem reasonable, except that there are no standard deviations on the results. However, as far as I m aware, these experimental protocols (dataset and model size) are not used in other papers: it would be nice to see experiments which match previous papers  protocols, for example with MNIST and CIFAR 10 at least (other papers use smaller model sizes). Hopefully the authors can answer my questions.<BRK>This paper tries to solve the catastrophic forgetting issue in the continual learning problem. The authors propose a method based on principal components projection to tackle this issue. The authors conduct experiments on image classification tasks to show the performance of the proposed method and compare it with two other baselines EWC and OWM. This paper tries to solve an important problem. It is not convincing. 2.It might strengthen the paper if the authors can show the comparison results on more other datasets, e.g., other image classification tasks. It would be better if the authors can show the proposed method can generalize to other tasks. 4.It is not clear why the proposed method can solve the issue that OWM faces with (bad accuracy when tasks are not quite related).
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>This paper provides generalization bounds for permutation invariant neural networks where the learning problem is invariant to the permutation of input data. Unfortunately, the technical value of the content and its novelty is very limited since the proof reduces to a very basic argument that counts invariances (which is simply n!where n is the number of invariant dimensions) and uses a standard approach to give a generalization bound. However, I do not understand how this work can improve our understanding of permutation invariant networks.<BRK>This paper presents a derivation of a generalization bound for neural networks designed specifically to deal with permutation invariant data (such as point clouds). Unlike Example 1, Example 2 (p.3) is not helpful in motivating the permutation invariant neural networks. I also found the proof of proposition 4 too confusing to easily follow. The heart of the contribution is that the bound includes a  1/n!<BRK>This paper derives a generalization bound for permutation invariant networks. In the context of this prior work, the contribution of this paper appears incremental. Overall, this paper is technically rigorous, and novel in its very specific context of deriving the generalization bounds for permutation invariant networks.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>This paper is reporting an unsupervised approach to learn node embeddings and communities simultaneously by minimizing the mincut loss function. The matrix P and adjacency matrix are coupled to generate community adjacency matrix to minimize the cutting. Similar work such as the methods of transferring matrix E to H then to P have already been published , which reduce the novelty of this study. 2.Though there is a schematic, the learning embedding process is still not described clearly.<BRK>The idea is simple and easy understood and the paper is well written. However, major concerns are:1. The authors should check the correlation between the detected communities and the original paper labels. For example, if considering the downstream node classification of node embedding as an evaluation task, then how about the performance of the following two step method. Spectral clustering has a scalability issue when meeting big graphs. Since the spectral process is also applied in the proposed method, efficiency and scalability evaluations are encouraged to provide, especially for big graphs which are not covered in the selected datasets in this paper. 5.In Sec 5.3 and Fig 2, it s mentioned that trends of the three datasets are different.<BRK>This work proposes a neural netowrk approach to minimize mincutloss, thus achieving embedding nodes and find communities at the same time. However, it is difficult for me to understand the paper and I feel that it is not clearly written. 1.The algorithm is not written in a box as in Algorithm 1. At first I thought algorithm 1 is the main method, but only after reading it I realized that it is one step of the algorithm. I would appreciate it if the complete algorithm (including input, output, parameters) can be summerized clearly. I thought the input of all methods are the adjencency matrix A. 3.In table 2 and table 4, why does the paper compare different methods with different measures? Is it possible to compare all methods using all measures?
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>The major contribution of this paper is the use of random Fourier features as temporal (positional) encoding for dynamic graphs. The reader finds that the proposed approach is interesting.<BRK>This paper proposed the temporal graph attention layer which aggregates in hop features with self attention and incorporates temporal information with Fourier based relative positional encoding. This idea is novel in GCN field. Experimental results demonstrate that the TGAT which adds temporal encoding outperforms the other methods. The baselines compared in this paper seems to be too weak. How does the single head variant of TGAT work?<BRK>What kind of temporal trends exist in the data that this method has learned? One particular recurring frustration is the use of the term “architect” which seems wrong. I’m not sure if this is a major advance. The paper is rather hard to follow and ambiguous.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>This paper seeks to understand both across layer and single layer behavior within neural networks (i.e.layer behavior along the depth of a network, and behavior of a single layer along training epochs). Theoretically, they show that the Wasserstein distance between predicted and target distributions is decreasing along the depth and for a single layer, along training iterations. This paper gives an interesting contribution to the in depth analysis of neural networks. However, some elements remain unclear:1. 3.There is no detail on the regularization strength of the Wasserstein distance, or what p (in definition 1) is chosen either in the experiments or in the theorems. Post rebuttal: I thank the authors for their response. On this basis, I am maintaining my weak reject rating.<BRK>The authors intuitively, and then analytically, explain the behavior in the hidden layers of deep convolutional networks and show how the behavior can be used to improve performance by "early exiting." I give this paper a weak reject. I also applaud the authors for their rigorous explanation of the hyper parameters and experimentation methods. The increase in accuracy isn t large enough across experiments to allay my concerns. I can be convinced otherwise with a compelling set of arguments.<BRK>This paper presents a method to compute the distance of distribution of two layers in neural networks by using the label distribution mapping (e.g., Frogner et al., 2015). I believe that the contributions of this paper are week in analyzing individual layers across layer since there are many extensive studies are conducted on information bottleneck methods with mutual information. However, authors of this paper presents a way to utilize the label distribution mapping to compare the distance of individual layers when an input image come as shown in Figure 5 which I believe the main contribution of this paper. Even in Section 3, the label distribution mapping is not clearly explained except for the description of FC+softmax.
Reject. rating score: 3. rating score: 3. rating score: 8. <BRK>In this paper, an inference WGAN model (iWGAN) is proposed that fuses autoencoders and WGANs. Due to the above concerns, rating is recommended as "3 Weak Reject." (2)	The proposed iWAN is only compared with WGAN. Especially, on the synthetic dataset, iWGAN seems to  have less mode collapse than WGAN.<BRK>This paper proposes a novel variation to the WGAN, which combines WGANs with autoencoders.<BRK>This paper presents an inference WGAN (iWGAN) which fully considers to reduce the difference between distributions of G(X) and Z, G(Z) and X. This algorithm has a stable and efficient training process. Therefore, the innovation of this paper is very novel.
Reject. rating score: 1. rating score: 1. rating score: 3. rating score: 6. <BRK>The paper presents three contributions: (a) the observation that there’s train to test leakage in many graph classification datasets (under isomorphism equivalence), (b) what appears to be a theoretically motivated way of improving scores on such datasets, by focusing on solving the examples that are isomorphic with training instances, and (c) a recommendation to remove such leakage from test sets. I don’t think the paper meets the ICLR bar. While (a) is very interesting, and an important contribution, (b) and (c) are contradictory. Missing reference: Bordes et al.(2013) and Toutanova et al.(2015) show there’s train to test leakage (under isomorphism equivalence) in the FB15K dataset.<BRK>However, the main assumption of the paper   which equates the quality of a graph learning benchmark with the amount of isomorphic graphs that it contains, i.e., the lower the better   seems questionable. The paper argues that isomorphic graphs are akin to duplicate images in computer vision and should be removed from a dataset. In the latter, a learning method is required to identify the correct bijection form V_1 to V_2 which is a non trivial task. However, the attributes are not considered in the analysis what leads to a large number of isomorphic graphs. The results of Theorem 6.1 on the other hand seems straightforward and would hold for any classification task for which the true label for an equivalence class of instances is known.<BRK>This work probes graph classification datasets for isomorphism bias. They also provide some recommendations for measuring the  right metrics  and release clean versions of the considered datasets. Also, as the authors themselves mention, taking node/edge labels decrease the isomorphism in most datasets. The results and recommendations presented in the paper are intuitive and somewhat trivial  I am not sure if ICLR is the right venue for this work<BRK>The authors discuss here the problem of isomorphism bias in graph dataset, i.e.the overfitting effect in learning networks whenever graph isomorphism features are incorporated within the model. However, the novelty of the work is limited, and also the proposed solutions cannot be claimed as superior to other approaches, due to the small improvement in accuracy.
Accept (Poster). rating score: 8. rating score: 6. rating score: 3. <BRK>This paper argues that defenses against adversarial attacks need to be stronger than they currently are. After rebuttal:I have raised my score after authors improved to quality of the text. Even though this work does not have empirical results on high dimensional datasets such as MNIST or CIFAR10, it has a nice theoretical contribution useful for finding stronger defenses against adversarial examples. They show how a prior defense based on generative models (INC) fails on the toy problems and show how a modification to INC can improve it.<BRK>Overall, I still would like to see a more detailed/in depth experimental setup, but I realise that this not directly possible within the timeframe allotted during the rebuttal period. I.Summary of the PaperThis paper studies robustness to adversarial examples from theperspective of having  topology aware  generative models. Specifically, I see the followingissues:  Missing clarity: while the appendix is very comprehensive, which  I appreciate, the main text could be improved; some statements appear  redundant, while others need to be re formulated to build intuition  This paper appears to span both theory and applications. Moreover,  topology  is reduced to  connected components   in this paper. I would rather say that the main goals are to  provide empirical evidence for the *relevance* or *applicability* of  the Theorem. Ivery much commend the authors of the paper for choosing this sort ofwriting style! The manifold assumption is that data lie _on_ a manifold or _close to_  a manifold whose intrinsic dimension is much lower than that of the  ambient space.<BRK>The paper tries to answer the following question:In adversarial defense training do manifold based defenses need to know the structure of the underlying data manifold? The question is quite rhetoric (the answer is most probably yes), nevertheless, the paper provides a theoretical and empirical answer. Nevertheless, I have a very basic question regarding the usefulness of the methods that the paper studies and the topic of adversarial defenses. There are some recent papers that demonstrate this [A] or recently feature denoising [B].
Reject. rating score: 3. rating score: 3. rating score: 8. <BRK>There is still a large concern wrt to the computational complexity. I kind of understand the argument about the hyperparameter tuning, but it seems not really fair to compare to a bruteforce parameter search (one can probably do some sort of bayesian optimization). Overview:Authors introduce a new VAE based method for learning disentangled representations. The main idea is to apply a “residual learning mechanism”, which resembles an autoregressive model, but here conditioning between sequential steps is done in both latent and input spaces.<BRK>The authors applied residual learning machenism in VAE learning, which I have seen such methods in Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks (https://arxiv.org/abs/1506.05751), which basically applied the residual learning method in GAN. Also, the best paper from ICML 2019 claimed that unsupervised learning method can not really disentangle the features. Otherwise, it is not convincing to the readers.<BRK>The authors of this paper present a novel that for unsupervised disentangled representation learning. The model, named sequential residual VAE (SR VAE), gradually activates individual latent variables to reconstruct residuals. Since the training involves a sequence of model training,  SR VAE certainly consumes more time than other VAEs.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>Cons:In my opinion, the paper scores low on novelty and original contribution. The experiments are done well.<BRK>The paper is well written. At the same time, the properties of the proposed method are not well exposed and the experimental evaluation is incomplete.<BRK>what are the computational requirements of the models presented in this paper? how does the model perform on longer sequences, e.g.for long term generation?
Reject. rating score: 3. rating score: 8. rating score: 8. <BRK>This paper compares a few encoder agnostic methods for using pretrained decoders in text generation tax. The author compared a few intuitive ways of doing this, and presents results showing that that pseudo self attention does the best. However, I think the results has some strange points that needs further investigation. Going from repr transfomer to context attention to pseudo self, there is an increasing amount of parameters initialized by pretraining. It would be good to verify that this is not due to under training. Except paragraph captioning, the results on other tasks are not better than prior results, which do not use pretraining. The baseline transformer is also usually worse than prior results. The human evaluation shows that the proposed method do better on story generation, but this one is essentially text to text. There is no comparison with previous text 2 text methods that use pretraining. If the proposed methods are truely encoder agnostic, then they should perform reasonably on text to text as well.<BRK>This paper proposes a simple yet effective method to adapt large scale pre trained language models, which have been shown to substantially improve performance on broadly classification based NLU tasks, to NLG. The approach is explored in the encoder agnostic {X} to text setup, where the source encoding {X} could represent arbitrary modalities, such as text or images. More concretely, the paper leverages a pre trained, large scale language model (in this case a GPT 2), and examines how to best cast such unconditional language model into a decoder that generates text conditional on the source information {X}. Cons:1.It is still unclear how using language model pre training affects adequacy (as opposed to fluency). Since none of the evaluation metric specifically assesses for adequacy on its own, it would be good to isolate the effect of pseudo self attention on adequacy, and compare it with the baselines, in addition to a Transformer trained from scratch on each downstream task.<BRK>This paper proposes a new architecture to train decoder models on language generation using a pre trained encoder (such as BERT or GPT 2). They introduce a novel block called `````"pseudo self attention" that allow injecting the input for conditional generation in the self attention layer (i.e.softmax of YW_q (XU_k | YW_k)^T (XU_v | YW_v) instead of softmax(YW_q(YW_k)^T)YW_v). They extensively evaluate their approach on a large set of tasks showing improvements across all of them (which includes class conditional generation, summarization, story generation and paragraph generation). The idea seems well motivated and the paper is well written and easy to follow. The experimental section is very thorough and show large improvements on a variety of task I particularly appreciate that they experimented with conditional inputs of different nature (class value, image, different languages etc...) to show the effectiveness of their method. Overall, while the idea is quite simple, the experiments speak for themselves and this could prove to be a useful `layer  to use on large pre trained language models.
Reject. rating score: 3. rating score: 3. rating score: 8. <BRK>This paper proposes a method to learn bilingual word embeddings by modifying the Sent2Vec (which is based on word2vec) approach, and applying it to bitext. They evaluate on monolingual and bilingual word similarity, bitext mining, and a zero shot document classification task where a classifier is trained on data in one language but evaluated on another (using their embeddings as features in both cases). The baselines are weak and the task is not standard. 2) For the zero shot document classification task, it should also be pointed out that LASER can handle many languages all at once. 3) Note that also the improvements on monolingual similarity using parallel data are well known. I think the main contributions of this paper are modifying Sent2vec so it can be used on bilingual data and using it to learn nice representations for words and sentences (and documents).<BRK>The paper does not bring anything novel to the field of cross lingual representation learning: it just revisits some older ideas (from the period of 2013 2015), now revamped, given the fact that more sophisticated and more effective methods are used to model exactly the same intuitions. Another note related to evaluation: to really establish how different cross lingual embeddings compare to each other, a wider set of experiments and downstream evaluation is definitely required, see the work of e.g., Glavas et al.(ACL 2019). The results are actually quite mixed, and the advantage of Bi Sent2Vec is its quicker training. However, what about more recent methods such as XLM which rely on exactly the same resources as Bi Sent2Vec to do the zero shot classification task? Figure 2: corpus size. Based on the results presented, it seems that the performance saturates by adding more parallel data, but the authors fail to fully understand their evaluation data in the first place.<BRK>The authors performed an in depth ablation study, to support their claims that the proposed model addresses some of the key problems with other existing approaches to cross lingual representation learning (e.g.hubness).* Comments on the paperThis paper is exceptionally well written, organized, and clear. Meanwhile, I believe the paper could benefit from more discussion or analysis of cases where the proposed model did not lead to improvements, in particular with Russian in the word translation retrieval experiment, where TRANSGRAM outperforms the proposed model. The proposed model becomes less convincing when I consider that it might only work for other agglutinative, English like languages, and I wonder how this approach would fair with other morphologically rich languages similar to Russian, and non agglutinative languages in general. How do I interpret “10^ 2” as a corpus size? In other words, what are “10^ 2 amounts of data.” Fix this.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>The paper considers the problem of extracting the underlying dynamics of objects in video frames. The paper focuses on two major applications: background/foreground extraction and video classification.<BRK>Could Table 1 be placed in the experiments section rather than in the middle of page 5? Our goal is to establish a basis invariant to the video dynamics that can then be used, for example, to partition the video into parts with differing dynamics   e.g.foreground/background. My main concern about the paper is that I find it very difficult to appreciate the efficacy of the method given the current presentation of the results. The Koopman operator acts on a differential system to identify a function space invariant to the dynamics.<BRK>In the proposed method, DMD is used in the latent representations of a convolutional autoencoder for image sequences. Some complaints:    the tables are a bit sloppy and should be formatted to fit in the document with normal sized fonts,    the images are too small to see well. The resulting methods are applied to a foreground extraction and a classification tasks, and compared with numerous baselines.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>This paper proposes to generate "semantic adversarial examples" (SAEs) by applying small perturbations in the semantic space, by contrast to more standard adversarial examples that apply perturbations to the image intensities. I found the paper interesting, however I am not convinced by the general concept:* While the method from Yao et al is supposed to work on real images, it requires to detect and estimate the pose and the shape of 3D objects, which is still challenging to do on real images. * The generated images are also valid images, in the sense that for a slightly different scene, they would have been generated by the image renderer used for VKITTI. It sounds more like what the authors have is a method that can generate scenes to improve the performance of an object detector when trained on synthetic images, rather than a method  to be more robust to malicious attacks. This is very interesting, however the paper is not branded toward this  application.<BRK>Review: This paper focuses on generating adversarial perturbation in semantic space. The main contribution of this paper is to propose a general method to generate semantic adversarial examples by using advances in differential rendering and inverse graphics. Pros:1.Generally, the presentation is clear and easy to follow. 2.A general way to transform any pixel attack algorithm to its “semantic version” is novel. I think this paper would be more compelling if proposed SAEs have some special property (e.g, easy to take effect in the real world or stronger robustness against defense strategy). 2.In section 5.3, the authors show that data augmentation using SAEs increase the robustness to SAEs, but pixel perturbation AEs do not.<BRK>Experiments demonstrated that the generated semantic adversarial examples (SAEs) can attack the SqueezeDet (see Table 1 and Table 2). By re training with augmented data by the proposed method, the robustness of SqueezeDet (see Table 3) can be further improved. Overall, this is an okay paper with incremental technical novelty and clear presentation. In general, studying the adversarial examples in the synthetic domain seems not a significant contribution. At least, reviewer would like to know whether re training on adversarial examples help to improve the performance on real dataset? (2) The conclusion is largely based on the 1547 semantic adversarial examples generated, while there are more than 4K synthetic images in the dataset. Please comment on the average running time for generating a semantic adversarial example. How does that compare to generating a pixel based adversarial example? It would be more convincing if this paper provides more such examples in the appendix. (4) SqueezeDet is the only model used in the paper.
Reject. rating score: 6. rating score: 6. rating score: 6. <BRK>The authors propose a new gradient based method (FAB) for constructing adversarial perturbations for deep neural networks. I wonder if this is the reason for PGD performing worse than FAB for large epsilon values on CIFAR10. The adversarially trained MNIST model of Madry et al.2018 learns to use thresholding filters as the first layer (observed in the original paper). While it is encouraging that FAB is robust to such gradient obfuscation, this is arguably not the ideal setting to compare gradient based methods (especially when averaging performance over models). For MNIST and Restricted IN, PGD performs comparably or even better than FAB (modulo larger epsilon values for which the large step size used could be an issue for PGD and the Linf trained model with the thresholding filters). Moreover, the runtime comparison performed in not exactly fair:  It is not clear how many restarts where included in the runtime of PGD. Its runtime should be in the same ballpark as FAB but the time reported is ~20x higher. Choosing an arbitrary number of steps for each method is not very enlightening. It is not necessary to run PGD 5 times to evaluate the robust accuracy at 5 thresholds. One can perform binary search for each input in order to find the smallest epsilon for which a misclassification can be found. This will result in at most 3 (sometimes 2) evaluations per point (instead of 5). Despite these shortcomings of the experimental evaluation, I still believe that the paper has merit. In that sense, it could potentially be a valuable contribution and could be of interest to a subset of the adversarial ML community. UPDATE: I appreciate the response and the additional experiments performed by the authors. The authors have addressed my concerns in their response.<BRK>The paper studies the problem of the white box attack of neural network based classifiers, with an emphasis on the "minimal distortion solution": The new input that changes the labeling output of the network with the minimal distance (l1, l2, l_inf) with respect to a given input. The main intuition of the algorithm is to do a local linear approximation of the network at the current point (which is the Taylor expansion up to the gradient term). The main concern for me about this paper is the comparison to other methods such as PGD. As far as I know, these attackers DO NOT explicitly minimize the distortion, thus it is quite believable that these models do not identify the minimal distortion solution (rather it will more likely to find a solution that lies in the boundary since it would be the easiest way to attack). I would like to see more implementation details of the other algorithms, for example, what is the performance if we add an additional regularizer as the distance of the current attacker to the given input to PGD. (In particular the justification for solving the local linear system instead of doing a gradient descent step). I apologize for the earlier misunderstanding and higher the score accordingly.<BRK>Authors extend deepFool by adding extra steps and constraints to find closer points to the source image as the adversarial image. Deepfool does and adhoc clipping to keep the pixel values in (0,1) but the new proposed method respects the constraints during the steps. Also during the steps they combine projection of last step result and original image to keep it closer to the original image. Moreover, at the end of the optimization they perform extra search steps to get closer to the original image. Rather than considering the original image, they randomly choose an image in the half ballpark of the total delta. According to the results in fig.2 the backward steps has the highest impact in comparison to deepfool. But mixing with original projection always helps a little and random restarts help a little too. Without the backward steps there is almost no gain from mixing the projections. Considering the full results in the appendix, the results are mixed with no obvious advantage in comparison to PGD specially.
Reject. rating score: 3. rating score: 6. rating score: 8. <BRK>Contribution:This paper proposes two methods building upon MADDPG to encourage collaboration amongst decentralized MARL agents:   TeamReg: the agents are trained with an additional objectives of predicting other agents  actions, and make their own action predictable to them   CoachReg: the agents use a form of structured dropout, and at training time a central agent (the "coach") predicts the mask dropout mask that should be applied to all of the agents. Review:The paper is well written and easy to follow. It includes the analysis and explanations of the failure modes, which is valuable in my opinion. The two main limitations of the work are the following:   Limited scale of the experiments. It is unclear whether the additional losses proposed in this work would still perform correctly with more agents, since the regularization pressure will increase. The only baseline method presented here is MADDPG, upon which this work is built. Is there a reason why this particular form of dropout was chosen? Finally, it seems to me that the two methods presented here (TeamReg and CoachReg) are not mutually incompatible.<BRK>The main contribution of this paper is that they propose to allow agents to predict the behavior of others and introduce this prediction loss into the RL learning objective. However, the novelty of this algorithm is not strong, given that the similar idea of  predicting the behavior of other agents  can be found in related work with discrete action spaces. However, It seems that this idea is transferrable to discrete action spaces as well, so long as we change the MSE loss between actions to KL loss between policy over states. Could it be the other way around? I doubt the motivation and effectiveness of this approach. If so, this is like you first assume the policy network is somewhat overfitting, then alleviate this issue by letting the coach adjust which part to keep and which part to drop. Intuitively, all agents will finally reach a point where they agree on the same policy mask distribution (which is the one generated by the coach). How does the same policy mask lead to an improvement in cooperation? Empirical or theoretical explanations are strongly needed in the main results, not in the appendix section. Experiments:  All variants of MADDPG in the experiments are weak baselines, assuming that $MADDPG + sharing$ means all agents share the same policy and Q function. However, since this algorithm only works for continuous action space, available relate work to compare with is quite limited. Experiments with more than two agents should be implemented. They seem to show that under these two proposed frameworks, the predictability of agents does not always encourage cooperation, at least for 2 out of 4 game settings mentioned in this section.<BRK>The rigour of the empirical evaluation and its documentation is exemplary. The related work section could be improved by including a section on the closely related work in the area of opponent modelling. A more thorough review in Section 3 would improve the positioning of the paper. In particular I think it would improve the discussion of the results to elaborate further on why the proposed methods do not improve, but also do not detrimentally affect the learning performance of agents in this environment. In Section 6.2 the authors note "MADDPG + policy mask performs similarly or worse than MADDPG  on all but one environment and never outperforms the full CoachReg approach." Again what is it about this specific environment that causes the policy mask ablation to be sufficient, enabling it to match the asymptotic performance and learn quicker than the full CoachReg method proposed? All references to papers both published and available on arxiv should cite the published version (e.g.Jacques et al.2018 was published at ICML). Please revise all references if accepted.
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>The proposed regularization penalty is only applied to a subset of the recurrent units; the motivation for this is to allow neurons not contained in the subset to learn different structures. Major commentsI have a number of serious concerns about the paper s motivation, logic, and experiments:  First, the paper motivates the proposed regularization as a way to encourage the network to have line attractor dynamics. The paper proposes a squared penalty on subsets of the weights in the recurrent network as a way to encourage line attractor dynamics. Also, the proposed regularization penalty only penalizes the diagonal elements of the A matrix to be close to 1 but shouldn t the off diagonal elements also be penalized to be close to zero? This baseline is important to determine if the proposed regularization simply helps because it is an l2 penalty on the weights (note that none of the other baselines have regularization). The paper motivates the method as trying to study line attractor dynamics, but then does not apply them to tasks where line attractors are required.<BRK>This regulariser works on a neuroscience motivated formulation of RNN, bringing the Jacobian of the dynamic system close to identity. While the alleviating the exploding and vanishing gradient problem for simple RNNs is an interesting direction, I think the empirical results are not sufficient to support claims in the paper. The paper starts by criticising initialisation and reparametrisation based techniques. In fact, one may argue that initialisation is a milder constraint compared with an explicit regulariser, since regularisation affects the entire learning process. It seems that such initialisation requires less tuning (i.e., just identity) compared with the regulariser weights (a rather wide range of choices). This could be due to the smaller size of the models (40 vs 100 hidden units in Le et al.). Despite this, I wonder why the performance of addition and multiplication seem even worse than the much smaller model reported in Hochreiter and Schmidhuber 1997? Actually, it would be helpful to test the proposed method on more practical tasks such as language (at least synthetic ones) and speech modelling, which would bring more impact on the wider community. A few technical questions:  Is the form of eq.1 necessary, or can the method be adapted for the more standard formulation of RNN used in machine learning? Is there an additional expectation over p(z)?<BRK>The paper proposes a regularization scheme to improve the ability of RNNs in capturing long range dependency in the latent space. + The motivation of the line attractor is novel and effective. The special RNN model studied in the paper has strong connections with neuro dynamics models. The illustration about the line attractor is particularly interesting. The paper is building a generative model for sequences. It’s not clear to me why VAE or variational RNN type of approaches cannot be used in this setting. The inference procedure can also be significantly simplified with variational inference. Minor comments  " All code used in this work is freely available on the github site ... . "
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>This work is an empirical study of testing how pruning at the pre training stage affects subsequent transfer learning (through fine tuning) stage. Overall, the paper is well written and explained. The goal is meaningful, and this is a sensible contribution to the ongoing interests of compressing BERT like large models for efficient training and inference. First, although the findings are interesting, the methods used in this paper are not new. However, as it is known that it is really difficult for modern hardware to benefit from random sparsity because it leads to irregular memory accesses, which negatively impact the performance.<BRK>This work explores weight pruning for BERT. It finds that pruning affects transfer learning in three broad regimes. My major concern about this work is its technical innovation and value to the community.<BRK>The paper conducts a series of interesting experiments on compressing BERT and makes several conclusions. The compression technique is magnitude weight pruning based on an existing work. The paper is well motivated and presents interesting experimental results and conclusions. I have some concerns on their experiment details, which needs some clarification. 2.It will be helpful to show the thresholds of pruning and how these thresholds relate to the training loss and accuracy.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>This paper proposes a method for constructing adversarial attacks that are less detectable by humans, by changing the target class to be a class similar to the original class of the image.<BRK>I will not get surprised if this paper is accepted. However, all reviewers still share concerns about the importance of the problem tackled. This paper should be rejected due to the lack of motivation to create adversarial examples less detectable by humans automatically.<BRK>I imagine normally the attacker has a target label in mind, so the part of the paper that chooses a target label is not very useful; and this is the main element of novelty, since the rest of the method is from DeepFool, as the authors explain. Minor suggestion: It would be useful to see examples like in Fig.5 but with the classes (true/target) listed.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>However, the theoretical novelty is quite limited. There is no guarantee whatsoever whether the good empirical results achieved on the three experimented would persist with other datasets. The flow of the ideas in the paper is clear and unequivocal. What about comparing to other federated learning frameworks, i.e.other than versions and extensions of FA? In the Introduction, it was promised that the proposed method would stop catastrophic training failures; has that been actually described in the experiments? Similarly so for the robustness issue (which is also the first word in the paper title), where is the empirical demonstration of the robustness of the proposed method?<BRK>In this paper, the authors propose a novel representation matching scheme to reduce the divergence of local models in federated learning. In addition, the authors propose an online hyper parameter tuning scheme. The empirical results show good performance. In overall, I think the authors propose an interesting alternative of weight regularization (also called weight divergence loss in this paper). Since FA, FA+WD, and FA+RM have different loss functions, it is unreasonable and unfair to use the same hyperparameters for them. Otherwise, the results of the experiments are questionable. 3.It seems that AH is irrelevant to federated learning.<BRK>This manuscript proposes two strategies to improve both the robustness and accuracy of local agents under the setting of federated learning. Hence instead of using online reinforcement learning for hyperparameter search, which is notoriously data inefficient, why not framing the problem as a pure online learning problem? The second contribution is an idea on using local distribution matching in order to synchronize the learning trajectories of different local models. This again is a novel and interesting idea.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>There are interesting ideas in this paper, however I have some questions and concerns about some of the claims made in the paper that I would like to see addressed. Please discuss this paper and clarify the seeming discrepancy between the results there and your claims. 4) The labels are misaligned in Figure 4. Please describe what these models are. So, please discuss this connection in your paper.<BRK>I d like to increase my score. And what are the differences between the proposed attack with previous methods? The authors could discuss more on the attack method and compare its performance with others. Overall, this paper analyzes the invariance based robustness of deep neural networks with norm bounded robustness, which is an interesting problem.<BRK>Same as the previous definition of adversarial robustness (robustness against imperceptible perturbations), perturbation robustness reflects the model s ability to maintain the prediction after a label preserving transform. A more valuable direction would be to evaluate the minimum l_p distance between classes, but it seems intractable at the moment. No automated solution can be inspired from the paper. This can also be verified by the two sphere experiments.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>This paper is well organized. But it lacks some more detailed analysis. 1.The idea of using the concept of age is not new. However, the authors did not provide the analysis that the age and the accumulated task reward are conflicting with each other. 3.It would be better the average survival time of the individuals is presented in this paper.<BRK>While the paper is interesting, I feel in its current state, it is not the level of an ICLR conference paper. Below is some feedback I want to give the authors to help them improve the work, so hopefully it can be improved either for this conference or the next. For the record, the score I wanted to give is a 4, but since I can only choose 3, or 6, I will assign a score of 3 for this review (although should really be a 4). I m not convinced that the approach (multi obj + end to end) which solves VizDoom cannot be solved using Risi2019. The authors explained why Risi2019 s approach cannot work on VizDoom with sufficient effort, and I buy their explanation.<BRK>Given that the architecture has a heterogenous pipeline, the authors propose, and empirically show (over a set of seeds), that allowing extra time for components to adapt to other, more recently changed components, enables neuroevolution to solve the second task. The ablations are an important part of this work, and it would be good to study these further. This ablation will reset the age 1/2 the time DIP does, reducing diversity/increasing selection pressure, and so another appropriate ablation is to see the effects of protecting MDN RNN and controller innovations (with the VAE being the most downstream component).
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>3.The proposed methods seem easy to apply. The recognized strengths and concerns are as follows. Since the throughput is strongly dependent on the underlying hardware, the number of operations also needs to be shown as a more general estimation of the model inference latency in various hardware devices.<BRK>Pros:  The proposed method is simple and rather easy to implement. The setting of C_j affects the result.<BRK>The paper addresses architecture search as well as model compression by simultaneously optimizing all layers/weights/submodules of the network.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>Briefly, the paper proposes to use a (damped version of) the SVG repulsive term between the current position of a SGLD trajectory and the empirical distribution defined by the trajectory. Unfortunately, I do not think that the experiments are convincing. Is it because of multimodality? Comparison to a single NN? etc...The proposed method is interesting and has a lot of potential. I would like to suggest the authors to spend more times on careful and controlled numerical experiments (Bayesian NN are not very good for this purpose)   with convincing numerics (which would give more reasons to delve into the proofs) the method can be very promising.<BRK>I have the rebuttal of the authors, the paper improved indeed and some point on role of M is better clarified now although it is still a bit convoluted. I think the author put a good effort in addressing some of my concerns and I m raising my score to 6. ####Summary of the paper:The paper proposes stein self repulsive dynamics for sampling from an unnormalized distribution. is this correct? This will be insightful to see if one would mix faster with respect to the other one.<BRK>This paper proposed another variant of Langevin dynamics, called “Stein self repulsive dynamics,” which simultaneously decreases the auto correlation of Langevin dynamics and eliminates the need for running parallel chains in SVGD. If the authors reply appropriately, I will raise the score to accept. How do we take a limit of M  > ∞ ?
Reject. rating score: 3. rating score: 3. rating score: 3. rating score: 6. <BRK>To that end, the authors present an architecture that is cyclic permutation invariant through a pooling operation on all the cycles. The paper is well written and well motivated. As I mentioned previously, it would also be important to analyze the sensitivity of the method with respect to the assumptions build upon. At this stage, I do not think that the paper is ready for acceptance.<BRK>The experiments should be rigorous cause it lacks reliable baselines for comparison. For explanations, the authors did not provide sufficient related works or references to prove that the problem the paper wants to solve is important. For experiments, the results presented in Table 1 are good but there are no official baselines (e.g.from some prior works) to make the comparison more reliable.<BRK>Minor note: there is a typo in the definition of v_iThank you for the submission. Their model may be useful for other domains with phase shifted data, such as multi sensor medical data. The primary reason for this decision is that the authors do not provide sufficient comparisons to related work and models, either in the form of a literature review, or in the form of model benchmarking.<BRK>This paper would be greatly improved by an addition of a related work section. Is there a typo here? They authors mention that these methods would require much more data than their graph convolution approach. I agree this is probably the case, but this would still be a useful empirical result to show the degree of data required for these alternative. What are previous approaches to detecting the properties explored in this work? In addition to discussing previous approaches in a related work section, some empirical analysis comparison would help contextualize this work as well. I think it could be significantly improved with a discussion of related work and better situating of the methods / more comparisons in the results.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>This paper proposes guided adaptive credit assignment (GACA) for policy gradient methods with sparse reward. Experiments of program synthesis and instruction following are conducted, to show the proposed GACA outperform competitive baselines. If it is, clearly show that. Overall, the proposed GACA method achieves promising results in program synthesis tasks. In particular, "Eq.(8) is the optimal solution of KL Eq.(7).Is it also the optimal solution of f divergence used in the algorithm?" Since Algorithm 1 explicitly uses f divergence, I think at least this point should be clarified by the authors rather than my guess. 4.The entropy regularized objective and the KL is kind of well known.<BRK>The authors formulate the credit assignment method as minimizing the divergence between policy function and a learned prior distribution. Then they apply f divergence optimization to avoid the model collapse in this framework. Empirical experiments are conducted on the program synthesis benchmark with sparse rewards. The main contribution of this paper is applying f divergence optimization on the program synthesis task for credit assignment.<BRK>Summary:This work proposed an off policy framework for policy gradient approach calledguided adaptive credit assignment (GACA) in a simplified setting of goal orientedentropy regularized RL. The experiments on sparse reward tasks such as WikiTableQuestions and WikiSQLdemonstrate the effectiveness of the GACA, comparing with a set of advanced baselines. The trajectoryreward is determined by the initial state, goal, and the sequence of actions taken thereafter. The authors also claimed that KL divergence performs worse than f divergence due to the mode seeking issue. Minor:There are many typos or grammar issues in this version.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>##############I have read the author s feedback which addresses some of the confusion parts in the paper. 3) How does the Eq (4),(5) give an estimation \hat{E}? The paper has provided consistency guarantee and several synthetic and real data experiments as support. For example, \hat{H} can have more all zero rows than E which still satisfies E\hat{H}   \hat{H}  but  \hat{E}  is not equals to E. In an extreme case,  \hat{H}   0 will have  E\hat{H}   \hat{H} but is clearly not consistent.<BRK>The authors introduce a method (B2B) for disentangling effects of correlated predictors in the context of high dimensional outcomes.<BRK>It is possible to introduce an L1 regulation in E? ##############After reading the author s feedback and the comments from other reviewers, I keep the current rating but tend to a borderline score and it is ok if it must be rejected because of the concerns of limited applicability and the experimental.
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>The paper proposed a new type of graph embedding technique for dynamic graphs based on tensor representation (node x feature x time). + Clear writing with tensor notations and explanation is well structured + Improved prediction results on 3/4 real world dynamic graph datasets  The theoretical results are a bit artificial. It would be good to show the scaling behavior of the proposed model.<BRK>This paper presents a M product based temporal GCNs to handle dynamic graphs. Experiments on four real datasets are performed to verify the effectiveness of the proposed model. Given the current status, I could not accept the paper. 2, The experimental setup is reasonable. 3, The paper is clearly written and easy to follow. I agree with the Reviewer #4 that the theoretical results are a bit artificial and trivial.<BRK>Summary: this work uses tensor methods to improve graph convolution for dynamic graph, where the nodes are fixed and the edges are changing. Specifically, it uses the M product technique to develop the operations of sequence of matrices that analog to these operations of matrices. Comments: this paper is mathematically interesting. M transfer is a tensor contraction, right? Decision: I feel this work novel and interesting in general.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>This paper is introducing a scale equivariant CNN architecture with joint convolutions over spatial and scale space. Moreover, the authors used decomposable convolutional filters to reduce the number of parameters. Based on Therom 1, it is shown that scale equivariance is achieved if and only if joint convolutions are conducted over spatial and scale space. to verify scale equivariance, visualizing features with tsne would be interesting  in table 1, what is the reason for doing experiments with and without batchnorm? what if the baseline s size is close to the proposed method, how it would be improved?<BRK>*Paper summary*The authors propose a CNN architecture, that is theoretically equivariant to isotropic scalings and translations. *Paper decision*Thank you for writing a very interesting paper indeed. I have to admit I am somewhat on the fence about this paper. *Supporting arguments* Experiments: The experiments are quite light, although I must admit that many other works in the area of equivariance are also light on experimentation and if there is enough theory, that is not such a great issue. The authors treat scale translation in continuous space as a group action on signals. This motivates the convolution presented in Theorem 1.<BRK>The main contributions are the proposed joint convolution across the spatial and scale space, and the decomposed filters to reduce computation cost and improve robustness. The paper is generally well written and well placed in the literature. Different from existing work on the scale equivariance CNNs, they build a more general model that allows different scale information to transfer through different layers. However, for the novelty part of the proposed method (the separable basis decomposition), it is not convincing enough because the differences between this paper and Cheng et al.(2019) and Weiler et al.(2018b) are not clear. The authors claim that the joint convolutions across the space and the scaling group are both "sufficient" and "necessary".
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>In this paper, instead of the original IB, authors consider a previously presented dual problem of Felice and Ay, where the Kullback Leibler divergence is minimized in the reverse direction: from the conditional distribution of output given encoding, p(y|hat x), to the conditional distribution given the original input, p(y|x). The "dual problem" itself has a more complicated form than the original IB, authors claim this is "a good approximation" of the original bottleneck formulation, and aim to prove various "interesting properties" of it. Evaluation:This is an entirely theory based paper; although an algorithm is given, it is not instantiated for any concrete representation learning task, and no experiments at all are demonstrated. However, authors do not quantify these well:  The computational complexity improvement is not made clear (quantified) in a concrete IB optimization task: it seems it is only for exponential families, and even for them only affects one part of the algorithm, reducing its complexity from dim(X) to d; the impact of this is not tried out in any experiment. In its current state the paper, although based on an interesting direction, in my opinion does not make a sufficient impact to be accepted to ICLR. Section 1.5 claims the algorithm "preserves the low dimensional sufficient statistics of the data": it is not clear what "preserves" means here, certainly it seems the decoder in Theorem 7 uses the same kinds of sufficient statistics as in the original data, but it is not clear that hat(x) would somehow preserve the same values of the sufficient statistics.<BRK>This paper introduces a variant of the Information Bottleneck (IB) framework, which consists in permuting the conditional probabilities of y given x and y given \hat{x} in a Kullback Liebler divergence involved in the IB optimization criterion. Interestingly, this change only results in changing an arithmetic mean into a geometric mean in the algorithmic resolution. Good properties of the exponential families (existence of non trivial minimal sufficient statistics) are preserved, and an analysis of the new critical points/information plane induced is carried out.<BRK>This paper proposes a new "dual" variant of the Information Bottleneck framework. The existing framework measures the retained information about the prediction via mutual information, which can be expressed as a KL divergence. In particular,  it can be shown that for exponential families the dual IB representation retains the exponential form. Overall, I think this paper adds a meaningful new perspective to the IB framework and the analysis appears to be thorough. The meaning of the denominator is not clear (it is a normalizing constant).
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>The paper addresses the task of learning with point clouds for semantic labeling (classification and segmentation). With the proposed learnable operations, the authors are able to efficiently learn the functions defined in 3D space, such as the semantic class labels. The operations include transferring the features between the grid and the point cloud, advection, and interpolation, all implemented in a unified learnable model. The architecture is evaluated on classification and segmentation tasks with common datasets, where it performs on par with existing methods. While the experimental evaluation does not indicate that the proposed method is a new state of the art, it convincingly validates that the proposed method is capable of learning powerful enough representations.<BRK>The paper is about using classical PIC/FLIP scheme in Computational Fluid Dynamics for solving the learning problem of 3D object detection and segmentation. This provides a very interesting perspective to 3D deep learning. can be compared with or at least contrasted in the related works. However, the performance of the proposed approach is at best comparable to some of the state of the art methods such as PointCNN or SE Net.<BRK>The work first explains how the simulation algorithm is mapped to the learning problem: MLPs are employed to learn sets of particle based features which are mapped to a Eulerian grid. This is repeated for a certain number of steps to obtain final positions. The paper presents a brief ablation study for number of iterated steps, grid size and point count, before presentation two comparisons with existing baselines. Overall, I found the idea to employ FLIP for Lagrangian learning tasks novel and very interesting. The method does not yield clear gains over previous work, but rather a similar performance for classification and segmentation of ShapeNet and S3DIS data is shown. Several of the deformations shown in figure 5 and 6 are also not really intuitiveAlso, on second sight, I don t fully understand the motivation for employing and learning a grid based deformation. It s also not obvious how to choose parameters such as the number of time steps.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>This paper presents ReMixMatch an improved version of MixMatch. The main contributions are the distribution alignment and the augmentation anchoring. However, there are some negative points that the authors should clarify:  The final method is a mixup of many different techniques, thus, not a strong contribution, but many smaller contributions. As shown in the ablation study, the main contribution on the obtained results seems to be the use of stronger transformations than in MixMatch. Overall the paper is well presented and contributes to further improve the performance on semi supervised learning. I there fore recommend it for acceptance. Would it be better or worse than the proposed approach?<BRK>The major contributions include: (1) distribution alignment to calibrate the predicted distribution of unlabeled data; (2) augmentation anchoring to allow more aggressive data augmentation; and (3) CTAugment to train the augmentation policy alongside the semi supervised model. Overall, the paper proposes some simple but interesting ideas, e.g.distribution environments. As pointed out in the weakness section, many design choices are not well motivated, and the effects of those designs are not well studied. The variation induced by aggressive augmentation is the root of the consistency loss that helps regularize the model. 2.The authors should provide ablation study and analysis of their CTAugment. Also does larger K value when applied for vanilla MixMatch approach the results in ReMixMatch? 5.It is recommended to evaluate the method on larger datasets such as CIFAR 100.<BRK>This paper proposes two modifications for the MixMatch method [1] and achieves improved accuracy on a range of semi supervised benchmarks. The main contribution of the paper is really strong empirical results. Another important contribution is the learned data augmentation strategy, which as far as I understand is novel and overcomes some of the limitations of  existing learned data augmentation techniques. The main drawback of the paper is that it seems to be more engineering focused, and doesn’t provide much insight into semi supervised learning. For the learnable data augmentation it would be great if the authors could provide more insight into the method, how it works, and why is it better than the alternatives. I would recommend discussing these results briefly in the paper.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>This paper describes a method for ensemble distillation that retains both types of uncertainty in the case of classification. The idea is to train a prior network (i.e.a conditional Dirichlet distribution) to model the distribution of categorical probabilities within the ensemble. Pros:The paper considers an interesting problem, and makes a clear contribution towards addressing it. The paper is very well written and easy to read. Cons:The scope of the paper and the method is limited to the problem of probabilistic classification. Decision:Overall, this is good work and I m happy to recommend acceptance.<BRK>It also proposes a new metric for evaluating the Prediction Rejection Ratio (PRR), uses it to compare how the EnD^2 model compares to the original ensemble and the EnD model. Rebuttal response:I acknowledge the authors  point about the importance of EnDD in addition to knowledge uncertainty estimation, and maintain my rating.<BRK>  Post Rebuttal   I appreciate the authors  effort in addressing the raised issues. (III) Missing from experiments  The main goal/motivation of the paper is to be able to decompose the total uncertainty when distilling an ensemble into a single model. Th concerns on consistency and conclusiveness of the results can hopefully be addressed in a journal version of the work as suggested by the authors. Does a “successful” training of the prior network require a large number of samples? Hyperparameter optimization: Appendix A provides the final values for the hyperparameters of each method.
Accept (Poster). rating score: 8. rating score: 3. <BRK>The main problem they try to tackle is to train agents for unseen tasks and environmental changes. The authors clearly position their work in the HRL paradigm and explain current limitations/challenges within that field. The paper is very well written, clearly stated the contributions. This behaviour is not described anywhere. The URL of the website with code and videos does not have any code. Why are the results of different methods (p 10/random) in Table 1 for different environments (Snake/Ant) different?<BRK>This paper is under the topic of hierarchical reinforcement learning. The motivation of this paper is "most methods still decouple the lower level skill acquisition process and the training of a higher level that controls the skills in a new task." The paper proposes a method to learn higher level skill selection and lower level skill improvement jointly. What I like in this paper:    1. My biggest concern is the motivation of this paper. 2.I think the author didn t justify his key design choices well. Section 2: the horizon T in the definition in \eta should be H.Section 4: the advantage function is not defined.
Reject. rating score: 1. rating score: 1. rating score: 6. <BRK>There is no intuitive discussion on what is missing in existing methods, why the proposed method can be better, and when the proposed method may also fail. Note that an important related work is missing, namely "Robust Inference via Generative Classifiers for Handling Noisy Labels" from ICML 2019 (see https://arxiv.org/abs/1901.11300). That paper was a 20 min long oral presentation at Hall A (i.e., one of the most crowded sessions), and the authors should really compare with it both conceptually and experimentally.<BRK>It is recommended to reject the paper, with the following concerns in mind. (1) The proposed approach is not deeply studied. Without the deeper study, Section 3 is at best a naive use of k NN for data cleaning, and it is not clear whether the contribution is substantial. It seems more related to applying k NN in general. (3) It is not clear whether the experiments are compared with respect to state of the art (or at least it is hard to see from Section 2). It seems that rather straightforward baselines are being compared. I thank the authors for clarifying this.<BRK>This paper proposes a k NN method for identifying corrupted labels, and then applies this k NN in the representation space of a deep neural net rather than the original feature space. Overall the paper is well written and the results look quite convincingThe theory appears to be important (if somewhat straightforward looking) contributions of existing k NN theory to the corrupted labels setting, based on the key quantity the authors defined as S_k, the minimum k NN spread.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>This work introduces a new polynomial feed forward neural network called Ladder Polynomial Neural Network (LPNN). Theoretical results show that LPNNs generalize vanilla PNNs and FMs. I assume that it is given in the input layer l 0, according to the notation. However, I still consider that the contribution of the paper is limited, and should be improved for a clear acceptance.<BRK>This paper proposes Ladder Polynomial Neural Networks (LPNNs) that use a new type of activation primitive   a product activation   in a feed forward architecture. The observation in 3.3, that batch normalization or dropout can be used for this model is perhaps tangential to the main argument. Overall, I think the paper has some merit and could be interesting for some readers, despite the fact that the contribution is not very original and the treatment could be improved in many ways.<BRK>In this paper, the authors a new type of polynomial neural networks LPNN that can have an arbitrary polynomial order. Empirical study shows that deep LPNN models achieve good performances in regression and classification tasks. In general, the paper is clearly written by addressing an interesting problem but I still have several concerns. The authors are expected to report more complex tasks to show its effectivenss.
Reject. rating score: 3. rating score: 3. rating score: 6. rating score: 8. <BRK>In addition, the author consider for two cases with the importance of second order oracle and use Hessian to improve the approximation of gradient when first order and second order oracle are equally important. In general, the paper is well written and easy to follow, but I still have some questions about this paper. More discussion about this issue is needed. .Second, to the best of my knowledge, the trust region radius is changing during the iteration for basic trust region algorithm. In practice, it is important to consider the space complexity. However, this work did not provide any space complexity analysis, especially to compare with first order algorithms. The authors need to make more comments on this issue. Finally, I think the experiment results contradict the theoretical results. However, the convergence analysis provided by the authors claim that the convergence speed is sublinear. I believe such a difference is due to a fact that the initialized parameter is near to the global minimum, thus the optimization landscape here is actually convex but not non convex.<BRK>This paper applies the spider algorithm (Fang et al., 2018) for reducing variance in first order stochastic optimization to a second order optimization algorithm, i.e., trust region algorithm. However, the idea of variance reduction is not novel and the result is not surprising since the improvement comes purely from spider (Fang et al., 2018) and thus this work is somewhat incremental. The comparison of this paper with a similar paper by Zhou & Gu (2019) is not convincing. But the authors did not present the complexity of SRVRC in Table 1. This is not appropriate since it is very similar and related to this paper. However, the cubic regularization based algorithm in Zhou & Gu (2019) can also achieve the same second order oracle complexity. Many places can be simplified or combined in order to increase the readability of the main theorems. The paper talks about $\epsilon$ SOSP, $\tilde{O}(\epsilon)$ SOSP, $12\epsilon$ SOSP and so on in many places. In the text after Corollary 4.1, there are some typos in the complexities where a $\min$ operator is missing. I quickly checked their paper and found in their table that the SFO complexity of Zhou & Gu (2019) is $\tilde{O}(\min\{n/\epsilon^{3/2},n^{1/2}/\epsilon^2,1/\epsilon^3\})$, which is in fact smaller than the complexity of STR1 in this paper.<BRK>This paper proposes new stochastic trust region algorithms for non convex finite sum minimization problems. The first algorithm STR1 has lower second order oracle complexity, while STR2 has lower first order + second order oracle complexity. The authors also give a Hessian free implementation of stochastic trust region algorithm. Technically, the authors first analyze trust region methods with inexact gradient and Hessian estimation, and then implement efficient gradient and Hessian estimators. Overall this paper is well written and easy to follow. I would recommend acceptance.<BRK>The authors propose a new analysis for trust region methods with approximate models. Using this result, they propose a number of methods to create stochastic trust region methods by constructing approximate quadratic models (based on a stochastic first and second order estimate) which satisfy the requirements for convergence. This paper is overall an interesting contribution which proposes a number of competitive methods for achieving approximate local minima in a stochastic regime, with both hessian based and “hessian free” methods. A couple of minor points:  In the experiments, it would be helpful to also include some measure of uncertainty (such as standard error bars) in the plots given the stochastic nature of the problem (although I do not expect high variance given the construction of the algorithm).
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK># 1.SummaryThe paper deals with the problem of learning grounded captions from images without joint text location information, but instead texts (words in captions) and locations are provided independently and the model needs to figure out their link. The model is built upon GVD (Zhou et al., 2019): each word generated by the encoder is grounded to the locations provided by the region proposal module (Up Down model (Anderson et al., 2018)), used to reconstruct the ground truth caption. Clarity and MotivationThe paper is generally well written, however there are some concerns on motivations. The authors use grounding as a proxy to improve image captioning results, which improvement is marginal wrt GVD (see Table 1). Why do we need to localize text if this has very marginal impact on the captioning metrics? It is missing the link between the potential applications where the localization of words is relevant. The authors claim that they do not uses any grounding annotation, however the pre trained Faster RCNN has been trained using annotations which consist of bounding boxes + categories. The authors should assess if this ovelap/bias in the pre trained Faster RCNN exists or not. Some other questions are still to be answered:* How are the regions R parametrized? Is it the visual representation or bounding box locations? * What happens to words that are not grounded to the image (e.g., verbs or articles)? * What is the intuition of multiplying word embedding and region embeddings to generate z in Eq.6?# 3.NoveltyThe proposed method is an extension of the existing model GVD, where the attentional module is removed and its functionality is replaced by the cyclical training mode with reconstruction of the object locations. # 4.ExperimentationThe experiments are carried out in a scrupulous way, by showing the comparing with GVD (with and without attention; with and without grounding supervision). These results are not convincing, combined by the fact that it is not clear in which applications one would want a very accurate grounded text. # Minor Points* Sec.3.1: it is not clear that the Language LSTM is the decoder.<BRK>The experimental results show that the performance on image captioning and video captioning are improved without grounding supervision. The motivation using cyclic feedback itself is not so novel for language generation, but focusing on grounding without localization supervision for visual captioning is interesting. The experimental results show that the proposed method can boost performance both qualitatively and qualitatively. I have several comments and questions below. If the combination of self attention in GVD and cyclical training proposed in this paper is complementary to each other, it does help to improve the overall accuracy. While the authors develop a cyclical training pipeline, including decoding, localization, and reconstruction, Figure 1 does not show which part corresponds to the decoding phase. The authors should clarify it to make the paper easier to be understood. $\theta^*$, a sum of two parameters for each arg max operator, doesn t guarantee that each term in the right side of Eq.(5) keeps its max. This equation seems to be a conceptual one, and the actual training would be performed according to Eq.(7).Therefore, the experimental results might not be influenced by the error in Eq.(5).$\hat{r}^l_t \beta_t^\top R$ between Eq.(6) and Eq.(7) means that $\hat{r}^l_t$ is a row vector while $r_n$ seems to be a column vector. There are similar errors, such as "5 GT captions" and "1 GT caption" in Sec.4.The format of items in References is not consistent. How are the experimental results sensitive to these hyperparameters?<BRK>The paper proposes an architecture that grounds words from a captioning model, but without requiring explicit per word grounding training data. Instead, they show that it is sufficient to use cycle consistency, verifying that by predicting word >grounding >word the two words are the same. This paper takes it to the domain of vision and language. While the novelty is not very large it seems like a solid step in an interesting direction. Evaluated on both image and video captioning with substantial localization improvement in the specific relevant eval settings. Specific comments:   In Table 1, the part of "Caption Evaluation" the proposed method is in bold, but it seems that "Up Down" method out performs the proposed method in B@1 and B@4. The localization model is linear? What would be the effect of richer models on localization accuracy? Qualitative analysis: It would have been useful to add evaluations by human raters to measure the perceptual quality of the localization.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>The authors consider the problem of sampling time series. To solve the problem they propose a method that is based on the autoregression model. The distinctive feature of the algorithm is speed up for the sample generation process. It seems like a good idea to compare to these methods (and it seems that video generation is a very resource demanding procedure, and they don t use parallel applications similar to proposed in the paper.What is the reason?) Most of the approaches use only one frame to generate video, but it seems that LSTM in these methods will benefit from using of multiple frames as input (and will be able to transfer information in autoregression manner by transferring all they need in a hidden state). In Figure 2 (a) it is not clear how the data and prediction were generated.<BRK>The paper presents a technique for approximately sampling from autoregressive models using something like a a proposal distribution and a critic. The idea is to chunk the output into blocks and, for each block, predict each element in the block independently from a proposal network, ask a critic network whether the block looks sensible and, if not, resampling the block using the autoregressive model itself.<BRK>This paper addresses the sequential limitation of autoregressive model when doing sampling. Would any of the existing AR speedup method be applicable for a comparison? Overall the paper is well motivated, with an interesting design of the variational distribution to approximate the true autoregressive distribution. The design of the confidence model looks a bit heuristic, but the trade off ability between efficiency and quality it brings is also quite interesting.
Reject. rating score: 1. rating score: 3. rating score: 3. rating score: 3. rating score: 6. <BRK>Main difference of this method is compared to Gauss Newton, is that it uses JJ  as curvature, which has dimensions b by by (batch size b), instead of J J as curvature, which has dimensions m by m (number of parameters m). Bulk of the paper is dedicated to theoretical convergence and connections between concepts. Since the focus of the paper is on a new optimization method for deep learnning, I feel like convergence proofs can be moved to Appendix, and more of the paper should focus on practical aspects of the method. Their method seems to be limited to neural network with one output (ie, univariate regression task). Experiments are performed on two tasks that are not well known in the literature. The choice is somewhat understandable given that their method performs for univariate regression, but also this makes it hard to evaluate whether the method works. The changes needed to make this paper acceptable are extensive, and I would recommed a reject.<BRK>The authors propose a scalable second order method for optimization using a quadratic loss. The method is inspired by the Neural Tangent kernel approach, which also allows them to provide global convergence rates for GD and batch SGD. However, this is not clear in the paper, instead section 3.1, is a bit vague about the derivation of (9). They rely essentially on the convergence results established for NTK in [Jacot2018, Chizat2018]. The main novelty is that the authors provide faster rates for the Gauss Newton pre conditioner which leads to second order convergence. This makes the result less appealing as in practice this is highly unlikely to be the case. A more fair comparison would be against other second order optimizers like KFAC. I think the paper will be stronger if extended to more general cases (multivariate output + more general losses), thus I encourage the authors to resubmit the paper with stronger experiments.<BRK>As pointed out by other reviewers, the proposed algorithm is restricted to single output regression and the claim "accelerate convergence without much computational overhead" might not be true in general multi output regression tasks. That being said, I do find the algorithm interesting and the theoretical results impressive. I encourage the authors to include experiments on multi output regression tasks (or tone down the claim about computational overhead) and resubmit the paper. Based on recent progress on the connection between neural network training and kernel regression of neural tangent kernel, this paper proposes a Gram Gauss Newton (GGN) algorithm to train deep neural networks for regression problems with square loss. Overall, this paper is well written and easy to follow. I think the authors should make the connection clear. I would like to see more discussions with natural gradient descent or Newton methods in the next revision. The authors claim that the proposed GGN algorithm only has minor computational overhead compared to first order methods.<BRK>My overall assessment is that the method is still quite limited and the method itself is not novel, but I am willing to change my score to accept if my concerns have been addressed. (2) The method is still quite limited to 1 output function scenario, where the NTK matrix is easy to compute. This limitation though is not mentioned in the paper. I hope the author should have a discussion on this and admit this limitation. (5) In the theoretical section, the paper states "However, to our knowledge, no convergence result considering large learning rate (e.g.has the same scale with theupdate of GGN) has been proposed." Here are some papers: [2,3,4](6) Lack of some second order optimization baselines, e.g., KFAC. I wish to see more evidence of showing they re the same as authors claimed. [3] Fast and Faster Convergence of SGD for Over Parameterized Models (and an Accelerated Perceptron).<BRK>Their method is described in Algorithm 1, but to summarize it, they use the Gauss Newton method to train neural networks, and prove quadratic convergence for the full batch training. Due to the seeming extra computational cost of the method, (the method requires computing the full Jacobian matrix which depends on the number of neural network weights) I am grateful that they provided comparisons with wallclock time to SGD. And there is this notion that second order methods have been shown to not generalize as well as first order methods, and thus it was nice to see that they had an experiment where they tested generalization. The background information was also nice to read. Weaknesses: They do not compare it with other methods optimization methods, such as Adam (a first order method) or natural gradient (a second order method), and I would have thus liked to have seen comparisons to these.
Accept (Poster). rating score: 8. rating score: 8. rating score: 6. <BRK>The authors propose a novel framework for training a knowledge grounded dialogue model. Overall I think it’s a strong paper with a good set of experiments, baselines, and considers multiple datasets. Disentangling the model elements is a clever way to allow for more robust pre training, and indeed yields favorable results.<BRK>The experimental results show that the proposed architecture help to resolve the low resource problems of knowledge grounded dialogue generation. Overall, this is a well written paper with reasonable ideas supported by strong empirical evidences. Secondly, knowledge encoder can be built purely on knowledge sources in parallel with the dialogue based components.<BRK>This paper studies knowledge grounded dialogue response generation in the low resource setting. In Figure 2 (c) and (d), some ablation results are reported for when pre training is removed for each of the three components independently. If so, are these baselines strong enough (SOTA or close to SOTA) to help draw a meaningful conclusion from comparison with them? Can authors comment on this? Except for pre training, the only difference from [2] is that copying and generation distributions are softly combined into separate distribution each, independently.
Reject. rating score: 3. rating score: 6. rating score: 8. <BRK>Thus they propose a way to constrain the posterior mean to alearned probability simplex and only perform manipulation within the probability simplex. The tackled problem is important. Variationnal text auto encoding is a very challenging task, for which no perfect solution has been proposed yet. Next, to ensure that information is filled in this constrained part, they define a pairwise ranking loss which enforce the mean of each sentence to be more similar to the output of the encoding lstm than the mean of other sentences. In what sense does it ensure that the space does not contain holes ? What ensures that the constrained part of the code is actually used by the decoder ? My main concern is with regards to the experiments, which are clearly not enough detailled. First, I cannot understand what NLL is considered in the preliminary experiments. Authors study the effect of code manipulation on an NLL. But the likelihood of what ? But what sense does it make to assess the nll of the generated sentence ? Also, authors compare the impact of modifications on the representations of $\beta$ VAE with modifications on their model, but these are not the same modifications. What ensure that they have the same magnitude ? Comparisons with metrics on text style transfer are also difficult to understand to me.<BRK>This paper presents a method for controlled text generation by using a new loss function (standard VAE loss with auxiliary losses added on). To address this problem, they constrain the posterior mean to a learnt probability simplex and try to ensure that the simplex is densely filled. This could be placed in an Appendix. In section 6.3, is K still 3 or is it now > 4? Some citations issues   You re missing a couple key citations. Additionally, I d like to see some more detail about the robustness of the method. The presented results are impressive but have a few missing pieces: citing some key results (Lample et al.2019) and including results about robustness. I think the questions I have, and any shortcomings this paper has, could be addressed in a camera ready version.<BRK>This paper tries to pinpoint why sequence VAEs haven t worked well to provide disentangled representations. The authors posits that this happens due to the fact that perturbing the intermediate representation (codes) pushes them in regions which are not seen in training, and hence the model is not well equipped to perform well for those codes. To address this, they augment the VAE objective with terms to ensure that codes are present in a probability simplex and the entire simplex is uniformly filled by codes. I found the observation very interesting, and the supporting experiments confirm the hypothesis. However, since I do not actively work in this area, I am not sure how exciting the result will be to other researchers. There s some related work on controlled text generation.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>The authors propose to express the weight of a convolutional neural network as a coupled Tucker decomposition. The Tucker formulation allows for an efficient reformulation. Notation should be unified in the text and captions (e.g.Table 1).In 3.2, when specifying the size of G, should it be G_r? It was not introduced.<BRK>Summary This paper proposes to learn simultaneously all the parameters of grouped convolutions by factorizing the weights of the convolutions as a sum of lower rank tensors. This enables architecture search for the convolution parameters in a differentiable and efficient way. As the authors present it in the abstract and introduction as an alternative to NAS, I believe a comparison to a NAS would be needed. Comments I think was paper is well written, and was clear at least until 3.2.<BRK>Summary: The authors introduce GROSS a reformulation of block tensor decomposition, which allows multiple grouped convolutions (with varying group sizes) to be trained simultaneously. However, it is quite niche and while the authors frame it as a form of NAS in my view, this contribution is more in the realm of hyperparameter search for grouped convolutions, and not NAS in general. In addition, the empirical results are relatively shallow, with only one dataset and without detailed discussion of the variance of the results.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>Summary The authors propose a novel meta rl problem where hierarchical tasks are characterized by a graph describing all sub tasks and their dependencies. They propose a meta rl approach to meta train a policy that quickly infers the subtask graph from new task data. In particular, the authors consider a large scale Startcraft II experiment which proves the efficiency and scalability of the proposed methodology. This work presents interesting and novel ideas in these settings. The experiments are quite interesting and convincing. I did not find any plot reporting it.<BRK>The authors also propose a UCB inspired intrinsic reward to encourage exploration when optimizing the adaptation policy. Overall, this paper is mainly an extension of the prior work [1], which uses a subtask graph for tackling hierarchical RL problems. This work builds upon [1] by extending to meta learning domains and studying generalization to new hierarchical tasks. While the contribution seems a bit incremental and the experimental setting is a bit unclear and limited to low dimensional state space, the inference of task specific subtask graphs based on past experiences and the proposal of a UCB inspired reward shed some interesting insights on how to approach meta hierarchical RL where long horizon tasks and sparse rewards have been major challenges. I also don t understand why MSGI Meta and RL2 would overfit in the SC2LE case and are unable to adapt to new tasks. It seems that the authors don t use a meta RL agent in order to get this domain to work. In NeurIPS, pp. 7156–7166, 2018.<BRK>The main problem that is tackled here are tasks that have a main goal that can only be reached by solving prerequisite tasks. They test their method on a simple game and a very complex one. Methodology and noveltyThe authors combine various techniques (subtask graph inference, gradient based meta learning and inductive logic programming). What is the big difference from the work by Sohn et al.(2018)?ExperimentsThe authors evaluated one agent. It would have been better if they trained multiple agents and showed a performance distribution, so it is clear that the performance is not just achieved by luck (Fig 5.). PresentationFigure 3 does not give a description of the subtask graph (middle) and the StarCraft II.
Accept (Poster). rating score: 8. rating score: 6. rating score: 1. <BRK>This paper proposes a new type of weakly supervised clustering / multiple instance learning (MIL) problem in which bags of instances (data points) are labeled with a "unique class count (UCC)*, rather than any bag level or instance level labels. The paper also provides a theoretical argument for why this approach is feasible. In slightly more detail:  (1) MIL where we are given bag level labels only is a well studied problem that occurs in many real world settings, such as the histopathology one used in this paper. However to this reader s knowledge, this is a new variant that is both creative and motivated by an actual real world study, which is exciting and alone warrants presentation at the conference in my opinion. (2) The theoretical treatment is high level, but still serves a clear purpose of establishing feasibility of the proposed method  this modest and appropriate purpose serves the paper well. Either way, it seems that a different approach than the KDE layer could have been taken  this should be added to the ablation experiments<BRK>The authors present a novel weakly supervised multiple instance learning model based on a bag level label called unique class count(UCC). The core content of the method is to learn mapping between bags and their associated bag level ucc labels and then to predict the ucc labels of unseen bags. Positive:(1) The authors use the unique class count(UCC) in the bag as a weak, bag level label to design a deep learning based UCC model for extracting features and clustering the individual instances in the unseen bags. (2) In this paper, a large number of experiments show the effectiveness of the algorithm in different data sets and semantic segmentation of breast cancer metastases. The authors’ proofs are not enough to prove whether the designed UCC classifier is perfect.<BRK>This paper proposes a MIL clustering method. The proposed MIL setup is called "unique class count (ucc)", this is, for a bag os samples ucc is the number of clusters in the bag. Once trained on a dataset the method can perform clustering on classes (classify) better than a fully unsupervised clustering algorithm and worse than a fully supervised model. The method is evaluated on MNIST, CIFAR10, CIFAR100  and on binary breast cancer segmentation. The main table of the paper (Table 1) compares the results of the proposed methods only with unsupervised methods and a fully supervised one. The results are reasonable. However, not a fair comparison. UCC model uses bags of sizes from 1 to 4. Moreover, during training, I guess that the same sample can go to different bags. And also, one could trivially get the full label of each sample.
Reject. rating score: 3. rating score: 3. rating score: 3. rating score: 6. <BRK>SummaryThis paper proposed a new graph pooling method based on the Haar basis on graphs. Therefore, I judge the paper as a border, tending to reject for now. Suggestions  The main part of the paper is 10 pages long. Another idea is to demonstrate it empirically by providing time and memory consumption to the experiment results. page 13, Appendix B, (10)	   I think "1" in this equation is an all one vector.<BRK>Overall graph classification and regression tasks are quite important and this work provides a new way of transitioning from node based learning methods to full graph representations via hierarchical compression. Nonetheless, I find that the organization of the paper needs additional work and the experimental investigation is not sufficient and compelling enough. In particular I find the discussion of the HaarPooling step s computational performance not particularly appealing since other parts of the hierarchical approach are computationally expensive for example, the spectral clustering or GCN steps are costly.<BRK>This paper presents a new graph pooling method, called HaarPooling. 2) The main contributions of this paper are not clear to me, compared with other SOTAs. HaarPooling can be applied in conjunction with any type of graph convolution in GNNs. The writing, organization and presentation are satisfactory.<BRK>The paper presents a new approach called HaarPooling in the context of Deep Graph Neural Networks. The approach solves dmiensional problems of applying the same model on graphs of different size and shows how to contribute to high performance in a set of graph classification tasks, while having low computational complexity. The paper is very well written. An explanation on this could be beneficial.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>This paper first provides a theoretical interpretation of separation rank as a measure of a recurrent network s ability to capture contextual dependencies in natural language text. The analysis is primarily done in the context of tensor space language models (TSLM) that was demonstrated to be a generalisation of n gram language models in earlier work. This dichotomy is overly simplistic and ultimately false. 5.The paper mostly fails to report performance comparison with existing numbers from prior work.<BRK>The goal of this work is quite interesting, but the reviewer feel a bit challenging to follow the writing. But the paper does not introduce TSLM in detail, making the part relevant to TSLM quite inaccessible. The analysis of the work is based on the model in (2), which is merely an approximation for the joint probability. Since the authors are considering a sequence, this may be related to de finetti s theorem and its extensions. If one wishes that the SVD reveals the rank K, K has to be smaller than the outer dimensions of the tensor T. This was not specified in the statement. We know in NLP pre trained word embeddings may be more useful. Did all the experiments use one hot embedding? The writing is a bit hard to access and the proofs might be a bit loose (did not check all of them.But Claim 1 is already a bit loose).<BRK>This paper derives lower bounds on the separation rank of a wider class of recurrent NLP models in terms of its depth and number of hidden layers, demonstrating that both the number of hidden units as well as the number of layers improves the ability of NLP networks to model context dependency. It then introduces a novel bidirectional NLP variant that is supposed to capture a good trade off between computational cost and performance. The improvements of the bidirectional models also seem to be minor, but no standard deviations for the performance results are reported. A clear description as to which language models are captured by the TSLM model is missing. Finally, the title does not reflect the content of the paper (there is nothing interpretable about the network structure).
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. rating score: 3. <BRK>The question addressed is that SOTA NLI models tend to lead tohigher confidence when some parts are deleted from the "premise". It is a problem known as under sensitivity. The idea of Interval Bound Propagation (IBP) is to use interval arithmetic to propagateintervals and bound the variation of the target basedon variation of the input. The paper is well written and easy to follow.<BRK>This paper proposes a model to verify the robustness of NLP models (change in the original probability), more specifically DAM, in the case of word removals in the input. The upper bound at the final layer is then compared with the label probability of the original input to assess if the probability increases or not. Overall, the paper is well written and the idea of using IBP with an attentive model seems to work empirically for SNLI datasets.<BRK>  Overall  This submission tackles to verify the “under sensitivity” problem of neural network models in the natural language inference by ensuring modes do not become more confident in the predictions when arbitrary subsets of words from the input text are deleted. The authors developed new verification approaches based on decomposable attention mechanism with interval bound propagation (IBP), which can prove the under sensitivity issue given a model and a particular sample.<BRK>This work is an application of interval bound propagation on evaluating the robustness of NLI model. This work is well motivated, assuming that the confidence of a neural model should be lower when part of the sentence is missed. However, the application of vanilla IBP is quite limited in certain model architectures.
Accept (Spotlight). rating score: 8. rating score: 8. rating score: 6. rating score: 6. <BRK>This paper provides both theoretical insights and empirical demonstration of this remarkable property.<BRK>In terms of discoverability, the authors would do the community a service by titling the paper in such a way that it captures the set up well. Could the authors explain this?<BRK>Could the authors explain this? In terms of discoverability, the authors would do the community a service by titling the paper in such a way that it captures the set up well.<BRK>%%% Update to the review %%%Thanks for your clarification and the revision   the paper looks good!
Accept (Poster). rating score: 6. rating score: 6. rating score: 3. <BRK>This paper makes an interesting theoretical contribution; namely, that SGD with momentum (and with a slight modification to the step size rule) is guaranteed to quickly converge to a second order stationary point, implying it quickly escapes saddle points. SGD with momentum is widely used in the practice of deep learning, but a theoretical analysis has remained largely elusive. This may also help to understand some of the limitations of this analysis.<BRK>In particular, the main contribution of the paper, as the authors claim in the abstract, is showing that stochastic momentum improves deep network training because it modifies SGD to escape saddle points faster. 3) The presentation of Section 3.2.1 is also not clear. I am suggesting to the authors to explain in more details the theoretical results of their paper and highlight why the 5 lemmas of this section are important to be in the main part of the paper. "Accelerated gossip via stochastic heavy ball method."<BRK>*Summary*This paper studies the impact of momentum for escaping Saddle points with SGD (+momentum) in a non convex optimization setting. They prove that using a large momentum value (i.e.close to one) provides a better constant for the convergence rate to second order stationary points. The approach is well motivated by the current seek for a better understanding of the training methods used in practical deep learning. However, I am not fully convinced that this work provides a results that exhibits a regime where momentum helps to escape saddle point faster (or to converge faster).
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>In general, this paper follows the min max training framework for adversarial robustness. Instead of using a gradient based attack to solve the inner maximization, the authors use a neural network to learn the attack results. Since this is a new way of robust training and there is no certified guarantee, I suggest the authors refer [1] to evaluate the effectiveness of the defense more thoroughly to convince the readers that it really works.<BRK>The authors propose a framework where one component is an attacker network that keeps learning about how to perturb the loss more, and one component is a defense network that robustify learning with respect to the attacker network. I have read the rebuttal and thank the authors for the response. Instead of just checking the differences of the attacking examples generated, can we take the inner attacker and see if it is more effective in attacking than PGM and CW? However, we see very little information on how to train the framework in the paper.<BRK>The paper proposes a new way of adversarial training by placing another neural network called "attacker" network, and let the attacker to learn how to generate adversarial examples during training. This training scheme is formulated to solving a joint training according to min max problem.
Reject. rating score: 1. rating score: 3. rating score: 6. rating score: 6. <BRK>This paper proposes a deep neural network solution to the set ranking problem. However, I have several concerns about the paper. Given the input sets A and B, how are the “current utility” computed. In Eq.(6) it seems that only one of R and P is multiplied by a non zero coefficient. For the real world experiments, the method seems to perform marginal better on average. Also note that the baselines are not deep neural networks, so do not leverage the capability of automatic differentiation and optimization. The authors’ adaptation for Rank Centrality involves summing up the weights; this does not model their interaction and seem to be a weak baseline. I was confused about the notation. I think this is unnecessarily cumbersome because the current work seems to be a natural instantiation of a modern neural network to this task. Alternatively if the authors can explain the connection more concretely (i.e some parameters learned by the neural network recovers models in prior work) the arguments can be convincing.<BRK>The experiments show the efficacy of the proposed methods. I have some major concerns with this paper. The paper presentation is not very clear. The paper contains many imprecise statements. Also, the presentation of the paper could be further improved. Therefore, I would keep the same score. This adds to the confusion. 2.The paper mentions multiple times that it does not use statistical models tailored for a dataset or application but instead use deep neural networks. In my opinion, NN is just another form of statistical model that captures statistical patterns of comparisons and in group interaction. The authors may want to rephrase those statements.<BRK>This paper proposed a novel architecture to tackle the match prediction problem. The G module takes the final utility estimates of the individuals in a given group comparison as input and produces the winning probability estimate of one group preferred over the other in the given group comparison as output. I would recommend a weak accept for this paper based on the following reasons:* Both the R/P and G modules  input and output dimensions are independent of the number of items. * The theoretical foundation is sound. I would hope that the authors will make some effort in making the paper more approachable and  practical:* A more detailed motivation section for the architecture will make it much easier for the readers to understand. * A conclusion plus future work section could come in handy for future researchers.<BRK>This paper attempts to solve match prediction problem, i.e., whether a group is preferred over the other. The key challenge is "consistency" since it s hard to find the universal pattern over tasks. Instead, this paper propose to learn reward and penalty modules and both vary when the underlying model changes. My comments:[1] The paper is well written[2] This paper tries to solve an interesting problem but the application is a bit limited[3] It would be great to conduct ablation study, e.g., analyze efforts of different components (R, P, G)
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>To sum up, the reported results in the paper are not convincing to me. The idea is interesting in the sense that an efficient self masking technique is proposed to generate user adaptive hash codes, by differentiating the importance of binary bits, for a fast recommendation system.<BRK>And some presentation in the parameter setting are not clear, e.g.,  is chosen consistently across all data sets ,  was consistently chosen .<BRK>The whole paper, especially the model, is not presented well.
Reject. rating score: 1. rating score: 1. rating score: 1. <BRK>The experiments seem not totally convincing. Most critically, the method does not seem to exhibit state of the art performance as claimed, but is somewhat lower (in terms of accuracy) than other baselines. It s claimed that these are the only datasets with user and item content, but why are both needed to run an experiment?<BRK>This paper omits the related work part and does a rough introduction to two baselines (CDL and DropoutNet) in a confusing way in Section 2. The experiments do not provide convincing evidence of the corretness of the proposed method, especially in Section 3.3.<BRK>The DropoutNet method in your experiments is very similar to CDL in terms of accuracy. Still, I’d strongly recommend adding to your experiments comparison with simpler hybrid models, e.g., Factorization Machines. Major drawback of the work is that it does not provide any quantitative evidence to support the main claim – that the proposed approach is at least more computationally efficient, since it underperforms competing methods in terms of accuracy. I would therefore suggest rejecting the work. 2)	A lot of attention is given to the “marketing application”. There are many typos and error both in text and in derivations.
Reject. rating score: 1. rating score: 1. rating score: 1. <BRK>This submission proposes NORML, a meta learning method that 1) learns initial parameters for a base model that leads to good few shot learning performance and 2) where a recurrent neural network (LSTM) is used to control the learning updates on a small support set for a given task. Same in fact can be said about many of the results reported in Table 1. Limited novelty: it is a fairly incremental variation compared to the Meta Learner LSTM (Ravi & Larochelle).<BRK>Minor:  page 1: Supervised few shot learning "aims to challenge machine learning models to ...": It does not challenge ML models; it is a specific ML paradigm. Theoretical and technical novelty is rather minimal. page 3: "The LSTM based meta learner proposed in this work, allow gradients to"   "Memory based Under review as a conference paper at ICLR 2020 methods (Ravi & Larochelle (2017)) that use all of the learner’s parameters as input to a meta learner tend to break down when using a learner with a large number of parameters (Andrychowicz et al., 2016).<BRK>This paper proposes a meta learner that learns how to make parameter updates for a model on a new few shot learning task. Ravi & Larochelle. ICLR 2017. The LSTM based meta learner proposed in this work, allow gradients to effectively flow through a large number of update steps. Because of these issues, it is hard to evaluate whether the idea proposed is of significant benefit.
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>The key idea is to set up a multi dimensional objective, where one dimension is about prediction accuracy and another about fairness. However, there may be several problems with this approach:1) For a causal estimate to be valid we need several assumptions. These assumptions are not discussed in the paper. Furthermore, the particular context of the paper, where the treatment is actually an immutable characteristic, makes such discussion much more subtle. Some other problems:  What is the reason for focusing on  neural classifiers ? What exactly is a "sensitive attribute"? In fact, many scientists would agree that causal inference is impossible without manipulation.<BRK>While the proposed method makes sense, I am not sure what exactly their contribution is. It is kind of clear that Pareto optimal exists, and what they did is to run the experiments multiple times with multiple \lambda values for the Chebyshev method and plot the Pareto optimal front. Just use test (validation) set to estimate the accuracy & fairness, then plot the results on the 2d plane.<BRK>The authors propose a novel joint optimisation framework that attempts to optimally trade off between accuracy and fairness objectives, since in its general formal counterfactual fairness is at odds with classical accuracy objective. As main contributions, the paper provides:* A Pareto objective formulation of the accuracy fairness trade off* A new causal fairness objective based on the existing Weighted Average Treatment Effect (WATE) and Average Treatment Effect for the Overlap Population (ATO)Overall, I think the paper makes an interesting contribution to the field of fairness and that the resulting method seems quite attractive for a real world practitioners.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>This paper analyzed which learning rate schedule (LRS) should be used when the budget (number of iteration) is limited. While there is some concern regarding the significance of novelty,  the paper seems meaningful enough to be accepted. 2.Various experimental results show that the simple linear decay method works well, and it might become a baseline method for future budgeted training solutions (assuming there is no similar work with the same purpose).<BRK>This work presents a simple technique for tuning the learning rate for Neural Network training when under a "budget"   the budget here is specified as a fixed number of epochs that is expected to be a small fraction of the total number of epochs required to achieve maximum accuracy. In this family of schedules, the paper shows that a simple linear decay works best for all budgets.<BRK>Pros:The paper is clearly written. Actually the linear decay schedule changes may simply find a good learning rate during training as long as the initial learning rate is larger than the optimal one. Nevertheless,  the problem setting and the observations could be beneficial to the community for further discussion, So I raised my score to weak accept. I would like to see other lr schedules in Table 2. My major concern for this work is a lack of deeper understanding about the reason why linear LR schedule works better, if any. What is the lr decay unit for linear schedule? I would expect the convergence to be related with number of iterations.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>Each protein folds to a 3D structure. It is well known that the function of a protein is determined by its 3D structure. Different models perform well for different kinds of proteins. Pros: Their methods perform better than comparable methods using 1D and 3D CNNs. Overall, this is a good application paper showing the application of a known technique to solve a problem in a new domain. Cons: The novelty is minimal and the problem is of interest only to specialists in this domain.<BRK>This manuscript describes a new deep learning method for the prediction of the quality of a protein 3D model in the absence of the experimental 3D structure of the protein under study. The major idea is to model a protein 3D model using a graph. Based upon this graph representation, the manuscript describes a graph convolutional neural network (GCN) to predict both local (i.e., per residue) and global quality. Unfortunately, there is no experimental result on CASP13 models, which significantly reduce my interest on this paper.<BRK>The paper proposes use of graph convolutional networks (GCN) for quality assessments (QA) of protein structure predictions. As a result, there is an interest in guessing quality of protein structure predictions on protein families that are not characterized experimentally. + The protein representation is reasonable. Overall, this is a borderline paper. There is little methodological novelty and the QA application is a bit of a niche problem in bioinformatics. However, the results show a decent improvement over the state of the art in this particular application, so this paper might be of importance for a limited audience interested in this problem.
Reject. rating score: 1. rating score: 1. rating score: 6. <BRK>The work poses an interesting question: Are GCNs (and GNNs) just special types of matrix factorization methods? But [1] shows that GCNs and GNNs are fundamentally different from matrix factorization methods, regardless of the loss function used to learn the embeddings. Matrix factorization (as broadly understood) will give embeddings that can even be used to cluster nodes. Hence, GCNs are not matrix factorization methods. I think the paper is a valiant effort, but unfortunately the core premise is incorrect. Deeper insights into graph convolutional networks for semi supervised learning.<BRK>The approach is closely related to GCN. 1.The wording "unifying" is a misnomer. The title "unifying graph convolutional networks" hallucinates a framework that unifies several neural network architectures, which is not precise. The derivation of this term starts from GCN and a Laplacian smoothing argument, and arrives at a matrix factorization form through a series of modeling modifications. The paper does not present a theoretical analysis. The derivation of the matrix factorization is only a modeling process. Supplementing a convergence plot and comparing the two approaches may help, if the alternating approach is indeed better. All information should be reported.<BRK>As far as I am concerned, the connection is closer to node embedding versus matrix factorization. It would be interesting to see if joint training the two loss in mini batch among a node and its neighbors can leads to any difference. The connection of GCN to MF is very indirect. It is an interesting and innovative idea to draw connection between GCN and MF.
Reject. rating score: 1. rating score: 8. rating score: 8. <BRK>The paper proposes, when given a CNN, an image and its label, a measure called angular visual hardness (AVH). The paper shows that AVH correlates with human selection frequency (HSF) [RRSS19]. (More on this in Con2)2. The presentation is confusing, and at times self contradictory. Do they?I would suggest reporting the angular separation of the category weights (maybe by showing them in a CxC matrix). In particular, in Section 2 on the related work from psychology/neuroscience, little specifics are discussed to contextualize the current work. 3.In Definition 1, “for any x”  > for any (x, y). 2.Try to be more concise and more precise in the presentation. What is human visual hardness (HVH)? (To authors and other reviewers) Please do not hesitate to directly point out my misunderstandings.<BRK>The authors compared the correlation between AVH and human selection frequency with model confidence and feature norm. The results show that both AVH and model confidence have correlation, but AVH has a stronger correlation than model confidence. As an application of AVH, the authors applied it to sample selection of self training for domain adaption. Overall, the experimental contribution of this paper is good, and the experimental conditions seem to be correct. In the analysis of the dynamics of training, the authors compared the AVH with feature norm. How about the dynamics of model confidence? The curves of different levels of hardness are missing in Fig.14.<BRK>Main Contribution:This paper is trying to bridge the gap between CNN and the human  visual system by proposing a metric  (angular visual distance) and validate that this metric is correlated to the human visual hardness and this metric has a stronger relation  compared to the softmax score which has been viewed as a metric measuring the hardness of images in CNNs. The observation is quite intuitive and has strong theoretical foundation, which is the main reason that I vote for the acceptance of this paper. Otherwise, if these two are fundamentally different with each other, what is the point of showing some connections between them? For the sentence "we use this dataset to verify our hypothesis", what is the hypothesis? 3.For the experiment, I would like to recommend authors adding the following experiments. 3.2) Introducing several other measurements to show the correlation. 3.3) I also would like to see similar results in Table 1 for different models.
Reject. rating score: 6. rating score: 6. rating score: 6. <BRK>This paper proposes a multi task dynamical system for sequence generation. The model learns a number of parameters that represents the latent code z. The main motivation of this paper is to treat each sequence as a task in the training set (customization of the individual data sequence). The authors claim that the proposed approach provides grater data efficiency. However, I still think the experiments and the comparisons are unconvincing.<BRK><Strengths> + This paper proposes a new dynamic model named hierarchical multi task dynamical systems (MTDSs) as a latent sequence model that enables users to directly  control the output of data sequence via a latent code z. It may not be surprising that the multi task version is better than these two weak baselines. 1.The experiments are carried out with a simple toy dataset DHO and MOCAP data.<BRK>This paper proposes to add a latent variable to a dynamical, thereby encoding the notion of "task", eg, in Mocap, the latent variable could encode the walking style in an unsupervised manner. Overall I think this is an interesting paper, however I am not familiar with all the related work. The paper is clear and well written, the idea is interesting and the experiments seem well designed and convincing.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>This paper extends transformers by enabling them to incorporate hierarchical structures like constituency trees structured attention with hierarchical accumulation. The paper is well written and well augmented with supportive figures.<BRK>This paper proposes a novel mechanism to leverage additional tree structure information into the transformer.<BRK>Summary: This paper describes an attention based method to encode trees with constant parallel time complexity maintaining scalability, uses this model to encode constituency parses of input sentences for the tasks of machine translation and text classification, and shows improved accuracy/bleu over models that do not encode the parses. Strengths:The method proposed by the authors is scalable despite encoding tree structures. The authors achieve an accuracy of 98.2 on the IMDB dataset. In other words, how much classification performance does this method yield over current SOTA models, because the SST results are quite a bit below the current SOTA.
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>This paper presented a new pooling method for learning graph level embeddings. Although I found this paper is generally well written and well motivated, there are several concerns about the novelty of paper, computational expenses, and the experimental results as listed below:1) The idea of using attention score is simple yet seems effective. 5) The experimental results are also problematic as well.<BRK>This paper proposed a topology aware pooling method to generate ranking scores for each node and so the pooling (or coarsening) of the graph can be achieved by picking those nodes with higher aggregated attention scores. Another important observation is that The proposed method seems to connect each hierarchy directly to the final layer, which is similar to skip connections. This is very similar to the proposed method, since those nodes with higher attention scores are those with more neighbors, which can be considered as ``local cluster centers’’ on a graph.<BRK>This paper proposes a topology aware pooling method on graph data, which explicitly encodes the topology information when computing ranking scores. Overall, this paper is well organized and the contributions are clear.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>Overall, the paper is well written, and easy to follow (even for non expert like me). This paper propose a simple solution, which is well motivated, to the problem as well as a proof of convergence. It has also received significant attention from the community in the recent years. To address these issues, the authors introduce the "follow the ridge" algorithm for minimax optimization problems.<BRK>SummaryThe present work proposes a new algorithm, "Follow the Ridge" (FR) that uses second order gradient information to iteratively find local minimax points, or Stackelberg equilibria in two player continuous games. The right solution concept for GANs is not what the paper is about, but before publication the authors should remove these claims, identify them as speculative, or substantiate them . They show that the resulting optimizer is compatible with heuristics like RMSProp and Momentum. This is established based on both theoretical results and numerical experiments.<BRK>Moreover, the authors give a deterministic convergence rate for the vanilla algorithm and a convergence rate using momentum. The definition in this paper does not appear to agree with the definition in [1]. In my opinion, the objective of the paper is important and relevant. The theoretical and empirical results are reasonably convincing. Overall, I think this paper proposes an interesting set of dynamics, several meaningful theoretical guarantees, and impressive empirical results.
Reject. rating score: 1. rating score: 3. rating score: 8. <BRK># Strong points  This paper deals with a highly interesting and relevant topic for ICLR. Chen et al.are the first ones to introduce larger images and data augmentation and acknowledge that the large scores are due to this. # RatingAlthough some of the results in the paper might look impressive, my rating for this work is reject for the following reasons (which will be detailed below):1) the main contribution, metric softmax loss, is not novel. The larger images are not standard in the few shot ImageNet evaluation protocol.<BRK>This paper develops a new few shot image classification algorithm. The first one is to use a metric softmax loss used to train on the meta training dataset without episodic updates. The second is that the features learnt thereby are further modified using a linear transformation to fit the few shot training data and the metric soft max loss is again used for classifying the query samples. The empirical results are weaker than existing work (see for instance, https://arxiv.org/abs/1904.03758, https://arxiv.org/abs/1909.02729 etc.); also see #3 below. 4.The training procedure is task agnostic, why do you train a different model for the 1 shot and the 5 shot case? I will consider increasing my score if some of the concerns above are addressed. I am very skeptical as to why the accuracy of fine tuning is only 21% in Figure 2.<BRK>Authors propose a new method for adaptation in a few shot learning setting. They also demonstrate the superiority of the metric softmax classifier vs softmax classifier and finally the overall superiority of the whole method proposed. Similar results are obtained on domain sift settings as well as when comparing the step 2 of this method with a fine tuning approach. I have read the rebuttal and think the paper could be a good addition to the programme.
Reject. rating score: 1. rating score: 3. <BRK>This paper proposes to use population algorithms as a mechanism for implementing distributed training of deep neural networks. The paper makes some claims about the relationship to previous work on (asynchronous) gossip algorithms that appear to be incorrect. In fact, the proposed PopSGD algorithm is very closely related to other methods in the literature, including AD PSGD (Lian et al.2017b) and SGP (Assran et al.2018).I recommend it be rejected due to lack of novelty and missing connections to much related work.<BRK>The paper considers scaling distributed stochastic gradient descent to large number of nodes. Paper proposes novel asynchronous variant to decentralized SGD, called PopSGD. page 3, related work: Nedic at al. Paper theoretically analyzes the proposed method and shows that in the convex case PopSGD has a linear speedup in the number of nodes compared to the sequential training on one node. Moreover, it is also not clear why \Theta(n) updates could be done in parallel.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>The authors compare their data augmentation results to "backtranslation". While the high level motivation and algorithm is interesting, I found the paper very hard to follow, and the experiments are weak.<BRK>The argument is also presented by the paper. Then again, the distribution gets flatter and becomes similar to a uniform distribution when the dim goes higher, which is a common issue.<BRK>The authors should better justify the assumption of Jalalzai et al, and why this is appropriate for the MLP classifier used later in the paper. In particular, why is dilation invariance even a good idea?
Accept (Spotlight). rating score: 8. rating score: 8. rating score: 6. <BRK>This paper provides a unified way to provide robust statistics in evaluating RL algorithms in experimental research. Though I don t believe the metrics are particularly novel, I believe this work would be useful to the broader community and was evaluated on a number of environments. + The details of all of these evaluations and individual performance should be provided in the appendix, however, it seems only MuJoco curves were included.<BRK>*Summary*Authors proposed a variety of metrics to measure the reliability of an RL algorithm. Mainly looking at Dispersion and Risk across time and runs while learning, and also in the evaluation phase. Authors have further proposed ranking and also confidence intervals based on bootstrapped samples. They also compared the famous continuous control and discrete actions algorithms on Atari and OpenAI Gym on the metrics they defined. Generalizability: How do authors think these metrics are generalizable.<BRK>Specifically, the authors focus on how to evaluate the reliability of RL algorithms, in particular of the deep RL algorithms. The paper is well motivated by providing convincing justification of evaluating the RL algorithms properly. In particular, the authors define seven specific evaluation metrics, including  Dispersion across Time (DT): IQR across Time ,  Short term Risk across Time (SRT): CVaR on Differences ,  Long term Risk across Time (LRT): CVaR on Drawdown ,  Dispersion across Runs (DR): IQR across Runs ,  Risk across Runs (RR): CVaR across Runs ,  Dispersion across Fixed Policy Rollouts (DF): IQR across Rollouts  and  Risk across Fixed Policy Rollouts (RF): CVaR across Rollouts , from a two dimension analysis shown in Table 1.
Reject. rating score: 1. rating score: 6. rating score: 8. <BRK>However, how the proposed algorithm benefits sparsity is not discussed. The idea of an accelerated version of variance reduced stochastic extragradient method is novel. This paper claims that extragradient reduces the gap between the obtained optimal value and the real optimal value, which is confusing. 16.The references are not in a uniform format. From the title, the main application of this work is sparse learning problem.<BRK>This is an optimization algorithm paper, using the idea of "extragradient" and proposing to combine acceleration with proximal gradient descent type algorithms (Prox SVRG). Having said that, it seems to me that combining momentum with an existing algorithm is not extremely novel   I would defer to reviewers who are experts in the optimization area to fully assess the novelty and technical difficulty of the proposed solution. technically sound, seems like a nice addition to the variance reduced gradient type methods.<BRK>The current paper builds on these two approaches and applies the momentum acceleration technique in a stochastic extragradient descent framework to achieve fast convergence. I am not working in the field of optimization, therefore, unfortunately I am not in a position to give detailed technical comments for the authors. However, as far as I could follow the paper, it seemed sound and well written to me in general. It would be good to explain and discuss intuitively the steps of the proposed algorithm in the main body of the paper as well, so that it is well understood. How should this set be chosen in practice?
Reject. rating score: 1. rating score: 1. rating score: 3. <BRK>They use a 3 layered MLP on top of the representation from auto encoder. Why is this interesting? There are no such constraint in AE as well   you can vey well have your hidden representation to be over complete   so this is not a good motivation for Gibbs energy2.<BRK>Positive things about this work  the topic is interesting  the last application is interesting (water temperature prediction) Negative things about this work  this work is very poorly  written and lacks sufficient clarity. This work needs a major rewrite. Hidden state usually refers to the encoder output, not to the decoder output. in general, the motivation is unclear. In fact, the authors could consider building on top of these other more modern approaches.<BRK>The energy formulations for Uθ, namely an autoencoder and Gibbs model, are not to my knowledge new in this context. This builds on an existing update scheme (Equation 8), but replaces the full operator ψ with an iterative update. The paper emphasises their view of an interpolation operator I, which is a little confusing in an autoencoder context.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>There is little contribution on the methodology side from the paper. Moreover, the bound does not depend on the embedding dimension at all. Is this to be expected?<BRK>However,  they also have experiments on real datasets, used in the literature. This gives them constant time for the calculation of the embedding w.r.t to the number of neighborsMain points:Overall, the article is well supported theoretically and quite complete.<BRK>A reader could easily interpret this to mean that the error on the downstream prediction problem will be bounded (which is not what this work shows). Overall (and described in the comments below), I believe this paper provides some interesting theoretical results for an approach that is widely used in practice. “r”, the number of sampled nodes, is not defined in the main body of the paper.
Reject. rating score: 3. rating score: 3. rating score: 8. <BRK>This paper studies a new problem, i.e., generating graphs conditioned on an input graph. Overall, the problem studied in this paper is interesting and novel, and the proposed method makes sense.<BRK>This paper studies a problem of graph translation, which aims at learning a graph translator to translate an input graph to a target graph. Overall, the problem is new and well motivated. The problem is new and well motivated.<BRK>In this work the authors tackle the problem of generating a given graph to a target output graph. The authors propose an architecture that consists of a graph translator, and a conditional graph discriminator.
Accept (Poster). rating score: 6. rating score: 6. rating score: 1. <BRK>The paper provides a comprehensive study on the two tower Transformer models in terms of the impact of its pre training tasks on large scale retrieval applications. The studies here show that, pre training with Inverse Cloze Task (ICT) the two tower Transformer models significantly outperform the widely used BM 25 algorithm for large scale information retrieval. I hope the authors will release the source codes to the community.<BRK>In fact, rather than experimenting on different ratios of train/test, is it possible to report on official test set, while splitting the train set into 90/10 for training and development? This paper studies a query related document retrieval problem using a framework which they call “two tower retrieval method”. The combination of ICT, BFS and WLP achieves remarkable improvement over the number of baselines including BM25 and other neural based models. The strength of this paper is that it includes comprehensive studies on the two tower retrieval problem. In that case, it should be clearly mentioned in the paper. I believe data used for the development and test should be different.<BRK>This paper proposes a solution to the large scale query document retrieval problem. The proposed method was shown to be a better alternative to the classic information retrieval approach such as BM 25 (token marching + TF IDF weights). The proposed method is based on two separate transformer models which has computational benefit over one cross attention model. For pre training tasks, Inverse Cloze Task (ICT), Body First Selection (BFS), Wiki LinkPrediction (WLP) were studied. However, there is a major technical problem in the proposed method. In the proposed approach, the query embedding (q_emb) and the document embedding (d_emb) train separately by two transformer models (two towers   Query tower and Doc tower). After that, the similarity was measured through a dot product.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>My main concern remains the experiments. My analysis of this work in short is that the problem that this paper addresses is interesting and not yet solved. This paper proposes a simple and efficient method for DRO.<BRK>The paper proposes an easy to implement algorithm for DRO on example weights, with the same computational cost as SGD. They claim the algorithm is more robust to the learning rate, so is it possible to train with the original learning rate used for the ERM baseline? Why was a different learning rate chosen? Many state of the art deep learning pipelines do not use plain SGD   for example, the WideResNet you used on CIFAR. Perhaps combining momentum with nested optimization of loss weights and parameters is why the baseline does not train?<BRK>They demonstrate that SGD with hardness weighted sampling is a principled and efficient optimization method for DRO in machine learning and is particularly suited in the context of deep learning. The DRO problem studied in this paper is relatively easy, in the sense that the inner maximization has close form solution (at least for KL divergence). Second, both experiments are not convincing enough. In Algorithm 1 Line 18 19, the algorithm proposes to do sampling with replacement using the softmax probability \hat{p}.
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>The authors investigate the benet, mainlytheoretical, of the proposed interpolation. As the goal of the paper is clearlytheoretical, the  real data analysis  part is not necessary in my opinion. The paper is easy to understand and correctly written.<BRK>More context needs to be given by comparing the main theorem to prior works (which I am not familiar with). The main theorem only appears on page 4 and the reader must consult the appendix to see the definition of all the terms that appear in the theorem. Specifically, it studies how the performance of the algorithm is affected by reweighting the k nearest neighbors according to their relative distance.<BRK>The paper studies theoretical perspective of double descent phenomenon for the interpolated K NN classifier. The paper is works in several interesting directions and gives theoretical reasoning to how interpolated K NN could exhibit the double descent phenomenon.
Accept (Poster). rating score: 6. rating score: 6. rating score: 3. <BRK>This paper describes a new method for learning deep word level representations efficiently. The architecture uses a hierarchical structure with skip connections which allows for the use of low dimensional input and output layers, reducing total parameters and training time while delivering similar or better performance versus existing methods. 1.From table 1a or table 2, the training time of the proposed method is not reduced compared with existing methods. 2.It seems the number of parameters in DeFINE still depends directly on vocabulary size. For dataset that has very large vocabulary size, [1] and [2] could potentially have larger compression rate.<BRK>Experiments are conducted for language modeling and machine translation tasks and performance improvements are observed with a reduction in parameters and lesser training time. The obtained results are nice (though this can be improved) and there is indeed some potential value in this work. I think the paper would benefit from some analysis of the differences in the word embeddings learnt by a general lookup table learning model in comparison with the word embeddings learnt by this model. For example, are the gains lesser on Gigaword? This would be interesting to know.<BRK>The paper proposes a novel sparse network architecture to learn word embeddings more effectively. I am not an expert in the area of machine translation, so I am able to sanity check the results and the reasoning and motivation given in the paper. Why would this allows to learn a more efficient low dimensional embedding than the original one? This may happen to be the case, but why? This does not allow me to conclude anything. Table 1: c) DeFINE seems to give better perplexity results, while using less parameters. This is good. I do not know what to conclude, as ideally I would like to see how would DeFINE do with the same number of parameters.
Accept (Poster). rating score: 8. rating score: 8. rating score: 3. <BRK>The paper proposes an approach to generate textual descriptions from structured data organized in tables, by using a "variational template machine" (VTM), which is essentially a generative model to separately represent template and content as disentangled latent variables to control the generation. Remarks:  It should be clearly stated which languages feature in the paper.<BRK>The paper is interesting and proposes a novel approach for addressing a currently not largely considered problem. The proposed model is sound and appropriate, as it relies on state of the art methodological arguments. It would be good if the authors could provide an analysis of the computational costs of their methods, as well as of the considered competitors.<BRK>This paper proposes Variational Template Machine (VTM), a generative model to generate textual descriptions from structured data (i.e., tables). However, I am not convinced that the proposed method is a significant development based on the results presented in the paper. The authors introduce two latent variables to model contents and templates. Did it have any effect on the performance of the baseline model?
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>Overall, I think the paper should be rejected as the contributions are limited and are not aligned with the experiments. This work proposes a new loss function to train the network with Outlier Exposure(OE) [1] which leads to better OOD detection compared to simple loss function that uses KL divergence as the regularizer for OOD detection. Cons:1  The level of contributions is limited. "Enhancing the reliability of out of distribution image detection in neural networks."<BRK>The paper considers the problem of out of distribution detection in the context of image and text classification with deep neural networks. 5.The method is only being compared to the OE method of [1]. The authors show that these modifications improve results compared to [1] on image and text classification. There are a few concerns I have for this paper.<BRK>This paper proposes to tackle the problems of out of distribution (OOD) detection and model calibration by adapting the loss function of the Outlier Exposure (OE) technique [1]. ### Post Rebuttal Comments ###I would like to thank the authors for their hard work during the rebuttal period. I think the current version of the paper is much improved over the previous version. The choice to remove the claims about calibration definitely improves the focus of the paper. If these were addressed I would consider increasing my score.
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>This paper proposes a new neural network architecture for dealing with graphs dealing with the lack of order of the nodes.<BRK>This paper proposes a method to learn graph features by means of neural networks for graph classification.<BRK>This paper proposes a neural network architecture to classify graph structure. Thus, the network can learn isomorphic features of the graph.
Accept (Poster). rating score: 6. rating score: 3. rating score: 3. <BRK>This paper attacks the problem of pruning neural networks to obtain sparser models for deployment. In introduces a principled importance sampling approach for which independence of samples allows one to obtain bounds easily. The proposal mechanism is very smart. The authors use a measure of the sensitivity of the network outputs to the channels in a particular layer (eqn 1). This will make life easier for anyone reading the paper for the first time.<BRK>Summary: In this paper, the author propose a provable pruning method, and also provide a bound for the final pruning error. To achieve a more reasonable algorithm, author prune the redundant channel by controlling the deviation of the summation statistically small,  and reusing the filter by important sampling the given channel. Weakness:1. experiment is too weakImageNet model has great impact on most CV problem, and the current release models are flooding in the open source world.<BRK>This paper studies the tasks of pruning filters, a provable, sampling based approach for generating compact Convolutional Neural Networks (CNNs). In general, this paper is very well written and organized. In contrast, all the results of this method gets worse results; this is less desirable.
Accept (Talk). rating score: 8. rating score: 8. rating score: 6. <BRK>The authors propose an interdependent gating mechanism that enriches the coupling between inputs and hidden states. For an input x_0 and hidden state h_0; h_0 gates x_0 to create x_1; x_1 then gates h_0 to create h_1; this cyclical gating operation is applied for several rounds and it s output is fed into a recurrent neural network. This results in the RNN processing a more contextualized version of the input tokens x. Pros:The paper is very well written and clear. Final notes:This paper raises many interesting question:  What is the really going on with the gating mechanism? The authors explore this question but the jury is still out on exactly what is going on here. "Mogrification" as a general preprocessing step: could it also improve performance for transformer models?<BRK>Summary:The paper proposes a novel LSTM architecture that adds several gating mechanism that gates the hidden state and inputs in between the LSTM update. Comments on the paper:1. The paper proposes an interesting architecture and it seems to show significant improvement in terms of performance for some language datasets. 2.The paper is very well written, the motivation and formulation is clear. 3.. One thing is that since this could take into account more context,  it seems that this model could potentially generate language / tokens with longer time dependencies. 4.Also, I am curious about the generalization ability of the model.<BRK>I have read the authors  response. This paper proposes a modification of LSTM networks in the context of language modeling called Mogrifier LSTM. The proposed Mogrifier LSTM utilizes the same recurrent unit as the LSTM, but the input and previous hidden state are updated with several rounds of mutual gating. * Experiments demonstrating strong performance on a number of language modeling tasks. Points in favor of acceptance include the high clarity of writing, good experiments of the proposed model, and a discussion of possible reasons for why the mogrification operation works well. The closest that the authors come to this is the single validation perplexity of the Multiplicative LSTM in Table 3.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>The paper proposes a new goodness of fit measure for generative models, and uses it to get insight into GAN s. While this is an important topic and a novel approach, I do not think the paper delivers on what it promises. First, while it claims to be a general method for generative models it, it is limited to only  GANs and even for GANs it is limited. Detailed remarks:  The main point that the training set points x must have p(x)>0 under the model is naturally satisfied for almost all models except GANs such as VAEs, autoregressive model and flow models with standard implementations as the support is the whole space. This is in contrast to the claim in the paper that "its applications can be extended to other generative networks such as Variational Autoencoders.". Even for GANs as this measure only looks at the support and not the distribution it is not clear if this measure does more then evaluate mode collapse. This is a main point by the authors, but it ignores the probability and only looks at the support.<BRK>This paper defines a goodness of fit measure F for generative networks, that reflects how well a model can generate the training data. This paper brings an interesting contribution to the evaluation of generative networks. The use of the square distance in the image space is not obvious and not justified. 2.Computation of this metric is not straightforward: there is no theoretical guarantee and it is computationally expensive. 4.Typos are obscuring the reading of the paper. Post rebuttal: I have read the authors  response and am maintaining my weak reject rating.<BRK>The authors might want to add some discussion in Section 4.2 regarding why the residual connection is detrimental for covering the support. This seems overly assertive. It only concerns the generation of the training data, but not the sampled data from the network (at least not directly). As shown by the authors, the proposed measure can be considered as the approximation of the true probability support not covered by the generative models, which also defines a necessary condition to avoid mode collapse. "Optimality" in terms of generative models may depend on the downstream tasks. I do not think there exists a universal definition of "optimality" for generative models. Assessing generative models via precision and recall. ICML 2019.
Reject. rating score: 3. rating score: 3. rating score: 3. rating score: 6. <BRK>This paper proposes a method to predict future trajectories by modeling partial and full occlusions. However, I failed to find how diverse the output of the model is. If the output is not that stochastic, then it would be tough to believe that the model can "predict" the future; instead, it may "extrapolate" the current condition only.<BRK>The key contribution of this paper is a model that can predict the dynamics of pre segmented image patches under multiple frames of occlusion. The key weaknesses I see are:  The objects must be pre segmented by some externally defined mechanism. Overall I don t believe this work is ready for publication, as there isn t that much novelty and the requirements are impractical. But if one has the segmentation masks, that simplifies things considerably and also offers a good estimate of the location and velocity (if there are 2+ frames).<BRK>Summary:This paper proposes a method that combines a recurrent neural network that predicts values that are used as inputs to a rendered which interprets them and generates an object shape map and a depth map for every step of the dynamics predicted by the recurrent neural network. The proposed method is able to handle object occlusions and interactions. It would be interesting to see if this can be done so the proposed network is more unified. Can the authors comment on this? However, the rest of components have limited novelty.<BRK>In this paper, the authors develop a highly structured model to predict motions of objects defined by segmentation masks and depths. The model trains a physics model (in the form of a slightly modified interaction network) and a renderer composed of a per object renderer combined with an occlusion model which composes the per object segmentation and depth into a scene segmentation and depth. Regarding using segmentation/depth as input to the model: for a real dataset, segmentation is more relevant: it is both less informative than positions (due to significant occlusions) and easier to measure.
Accept (Poster). rating score: 6. rating score: 6. rating score: 3. <BRK>The NAS search algorithm is similar to previous one shot NAS, but the search space is channel wise: each channel has it’s own kernel size, which is quite novel and interesting. Results are strong in terms of FLOPS and parameters. Although some recent works (e.g., MixNet) have tried to partition channels into groups, this paper goes further and searches for different kernel size for each single channel. How do you justify the generality of the channel wise search space? I recommend the authors including “channel wise” in the title. This information would be helpful to interpret and justify your algorithm 1.<BRK>In general, the paper is well written and easy to follow. The searched models achieve a new state of the art result on the ImageNet classification task for mobile setting with restricted FLOPs. In short, the proposed method is interesting and the results on ImageNet are impressive, I weakly accept this paper and hope that the authors can make the experiment section more solid in a revised version. However, the experiment section is not solid enough.<BRK>The biggest problem of this paper is that experiment is not enough. Conclusion:This is an interesting paper with novel idea and efficient implementation. However, more experiments are needed to validate the utility of the proposed method.
Reject. rating score: 6. rating score: 6. rating score: 8. <BRK>This paper targets at studying the mutual exclusive bias which existed in children learning, to help understand whether there exists similar bias in deep networks. The paper is very well organized and written. However, I have the following concerns. So what’s the key difference? 3, In Sec.3, the first and section paragraph, I can not quite understand how the ME bias theory guide the following synthetic experiments. If one uses word2vec as the representation in NN, the ME bias will be solved. It seems to me that the tasks are organized as unbalanced instances of each classes, and asking the common NNs to learn this  task. the authors clarified and answered the questions. I would like to raise the score.<BRK>*** Increased to weak accept after discussion of merits of ME bias was improved in the paper *** This paper investigates whether neural networks exhibit a ‘mutual exclusivity (ME) bias’, whereby novel inputs tend to be associated with previously unseen outputs, an inductive bias that is cited to be present in children when learning to associate new words and objects. The authors pose an interesting hypothesis, but it would gain a lot of credibility if they could provide an empirical analysis of an algorithm that uses ME reasoning to improve learning in a realistic setting or if they could at least perform some quantitative analysis of the effects of ME bias on task performance for a toy example.<BRK>Summary:This paper makes an observation that most of the neural network architectures do not learn the mutual exclusivity (ME) bias: if an object has one label, then it does not need another. Authors argue that ME bias could help the model to handle new classes and rare events better. I support accepting this paper. As the authors also agree, ME bias is missing not just in DNNs. It is the issue of MLE. It would be good to have some non NN results too. I see this is a challenge for MLE than DNNs.
Accept (Poster). rating score: 6. rating score: 6. rating score: 3. <BRK>This involves achieving sparsity by application of a binary mask, where the mask is determined by current parameter values and a learned threshold. The algorithm proposed in this paper seems sensible, but rather ad hoc.<BRK># Clarity  The description of the main idea is not clear. What are "structure gradient" and "performance gradient"? They are not mathematically defined in the paper.<BRK>Thus, the novelty should be summarized, and highlighted in the paper.
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>This paper combines ideas from attentive and sequential neural processes to incorporate an attention mechanism to the existing sequential neural process, which results in an attentive sequential neural processes framework. Second, the argument that augmenting SNP with an attention mechanism is not trivial is somewhat contrived. Fourth, the technical exposition of this paper is too vague. It would be a good experiment to see if the imaginery component is necessary. To summarize, I believe the paper in its current state is not well motivated and appears very incremental given the prior works of SNP and ANP.<BRK>This paper deals with the underfitting problem happening in neural process and sequential neural process (SNP). A combination of attention into SNP. 3.Different tasks were evaluated to investigate the merit of this method. The comparison for time complexity and parameter size was missing. 3.An incremental research.<BRK>Authors present a method to address the problem of underfitting found in sequential neural processes. Authors addressed this problem by introducing an attention mechanism and model, i.e.Attentive sequential neural processes, which incorporates a memory mechanism of imaginary context. This imaginary context is generated through an RNN network and are treated as latent variables. It would be nice to demonstrate the performance in more challenging tasks as well, however the results presented and the new context imagination introduced are quite promising indeed.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>This paper proposes a new loss for training models that predict where events occur in a sequence when the training sequence has noisy labels. The central idea is to smooth the label sequence and prediction sequence and compare these rather than to force the model to treat all errors as equally serious. The proposed problem seems sensible, and the method is a reasonable approach. The evaluations are carried out on a variety of different tasks (piano onset detection, drum detection, smoking detection, video action segmentation).<BRK>The authors propose SoftLoc, an interpolation of two temporal event prediction losses (one based on label & prediction smoothing, and one based on weakly supervised count based loss) that makes the predictor more robust to noisy training data. They demonstrate on various temporal alignment datasets from music to wearable sensors to video action segmentations, that their method is performs well both on noisy free and noisy settings compared to prior approaches. Strengths:(1) relatively thorough experimental valuations: using 4 datasets comparing with sufficient number of prior approaches (One potential improvement could be to try noise distributions other than Gaussian)(2) simple objective and consistent improvements. Weaknesses:(1) the novelty of the method appears limited. The weakly supervised loss is borrowed from the prior work, so it seems like the main algorithmic novelty is to add noise to predictions (as opposed to just adding to labels as done in prior work). (2) is Issue 1 an actual problem? Such toy experiments may complement the existing end to end experiments to demonstrate the precise properties of the proposed method.<BRK>This term helps to relax the model’s reliance on exact label locations. 2).$\mathscr{L}_{MC}$: a mass convergence loss that acts as a regularizer to facilitate the model with precise impulse like localizations. Various applications, such as PIANO ONSET, DRUM DETECTION and TIME SERIES DETECTION are performed to verify the effectiveness of the proposed method. And state of the art performance is achieved. Despite the achievement indicated by the experiments, I still have some concerns about this paper. And the label smoothing idea (applying a ˜S^2 Gaussian filter to the labels) has been introduced to increase the robustness to temporal misalignment of annotations [2]. The reason should be clarified. (3)	The authors propose the two side relaxed loss L_{SLL} for the soft learning of temporal localization problem. However, in the ablation study, the authors do not give the results with different level of label noise for one side variant. Adding these results could help to demonstrate the necessity of the two side relaxed loss L_{SLL}. References:[1] Improved musical onset detection with convolutional neural networks[2] Onsets and frames: Dual objective piano transcription
Reject. rating score: 1. rating score: 3. rating score: 8. <BRK>This is just an example of the writing problem of the paper. This paper is poorly written. I doubt this paper can be easily accepted at a Physics venue. There are many other issues. Finally, I want to point out that, the generalization of kernel methods have been intensively studied in the machine learning literature, for example using the RKHS theory. I agree that there could potentially be great ideas in this paper. The conference is a venue with quality control. For example, the definition of renormalized NTK should better be defined in equations such as $K_r(x, x )   \sum_{k   0}^r b_k <x, x >^k$, rather than be described in words like "trim after the r’th power". However, the modifications made by the authors are still not sufficient.<BRK>This paper explores how tools from perturbative field theory can be used to shed light on properties of the generalization error of Gaussian process/kernel regression, particularly on how the error depends on the number of samples N. For uniform data on the sphere, a controlled expansion is obtained in terms of the eigendecomposition of the kernel. The topic is salient and will interest most theoretically minded researchers, and I think there is an abundance of new ideas and novel content. For publication in a machine learning conference, I think more effort should be devoted to speaking to the machine learning audience. Overall, I am a bit on the fence, but leaning towards rejection for the above reasons. I could be convinced to increase my score if I am reassured that non physicists are able to follow the arguments and find this paper interesting.<BRK>This theoretical paper exploits a recent rigorous correspondence between very wide DNNs (trained in a certain way) and Neural Tangent Kernel (a case of Gaussian Process based noiseless Bayesian Inference). ‘‘notably cross talk between features has been eliminated’’ : has it been eliminated or does it simply become constant ? Here it is thus extended to the NTK case. The paper is well situated within this literature. There are a couple of points however that could be improved, that would make the paper more useful for the community. Here are some of them, with other typos as well: ‘Furthermore since our aim was to predict what the DNNs would predict rather [THAN?] However for the sake of ease of read of less patient readers, I think it would be appropriate to have, somewhere, a more self contained description of the results’ list. Could you explain intuitively, to the inexperienced reader, why the noiseless case is harder to deal with than the finite noise one ?
Accept (Spotlight). rating score: 8. rating score: 8. rating score: 6. <BRK>Summary This papers presents a pixel autoregressive model for video generation, in the spirit of VPN (Kalchbrenner’16). DecisionThe paper proposes a well motivated method backed by solid state of the art results. Pros  The proposed method is relevant and well motivated. The experimental results are strong. However, this is exactly the problem that latent variable models such as variational inference or normalizing flows are designed to address. Would a certain combination of latent variable models with the proposed autoregressive approach alleviate these issues? Minor comments  Contrary to the summary in the related work section, Kumar’19 does not use variational inference and operates purely on the normalizing flows technique.<BRK>This paper presents an approach for scalable autoregressive models for video synthesis. Each of these ideas is individually close to ideas proposed elsewhere before in other forms, as the authors themselves acknowledge [Vaswani et al 2017, Parmar et al 2018, Parikh et al 2016, Menick et al 2019], but this paper does the important engineering work of selecting and combining these ideas in this specific video synthesis problem setting.<BRK>This work proposes an autoregressive video generation model, which is based on a newly proposed three dimensional self attention mechanism. Any justification for this? The proposed method achieves competitive results across multiple metrics on popular benchmark datasets (BAIR Robot Pushing and KINETICS), for which they produce continuations of high fidelity. However, in the experiment, the input of the model for the BAIR Robot Pushing dataset is the first frame.
Accept (Spotlight). rating score: 8. rating score: 6. rating score: 6. <BRK>## SummaryThe authors propose a method for training physical systems whose behavior is governed by partial differential equations. The paper is generally very clear, organized and well written. On the whole, I think the paper is inventive, well written and potentially very impactful. * Page 5: I think the description of predictor corrector could be clearer. Is this exactly when we are restricted to the "supervised" loss?<BRK>The method introduces a predictor corrector scheme, which employs a hierarchical structure that temporally divides the problem into more manageable subproblems, and uses models specialized in different time scales to solve the subproblems recursively. The algorithm described in Section 5 seems to be the core contribution of this work.<BRK>In this paper, the authors outline a method for system control utilizing an "agent" formed by two neural networks and utilizing a differentiable grid based PDE solver (assuming the PDE describing the system is known). Three application examples are discussed: Burger s equation (1D), and incompressible flow (2D) with direct and indirect control. Was it truly necessary for the simpler experiments? The paper presents an interesting mix of neural networks and traditional PDE solvers for system control, and I vote for acceptance.
Accept (Poster). rating score: 8. rating score: 6. <BRK>Summary: the paper consider representational aspects of neural tangent kernels (NTKs). More precisely, recent literature on overparametrized neural networks has identified NTKs as a way to characterize the behavior of gradient descent on wide neural networks as fitting these types of kernels. This paper focuses on the representational aspect: namely that functions of appropriate "complexity" can be written as an NTK with parameters close to initialization (comparably close to what results on gradient descent get).<BRK>It would be good to include some further discussion on this in the paper. A comparison would be helpful either way. In particular, they show that such a sampling leads to weights close to initialization, that the neural network function is close to its linearization in L2(P), and that the linearization is close to the target function in L2(P). * how these results apply to networks obtained via optimization in the NTK regime should probably be discussed moresmaller things:* eq (1.2): what is the mearning of the epsilon factor?
Reject. rating score: 3. rating score: 3. rating score: 8. <BRK>This paper proposes a novel extension to SGD/incremental gradient methods called CRAIG. In particular, the algorithm formulates a submodular optimization problem based on the intuition that the gradient of the problem on the selected subset approximates the gradient of the true training loss up to some tolerance. How does CRAIG perform over multiple epochs? Why does CovType appear more stable with the shuffled version over the other datasets? Strengths:The proposed idea is novel and intriguing, utilizing tools from combinatorial optimization to select an appropriate subset for approximating the training loss. Weaknesses:Some questions I had about the work:  How well does one have to approximate $d_{ij}$ in order for the method to be effective? Page 14, prove not proof  Page 14, subtracting not subtracking  Page 16, cycle not cyckeOverall, although I like the ideas in the paper, the paper still needs some significant amount of refining in terms of both writing and theory, as well as some additional experiments to be convincing. The authors provide an approach to approximate this for both logistic regression and neural networks. In machine learning, the empirical risk (finite sum) minimization problem is an approximation to the true expected risk minimization problem.<BRK>Although I find the approach interesting, I have three main concerns with the proposed method. The argument in section 3.4 is that the variance of the gradient norm is captured by the gradient of the last layer or last few layers, however this is true given the parameters of the neural network. In addition, there is no experimental analysis of the epsilon bound and the actual difference of the gradients for the subset and the full dataset. There are also no baselines that use a subset to train. international conference on machine learning. "On the ineffectiveness of variance reduced optimization for deep learning."<BRK>This paper presents a method for subselecting training data in order to speed up incremental gradient (IG) methods (in terms of computation time). The idea is to train a model on a representative subset of the data such that the computation time is significantly decreased without significantly degrading performance. The approach is novel and has well developed theory supporting it. The paper is very clear, well written, and was a genuinely fun read. Though admittedly, I could   be misremembering this. Do you see similar results on   different hardware? Has the performance   when training on a subset selected via the stochastic algorithm   been compared to the performance when training on a subset selected by the   deterministic version?
Accept (Spotlight). rating score: 8. rating score: 6. rating score: 6. <BRK>This paper proposes a novel semi supervised learning paradigm where the algorithm learns from both clean instance level labels and noisy rule level labels, and also a simple but effective algorithm as solution. Empirically the paper demonstrates the effectiveness of the proposed algorithm with consistent improvements over several baselines on a wide range of classification tasks. The proposed methodology is clean but effective, with extensive experimental support. Therefore I vote for accepting this submission.<BRK>The paper addresses the problem that labelled data is often unavailable in the quantities required to train effective models. It deals with classification problems, and proposes a method to obtain more (but weaker) labels data with minimal involvement from human labellers, by asking them to generalize their labelling decisions into rules and then learning restrictions on those rules to avoid learning incorrectly generalized labels. The presentation of the implementation the authors choose for their proposed approach is clear, and the implementation is sensible. I would argue for accepting this paper.<BRK>In case of a lack of labeled data, human designed rules can be used to label the unlabelled data. I think this paper is tackling an important problem in machine learning, and the proposed idea is novel and interesting. I vote for weak acceptance because there are still some technical points that are not well addressed enough:First, although the intuition of this model makes a lot of sense to me, the construction of the loss function is quite heuristic, with a lot of terms simply summing together, making it hard to judge which components are most important for the final results. The paper can be further improved if the algorithm can be more principled. My score does not change, but overall I advocate to accept this paper.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>The method is empirically validated through through various domains and neural networks architecture. (2) The theory is not very useful in justifying the method. Same criticisms hence can be made to this paper. The problems are listed below:Here s what I can find of the authors  interpretation of the prior work Padam: "The internal cause is that a concave function is applied rather than the linear function in ADAM. Building on Padam, the paper further justifies the proposed method by:" This form of Φ(·) not only directly inherits advantages of PADAM,as is depicted in Figure 1, but also makes a better guarantee for larger learning rates. Even when|g| → 0, a more extensive learning rate αt is allowed. " So the justification is very weak. (3) The method seems not to be able to beat the previous baseline Padam, which makes it questionable as a practical algorithm.<BRK>This work proposes a general framework for adaptive algorithms, and presents a specific form: ADAPLUS. In the theory part, this work gives convergence analysis of ADAPLUS. Since this paper gives a general framework and claims that offset term can achieve superior performance, it is better to give the convergence analysis of general algorithm in the framework and discuss the benefit of the offset term theoretically. 2.And the experiment shows that ADAPLUS performs on par with PADAM on CV task. I wonder why the authors did not give the experimental result of PADAM on NLP task?<BRK>This work proposes a modification to the ADAM optimizer by introducing an adjustment function, which consists of a square root function and an extra parameter delta. 2.I do not understand why Figure 1 says the proposed method is better than Padam. There exist some work such as [1] have proved the convergence guarantee of the adaptive algorithms including Padam in the nonconvex setting. 4.There is one missing baseline Yogi [2] in the current paper. 7.To fully evaluate the performance of the proposed method, the authors should at least conduct an experiment on the task of language model.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>This paper studies the mean field models of learning neural networks in the teacher student scenario. The main contributions are summarized in Theorems 2 4, which characterize the stationary distribution of gradient descent learning for what are commonly called committee machines. Because of these reasons, I would not be able to recommend acceptance of this paper. The authors do not seem to know the existing literature on analysis of learning committee machines. In Example 2, the authors claim that when \sigma is an odd function \rho is a stationary distribution if and only if the difference is an even function. Consider the case where \sigma is a sign function. This is a counterexample of the authors  claim here.<BRK>The paper studies the dynamics of neural network in the Teacher Student setting, using the approach pionnered in the last few years. This is not a new area! There are three main sections in the paper, discussing the results. * The first result is a theorem that, if I understand correctly, says that the stationary distribution of gradient descent on the population loss (i.e.the test error) a necessary condition for the stationary distribution is that it has zero generalisation error (Eq.4).That seems like an incremental step compared to previous results that write down the PDE (the four mean field papers from last year) and it looks very similar to results that show gradient descent provably converges to global optima etc. * Sec.2.2 also discusses the difference in learning to teacher nodes with large or small weights, resp.Again, this is well known in the asymptotic limit and rather unsurprising. * The extension to ResNets is definitely more interesting. The authors write down mean field equations for two models, and prove, if I understand correctly, that it is a necessary condition to recover the teacher weights to generalise perfectly, which, as I said above, seems unsurprising. In the end, given the paper is not discussing the relevant literature in teacher student setting, and that I (perphaps wrongly) do not find the results surprising enough, I would not support acceptance in ICLR.<BRK>This paper studies the mean fields limit of neural networks and extends the mean field limit treatment to resnets. What are the concrete insights that the results of this paper bring? As such I cannot recommend its acceptance. Some more concrete questions/issues follow: The introduction several times states: "First, for the two layer networks in the teacher student setting, we characterize for the first time thenecessary condition for a stationary distribution of the mean field PDE and show how it relates to the parameters of the teacher network. But where is this discussion of necessary condition? It would be really interesting to see a discussion of what is similar and different between these works and results and the present work. Exact solutions to the nonlinear dynamics of learning in deep linear neural networks. So this alone does not seem very novel result.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>The hard constraints from human inputs about a specific problem are relaxed into continuous constraints (the "slow" reasoning part), and a reconstruction loss measures the fitness of the inferred labels with the observations (the "fast" pattern recognition part). Besides, after reading Reviewer 3 s comments, I also feel it unsuitable to train DRNet (generalization) on test set for 25 epochs even though you made it explicit in the revised paper. Therefore, I am inclined to reject this paper. updates after reading authors  rebuttal Thanks for revising the paper and addressing my concerns!<BRK>I like the general idea of this paper, since it has the flavor of combining deep learning with logic rules, although I feel weird to view the generative decoder as thinking fast and the reasoning modules as thinking slow. I am not a big fan of some big claims in the paper. The notion of thinking fast and slow in the model does not well match the intuition given in the first paragraph of the introduction. It is far away from the concept of (symbolic or logic) reasoning.<BRK>All the reasoning has to be done manually beforehand to be then incorporated in the form of constraints. Unfortunately, this paper has a couple of major flaws:•	The results for DRNets (Generalization) on the MNIST Sudoku are compromised because the model trained on the test set for 25 epochs after being trained on the training set. •	The paper introduces the constraint aware SGD algorithm to incorporate batching rules into the training of the encoder. •	Although I appreciate the reference to Kahneman’s model of the mind, I suggest to remove the first two paragraphs from the introduction and use the space to motivate the de mixing problem instead.
Accept (Poster). rating score: 6. rating score: 6. rating score: 3. <BRK>In this work the authors propose a framework for combinatorial optimisation problems in the conditions that the measurements are expensive. The basic idea is to make an approximation of the reward function and then train the policy using the simulated environment based on the approximated reward function. The applications are shown in a set of biological tasks, which shows that the model performs well compared to the baselines. The idea of learning the models of environment (or reward) and simulating the model to train the policy is not novel (e.g., https://arxiv.org/pdf/1903.00374.pdf). Similarly, in terms of formulating the discrete search problem as a reinforcement learning problem, again there are similar works in the past, which are cited in the paper, but the combination of these two is novel to my knowledge; having said this the paper should discuss relevant works such as the one above.<BRK>ContributionThis paper apply a model based RL algorithm, DyNA PPO for designing biological sequences. I agree with the authors that most existing optimization methods are ill equipped for the large batch / low round settings and as sample efficiency becomes critically important as the number of round gets lower and their method is a good solution in such settings. Experiments:The experiments are overall well presented and seems robust given the number of replicates that was made each time. Points of improvementGiven the applicative nature of the paper and the proposed method there are few small experiments that could have been done to strengthen the manuscript (see questions and comments above). Preliminary rating:* weak accept *<BRK>Designing new discrete sequences satisfying desirable properties is an important problem in molecular biology. This is a difficult combinatorial optimization problem because of the difficulty in optimizing over a combinatorially large space. The paper is well written, but I have questions about the efficacy of the method, particularly because I think some of these results are against weak baselines. VAE based methods have worked well for designing sequences like SMILES strings, but the authors dismiss them claiming that they are better modelled as molecular graphs. For AMP Design, again they compare with a weak baseline and don t compare with VAE based methods (like for example: Das et al.PepCVAE: Semi Supervised Targeted Design of Antimicrobial Peptide Sequences)
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>This submission extends previously proposed KERMIT from two views to more than two views. I believe this paper could be of interest to multi view modelling/learning community. Though the original KERMIT approach is very interesting and you application of it to more than two views is also interesting I find the presentation to be poor. Even though your extension from two views to multiple is simple I find reliance on a diagram to be a mistake as I find your description not to be very clear. Given that there are no equations to support the reader and that the original equations are not adequate I find it hard to understand Sections 2 and 3.<BRK>Most of the math in this paper can be found in the original Chan et al.s paper.The extension to the multichannel case is incremental as it is hard to justify the challenge of such extensions. This paper proposes a multichannel generative language model (MGLM), which models the joint distribution p(channel_1, ..., channel_k) over k channels. I feel that this paper is not ready for publication at ICLR due to the following major issues:* Missing important related work: This paper seems unaware of an important related work "Multi Task Learning for Multiple Language Translation" by Dong et al, ACL 2015. Although machine translation is just an example of MGLM, Dong et al.is highly relevant to the conditional generation with MGLM, needless to say that they share the same multi language translation problem domain.<BRK>[Paper summary]This work is an extension of KERMIT (Chan et al., 2019) to multiple languages and the proposed model is called “multichannel generative language models”. The authors carry out experiments on multi30k dataset. The authors work on multi30k dataset, which is not a typical dataset for machine translation. 2.For novelty, this is an extension of KERMIT to a multilingual version, which limits the novelty of this wok. 3.The best results on En >De in Table 1 are inconsistent. This makes me confuse about how to use your proposed method.
Reject. rating score: 1. rating score: 6. <BRK>The paper studies active learning in graph representations. To decide which nodes in a graph to label during the active labeling, the paper proposes two approaches. First it argues that one should consider region based measures rather than single nodes. Second, it proposes to adapt the page rank algorithm (APR) to determine which nodes are far away from labeled nodes. “APR outperforms all other methods at low sampling fractions”. Clarity: I found the paper rather difficult to understand and follow:Some specifics:2.1. The introduction could be more concisely discussing the motivation, the main idea of the paper, as well as contributions. 2.5.“Thus, hybrid techniques, combining several approaches, outperform using only one approach have been proposed.” It is not clear what this refers to and where the hybrid techniques have been evaluated. Furthermore, the clarity of the paper should be improved to follow the author arguments and make the paper easier to read.<BRK>The authors present an algorithm for actively learning the nodes in a graph that should be sampled/labeled in order to improve classifier performance the most. 1) The propose to sample nodes nodes based on "regional" uncertainty rather than node uncertainty 2) They use an variant of pagerank to determine nodes that are central, and hence most likely to affect subsequent classification in graph convolution classifiers. While both techniques seem straightforward extensions of previous approaches (and are well explained in the paper),  the experiments indicate that they work better than prior approaches. It would have been nice if the authors had also discussed ways in which one or more of these techniques could be combined though, or discussed how we could pick the right approach (in a more empirical way, since it is not clear what the threshold for high sampling rate/low sampling rate distinction is, or if it varies from problem to problem)
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>This paper addresses both these issues. To address these issues, the authors introduce two restrictions on the networks: (1) They enforce “monotone” networks, meaning that following the first layer, all synaptic weights are positive. (2) They require that the task in question be a binary classification task. Ultimately, I think this is a great paper, and I think it should be accepted at ICLR. As such, it should be recognized in discussion that this paper provides some important contributions to our understanding of feedback alignment, but does not ultimately move the question of biologically realistic learning forward all that much.<BRK>This paper presents an approach towards extending the capabilities of feedback alignment algorithms, that in essence replace the error backpropagation weights with random matrices. The authors propose a particular type of network where all weights are constraint to positive values except the first layers, a monotonically increasing activation function, and where a single output neuron exists (i.e., for binary classification   empirical evidence for more output neurons is presented but not theoretically supported). The strong point of the paper and main contribution is in terms of proposing the specific network architecture to facilitate scalar error propagation, as well as the proofs and insights on the topic. However, this also seems   at the moment   to be of limited applicability.<BRK>I hope that, in the next revision, the authors could include more about the limitation of their work and potential alternatives to improve the generosity of the proposed method. There are several issues and concerns that leads me to the following comments and concerns:(A) Why is it necessary to construct a monotonic layer which is constrained to only be able to approximate monotonic functions? (C) What is the different between the proposed network along with the update rule and a network with only non negative weights in the layers above the first layer trained with RPROP? If so, another perspective of the story is that the paper emposes a non negative constraint on the weights in a neural network, and this could be used as a baseline.
Accept (Poster). rating score: 6. rating score: 6. rating score: 3. <BRK>The authors propose a methodology to discover new categories in an unlabeled dataset with the help of a label one. First bootstrap some features using self supervised learning on labeled and unlabeled data. I propose a weak accept. Q1.The paper is about discovering new visual classes.<BRK>Specifically, they initialize the network using the self supervised learning on the union of all available data and then further finetune it using labelled data. Based on this, they propose the rank statistics which leverages the activation knowledge on labelled classes and rank the activated dimensions. Finally, the network is jointly optimized with the ground truth and generated pseudo labels (the pseudo ones will be updated during training). The writing of this paper is satisfactory. 2.Some experimental issues. a) how will the choice of k in top k rank influence the performance?<BRK>The paper is very well motivated, written, and methods are described nicely and succinctly. Overall, my current vote for this paper is a weak reject. While the ablation w/o self supervised learning performs more poorly than everything combined, the other parts of the ablation (with self supervised learning) also perform poorly. You assume that the number of clusters is known; this is one of the advantages of all of the prior work in that they can estimate this.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>This paper proposes a new convolutional operator called Harmonic Convolution to improve these generative networks to model both signals or signal to noise ratio. Applications on audio restoration and source separation are given. There is a little typo in Formula 1 for the STFT spectrogram, I would use the modulus |.| rather than || . Numerical experiments show that the Harmonic Convolution improves over existing regular and dilated convolutions in various settings. After all, the numerical results seem to me encouraging.<BRK>In this paper, the authors introduce a new convolution like operation, called a Harmonic Convolution, which operates on the STFT of an audio signal. This Harmonic convolution are like a weighted combination of dilated convolutions with different dilation factors/anchors.<BRK>The paper considers the effectiveness of standard convolutional blocks for modelling learning tasks with audio signals. In the experiments, the work is evaluated on signal de noising (audio restoration) and sound separation. This illustration does not say anything about the influence of the depth and number of convolutional blocks on a learning task. It would be interesting to add an experiment with different types of channel noise and which network design is more likely to de convolve the noise from the signal.
Reject. rating score: 1. rating score: 6. rating score: 6. <BRK>rebuttal  I have read the rebuttal and discussed with the authors, and I retain my original score. In particular, it is argued that since geodesics (shortest paths) in the Riemannian interpretation of latent spaces are expensive to compute, then it might be beneficial to regularize the decoder (generator) to be flat, such that geodesics are straight lines. One such regularization is proposed. The paper propose to use a flexible prior and then approximate geodesics by straight lines. Taking the stochasticity of the VAE decoder into account drastically change the behavior of geodesics to naturally follow the trend of the data.<BRK>Notes:    This paper suggests the use of VAEs with stronger priors along with more powerful regularization of the decoder (especially its curvature). Paper also uses mixup in the latent space to provide regularization at points farther from the data. The experiments suggest this is an important problem with VHP VAE and also that it s successfully addressed. I found this figure a bit hard to itnerpret.<BRK>1.The idea of explicitly forcing the encoding space to be flat by putting constraint on metric tensor is simple but neat. 7.In Fig.7, the authors have shown with and without  Jacobi normalization which I am really not convinced with, need better explanation. I wonder what will happen if you put an unfolding constraint in the encoding space like LLE, ISOMAP etc.. The loss function is data driven so this should give atleast similar behavior.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>Wouldn’t that then imply that the uncertainty would be zero for any input (even an out of distribution one), as the prior network and predictor network always agree? Seventh page, “[…] inspired by, an builds on, […]”  > “inspired by, and builds on, […]”  Ninth page “montonicity”  > “monotonicity”Overall, I tend to accept this work, although, depending on the author rebuttal and other discussions, I am willing to change my rating accordingly. Perhaps a small toy example would be informative. The theoretical considerations also help in providing some guarantees about such an approach.<BRK>An experiment compares this previously proposed method to other approaches for uncertainty estimation on CIFAR 10. While the experiments add little value to the community, this may be acceptable for a mostly theoretical paper. The experimental evaluation is very limited, training only on CIFAR 10.<BRK>Overview:This paper introduces a new method for uncertainty estimation which utilizes randomly initialized networks. Overall, I cannot say I am fully convinced that the paper should be accepted as is (also see questions below), but generally I am positive about this work, and hence the final score: “weak accept”. “prior”   The explanation of why using a randomly initialized network makes sense is not very strict.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>The authors propose a simple method for avoiding bottlenecks during NN training, whereby training examples are utilized multiple times per read. The work focuses on cases where the cost of preparing a minibatch exceeds that of a training step (both a forward pass and, subsequently, a parameter update). Feedback:  The proposed method itself is very simple: that s fine. While some cursory analysis of data echoing s theoretical implications would be appreciated, I am fine with practically motivated solutions that address real issues. Simple  tricks  that are easy to implement and widely applicable are often useful tools. The work is predicated upon the assumption that the ratio of said costs $R > 1$, but the authors state that an unspecified subset of their experiments violate this assumption. What s more, real world values of $R$ are not reported (or even measured!). By the same token, the appropriate statistic for various result figures would seemingly be time rather than, e.g., the number of fresh examples read. Questions:    Why was extensive hyperparameter tuning necessary? Why are most results reported in terms of time/steps to achieve a target value? Nitpicks, Spelling, & Grammar:    Metaparameters  > hyperparameters    Streamline list at end of introduction:    """    In this paper, we demonstrate that data echoing:        1. reduces the...    """<BRK>This paper proposes a method to compensate the high latency brought by data IO/processing in neural network training. Specifically the authors propose to repeat training on the same subset of data during waiting time for the new data. In this way, the data efficiency is improved, as verified by thorough experiments on various of real world tasks. Although the experiments look promising, I have to say the innovation of this paper is limited. The way of reusing the current data during waiting looks more like a straightforward trick, rather than a novel idea that deserved to be published at ICLR. Even in industrial level applications (e.g., billon level recommendation or click prediction task), AFAIK the training (including feedforward/backprop/communication in the distributed setting) consumes most of the time, while the data reading/preprocessing is comparatively cheap. Last but not least, what will the final performance will be given the potentially harmful consecutive reuse of data? Will it be worse than baseline?<BRK>I thought the paper is very nicely motivated, although this is out of my area so I cannot comment on how thoroughly the problem of data fetching is investigated in other works. The evaluations are also nice, and appropriately uses a large model (Resnet 50) and dataset (Imagenet). The simplicity of the method is a plus, but I question a fundamental part, especially if batch echoing is used isn t this just the same as running SGD twice, and therefore halving the stepsize and doubling the number of steps? From the optimization viewpoint, it seems that if less data was used and a good validation error level is reached, then how do we not know that less data wouldn t work well in the first place? Basically, what I am saying is that the idea is nice, but the results look a bit magical. After rebuttal: The authors have addressed my concerns and I more or less believe the results. I encourage the authors to make their code available so that it can be easily incorporated in applications.
Reject. rating score: 1. rating score: 1. rating score: 6. <BRK>Summary: The paper proposes an uncertainty based method for batch mode active learning with/without noisy oracles which uses importance sampling scores of clusters as the querying strategy. (+): Applying the denoising layer is an interesting and viable idea to overcome noise effects. Therefore, the sampling time of a new algorithm should be gauged based on that while performing better than random. 2017.*********************************************************************************************************************************************************************************************************POST REBUTTAL:In the revised version, there are new tables (Table 1 4) provided in the appendix which I found too different than results reported for previous baselines by more than 6%. This serves as an upper bound.<BRK>This paper provides a solution for batch active learning with noisy oracles in deep neural networks. They also improve the robustness by adding an extra denoising layer to the network. The main concern is that the two contributions are rather orthogonal to each other and each of them is not that significant. The second contribution, a de noising layer, is relatively orthogonal to batch active learning.<BRK>The authors tackled is the problem of training machine learning models incrementally using active learning with the oracle is noisy. The paper seems technically sound. Use bigger parentheses in Eq.(3).In other to increase the impact of your work, consider in your introduction (or in the "related works" Section) this kind of approaches that are also active learning algorithms:D. Busby, “Hierarchical adaptive experimental design for Gaussian process emulators,” Reliability Engineering and System Safety, vol.
Accept (Poster). rating score: 8. rating score: 6. rating score: 3. <BRK>This paper developed a novel layerwise adaptation strategy, LAMB, that allows training BERT model with large mini batches (32k vs baseline 512). In addition to demonstrating superior results across various tasks in practice, the paper also provides theoretical convergence analysis on LAMB optimizer. The paper is well written and structured.<BRK>This paper proposes a learning rate adaptation mechanism, called LAMB, for large batch distributed training. Strengths: + Demonstrate the scalability of large batch training (up to 64K) on BERT Large with comparable accuracy. What is the significance of the range [α_l, α_u] in Theorem 2 and Theorem 3, and how to choose the value for them in practice?<BRK>In this paper, the authors made a study on large batch training for the BERT, and successfully trained a BERT model in 76 minutes.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>The claims with regard to learning theory are over stated in the paper. The authors proposed three variants of the general framework. That being said, I do not see this paper to be that significant of a contribution.<BRK>This paper proposes a framework for deep metric learning. Is there a particular reason why they weren’t included in the experiments? The main contribution of the paper is a unification of previous deep metric learning algorithms, which would be helpful to the community and could inspire new approaches.<BRK>The authors could have stated more precisely in what sense the metric learning unbalanced problem they consider is different from usual unbalanced binary classification. My main concerns are about the net contribution of the paper. Would a choice of more general distances be incorporated in the proposed method?
Reject. rating score: 1. rating score: 1. rating score: 3. <BRK>The authors propose a model for Click Through Rate Prediction using a model consisting of an embedding layer, a Transformer stack, a Factorization Machine, and a DNN. I have several major concerns about the submission:2. 1.Clarity and writing: The contributions which are relevant to the ICLR community are not explained well and the paper needs copy editing for English grammar4. Novelty: While seemingly showing good results on some benchmarks, the model is a mix of many components and it s not clear which components actually improve performance and would be worth further study. What does it mean that "DNN aims at bit wise level" if the DNN receives the same embedding features as the encoder, which supposedly "learn[s] at vector wise level"? E.g.even completely removing self attention barely makes a dent in how well the method compares to other published work, moving it from rank 1 to rank 2. The biggest architectural innovations here are the bi linear attention mechanism and max pooling self attention. They are hard to interpret in this context. It s not clear how they would perform in a simpler architecture (e.g.vanilla BERT or Transformer) and in the context of a more standard benchmark.<BRK>The paper applies Multi Head Self Attention (MHSA) to a CTR prediction model with some small changes. The empirical results on two public datasets show it improves performance over some baselines. The paper does include some small modifications to MHSA and achieves better performance, such as bi linear similarity and max pooling. However, the nature of these changes seems more incremental. The experiment section is very detailed and the paper conducts several ablation studies to understand which components contribute the most, which is nice. However, the paper is missing several important baselines, for example, Deep & Cross [1], which makes the results less convincing. Another issue with the paper is that it does not control the model capacity when comparing performance. Minor: in the ablation study, it shows head   1 has the best performance.<BRK>This papers proposes DeepEnFM approach for CTR prediction task. Such transformer encoder is composed of self attention with bilinear (to replace dot) and multi head, which is followed by a mx pooling layer and then a FC layer. Besides, some resnet style trick in placed in the middle. These two parts are then used for final prediction. Do we have any study to verify this hypothesis? * Regarding to above hypothesis, i think it doesn’t hold for all the CTR prediction tasks. Computation cost will be dramatically increased when embedding size increases because of bilinear between key and query and the FC on top of self attention. The major reason is that 1) the proposed method just replaces MHSA with two changes, i.e., bilinear + max pooling, 2) other tricks such as resnet style connection, layer norm and position encoding have been adopted everywhere. * The gain of proposed method is not so clear though the author test to remove each component from the architecture. As the change of encoder part is on top of MHSA, but there is no experiment to show the gain compared to using original MHSA instead of newly proposed bilinear + max pooling. I suggest to do this for better understanding the gain of changes.
Reject. rating score: 3. rating score: 3. rating score: 6. rating score: 6. <BRK>The paper considers TD learning with function approximation, and establishes convergence results for over  and under parameterized models in the lazy regime, and illustrates the theory on simple numerical examples. Although the obtained results are interesting and the paper is well written, the contribution is quite incremental, in that it simply combines prior work on TD learning with linear function approximation with lazy training in order to show that models with a certain scaling can lead to convergence. I encourage the authors to further explain their motivation in studying such a setting. It is claimed that the over parameterized regime is only useful for finite state spaces, which seems quite limiting, since one cannot obtain global convergence in the under parameterized case. When considering neural networks at infinite width, would the results be applicable if one assumes that V* belongs to the RKHS of the corresponding neural tangent kernel?<BRK>This paper analyses the convergence of on policy TD learning for policy evaluation with non linear function approximation (deep nets) in the lazy regime. I am mainly concerned with the significance of the content in the paper and positioning with respect to past theoretical/empirical work. (The results are for specific function approximation in this paper, and hence it is unclear if that is the case we use in practice)2. I am not sure if the techniques used in the paper are relatively novel (from a theoretical point of view), and I would appreciate if the authors can elaborate a bit on this. While the setting of policy evaluation is novel, I am concerned about how many new techniques are to be gained from a theoretical point of view here.<BRK>The paper discusses the policy evaluation problem using temporal difference (TD) learning with nonlinear function approximation. This can happen if the approximation is rescaled, but can also occur as a side effect of its initialization. Although I did not carefully check the math, this seems like a solid contribution on the technical side. My main concern about the paper is that it falls short in providing intuition and contextualizing its technical content. If some of the technical material is moved to the appendix  like auxiliary results, discussion on proof techniques, etc , the additional space could be used to discuss the implications of the theoretical results in more accessible terms. For example, a subject that ought to be discussed more clearly is the nature of the approximation induced by the lazy training regime. Although the authors mention in the conclusion that “...convergence of lazy models may come at the expense of their expressivity”, after reading the paper I do not have a clear sense of how expressive such models actually are. It seems to me that this subject should be more explicitly discussed in a paper that sets out to provide theoretical support for deep reinforcement learning. Still regarding the behavior of lazy approximators, my intuitive understanding is that they work as a linear model using random features.<BRK>This paper discussed the nonlinear value function approximation for temporal different learning on on policy policy evaluation tasks in the lazy training regime. Moreover, the authors also characterized the error when the value function is under parameterized. Overall, this is a good paper. But the paper organization is awful. There are many places that are ambiguous or with notations that not formally defined. I think the authors should polish the whole paper and make it more readable. Below are some main clarity issues I find, but the authors should not only solve the issues I mentioned. 5.In Equation (11), what is the definition of the measure \pi? It can be better to introduce the result from the textbook and list the condition that need to verify, then give the lemmas show that the conditions can be verified. The perspective on viewing the TD learning as linear dynamic system on functional space can inspire several new research in this field. My main concern is about the paper organization.
Reject. rating score: 1. rating score: 1. rating score: 3. <BRK>The paper devises a pipeline that aims to address catastrophic forgetting in continual learning (CL) by the well known generative replay (GR) technique. It is more system engineering than science. All of these pieces are very well known methods (e.g.VAEs, conditional VAEs, CL, catastrophic forgetting, domain transformation) in the literature and this paper puts them together in a straightforward way.<BRK>If the novelty is in applying to continual learning and new datasets, it is not clear that this is sufficient. “Redundant weights” seems like not a very strong constraint especially for a small cardinality label space (like 10, in the case of this paper). The notation for the proposed parameters theta, theta’, phi, phi’ are not consistent with the notation in the intro section, where phi was used for the encoder and theta for the decoder.<BRK>The authors do not explicitly define continual learning, incremental learning, and catastrophic forgetting problem. I do not understand why making use of labels is important for solving the catastrophic forgetting problem and how the labels are useful in the generative replay process. The paper provides some good experimental results. It is also not clear to me why CIFAR datasets involve two domains and how these domains are relevant in each of the tasks. In summary, since DiVA gives a good experimental performance, the proposed method might be promising.
Reject. rating score: 6. rating score: 6. rating score: 6. <BRK>It introduces an interesting approach for debiasing representations. An interesting use case of the proposed method (which the authors indirectly mentioned in their response to my review) is in a multi modal setting. The proposed method is sound and interesting, and the empirical results, thorough. I vote for accepting the paper as a poster.<BRK>This is an interesting and important aspect of machine learning models neglected by many recent developments. The only problem is that the paper seems to be a bit immature as the exemplar application is too naive for illustrating the idea. Therefore, the solution given for this important problem seems to be too ad hoc and not generalizable.<BRK>Overall the paper presents an interesting contribution that would be useful for future study in reducing bias dependance in ml. Overall the method is very interesting. That being said, I don t feel the paper needs to provide this comparison given how recent those works are, but it would improve the quality of the paper.
Reject. rating score: 3. rating score: 3. rating score: 3. rating score: 6. <BRK>In the paper, the authors propose a pipelined backpropagation algorithm faster than the traditional backpropagation algorithm. The proposed method allows computing gradients using stale weights such that computations in different layers can be executed in parallel. I have the following concerns:1) There are several important works on model parallelism and convergence guarantee of pipeline based methods missing in this paper, for example [1][2]. 5) Last but not least, convergence analysis of the proposed method should be provided given that asynchrony may lead to divergence in the optimization. "Training neural networks using features replay."<BRK>The paper proposed a new pipelined training strategy to fully utilize the memory and computational power to speed up the training process. For the method proposed by the paper,  it is like the async SGD method. Based on this, I think the paper has some room for improvement.<BRK>This paper proposes a new pipelined training approach to speedup the training for neural networks. The approach leads to stale weights and gradients. The authors studied the relation between weight staleness and show that the quality degradation mainly correlates with the percentage of the weights being stale in the pipeline. The quality degradation can also be remedied by turning off the pipelining at the later training steps while overall training speed is still faster than without pipelined training.<BRK>This paper investigates the impact of stale weights on the statistical efficiency and performance in a pipelined backpropagation scheme that maximizes accelerator utilization while keeping the memory overhead modest. The paper is well written and easy to follow. Though promising results have been demonstrated, a drawback of the proposed method is that it introduces more memory overhead compared to GPipe. Further, no proper convergence analysis of the proposed approach is provided and is desired due to the likely divergence in the optimization. Gpipe: Efficient training of giant neural networks using pipeline parallelism, 2018.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>They propose a "top down training strategy" to search where to make the cut for the "top layers" of the "good classifier", based on the validation set. ( ) No WER (not even without a language model) results on WSJ make it harder to (i) compare to other work (is it just that in this case the authors didn t optimize properly in the first place?), (ii) compare the relative gains between with and without the method in WER. ( ) For an experimental (no theorem) optimization paper, there should be experiments on at least another domain. And in particular one would have expected more analysis of the experimental optimization results.<BRK>This paper proposed a Top Down method for neural networks training based on the good classifier hypothesis. For instance, under which settings this method is most efficient? In what layer should  I start the fine tuning? Is it better to reinitialize the bottom layers or fine tune them? Does the proposed approach applicable to different domains? Does the proposed approach applicable to different models or only for the proposed one? That way, people can compare results with other ASR models.<BRK>This work proposed a mechanism to freeze top layers after supervised pre training, and re initialize and retrain the bottom layers. The layer freezing trick however is relatively well known, and thus leaving the novelty of the proposed idea to be limited at what layers they choose to freeze.
Reject. rating score: 1. rating score: 3. rating score: 8. <BRK>The paper presents expected gradients which is a method which looks at a difference from a baseline defined by the training data. Attribution priors as you formalize it in section 2 (which seems like the core contribution of the paper) was introduced in 2017 https://arxiv.org/abs/1703.03717 where they use a mask on a saliency map to regularize the representation learned. I think a few papers to have a look at are a survey article about graph based biasing http://www.nature.com/articles/s41698 017 0029 7 as well as methods for using graph convolutions with biases based on graphs: https://arxiv.org/abs/1711.05859 and https://arxiv.org/abs/1806.06975 . Some of these should serve as baselines. It is not clear which model is used in Figure 2. It is also not clear from the literature if these models are really working so I think these results should be presented in a more detail. As I understand it, real improvements in predicting clinical variables has not been shown to be reproducible so this would be a significant claim of this paper. It is not clear if the paper is presenting "expected gradients" or existing attribution priors. Most of the experiments revolve around existing attribution prior methods. So with that the paper positions itself not as a survey but as a method paper but lacks evidence that the method expected gradients performs better.<BRK>Summary.The paper improves the existing feature attribution method by adding regularizers to enforce (human) expectations about a model’s behavior. Three different datasets (i.e.image, gene expression, health care) are chosen to evaluate the proposed model’s effectiveness, while different regularizers (i.e.image prior, graph prior, and sparsity prior) are explored for the respective task. 2.Three datasets from different domains (i.e.image classification data, gene expression data, and health care data) are used to evaluate the effectiveness of the proposed approach. Data shows that the proposed approach shows better generalization performance (i.e.better performance in test dataset) than baselines. 1.Task specific heuristic human priorI agree (and personally like) the motivation that a method is needed to align a model’s behavior with human knowledge or intuition   model’s behavior may be explained by feature attribution methods while making models accept human knowledge is challenging. However, such an ability is achieved by simply adding task specific heuristic functions as a penalty or a regularizer. I am concerned that only a limited set of expert invented human priors can be used in this approach. However, the difficulty would be the lack of formal measures of how the network output is affected by spatially extended features (rather than pixels). A key motivation behind this work is “incorporating humans into the modeling process”. This would imply that (human understandable) information needs first to be transferred from a model to humans. However, I am concerned about what information end users are expected to obtain from the model. A user study would be needed to support that the proposed method can really provide a way to incorporate humans into the modeling process. 1.Plots in Figure 3 are not intuitively understandable. 3.A template for the reference section looks different from other ICLR papers.<BRK>This is a general framework that the users can define different attribution priors for different tasks. For example, in this work, the authors proposed three reasonable priors for image input, graph data, and clinical medical data. Moreover, the authors proposed the expected gradients algorithm which is a nice extension of the integrated gradients algorithm. The benefit of expected gradients is that it does not need a baseline input, which is usually arbitrary decided by the designer. The results in all three experiments are impressive. More impressively, the model does outperform all other controls with a good margin in the anti cancer drug prediction experiment, which is a nice demonstration of that domain knowledge could be incorporated in a neural network training to achieve better performance. Overall, I found the paper clearly written and the results are impressive. Even though the authors has shown in Table 1 benchmark that expected gradient is performing better than integrated gradient. It would be nice to see how integrated gradient method perform in the three experiments (image, drug data, mortality prediction), does the expected gradient method always outperform? Would be nicer to do for example "... as measured by R^2 (Figure 2 Left).
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>Similarly to HART, MOHART utilizes an attention mechanism and LSTM units. I found the paper enlightening, based on a neat idea. The experimental results are extensively analyzed and the Author s insights about their algorithm are substantiated by the experiments. It is one of the more competitive and application driven fields in computer vision. Recent papers from those that claim state of the art could good candidates for comparison.<BRK>This paper deals with the problem of multiple object tracking and trajectory prediction in multiple frames of videos. Finally, experiments on real data demonstrate that the proposed method that accounts for relation reasoning is helpful by a limited magnitude. The main contribution of this paper is the novel relation reasoning block. However, there are three key concerns of mine: 1. I also appreciate the honesty that the current model is not competitive with the ones that have an accurate bounding box as input. But I think a more detailed study can be conducted, especially in the toy example case. 3.The end to end approach is also another perspective where the authors try to differentiate their methods from others.<BRK>This paper presents an extension to HART [Kosiorek 2017] to track multiple objects. They extend this by adding a relational reasoning module to allow interaction between the parallel models. The relational reasoning module uses Lee et al.(2019) s self attention block (similar to Vaswani et al.2017).They find that the simple baseline is surprisingly effective, but that MOHART (their model) improves performance in environments with stochastic interactions and crowded settings which tend to be more noisy. For the synthetic experiments, I would have expected the fact there are repulsive forces between the objects would have been sufficient for the relational module to be helpful.
Accept (Poster). rating score: 6. rating score: 6. rating score: 3. <BRK>The authors study depth adaptive Transformer models and show that they can perform well even under fairly basic strategies to stop the Transformer early. The paper is well written and the results convincing. This is a fine measure for inference time, but during training the model proceeds on the whole sequence, right? Is there any improvement over a baseline Transformer or is this technique solely for inference? I thank the authors for the response and clarification. I stand by my score in the light of it.<BRK>The paper experiments these different training strategies on IWLST and WMT datasets. Overall I believe the problem considered is interesting and the paper did a good job in setting up the problem and explaining the experimental setup results. The paper mainly needs to improve in discussing existing work. While the training setup is different here, without the large shared Transformer layers, and this paper mainly focuses on the dynamic halting strategies, it is important to discuss these differences in detail in the paper. Doesn’t a dirac delta q^* cause problems here? There is a conflict in writing in both abstract and introduction as some sentences say that current models use the same computation irrespective of hardness of the input, followed by discussion of Universal Transformers, which do adaptive computation based on input hardness. The writing flow needs to be fixed in both abstract and intro. Fixing the discussion about related works , as other reviewers also mentioned, will improve the paper.<BRK>I want to thank the authors for addressing the other issues/questions I raised. Original Review Below  Summary: The author proposes a new way to improve the supervision of training encoder decoder Transformers so that it can make flexible, depth adaptive predictions at inference time. The paper compares multiple dynamic computation schemes to investigate the effectiveness of these different approaches (e.g., at both sequence and token levels). However, I think the paper can be further improved in terms of both its organization/clarity and its experimental study (see details following). Some minor errors that don t have much impact on the score:9. 4.In the token specific likelihood based method, you used an RBF kernel to model the influence of a time step t on its neighboring time steps. I think the current shape of the paper is marginally below the acceptance threshold. I find it interesting that the mixed training strategy doesn t work.
Accept (Spotlight). rating score: 8. rating score: 6. rating score: 6. <BRK>This paper covers the author’s approach to learning a model of a game, which can then be used to train a reinforcement learning agent. This is a well written paper, and the results are very impressive. As I said above that is very impressive. Ideally I would have liked to have seen some variance in the amount of time Rainbow was trained for compared to the associated computational costs. Clarity on this especially in sections like 6.1 would help readers better grasp the tradeoffs of the approach.<BRK>The paper addresses sample efficient learning (~2 hours of gameplay equivalent) for Atari (ALE) games. Can this approach be stacked to benefit from training in a lighter weight approximate model (env ) of the world model (env )? This reviewer moves for a weak accept on account that the paper is well written (with quite thorough experiments explaining improvements in sample efficiency and possible limits in final task performance) but specifically targets ALE where execution is so cheap.<BRK>SummaryThis paper proposes a model based reinforcement learning algorithm suitable for high dimensional visual environments like Atari. OriginalityThe originality of this paper is not very high since the proposed algorithm and its components are not novel (there might be some minor novelty in the environment model architecture). However, this paper should not be judged based on its originality but based on its significance. Demonstrating improved sample efficiency compared to strong model free baselines in low training regimes is a significant result. The significance is however decreased by the fact that the paper does not answer the question how to obtain good asymptotic performance that matches (or comes close to) model free state of the art results. I think this paper is worthwhile publishing at ICLR.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>Their construction was inspired by the information bottleneck framework. The concept of distribution shift is not formally introduced in the manuscript. My major concerns for this submission are its clarity, novelty, and theoretical depth. However, I have not found any discussion related to this, which evidence that the author(s) might lack a proper understanding of classical treatments.<BRK>The paper proposes a specific approach to enforcing this information bottleneck, called "entropy penalty", which tries to minimize the L2 distance between the representation at the first layer and the mean representation of the corresponding class. You can use leaky relu activation to make sure information is not lost in activation functions.<BRK>They further assume the hidden layer is Gaussian, and use squared l2 loss as entropy penalty. In this sense, I have the impression that the presentation is not very clear (EP can learn something, but what it is?). 2) The claim is that EP learns robust features for deep learning methods, but both the analyses and experiments are not enough to show that. More comparisons are needed to give a sense of the advantage of EP.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>This paper proposes an auxiliary reward for model based reinforcement learning. The proposed method uses ensembles to build a better model of environment dynamics and suggests some rules to optimize the new ensemble based dynamics and to estimate the intrinsic reward. I am torn on this paper. I will vote "weak accept" for this paper, as I think it is incremental and the experiments are too limited. The method should be evaluated in a setting­ with truly sparse rewards.<BRK>SummaryThis paper proposes a model based method for intrinsic rewards based on probabilistic neural network ensembles. For a particular ensemble element, an intrinsic reward is defined as a log term that measures the deviation in prediction between a Gaussian mixture over all ensemble elements and the particular ensemble element (at the previous update period). Second, the experiments are conducted in a sparse reward modification of Mujoco type environments that are non sparse by construction. This way of sparsifying rewards yields weird partial observability issues, e.g.the same state action pair observed at the right moment in time yields significant reward whereas at the wrong moment in time yields no reward at all. The method s improvement over other intrinsic reward approaches is minor (the environments chosen by the authors are also not ideal). I still feel this paper shouldn t be accepted to ICLR.<BRK>This paper presents an approach for using an ensemble of learning dynamics models to generate an intrinsic reward for reinforcement learning in sparse reward environments. That plot could be very enlightening as to what is going on. For the experiments, it would be very interesting to see the intrinsic rewards accumulated over time for each approach.
Accept (Poster). rating score: 8. rating score: 8. rating score: 3. <BRK>To alleviate the issues of reward sparsity and mode collapse in most text generation GANs with a binary discriminator, this paper proposes a self adversarial learning (SAL) framework with a novel comparative discriminator that takes pairs of text examples from real and generated examples and outputs better, worse, or indistinguishable. 4) Missing training details: It is unclear how the model architectures are chosen, and learning rate, optimizer, training epochs etc. I like the idea in the paper and am happy to vote for acceptance. Cons:1) SAL has a new discriminator, which can be viewed as an architecture change.<BRK>Summary: This paper describes a self adversarial method to train a GAN for text generation that circumventes the problems of mode collapse and reward sparsity. They replace the traditional binary discriminator with a comparative discriminator, which provides the generator with more frequent rewards that are not always restricted to the limited number of real training examples. I appreciate the human analysis conducted by the authors. How is BLEU evaluated for this text generation task?<BRK>Decision: weak reject. This paper is well motivated: clearly sparse rewards and mode collapse are two problems need to be solved in GAN based text generation, however, the following concerns prevent me from finding this paper acceptable in ICLR:The “self play” idea is widely used in RL. As a simple extension to GAN, I’m not convinced that the problem of mode collapse could be solved by proposed mechanism. Moreover, in the paper, only comparison between proposed mechanism with GAN based models are shown. This is different from the CAL model in the ablation study. Those metrics could be helpful for audience to understand how the model performs in comparison with other captioning models.
Accept (Poster). rating score: 8. rating score: 6. rating score: 3. <BRK>Some of their experiments are performed on a tiny search space with only 32 models. The paper shows that NAS methods comes up with shallower but wider cells. This means to me that this paper cannot be used as a reliable reference. It appears to be the case that the smoothness and the variance both depend on the eigenvalues of the weight matrices. This would make the result more reliable.<BRK>I think this paper should be accepted. Nevertheless, I do agree that this paper has a clear motivation, and the observation is interesting and important. + Theoretical justification for the gradient variance between the narrowest and widest cells are sound. Trending of DARTS evaluation results does not agree with SNAS and AmoebaNet. Could the author(s) comment on this?<BRK>Summary:This paper tries to understand the characteristics of the architectures found by common NAS methods in the cell search space. Comments:  Overall the paper is interesting and well written. Liked the empirical analysis and theoretical insights backing it up. The generalization experiments suggest to me that on bigger datasets wider and shallower networks might be better for generalization actually.
Reject. rating score: 3. rating score: 6. rating score: 8. <BRK>I have some question about the extent to which this work is in scope for ICLR. But a lower bound for the convex case seems to be stretching this a little far.<BRK>Despite the tight lower bound, the assumption (1) and (2) above seems to be restrictive, but they are necessary for the analysis of this paper.<BRK>The paper fills an existing gap in the literature and it achieves two very interesting results:1  The lower bound now matches an existing upper bound for Point SAGA, showing that no better algorithm can exist (at least in a worst case sense). As pointed out by the authors, the requirements on the dimensionality in the theorems of this paper are milder than previous results.
Accept (Poster). rating score: 8. rating score: 6. rating score: 3. <BRK>This paper makes a convincing case for improving the usefulness of production level, large scale models by making them quickly editable without extensive retraining. The paper demonstrates effectiveness for both image classification and machine translation tasks, covering a wide range of relevant scenarios. I recommend acceptance because:  The paper considers a real issue for production models which are becoming widespread, and retraining for targeted modifications is impractical. Experiments are consistently well designed and executed. The method proposed in [1] is very similar, even if it is used in the continual learning settings.<BRK>This paper proposes a way to effectively "patch" and edit a pre trained neural network s predictions on problematic data points (e.g.where mistakes on these data points can lead to serious repercussions), without necessarily re training the network on the entire training set plus the problematic samples. More concretely, the edit operation on the problematic samples are done using a few steps of stochastic gradient descent. To this end, the paper uses a loss term that incorporates these criteria, as weighted by interpolation coefficient hyper parameters. Experiments are done on CIFAR 10 toy experiments, large scale image classification with adversarial examples, and machine translation. Pros:1.The paper is well written, and clearly motivates the problem and why it is important.<BRK>The authors propose Editable Training that edits/updates a trained model using a model agnostic training technique. Editable training is able to correct mistakes of trained models without retraining the whole model nor harming the original performance. This paper has brought attention to mistake correction problem in neural networks and proposes a simple and concise solution. In addition, extensive experiments on both small and large scale image classification and machine translation tasks demonstrate the effectiveness of different editor functions. Overall, this paper is well written with extensive experimental results. Below are a few concerns I have to the current status of the paper.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>Given the set up’s simplicity, a short theoretical argument (maybe even a theorem) about the quality and number of local minima one would expect to find could have been more concise and compelling than the empirical analysis from the paper. The authors cite a paper by Adrian Barbu as the inspiration for their pruning algorithm with annealing, and use it “to improve the capability of NNs to find a deep local minimum even when there are irrelevant variables”. I vote to “weak reject” this paper. I recommend that the authors cite and discuss https://arxiv.org/pdf/1805.01930.pdf , and possibly submit the paper at a less competitive conference. Following up on the previous point: it would be great the authors could include data sets where CPNA does not outperform.<BRK>Overall, I am a bit concerned with the significance of this paper. This paper presents a few sets of experiments related to deep local optima. The paper claims that it is quite easy to find a deep local minimum with good generalization when the number of irrelevant features is small, and it becomes harder to find a deep minimum with good generation as the number of irrelevant features increases. It will be more interesting to study on CNN, etc.<BRK>The reviewer represents the opinion that more focus on such setups would greatly benefit the community in terms of progressing the theoretical understanding. The claim made in the paper that there is a relationship between the number/suboptimality of local minima  and the scarcity of the data is both convincing and interesting.
Reject. rating score: 1. rating score: 3. rating score: 8. <BRK>This paper proposes the use of Federated Averaging for achieving personalised user embedding. The key contribution of this paper is not clear. It seems to be the introduction of the notion of split personalisation constraint, and it shows that the modeling each user with a “private” embedding that feeds to a global MLP with a global BLSTM as another input (named as FURL) can achieve the constraint so that FL can be used.<BRK>In this paper, the authors propose using federated learning (FL) to train personalized models, which improves the scalability and privacy preservation of the existing personalization techniques. The empirical results show good performance. However, in general, I think the contribution is limited. The reasons are as follows:1.<BRK>Reviewer has limited knowledge of previous work in the personalized FL field, thus is only able to confirm the novelty from Authors  related work section. Authors approached the problem with defining the constraint of split personalization, and argued that common FL setting such as Federated Averaging could satisfy this constraint. Authors also compared the conversage curve and visualized final embeddings to show that federated learning produces acceptable convergence and equally reasonable embeddings. The claimed benefits of such models are 1) preservation of user privacy by keeping the personalized parameters locally on each user s device, and 2) reduced data exchange to make the training complexity grow linearly with the number of users.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>The method employs as a basic input the SMILES representation of molecules which are not well defined in terms of the representation, though. The experimental results on the tasks of the property prediction and molecular optimization using the benchmark datasets demonstrate the effectiveness of the proposed method in comparison with the others. Though this paper provides some contributions to the field of molecular graph representation, it contains flaws in presentation, lacking details of technical contents; thus, the paper is regarded as "borderline". * This paper lacks some important technical contents, making it hard to understand. And, in the first place of the paper, it would be better to explain what kind of and how many properties of the molecular are considered. It is unclear how to apply the proposed method to the semi supervised learning framework? The comparison experiments seem to be inconsistent. The proposed method is compared with different methods in different datasets/tasks. Toward fair comparison, it should be evaluated in comparison with some baselines including such as JT VAE consistently. There, however, are some approaches to canonicalize the SMILES representation itself such as by canonical SMILES.<BRK>The authors present a method All SMILES VAE that’s used for predicting chemical properties of small molecules and also for optimizing the structures of these molecules. The authors evaluate their model on the Zinc250K and Tox21 dataset and report that they are able to exceed the previous SOTA. While it’s interesting to be able to optimize molecules in the space of SMILE strings, the impact is less clear. While this may lead to directed searches, it will prevent truly novel molecules from being synthesized. The authors will need to address and provide experiments with unconstrained search. It seems from the text of figure 5, that the SSVAE and GraphConv results have been taken directly from the paper. Some clarification questions:   For optimized/predicted strings, which are presumably novel molecules not in the dataset, how is the true chemical property  e.g.logP, determined? Overall, I think that this paper has some interesting ideas and is well written. However, the novelty and impact of the model is somewhat lacking. If this were introducing a new application area to this field, then I think the case for acceptance could have been stronger, however there has already been a lot of work related to molecular property prediction/design. So, I went with 3, but please consider this to be a 5.<BRK>Instead of using graph neural networks, the authors hava an approach based on SMILES which encode molecules as strings. To avoid the problem that any given molecule may be represented by multiple SMILES strings, the authors consider an encoder that makes use of several random SMILES representations of the input molecule. These are preprocessed using recurrent neural networks generating an average representation by pooling the representations generated with each SMILES sequence for each atom in the input molecule. The model decodes then into a disjoint set of SMILES strings different from those used at theinput. This enforces the model to learn a bijective mapping between molecules and latent representations. The proposed model can also do semi supervised and supervised prediction tasks. Clarity:The paper is very clearly written and it is very easy to read. It contains a very detailed description of previous work. Significance:The experiments show that the proposed method can outperform previous ones. However, I miss additional evaluations using existing frameworks such as  Guacamol.
Accept (Spotlight). rating score: 8. rating score: 8. rating score: 3. <BRK>The paper is well written, presents an elegant idea in a clear and straight forward manner, and is solidly built on top of the current literature on self supervised learning for image processing, which is also very well summarized. At this point, the number of classification heads can be treated as a hyperparameter of the algorithm. This constraint acts as a "regularizer" that allows the authors to minimize the cross entropy loss between inputs and pseudo labels while avoiding the degenerate trivial solution where all samples are assigned to the same pseudo label. That is done by remarking that minimizing the loss function over the pseudo label assignments (under the equal partition constraint) can be formulated as an optimal transport problem that can be solved efficiently with a fast version of the Sinkhorn Knopp algorithm.<BRK>Summary & Pros  This paper proposes a representation learning method based on clustering. The proposed method performs clustering and representation learning alternatively and simultaneously. For clustering, the objective can be formulated as an optimal transport problem and it can be efficiently solved. If the number of each class is imbalanced, the equipartition constraint might degrade the quality of the label assignment. The SOTA method can be considered as a combination of (instance wise) clustering and self supervision. I think this direction against self supervised learning is important because it requires relatively smaller domain knowledge. So I think it would be better if more analysis about the convergence is given in a rebuttal.<BRK>This paper develops a novel self supervised learning method by combing clustering and representation learning together. Under the weak assumption that the number of samples should be similar across different clusters, the authors further develop a modified Sinkhorn Knopp algorithm to solve the problem. In general, the whole paper is well written and the developed solution is interesting. However, I have the following comments:1. The authors are suggested to provide more explanations about the differences. 2.The used assumption that samples are uniformed distributed across different cluster are too strong in practice. 5.How about the time complexity of the developed algorithm?
Reject. rating score: 1. rating score: 1. rating score: 6. <BRK>Summary: The paper uses a Gaussian Processes framework previously introduced in [1] to identify the most important samples from the past for functional regularization. (for example for P MNIST the gain is 0.6%+ 0.1) where there is a lack of complete discussion on how the two methods are different. Authors indicate on page 3 “Our goal in this paper is to design methods that can avoid such catastrophic forgetting.” and reiterate on this on other parts of the paper yet there is no forgetting evaluation to support this claim. (b) On page 1, paragraph 3, they mention some prior work such as GEM and iCaRL “do not take uncertainty of the output into account”. This is what we mean by scalable.<BRK>The paper proposed a new functional regularization method with gaussian process which has similar direction with recent two works (khan et al, titsias et al). They select most memorable samples depends on eigenvalue. The model FROMP outperforms baselines and their ablations. However, the experiments are only performed on shallow networks, it is required to apply on much deeper networks, such as ResNet. Also, in the experiment results, I feel the performance of the FROMP largely depends on the number of the coreset, while  important  selection just shows marginal effects even on split CIFAR. I have several wonderings on the paper.<BRK>StrengthsTo some extent, I think the proposed method is novel, although there is a similar work named as Functional Regularisation for Continual Learning (FRCL). FROMP first uses NTK in Gaussian process for continual learning and proposes a new strategy of selecting memory samples. The strategy of selecting samples to be stored is simple and effective. The experimental section needs more detailed analysis. Other comments In this paper, for Split MNIST experiment with multi head, it shows that the method of EWC achieves worse results than SI. I expect authors could explain this point.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>This paper considers a the differential privacy problem regarding the parameter tranfer algorihtm in meta learning, such as MAML and Repile. To me, the setting is very interesting and according to the paper, it seems that it is the first formalization for this setting. All the datasets the paper uses are very easy ones. The experiments demonstrate the effectiveness of the proposed differentially private parameter transfer.<BRK>This paper proposes the notions of different privacy levels for different attack models, namely global and local meta level and within task level privacy for meta learning. It proposes an algorithm for global within task privacy. It provides privacy and utility guarantee of the proposed algorithm and experimental evaluations. The proposed definitions make sense to me for the scenarios mentioned in the paper. The utility guarantee also seems interesting. I think the experimental evaluation can be made more complete, for example, you may consider:  a convex setting as was considered in the utility guarantee,  varying epsilon values.<BRK>This paper considers the problem of achieving formal privacy guarantees in the context of parameter sharing meta learning. The problem is well motivated: since in meta learning we want to leverage information from similar tasks to increate data efficiency, there may be privacy concerns for each of the task owners about both other task owners and the aggregator (meta learner). In combination with post processing and composition guarantees this gives privacy for the overall mechanism. They are able to show theoretical guarantees via the standard accuracy guarantees of private SGD and no regretguarantees of OCO.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>Summary : The paper proposes an exploratory objective that can maximize state coverage in RL. They show that a formal objective for maximizing state coverage is equivalent to maximizing the entropy of a goal distribution. The core idea is to propose a method to maximize entropy of a goal distribution, or a state distribution since goals are full states. Overall, I am not convinced that an objective based on H(s|g) is equivalent to an maximizing H(s), and why is this even a good objective for exploration? In light of this, I am not sure whether the core idea of the paper is convincing enough to me. Overall, I would recommend to reject this paper, as I am not convinced by the proposed solution, and there are lot of theoretical details missing from the paper.<BRK>The paper introduces SKEW FIT, an exploration approach that maximizes the entropy of a distribution of goals such that the agent maximizes state coverage. ", it is empirically illustrated that the method does result in a high entropy state exploration. I m unsure about the interpretation of this sentence given Figure 6 because other methods do not seem to fail entirely when given enough time. The experiments are interesting, yet some interpretations might be too strong (see below):  In the first experiment, "Does Skew Fit Maximize Entropy?<BRK>This paper introduced a very interesting idea to facilitate exploration in goal conditioned reinforcement learning. The key idea is to learn a generative model of goal distribution to match the weighted empirical distribution, where the rare states receive larger weights. The experiments offer a comparison to several prior exploration techniques and demonstrate a clear advantage of the proposed Skew Fit method. A formal analysis of the algorithm is provided under certain assumptions. Cons:The weakest part of this work is the task setup. It is especially when the agent has no access to task reward and only explores the environment to maximize state coverage. I would also like to see how Skew Fit works with different goal conditioned RL algorithms, and how the performances of the RL policy in reaching the goals would affect the effectiveness of this method in exploring a larger set of states.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>Paper contributions   This paper proposes a method for constructing representations using a matrix of Wasserstein distances. These distances measure the discrepancy between each class and each environment, that is a random combination of some classes. General notes The general idea of measuring the distribution divergence for a set of classes is interesting and seems to be novel. I don t follow why the paper proposes to use  environments     random combinations of classes. The experimentation is very weak and does very little to support the claims. The paper doesn t provide any comparison to existing methods or simple baselines. There is no experiment demonstrating interpretability of the proposed approach. Some of the claims are vague and excessively broad:  The proposed technique can be used with any task, but the paper is clearly limited to the retrieval task  The environments are too vaguely described and can be misinterpreted in the introductionConclusion I recommend to reject on the basis that   the approach is more limited than the paper advocates  the experimentation is weak  some claims are not addressedOther notes I recommend using term divergence instead of distance when it is not symmetrical.<BRK>The paper defines a representation learning strategy based upon estimationof a matrix of Wasserstein distances. The idea is excellent. Phrases like "belonging to any random subset of the dataset" suggesta non deterministic method of selecting an element of the power set ofthe training data, but it is unclear what to do if more training dataarrives in this case. In the experiments section phrases like "environments consist of random combinations of classes" is also not helpful. Do you mean something like "uniformly selected from the set of all class pairs?" I want to accept this paper if the exposition is improved, which I thinkis possible during the response period. My other comments are not blocking issues, but would either improve thecurrent paper or inform future directions of research. [1]  That paper seeks a projection that maximizes the ratio of Wasserstein distance between classes vs. within classes. Ifthe matrix is full rank with a flat spectrum, however, that might indicatethe choice of environments is too granular and overfitting has occurred,it s not immediately obvious to me how to guard against this.<BRK>The authors proposed a template based interpretable representation that works based on the earth mover s distance of each class to a number of "environments", which could be taken as union of a few random classes. The method is evaluated based on classification and retrieval tasks. Here are my concerns:  Since the environments are taken randomly in the experiments, it is not investigated how sensitive the method is with respect to the choices of environments.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>This paper proposes an attack method to improve the transferability of targeted adversarial examples. There are a lot of typos in the paper.<BRK>This paper proposes distillation attacks to generate transferable targeted adversarial examples. I think their proposed attack is interesting due to its simplicity and effectiveness. 4.In general this paper lacks empirical analysis on why distillation helps improve the transferability. I think this paper still misses a more in depth analysis, and thus I keep my original assessment.<BRK>The paper suggests to use temperature scaling in adversarial attack design for improving transferability under black box attack setting. Based on this, the paper proposes several new attacks: D FGSM, D MIFGSM, and their ensemble versions. Experimental results found that the proposed methods improves transferability from VGG networks, compared to the non distillated counterparts. Firstly, the presentation of the method is not that clear to me.
Reject. rating score: 1. rating score: 3. rating score: 3. rating score: 6. <BRK>The paper studies stochastic optimization with consistent (may not be unbiased) estimators. This problem is well motivated through the example of learning graph representations where consistent estimators are easier to obtain than unbiased one. Under the assumption that the estimate converges to the consistent gradient exponentially fast w.r.t.the sample size, the authors give convergence rates for convex, strongly convex and non convex optimization. The main convergence theorems seem to follow from standard techniques for inexact/noisy gradients. Convergence Analysis   As mentioned above, since the setting is like GD with noisy gradients, a more careful analysis in the strongly convex setting can improve the convergence result. Why is this needed?<BRK>The analysis of the convergence of SGD with biases gradient estimates dates back to Robins&Monroe, but the authors of this paper focused on a recent original algorithm that shows that once can estimate the approximate gradient of a large GNN network, simply by sampling nodes randomly. Is there something such as the computational cost of Adam, that I m missing, especially when looking at the graphs? The main contribution of the paper is the proof that the algorithm converge, but there is no theoretical analysis of the key quantity "t", which is the number of sampled nodes in the neighbours of the output nodes. Overall, while proving that the FastGCN algorithm is consistent is important, it is hard to understand how useful the results are and how they can be useful in practice.<BRK>This paper aims to solve the stochastic optimization problems in machine learning where the unbiased gradient estimator is expensive to compute, and instead use a consistent gradient estimator. The main contributions are the convergence analyses of the consistent gradient estimator for different objectives (i.e., convex, strongly convex, and non convex). Overall, it is interesting and important, but I still have some concerns. Is that right? Besides, for Figure 1, can the "SGD unbiased" be viewed as "SGD consistent (sampl $n$)"?<BRK>The authors then establish that SGD algorithm when run with consistent gradient estimators (but not necessarily unbiased) have similar convergence properties as SGD algorithms when run with unbiased gradient estimators. Consistent gradient estimators have been proposed for such graph problems in the past but this paper establishes theoretical properties of SGD with such estimators. The paper is well written and the results are convincing. I have a few questions/comments1. It is clear that using unbiased SGD, unbiased ADAM is better of than using biased SGD.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>It is not clear what are the previous contributions prior to this paper, and it seems [1] shares some similar results/observation with the this paper.<BRK>It is not very clear due to the vague definitions. Because of these concerns, I think this paper is on the borderline.<BRK>Overall I quite like the analysis of this paper. I think it could be clearer and contain more experiments but it is otherwise rather convincing proof that DNNs learn low frequency patterns first. The paper would benefit from always making this clear in the text and figure captions.
Reject. rating score: 1. rating score: 1. rating score: 6. <BRK>** Summary **In this paper, the authors propose a new variant of Transformer called Tied multi Transformer. Given such a model with an N layer encoder and an M layer decoder, it is trained with M*N loss functions, where each combination of the nth layer of the encoder and the mth layer of the decoder is used to train an NMT model. The authors propose a way to dynamically select which layers to be used when a specific sentence comes. When compared Tied(6,6) to standard Transformer, as shown in Table 1, there is no improvement. c.	In terms of training speed, compared to standard Transformer, the proposed method takes 9.5 time of the standard Transformer (see section 3.4, training time). Therefore, I think that compared to standard Transformer, there is not a significant difference. 2.The authors only work on a single dataset, which is not convincing.<BRK>This work proposes a way to reduce the latencies incurred in inference for neural machine translation. The authors claim that the use of knowledge distillation is novel. I have several concerns to this work and I d recommend rejecting this submission. One of the problems of this paper is presentation.<BRK>This paper proposes a novel procedure for training multiple Transformers with tied parameters which compresses multiple models into one enabling the dynamic choice of the number of encoder and decoder layers during decoding. The idea is simple and reasonable and the results are promising.
Reject. rating score: 3. rating score: 3. rating score: 6. rating score: 6. <BRK>This paper presents a model with beta bernoulli dropout of neurons for network pruning. The model assumes the probability to dropout a neuron is a function pi(phi, x), which depends both the beta variable phi and the input x. The model is trained with stochastic gradient variational Bayes with continous relaxation. The model and algorithm sound, and the intuition of determining the dropout probability based on the importance of each dimension makes sense. One weakness of this work is the lack of large scale experiments, for example, pruning a MobileNet on ImageNet. Figure 1: bottom right figure (input regions pruned by DBB) is missing? Update:The authors do address my concern #2. After reading other reviews and reading the revised paper I do think this approach of this paper is novel and can potentially lead to a gain. However I still don t think the experiments are convincing enough. It needs to be tested on a larger variety of models (ResNet or MobileNet) / datasets (ImageNet, etc.) to prove its significance.<BRK>The paper proposes Variational Beta Bernoulli Dropout to sparsify the parameters of the network. The paper presents necessary theoretical details as well as the experimental comparison with the other dropout methods on MNIST and CIFAR 10/100 datasets. The paper is well written overall and easy to follow. The paper provides a thorough background on previous work; however the motivation for having an input dependent dropout method is relatively weak. The paper explains well how the two proposed dropouts can be learned during training, but it s not clear about the inference, specially in variational dependent Beta Bernoulli dropout. This is not clear to me what it means, and also the related footnote which says different thresholds were tried but the difference is insignificant! Also, it is not clear if xFLOP and Memory report the best, mean or median of 3 runs. In Table 1, what does column Neurons represent? Is it the model parameters at inference time? In the experimental results, some models are missing that are mentioned in the paper as previous work which seem to be good to use for comparison, such as Sparse Variational Dropout (Molchanov 2017) and Structured Sparsity Learning (Wen et al 2016). I encourage the authors to expand more on analyzing the experimental results! In Table 1 and Table 2, there are 2 lines for BB and DBB, which is helpful to explain what each line represents. Looking at the results of all tables, and comparing different dropouts w.r.t :1) Error, 2) xFLOPs and 3) Memory, I cannot draw a clear conclusion from the results. For example, in Table 2, CIFAR 10, comparing first line of BB to SBP and second line to VIB, the difference is not significant. More analysis about the results can be helpful!<BRK>The paper proposes a new way of training variational dropout which is adaptive to input samples due to the proposed sparsity inducing beta Bernoulli prior. The authors provide a good motivation for their model, introduce beta Bernoulli and dependant beta Bernoulli prior and propose the method in the variational inference framework. From the Tables 1, 2 we can see that BB is comparable with DBB and the latter is not uniformly better than the former in terms of error, xFLOPs and memory. This similarity in the performance is more significant for LeNet5 Caffe network, for CIFAR 10 and CIFAR 100 datasets. Is the overhead of DBB worth the benefits it gives? It means that DBB should keep all weights after the first stage, in other words the memory consumption of DBB is the same as BB. Overall, the paper proposes interesting and well motivated method for training sparse networks. Although, there are concerns about the DBB extension I would recommend considering this paper for acceptance. Indeed, the run time memory mostly consists of activation maps, therefore DBB can benefit from input dependent sparsity. Considering the first concern I still think that the advantage of DBB is not clear and I agree with AnonReviewer3 who said that except LeNet 500 300 other results are mixed. However, overall I do think that the proposed method is novel, well theoretically grounded and is proved that it works comparably if not better than the state of the art approaches.<BRK>The paper proposes a new method for learning to make neural networks sparse by adopting a beta Bernoulli prior with variational dropout. One motivation for the method is to make the dropout rate dependent on the input, by introducing the input to a layer as a factor in the computation of the Bernoulli parameter for the layer which controls whether some parts of it will get turned off. The motivation for the goal of making neural networks sparse is clear, since it can potentially lead to significant memory and computation savings (although given that hardware architectures typically used for executing neural networks generally expect dense computations, it may be difficult to realize these savings in practice). Furthermore, it s satisfying to see that the underlying method has a strong probabilistic justification. However, while a significant amount of the paper was devoted to the input dependent version, it was unclear from the empirical results whether there is much actual advantage to the additional complexity. Empirical validation of the method with experiments on larger datasets such as ImageNet would lend further credence to the viability of the approach. I think an interesting experiment would be to see how the method performs when computing the expectation on equation 13 through empirical samples; given the savings in FLOPs and memory, we could run the network with several samples even without exceeding the original computation budget. Some other design choices (such as the factorization of q, and equation 17) seem somewhat arbitrary, so I would also prefer to see further justification or a sketch/empirical evidence of why alternative methods may not work as well. For the above reasons, I am rating the paper as weak accept. Small note: please use \citep and \citet (instead of \cite, when using natbib) properly throughout the paper so that citations are formatted correctly.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>In this paper, the authors study the convergence of (stochastic) gradient descent in training deep linear residual networks, where linear transformation at input and output layers are fixed and matrices in other layers are trained.<BRK>This paper studies the convergence properties of GD and SGD on deep linear resnets.<BRK>*Summary* This paper deals with the global convergence of deep linear ResNets.
Accept (Poster). rating score: 8. rating score: 8. rating score: 6. <BRK>This paper gives a nice interpretation why recent works that are based on variational lower bounds of mutual information can demonstrate promising empirical results, where they argue that the success depends on "the inductive biasin both the choice of feature extractor architectures and the parametrization of theemployed MI estimators." Moreover they show some connection to metric learning.<BRK>It would be interesting to see which factor contributes more to the performance: I_NCE being a triplet loss or an inductive bias in the design choice? The paper addresses a question on whether mutual information (MI) based models for representation learning succeed primarily thanks to the MI maximization. The paper conducts a series of experiments that constitute a convincing evidence for a weak connection between the InfoMax principle and these practical successes by showing that maximizing established lower bounds on MI are not predictive of the downstream performance and that contrary to the theory higher capacity instantiations of the critics of MI may result in worse downstream performance of learned representations.<BRK>In this paper, the authors studied the usage of the mutual information maximization principle in representation learning. They argue that the bias in the estimation of lower bound of MI may loosen the connection between InfoMax principle and representation learning. Specifically, they figure out the following phenomenon by experiments. 1.Large MI is not predictive of downstream performance. 3.Encoder architecture can be more important than the specific estimator.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. rating score: 6. <BRK>The proposed memory layer models the memory as a multi head array of keys with a soft clustering mechanism and applies a convolution operator over the heads. Generally, the paper is technically justified. A novel clustering convolution mechanism is proposed  for memory augmentation and graph pooling. However, there are still some rebuttal requests.<BRK>In order to bolster their results the authors may run their approach on a few other datasets in Wu et. al.2018.Minor issues:   Provide error bars for the tables   Sec 4.2 typo : “datastes” Overall this paper is well written and easy to read.<BRK>In light of this clarification, I think the proposed algorithm is novel enough and the jointly training mechanism is also beneficial for the state of the arts results reported in the experiments. Or are they learned from scratch? Based on the authors  reply and other reviews, I have changed my rating to "Weak accept".<BRK>The paper presents "memory layer" to simultaneously do graph representation learning and pooling in a hierarchical way. At this point, the ideas for graph representation are plentiful, but there have not been a coherent story on how and why new architectures should work better than previous ones. * Clear visualization of the results.
Accept (Spotlight). rating score: 8. rating score: 8. rating score: 6. <BRK>This paper presents an unbiased estimator of marginal log likelihood given a latent variable model. The method extends the importance weighted log marginal using the Russian roulette estimator. The marginal log probability estimator is motivated for entropy maximized density estimation and use of REINFORCE (log derivative) gradient for learning a policy with a latent variable. The paper is well organized and provides a contribution for optimizing latent variable models in certain scenarios. Perhaps, if its expectation with respect to q(z;x) is applied, this can be shown from equation (6). 2) How was parameter m set for the experiments?<BRK>This paper proposes an unbiased estimator of $\log p_\theta(x)$. Many unbiased estimators of $p_\theta$ exist, but $\log p_\theta$ is needed in many other settings, some of which are not well served by standard estimators of $p_\theta$. The SUMO estimator is essentially a Russian roulette based extension of IWAE; it is exactly unbiased, but takes a random and unbounded number of samples. This allows marginally better optimization of certain models than IWAE with a much smaller average number of samples, and (more importantly) opens new possibilities such as entropy maximization which are not well served by lower bounds like IWAE. (Your comments about occasional "bounded but very large" gradient estimates are troubling in this respect, depending on what exactly you mean by "bounded".) Given that it is also extremely on topic for ICLR and novel, I m rating the paper as "accept." In fact, SGD can be shown to work with biased gradient estimators, with suboptimality in the results depending on the bias; see e.g.Chen and Luss, http://arxiv.org/abs/1807.11880 .<BRK>The authors consider the unbiased estimation of log marginal likelihood (evidence) after integration of latent variable. On top of the importance weighted autoencoder (IWAE), which is only guaranteed to be asymptotically unbiased, the authors propose to use Russian Roulette estimator (RRE) to compensate the bias caused by the finite summation. The proposed method is interesting and can be applied in many other estimators with similar properties as Eq.(6).Bias compensation using RRE is interesting, but it seems there must be many literatures that took advantage of using RRE to improve estimators. The authors have to be thorough in presenting previous research and explaining the authors’ contribution that is distinguished from those. In general, this paper is well written and dealing with important problem with interesting method. Several analysis for understanding the advantages of using the proposed method is insufficient.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>The paper is well written (apart from the miniscule Figure 3 containing the main result). I recommend acceptance, with caveats: the energy performance is actually not directly calculated, but speculatively estimated, it depends on the computational architecture chosen to implement the respective networks.<BRK>The authors claim, and to a good extent show that, their proposed method is best of both worlds: train the models efficiently with standard encoding / SGD, this is something we know works and scale well, then convert and fine tune with spike backprop to get models that perform well under a shorter integration window, and thus are more efficient at inference time. The paper is well written, clear and easy to understand.<BRK>The first approach of previous work is converting the weights of a trained artificial neural network (ANN) with a given architecture, to the weights and thresholds of a SNN, and the second approach uses a surrogate gradient to train an SNN with backpropagation. 3.Typos: sec7 4th line “neruons”, sec 2.2 “both the credit” (remove “the”) Following the author response I have upgraded my rating.
Accept (Poster). rating score: 8. rating score: 8. rating score: 8. rating score: 3. <BRK>This manuscript proposes a general framework to learn non Euclidean distances from data using neural networks. The authors provide a combination of theoretical and experimental results in support of the use of several neural architectures to learn such distances. In particular, the develop “deep norms” and “wide norms”, based either on a deep or shallow neural network.<BRK>This paper proposes a modeling approach for norm and metric learning that ensures triangle inequalities are satisfied by the very design of the architecture. This architecture is used to model a norm, and in conjunction with an embedding   a metric. The authors also propose a mixture based approach that combines a given set of metrics into a new one using a max mean approach. The results are illustrated on a few mostly synthetic examples including metric nearness for random matrices, value functions for maze MDPs and distances between nodes on a graph (some problems here are sourced from open street map). I found the paper to be very well written.<BRK>This paper shows how to enforce and learn non Euclidean(semi )norms with neural networks. This is a promising direction for the community as partof a larger direction of understanding how to do bettermodeling in domains that naturally have non Euclideangeometries.<BRK>This paper is about learning and utilizing distance metrics in neural nets, particularly focusing on metrics that obey the triangle inequality. The approach given is quite well motivated. After describing the motivations and the differences between the three algorithms, the paper then goes on to show results on a couple of toy tasks (metric nearness, graph distances) and then a more challenging one in learning a UVFA.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>Summary: This paper applies monotonic attention to the multiheaded (self attention) mechanisms used in a Transformer. I think more could be done to distinguish the behavior of the encoder self attention, the encoder decoder attention, and the decoder self attention. The latency reduction losses are novel, however. Overall, I think this is a solid accept, especially with some improvements to the presentation.<BRK>This paper proposes a fully transformer based monotonic attention framework that extends the idea of MILK. Though the idea of monotonic multi head attention sounds interesting, I still have some questions below:About the method:   1. Is that possible that the MMA would have worse latency than MILK since all the attention heads need to agree to write while MILK only has one attention head? The results in fig 2 seem counterintuitive. 2.I suggest the authors do more analysis of the difference between different attention heads to prove the effectiveness of MMA. 3.For the left two figures in fig 4, which one is the baseline, and which one is the proposed model?<BRK>While prior works deal with recurrent models, the authors adopt previous approaches for Transformer. I can not recommend accepting this paper due to the two main reasons. 1) The proposed solution lacks novelty. The current baseline is the recurrent model, but since the main contribution of this work is in how to deal with several heads the proper baselines would be (i) the same, but with single head attention, (ii) the same, but without L_var (summing latency penalty over heads is straightforward). However, these baselines are absent and the improvement is likely to be due to the replacement of RNN with the Transformer   this would be a limited contribution. Other comments on the experiments.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>The proposal is an adapted batch normalization method for path regularization methods used in the optimization of neural networks. In that regard, it is natural to remove these singularities by optimizing along invariant input output paths. Yet, the paper does not motivate this type of regularization for batchnormalized nets. In fact, batch normalization naturally remedies this type of singularity since lengths of weights are trained separately from the direction of weights. Then, the authors motivate their novel batch normalization to gradient exploding (/vanishing) which is a completely different issue. Theorem 3.2 and 4.1 do not seem informative to me. Authors are saying that if some terms in the established bound in Theorem 4.1 is small, then exploding gradient does not occur for their novel method.<BRK>This paper analyzes a reparametrization of the network that migrates from the weight space to the path space. It enables an easier way to understand the batch normalization (BN). Theorem 3.1 itself is interesting and has some value in understanding BN. However, the main contribution of the paper, i.e., the proposal of the P BN, is not motivated enough. This is not verified by theory either. The formulation of the P BN seems to be closely related to ResNet, since it sets aside the identity mapping and only normalizes on the other part. How would you do this P BN in more complicated networks?<BRK>Originality: The paper proposed a new Path BatchNormalization in path space and compared the proposed method with traditional CNN with BN. The experimental part is not convincing. It is not easy to imagine how the re parameterization works on CNNs since the kernel is applied over the entire image ("hidden activations").
Accept (Spotlight). rating score: 6. rating score: 6. rating score: 6. <BRK>This paper studies counterfactual event prediction in physical simulation. There are also rich ablation studies. The writing is clear and easy to follow. Compared with that, the current manuscript has improved a lot.<BRK>Is this a complete piece of work or work in progress? 3) The approach attempts to show that confounder representations are learned as the main evidence that the model can perform counterfactual reasoning. Is the work a novel combination of well known techniques? I can t find any description.<BRK>Original comments:In this paper, the authors proposed a new method to learn physical dynamics based on counterfactual reasoning. The experimental result also shows promise. 2.This paper also provides a nice work that bridges the gap between the counterfactual reasoning and deep learning community.
Reject. rating score: 6. rating score: 6. rating score: 6. <BRK>#######################Rebuttal Response:Thanks for these clarifications and updating the paper. #######################Review: Summary: The paper introduces an iterative learning scheme to perform system identification on partially observable systems. The proposed approach iteratively optimizes the unobserved state and the model parameters. Furthermore, the authors show that existing approaches don t scale to  high  dimensions. The approach is sound and reasonable and the paper is well written but I am uncertain whether this paper fits the scope of ICLR. Furthermore, the experiments can be improved, which is especially important as this paper does not propose a fundamental new approach. It would be really interesting to see this model controlling an actual quadcopter. The initial experiments demonstrating that the approach works and previous methods don t scale to high dimensions are very good and highlight important points. However, the more complex experiments might be not indicative of the performance. Furthermore, it would be interesting to see a non linear state model and a non linear observation model. Does the iterative approach also learn this model? > it is a bit unclear whether the linear model approximates just the noise or the complete model? Could you please clarify this point?<BRK>This paper proposes a novel way to address the well studied system identification problem. To this aim, the authors propose the "System indetification via Iterative Smoothing and Learning" (SISL) algorithm. The gist of the approach is to formulate an ML problem to estimate the system model parameters from a parametric family of models to estimate both the dynamical system evolution (state updates) and the observation process. The exact optimization for this ML problem is not tractable. This work proposes to solve a surrogate point estimate  ML problem. This optimization is solve using an alternate approach (between smoothing and learning). The synthetic setting is also used to motivate the need for methods able to handle large system dimensionality for non linear and partially observable systems. I believe that the paper can be improved in the following ways: 1) There are intermediate steps in the derivation of the maths that could be better explained. Equation 4 is not really derived from Equation 3. Also, I did not understand why the naive approach is not plotted on Figure 3 (a and b) (but it comes back in the appendix).<BRK>This is a strait forward paper that aims to address the lack of scalability of prior methods on system  identification. Below are some pros and cons for this paper:Cons:(+) The proposed method is simple and it could be  quickly adopted by robotics researchers and practitioners(+) The method seems to outperform previous algorithmsPros:( ) The idea of working with deterministic systems is restrictive. While the process noise may appear in some robotics applications to be small  I see no way of how one could reduce the effect of the observation noise. ( ) It would definitely strengthen the paper if the authors could elaborate more on the concepts of controllability, observability and how these concepts relate to their method etc. How does the existing methods handles these properties? How is the performance of the method affected  when the true system is not controllable but it is stabilizable? ( ) There seems to be no assumption on the shape of the trajectories. These are signals that can excite dynamics so that to ensure proper identification.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>* Writing of the paper can probably be polished further for better clarity. Another of my concern is that, if the goal is to make the sparsification decision aware of the network output (e.g., the value of the loss function), a simpler approach would be to enforce L1 regularization over the edges.<BRK>This work proposes iSparse framework, which aims to sparsify a neural network by removing redundant edges. Comment:Although I am not an expert in network pruning or network sparsification, I know that the Lottery Ticket Hypothesis (Frankle & Carbin, 2019) were able to remove at most 80% of the weights of neural networks (both fully connected and ConvNets) and still retain the original performance level.<BRK>This paper proposes a sparsification technique that seeks edges contributing negligible amounts to the performance of a network. How did you determine theta_l for each layer? The major problem of this paper is the experimental section.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. rating score: 6. <BRK>nan<BRK>The proposed meta learning approach to training the model seems to perform well across multiple simple and challenging datasets, and therefore I would recommend accept.<BRK>I m happy to increase my score and recommend acceptance based on the revised paper.<BRK>nan
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>This paper claims that one only needs a reward prediction model to learn a good latent representation for model based reinforcement learning. I think it is crucial to include DeepMDP, as it is the one most likely to perform competitively with the proposed method. The contributions consist only of learning a multi step reward model for planning, and only provide results in two dense reward environments.<BRK>This is in contrast to existing work which generally use a combination of reward prediction and state reconstruction to learn the latent model. The paper is also very well written and easy to follow. The results on images in the appendix seem to show a delta between the true and predicted reward, suggesting that the proposed method does not yet work on images. (2): From what I can see, the proposed method is very similar to the PlaNet algorithm with state reconstruction loss removed. (3): One of the strengths of model based reinforcement learning is the ability to plan to reach unseen goals with a model trained via self supervision or different goals. Does the proposed approach lose some of this, by overfitting to only the task reward?<BRK>Summary:This paper proposes a novel algorithm for planning on specific domains through latent reward prediction. Using these functions, the authors define the objective using the mean squared error between true and multi step prediction of rewards. In this paper, the authors assume deterministic transition and use deterministic function for latent transition. It seems to be the authors want to use MPC, which is a powerful planning algorithm. It seems to be different results from intuition, because the authors emphasize that the strength of the proposed method is efficiency of learning in RL tasks with irrelevant information. Questions and minor comments:  What objective is used to learn the latent model of the state prediction model algorithm?
Accept (Spotlight). rating score: 8. rating score: 8. <BRK>In this paper, the authors present a new adversarial training algorithm and apply it to the fintuning stage large scale language models BERT and RoBERTa.<BRK> 	This paper modifies and extends the recent “free” training strategies in adversarial training for representation learning for natural language. The paper is well written.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. rating score: 6. <BRK>The new proof provides new insights into the universal approximation property. I consider these the main contribution of the paper. Specifically, the authors  provide an upper bound on the required width for the neural network  show that the approximation property still holds even if strong further requirements are imposed on the weights of the first or last layer. It’s a very good paper. The work makes useful contributions that should and will be of interest to many in the field. The paper is generally well written. Some remarks:  Being somewhat long, the “Proof of Theorem 3.1” would be a much better read if the authors prefixed it  with an outline of the strategy that the proof takes.<BRK>This paper studies the representation power of single layer neural networks with continuous non polynomial activation, and specifically, provided a refinement for the universal approximation theorem:1. The writing of the paper is concrete and solid. 3.This analysis and some of the results derived in the proof may be used for other analyses, e.g.representation power of multilayer networks. Some further discussion of the results may be of interest to the readers. Some comment on those results may be beneficial (e.g.https://arxiv.org/abs/1810.04374).<BRK>The new proof provides new insights into the universal approximation property. I consider these the main contribution of the paper. Specifically, the authors  provide an upper bound on the required width for the neural network  show that the approximation property still holds even if strong further requirements are imposed on the weights of the first or last layer. It’s a very good paper. The work makes useful contributions that should and will be of interest to many in the field. The paper is generally well written. Some remarks:  Being somewhat long, the “Proof of Theorem 3.1” would be a much better read if the authors prefixed it  with an outline of the strategy that the proof takes.<BRK>The authors derive the universal approximation property proofs algebraically. They assert that their results are general to other kinds of neural networks and similar learners. They leave the paper with a question regarding limitations on bias weights. I have opted for a weak accept since it seems thorough and the conclusions offer promise for other applications.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>If the motivation of this paper is to remove the representation error of GAN, GAN should be viewed as the main body. The proposed methods are evaluated on two image restoration tasks, including compressive sensing and image super resolution. The effectiveness of the combination is also presented.<BRK>The proposed hybrid model is helpful on compressed sensing experiments on the CelebA dataset; however, it is only marginally better than deep decoder on image super resolution and out of distribution compressed sensing. A smaller version of Figure 1 can be probably moved to the beginning of the paper to illustrate the problem of GAN. But even with the help of Figure 1, it is still unclear what is the fundamental problem for GAN. Figure 5 should be renamed as a Table. Moreover, the motivation is not strong enough.<BRK>This paper presents a method for reducing the representation error generative convolutional neural networks by combining them with untrained deep decoder. The method is evaluated on compressive sensing and super resolution, where a better performance than the isolated use of Deep Decoders and GAN priors. The main contribution of the paper is not the performance, but the simplicity of this approach.
Reject. rating score: 3. rating score: 3. rating score: 8. <BRK>From an experimental point of view, the baselines considered are very weak. Overall, the conceptual and experimental contributions of the paper are rather weak and I thus recommend rejection.<BRK>7   What is an “advanced” DNN? This should be clearly surfaced in the introduction and presentation of contributions if DPAR is required for the proposed generalized min max formulation to improve robustness.<BRK>The problem is important and interesting. The proposed framework has solid theory and is well conceived. Overall I feel it is a well written paper with sufficient contributions and is of interest to a range of ICLR audience.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>This paper considers the autoencoder model combining the usual information bottleneck and the Gaussian mixture model (GMM). While the framework and the performance of the proposed method are interesting and promising, some of its main parts are unclearly explained. (16) and (17): The distribution q(x_i|u_i,m) is undefined. I wonder why Q_\phi(x|u) in Eq.(11) doesn’t have to be a distribution.<BRK>The idea of using a latent mixture of Gaussian s to variationally encode high dimensional data is not new. These methods are respectively implemented in the TensorFlow and PyTorch APIs. This paper however uses the arg max of equation 19.<BRK>This paper purposes to cluster data in an unsupervised manner that estimates the distribution with GMM in latent space instead of original data space. The whole pipeline is clear and makes sense.
Reject. rating score: 1. rating score: 6. rating score: 6. <BRK>This paper presents a grammar based generation approach for "slot filling" style code generation tasks. The idea of formalizing code completion as structured language modeling and extending Alon et al., 2019a for the task is natural and well executed, with strong models and significantly improved results on two code completion benchmarks for both Java and C#. Detailed Review:*Technical Contribution* I have a very mixed feeling with this paper, while the model registers high empirical performance, the technical contribution is a bit limited, as detailed below:      *Path based Context Encoding* The most important contribution in this submission is the application of path based AST encoding model of Alon et al., 2019a to encode context (the given contextual and partially generated ASTs) for code generation. *Node based Tree Generation Model* Apart from the path based context encoding model, the node based generation model presented in Section 2 also seems interesting. How to Improve: to better understand the different technical contributions outlined above and their relative impacts, the following ablation studies would be helpful:          Importance of Path based Context Encoding: the Seq→Path ablation in Table 3 alone might not be adequate to demonstrate the importance of path based encoding of AST contexts for code generation tasks. The authors should compare with the GNN based context encoding approach in Brockschmidt et al.(2019a) as this is the most relevant work. However, there are indeed code generation systems (some of them cited in this paper) that synthesize open domain code snippets in general porpuse programming languages without restriction on vocabulary or grammar. How to improve: the authors might present more evidence to substantiate the their claim on the novelty of the AnyGen benchmark compared with existing open domain, general purpose code synthesis benchmarks, or consider revising the claim and the title. 2019<BRK>The paper proposes a model to address the Any Code Generation (AnyGen) task, which basically to fill missing code from a given program. The model makes use of partial Abstract Syntax Tree (AST) as input. The conducted experiments show that using AST paths from root and leaves are good for AST node generation, but whether those inputs are robust and sufficient should be further explored. There are some restrictions to the method, for example,  the input is only a single function, and the missing expression is not that complex. Nevertheless this work presents a novel method towards code generation. The paper also introduces a new metric to evaluate the prediction accuracy for generated expressions. 2.In the Restrict Code Generation test, it seems that the author filters out non primitive types and user defined functions. Therefore, does the experiment on Java small dataset fully show the proposed model’s strength?<BRK>This paper proposes a generative task for programming code where an expression from the program is generated given the rest of the program (minus the expression). Again, this is similar to the prediction of words in language models. The method takes into account the AST corresponding to the program. The results for the Java dataset improve state of the art by 1 2%, while the results for the restricted C# dataset show a much more significant improvement (in the order of 10 15% improvement, depending on the metric). I would have liked to see a qualitative analysis of the results. In other words, when the prediction looking at the tree structure is correct and the overall prediction is not, what goes wrong? The elimination of the methods with more than 20 lines of code seems ad hoc to me and biases the evaluation with relatively short methods (how many methods were eliminated this way?). One thing that I struggle with is understanding how useful the proposed task is and how it can be generalized/used in practice for some relevant higher level task in AI4code.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>The very idea of a flow based model for graphs using the message passing algorithm may be considered as a contribution, but this is also blurred because of the concurrent work GNF.<BRK>What is the motivation of using the dual of the graph?<BRK>Experimental results show that the proposed model is superior to recent models in image puzzling and layout generation datasets.
Reject. rating score: 1. rating score: 1. rating score: 1. <BRK>This paper try to use CNN to build recognizer for handwritten Amharic characters. The CNN they used is simple and standard. Apparently this paper no novelty at all. They just apply CNN to a new task. This kind of work is not qualified for ICLR at all. There are also some problems in paper organization. They should split the introduction part into several paragraphs to improve reading experience. And it seems that they forget to add reference part. Given the quality of the writing and content, I decide to reject this paper.<BRK>The formatting of the paper needs work, and the work is not substantially novel. For some reason, many sections of the paper were ill formatted, perhaps due to using an insufficiently portable submission format. Characters with arguably the same level of complexity, such as Chinese characters, have been thoroughly explored. The application of existing technology to a different script does not, by itself, compel me to feel that this is an ICLR worthy paper. That being said, I think it is quite notable the effort that went into creating the data set for Amharic character recognition. I would encourage the authors to distribute this data set so that others may join in the research efforts.<BRK>The authors collect a dataset of handwritten Amharic characters and apply a CNN model for character recognition. The dataset is novel and would be of interest to the character recognition community, and I would encourage the authors to present it in its own right along with technical details about its collection. 7.Are the images in Figure 3 from your dataset? To the best of my understanding, there is no held out test set, and so we cannot know the performance of the model on unseen data. Please show some examples from the new dataset you have collected! It appears that validation accuracy was taken into account when selecting hyperparameters, and so, validation accuracy also does not represent the model s performance on unseen data. I would recommend that the authors introduce a test set into their dataset split, or designate the validation part of the dataset as a test part use cross validation for hyperparameter tuning. It is challenging to compare to prior work since, according to the authors, prior work on Amharic character recognition has been focused on printed text. While Figure 3 shows that different characters can be written similarly, it would be great to provide a quantitative measure of this phenomenon. 2.It would be great to know more about how many individuals were selected (and the choices made about their demographics) for writing the example characters, and whether there were any interesting variations observed in the dataset based on attributes highlighted in the paper (e.g.age range)3. 4.In the text, features such as a mark of palatalization are noted.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>This paper provides a method for lossless compression of text. It s heavily inspired by the language modelling methods that have been developed for the purposes of predicting the next character/word in a sentence, and it uses this idea as its backbone. The only difference is that the results are presented in the compression setting. there s no comparison even with BERT (how well it do to predict the next character vs. this)...  no runtime numbers  no reproducibility discussion (i.e., how can I guarantee that my decoder can get exactly the same numbers as my encoder so that I can decompress on a different machine)  no discussion about whether files were created/decompressed (this is ABSOLUTELY CRUCIAL for compression papers to discuss)Overall, I am not excited about this paper, and unless the authors put a lot more into it, there s just not enough novelty to justify a publication at ICLR.<BRK>In my view, the experiments described in the paper resemble a hyper parameter search more than architectural improvements. In particular the authors have done a great job reviewing existing compression literature and positioning their method within the space of prior work. The paper does not answer the question of whether or not this is true. Furthermore, similar to autoregressive models, transformers are known to be slow at inference time. For reasons mentioned above, the paper should include additional experimental evaluation. In particular, it should consider the effect of training the model on one dataset, but evaluating it on another dataset; and discuss how differences in performance (if any) compare to standard methods. 4.Description of the “training with revisits” is not very clear. My understanding is that it resembles a pass through the data, where some of it is considered again at specific intervals.<BRK>This paper explores the effectiveness of the Transformer architecture to the lossless data compression problem. The authors conduct their experiments on the enwik8 benchmark. My main concern of this paper is that the proposed method was only evaluated on a single benchmark data. Minor comment:In Section 4.2, there is a missing citation. ... we do not use Adaptive Inputs (Baevski & Auli, 2018; ?) ...Please check and fix it.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>The paper presents a graph neural network model inspired by the consciousness prior of Bengio (2017) and implements it by means of two GNN models: the inattentive and the attentive GNN, respectively IGNN and AGNN.<BRK>The authors propose to use sampling methods in order to apply graph neural networks to large scale knowledge graphs for semantic reasoning. To this end induced subgraphs are constructed in a data dependent way using an attention mechanism. Overall, I think that the proposed GNN architecture is an original and interesting approach for this specific application. I am missing a discussion of the limitations of the proposed approach.<BRK>The proposed way to reduce the complexity by restricting the attention horizon sounds interesting and seems necessary for scaling up. # Originality  The idea of learning an input dependent subgraph using GNN seems new.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>In this paper the authors propose a metric based model for few shot learning. The goal of the proposed technique is to incorporate a prior that highlight better the dissimilarity between closely related class prototype. Thus, the proposed paper is related to prototypical neural network (use of prototype to represent a class) but differ from it by using inner product scoring  as a similarity measure instead of the use of euclidean distance. There is also close similarity between the proposed method and matching network overall, the paper does not  highlight the novelty of their proposed method especially prototypical network and matching network.<BRK>The authors propose a new neural network model, called as Dissimilarity Network, to improve the few shot learning accuracy. However, the paper is not quite well written. Also, the terms, “score”, “metric”, “dissimilarity” are mentioned in the paper but the paper is not really learning the metric, to my understanding. Thus the details of the paper is quite hard to grasp. Lastly, the idea of designing the global embedding and the task aware embedding is interesting but shouldn’t really be restricted to few shot learning. It would be interesting to test the idea on general classification tasks, for example in a simple cross validation settings. The current writing refers to that the authors comprises a completely new dataset with new labels. 4)	In Section 2.2, it would be nice to add the mathematical definition of “prototype”. Also it would be nice to add more details about the attention mechanism. 7)	In the result section, it would be nice to discuss when the proposed method is doing better than other methods, for example RelationNet, as well as when it’s worse since different datasets show different results.<BRK>The stated contributions of the paper are: (1) a method for performing few shot learning and (2) an approach for building harder few shot learning datasets from existing datasets. The authors describe a model for creating a task aware embedding for different novel sets (for different image classification settings) using a nonlinear self attention like mechanism applied to the centroid of the global embeddings for each class. The resulting embeddings are used per class with an additional attention layer applied on the embeddings from the other classes to identify closely related classes and consider the part of the embedding orthogonal to the attention weighted average of these closely related classes. They compare the accuracy of their model vs others in the 1 shot and 5 shot setting on various datasets, including a derived dataset from CIFAR which they call Hierarchical CIFAR.
Reject. rating score: 6. rating score: 6. rating score: 6. <BRK>I m still not completely convinced that the multi layer analysis well explains the reality, but because of the other contributions I am updating my score, which would be a 5/10 on the old ICLR scale. This paper investigates the placement of Layer Normalization in the transformer architecture. The authors show that the Pre LN placement leads to better behaved gradients as the network gets larger. This in turn allows them to remove the warmup stage of the learning rate schedule, leading to a faster and simpler training procedure. Even though the novelty here is limited, Pre LN placement has been used in prior work, the potential for accelerating future research is large. Still, I have some concerns about the relation between the analytic investigation of the gradient norms and the empirical results that are presented, and I am concerned that the analytical results are used to imply something stronger than they actually show. At some level, it seems like the theoretical results have come along for the ride but do not clearly demonstrate that there is a problem with Post LN and that this problem is fixed by switching to Pre LN, or at least the relationship is not clearly explained.<BRK>Summary: The paper investigates the myth about layer normalization and learning rate warmup for the Transformer architecture. It shows, both theoretically and empirically, that putting the layer normalization in the residual blocks rather than between the residual blocks, could make a big difference to the scale of the gradient at the initialization stage. Pros:  + A well written paper with a good organization; notations are clear. + Good experimental design that compares the pre LN and post LN Transformers in different settings/tasks. One of the two major concerns I have is the novelty of this paper in terms of its methodology and empirical value to the community. The Pre LN setting of Transformers has already been widely used. 2.The second major concern I have is the connection the authors established between its theoretical findings and the empirical findings. But even when the gradient clipping is applied, learning rate warm up still seems very helpful (and sometimes necessary), as was used in all of these works. Therefore, I think to further verify the theoretical hypotheses of the paper, the authors should at least also study whether (and to what degree) the very simple "gradient clipping" (or other gradient normalization techniques) solves the problem (which is a common solution to exploding gradients). What do you expect to be the relationship between "the number of warmup steps" and solving the "gradient scale problem", which you proved on these assumptions?<BRK>1.Specific problem tackled by the paper:Moving the LayerNorm layer to be inside the residual connection in a stack of transformers can remove the need for learning rate warm up. This paper provides a theoretical motivation for doing this. [d] In Figure 3(b) the gradients are clearly decreasing with the number of layers, are there any comments on this? Their experiments provide good context for the problem they are solving and acts as a solid reference point for their (and other peoples  future) work. If so, this should be made very clear. 3.Claims of the paper:The authors claim that layer norm should be placed inside the residual connection (Pre LN) rather than outside (Post LN) it. i.e.During training a Post LN transformer is likely to have weaker gradients in the lower (closer to input layers) than at the output layers. Figure 1 could also be enhanced by labelling Post LN as previous work and Pre LN as current work. The authors show machine translation results, demonstrating that using Pre LN rather than Post LN leads to faster convergence, however the models converge to the same result. It would be worth connecting these. (2) The paper is well organised and the problem is very well motivated. Cons:(1) This work is incremental. (2) While the organisation of the paper is good, the paper is not well written.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>The technical novelty lies in thenormalization of the feature weights across local explanations wherethe proposed scheme utilizes a well motivated L0 normalization inplace of the existing L2 normalization in Ribeiro et al., 2016. However, I can  imagine that the high level idea of sparse aggregation of local  explanations can easily generalize to many local explanation  schemes. Moreover, the evaluation is  completely limited to a single data set (which is good as a strawman  but not sufficient to make significant claims). Generating class level interpretations is an  interesting idea but its novelty is somewhat unclear. In terms of explanations, there are contrastive explanations [1]  which are not really discussed in this paper. It is not clear why in the SmoothGrad and VarGrad baselines, the  class level interpretations are generated with just 10 images per  class. Are the class level interpretations of LIME and NormLIME also  generated from just 10 images per class. If LIME and NormLIME used more than 10 images to  generate class level interpretations, the comparison does not seem  fair. For the evaluation in Sec.5, it is not clear how the features are  removed. Are they removed based on the global explanations (feature  importances) of each baseline? Moreover, it seems natural that something like  SmoothGrad and VarGrad would be able to capture the feature  redundancies if the redundancies were the actual cause for this  marked difference between the relative performances in Fig.4(a) and  4(b).<BRK>Months ago, I read this article on arxiv (https://arxiv.org/pdf/1909.04200.pdf). It is an interesting work that tries to propose a simple yet effective interpretable model. I am not familiar with this research direction, and I try to make an educated guess. Pros:  As the author suggested, the method is simple and effective. The authors conducted user studies to demonstrate that the results generated by their proposed method is strongly favored over previous methods. Cons:  Subscripts in equations need improvement to make them consistent. Section 4, Figure 3, top, it seems obvious to choose the fourth one to distinguish the number 9?<BRK>This paper proposes a new method for DNN interpretability based on LIME, itself based on ensembling of large numbers of low complexity models called "local explanation models". This method allows to better capture the relative importance of each feature, and is also able to recover the class specific signals that DNNs use to distinguish between a number of classes. Score: Weak AcceptWhile this method seems like a good step forward, I am uncertain about its significance, mostly because of the choice of dataset and because it appears to be a minor change to a well known algorithm. Why should we expect this method to work beyond MNIST? Will it work on non image data? Do the authors have a stronger intuition than what is hinted at in the paper? Other comments:  The human evaluation is very interesting, and suggests that this method correlates much better with human judgement than previous ones. It could be from the proposed change or from the class specific information.
Reject. rating score: 3. rating score: 3. rating score: 3. rating score: 6. <BRK>This paper studied how to leverage the power of graph neural networks for counting subgraph isomorphism. The GNN and sequence modeling methods are discussed for solving this problem. The experimental results confirmed the effectiveness of these methods. More practical use case would be search for the matched subgraphs given the sub graph query using subgraph isomorphism detection. Without comparing these existing fast (approximation) methods, it is really unfair to compare with only non DL baseline VF2, which seems served as ground truth as well.<BRK>The evaluation is only for synthetic dataset for which generating process is designed by the authors. If possible, evaluation on benchmark graph datasets would be convincing though creating the ground truth might be difficult for larger graphs.<BRK>This paper proposes a method called Dynamic Intermedium Attention Memory Network (DIAMNet) to learn the subgraph isomorphism counting for a given pattern graph P and target graph G. This requires global information unlike usual GNN cases such as node classification, link prediction, community detection.<BRK>This paper proposes a dynamic inter medium attention memory network and model the sub graph isomorphism counting problem as a learning problem with both polynomial training and prediction time complexities. One of the main advantages of this paper is that the proposed method can efficiently deal with large graph tasks, so the model behaviors of different models in large dataset similar to Figure 5 is encouraged to be given.
Accept (Spotlight). rating score: 8. rating score: 8. rating score: 6. rating score: 1. <BRK>This paper seeks to separate "causal" features from ones with spurious correlations in the context of natural language machine learning tasks. Furthermore, training an SVM on the original results in irrelevant attributes (such as movie genre) being weighted, whereas these weights are largely removed when training on the union of the datasets. Overall, I think this paper should be accepted because it makes several interesting contributions: It proposes an interesting approach, shows intriguing experimental results, and produces an interesting dataset (size ~2k) that may be useful for future testing. The main limitation of the paper is that the evidence is largely circumstantial. My suggestion for a further experiment would be to apply the movie review classifiers to, say, book reviews   something where the task is fundamentally the same but the context is different.<BRK>Summary:       The authors take two tasks,sentiment analysis and natural language inference, and identify datasets for them which they counterfactually augment it by asking people over the Amazon Mechanical Turk Platform to change either the sentiment (in the case of sentiment analysis) or the nature of relationship in the NLI task by making minimal changes to the text that produce the targeted changes. Authors find that popular models trained on either fail on the other dataset while the models trained on both actually generalize much better. This is because the original sample and its counterfactual pair the label changed , has the difference in the text that matters to the change and this pair could reduce spurious correlations that models might find in the data distribution. The one part (I dont have much NLP background but I do have a causality background) that I like most is that the new text generated are counterfactual in some real sense with respect to a real world generating process   that is people modifying text with changed targets. A lot of existing work that claim to do counterfactual changes do not specify assumptions about the generating mechanism. Cons:      I think the authors want to make an explicit connection to counterfactuals as understood in the causality community.<BRK>This paper addresses the problem of building models for NLP tasks that are robust against spurious correlations in the data by introducing a human in the loop method: annotators are asked to modify data points minimally in order to change the label. The authors apply this method to the IMDB sentiment dataset and to SNLI and show (among other things) that many models cannot generalize from the original dataset to the counterfactually augmented one. This contribution is timely and addresses a very important problem that needs to be addressed in order to build more robust NLP systems. My main hesitation comes from a lack of clarity about the main lesson we have learned. A few small comments:* There was some analysis of the augmented IMDB dataset, but none of the SNLI dataset. * Table 3: I would make two columns for each model with accuracy on original versus revised.<BRK>The authors propose a new way to augment textual datasets for the task of sentiment analysis, in order to help the learning methods to generalize better by concentrating on learning the different that makes a difference. The main idea of the paper is to augment existing datasets with minimally counteractual versions of them, that change the sentiment of the documents. In this way, all spurious factors will naturally cancel out. The authors use the newly created datasets and show that indeed, the retrained algorithms on the augmented datasets generalize much better. Overall, I find the idea of the paper quite interesting and I’m excited to use the datasets they have created. However, I think the relative novelty of the paper does not meet ICLR standards, and it’s better suited as a whitepaper attached to an open dataset release.
Accept (Poster). rating score: 6. rating score: 6. <BRK>## OverviewThe paper tackles the identifiability problem in generative modeling, i.e., recovering the true latent representations from which the observed data originates. The paper argues that identifiable variational autoencoder (iVAE) suffers from intractability issue which leads to suboptimal solutions. The paper instead proposes an identifiable normalizing flows (iFlow) method as an alternative. The paper is very well motivated and well supports its claim. The paper proposes iFlow, an identifiable normalizing flow method which allows recovery of true latent space from observed data. 3.The paper provides theoretical justification on the identifiability of the proposed iFlow method. Can you also report the hyper parameters used for iVAE?<BRK>This paper is about learning an identifiable generative model, iFlow, that builds upon a recent result on nonlinear ICA. The key idea is providing side information to identify the latent representation, i.e., essentially a prior conditioned on extra information such as labels and restricting the mapping to flows for being able to compute the likelihood. As the loglikelihood of a flow model is readily available, a direct approach can be used for learning that optimizes both the prior and the observation model.
Reject. rating score: 3. rating score: 6. rating score: 6. rating score: 6. <BRK>This paper presents a method for learning latent variable models of paired data that decomposes the latent representation into common and local representations. The approach is motivated by Wyner’s common information, and is made tractable through a variational formulation. While I found the formulation and motivation from Wyner’s common information and Cuff’s channel synthesis interesting, the resulting model and experiments were unconvincing. There are many terms in the Wyner model proposed, and there are no ablations demonstrating which terms are important and which are not (e.g.do you need both L_xx and L_xy?). The main win appears to be for style content disentanglement, but the results there are qualitative and often change the content when only style is changed. Prior work could likely also do “style control” by e.g.interpolating subsets of dimensions. What’s the discrepancy with Fig 5 where conditional NLL is highly dependent on \lambda for MNIST?<BRK>This paper presents a variational auto encoder approach for paired data variables, with a separate notion of common and individual randomness. Besides, KL divergence based constraints are proposed to encourage consistency of different modeling components. The authors did a great job in the literature review and experimental comparison. The comparison to the information bottleneck is also interesting. • The Alice Bob example is helpful to understand the main purpose of this paper 	• The authors introduced the theoretical background of Wyner s common information   the two contexts it arises. It would be nice to have more justifications on the choice in the context of VAE learning (optimality?), as opposed to other seemingly more natural choices.<BRK>The paper proposed a variational autoencoder for a pair of correlated observation variables, motivated by Wyner s common information. Overall, the paper is technically sound and well supported by theory and experiments. I wonder whether the authors can provide some general guidelines on how to choose this important parameter in practice, as the results seem to be highly dependent on the choice. How would the proposed VAE model be applied when the two correlated variables are not explicitly observed or defined?<BRK>The overall objective is motivated by Wyner s mutual information minimization. Using a few common techniques to bound KL divergence, the paper arrives at a few terms that are reminiscent to the variational lower bounds, including terms that constraints the hidden variable to be similar to the prior, and two cross modal reconstruction terms. The paper includes a comparison between similar models, both in terms of formulation and experiments. The formulation and the lower bound for learning are the strengths of the paper. The lack of discussion on some of the common problems for VAEs and the experiments are the weakness of the paper. However, after the derivation, the framework falls back to common VAEs, and is not very different from VCCA private. The paper should state this clearly when comparing the two. In terms of the common problems for VAEs, the paper does not address a few degenerate cases. Finally, as with most VAE models, the paper does not discuss how well lower bounds approximates the likelihood and the resulting learned representation when the gap between the likelihood and the objective is large. The experiments in the paper are somewhat lacking. Figure 7 is where the capability of the model is fully demonstrated: a clear distinction between the shared and the private views are shown.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>Moreover, when it is combined with some fast  training methods, such as cyclic learning rate scheduling and mixed precision, the adversarial training time can be significantly decreased. The experiment verifies the authors  claim convincingly. Overall, the paper provides a novel finding that could significantly change the adversarial training strategy. The paper is clearly written and easy to follow. I recommend the acceptance.<BRK>Coupled together with tricks for accelerating natural training, such as cyclic learning rate, mixed precision, the robust models can be trained faster than previous methods. +The experimental results are impressive. + The method is simple, and I guess reproducible. +The paper shows surprising facts of a well known method. +The paper is generally well written and easy to follow. I do have some concerns of the work  The paper is empirical and the techniques are combinations of previous methods. I would like the authors to clarify their method to resolve such conflicts and make it clear how R FGSM can be as robust as PGD as in table 1. (2) The authors work hard to address the comments. (1) As pointed out in public discussion, the success of the proposed RFGSM relies on early stopping.<BRK>The main claim of this paper is that a simple strategy of randomization plus fast gradient sign method (FGSM) adversarial training yields robust neural networks. This is somewhat surprising because previous works indicate that FGSM is not a powerful attack compared to iterative versions of it like projected gradient descent (PGD), and it has not been shown before that models trained on FGSM can defend against PGD attacks. Judging from the results in the paper alone, there are some issues with the experiment results that could be due to bugs or other unexplained experiment settings. Suppose I want to use the method to defend against an adversary with power epsilon 14/255, then it is conceivable that I would use a slightly larger step size, say 16/255, as suggested by the authors. After rebuttal: The authors  new experiments and response answers most of my concerns.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>5.Since the used benchmark datasets are already reasonably explored, authors are advised to include evaluation on other datasets as well, e.g., from [6]. For example, this is the reason [3] does evaluate its model on a larger training split instead of a smaller one. Therefore, I am still more inclined to rejecting the paper.<BRK>Maybe the time complexity is the major contribution of this paper.<BRK>Isn’t this leading to overfitting? Experiments are nicely executed and the proposed approach is compared against a rich array of other models.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>This paper considers how we can train image classification models so that they can ignore task irrelevant features. The authors then proposed using Actdiff loss, Reconstruction loss, and Gradmask loss that are designed to suppress the effect of irrelevant features. I think the problem considered in this paper is interesting and important. Thus, we need a way to train image classifiers that can ignore such irrelevant features. My major concern on this study is the experiments. * (Sec4) "Gradmask proves to be too powerful a regularizer for this task, and never produces a model with good generalization performance." * (Sec5) "The gradmask and combination actdiff and gradmask models improved over baseline, but there is no clear reason why this would be true from the saliency maps." However, the effectiveness of the proposed approach is not convincing enough. It would be great if the authors can clarify and demonstrate which regularization is helpful under which circumstances and why, and when it is not.<BRK>This paper attempts to tackle the overfitting problem due to the focusing on the distracting information. Cons:1.The presentation of this paper is not clear. The authors mention that “Conv AE Actdiff” is the one using both actdiff loss and reconstruction loss. Does Conv AE means they implicitly contain reconstruction loss? The authors should elaborate them clearly. The corresponding double quotation marks should be revised. However, this is not the case. 2.In fact, the training data with masking is not sufficient (may only available in some medical images). 3.From the experiments on real tasks, I barely see improvements by the proposed method, which makes the conclusion unconvincing.<BRK>This is a necessary control to be sure that any benefits from masking are due to domain transfer and not other regularization effects. * Does the paper present experiments that promote deeper understanding of why the approach failed? Therefore, I think there s no way for some of the baselines (plain classifier, autoencoder) to generalize correctly. Many alterantive approaches were considered and their performance reported. Experiments follow a logical progression, starting by verifying the idea on a synthetic dataset, then moving to real data, and then evaluating on a half synthetic dataset designed to debug the approach. This presentation is a bit confusing since reconstruction loss was presented as another loss and it shows up in the tables implicitly based on the architecture being compared. The paper embraces its negative result. Why should the particular masks chosen for the experiments have this property? In this case there may be lots of competing losses, so it s important to tune the weights somehow to ensure the tradeoff between losses is optimal. The results (and the conclusions) suggest Actdiff is not very effective at increasing generalization.
Reject. rating score: 1. rating score: 3. rating score: 8. <BRK>This paper introduces the idea of wildly unsupervised domain adaptation, where the source labels are noisy and the target data is unsupervised. To tackle this, the authors propose an architecture based one two branches: one acting on the mixed source target data and the other on the target data only. Originality:  In essence, the proposed method combines co teaching (Han et al., 2018) and pseudo labeling (Saito et al., 2017). The main novelty consists of using two branches to model the two domains. 2 are not explained anywhere. For example, based on the results in Table 1, one might rather want to use TCL as the second stage, i.e., have a baseline Co+TCL. Summary:The novelty of the proposed method, relying on a combination of co teaching and pseudo labeling, is limited. Furthermore, the clarity of the paper could be significantly improved.<BRK>This paper presents a method for unsupervised domain adaptation. The problem is well known in literature and follows the setting of labeled source and unlabeled target set. This work proposes the “butterfly network” suitable to train on noisy data (labels) and assign pseudo labels to the target set. The introduced losses should be better justified. Anyway, as I said the paper has some merit, it provides many insights and extensive analysis on “butterfly” method for unsupervised domain adaptation. The experimental section is extensive and demonstrates improvement in performance using this method compared to state of the art, even though for some "real world" datasets (e.g.SUN, Caltech, ImageNet) the improvement is not so significant as in the case of MNIST SYND. Could the authors provide results on MNIST SVHN to help compare with other papers in literature? This not because I think the method is complex but because some key components that I pointed out previously about the method are not clear and I strogly believe these are key components to replicate the results.<BRK>This paper proposes a new problem setting in the domain adaptation field. However, in wildly unsupervised domain adaptation (WUDA), we do not need a perfectly clean source data, which means that WUDA problem is a more general and realistic problem than existing ones. They tested the proposed method on simulated and real world WUDA tasks (35 tasks in total), and the accuracy of proposed method is higher than those of representative UDA methods. Since WUDA, as a new problem, could lead a new research direction in the domain adaptation field, this paper should be presented in ICLR 2020. Detailed comments can be seen below. Pros:+ WUDA, as a new problem, is very important for the domain adaptation field. + Butterfly, as a solution to WUDA, outperforms representative UDA methods on simulated and real world WUDA tasks. + Following Ben David s paper, this paper also presents an upper bound of the target domain risk. The authors should explain this in the caption of Figure 3. When T   1, you directly use source data as the pseudo labeled target data since there are no pseudo labeled target data in the first step (based on Algorithm 1).
Accept (Poster). rating score: 6. rating score: 6. rating score: 1. <BRK>** SummaryThe paper studies the problem of program synthesis from examples and it proposes the notion of property signature as a set of "features" describing the program that can be used to simplify the synthesis by combining together sub programs with similar features. The use of properties to summarize some features about the program and the possibility to evaluate them directly from samples seems a very interesting idea. As the authors mentioned, this may help in creating useful features and useful architectures to simplify the learning task. The authors also provide an extensive comparison to related work. The downsides of the paper are:  While it is clear how to build property signatures, it is quite unclear to me how they simplify the generation of programs that combine smaller/simpler programs.<BRK>The paper does not give enough evidence to ascertain the value of either contribution. There are now a large number of program synthesis works using ML, and a huge literature on program synthesis without ML. While many of ML works use a DSL as the testbed, surely the authors  feature selection method can be applied in some of these DSLs, allowing comparisons with current art? On the other hand, many of the ML methods don t require the DSL used in the works that introduce them. Can searcho + your set of training and test programs distinguish between these methods, and establish a benchmark? I think this paper could be valuable if it could demonstrate either in what ways the new feature selection algorithm is  an improvement over prior ML methods, or that searcho is valuable as a benchmark or for approaching interesting applications. ######################################################################################edit after author response:  raising to 6, I think the deepcoder experiments are useful in contextualizing the contribution of the authors  feature selection method.<BRK>The property signatures are essentially some key attributes that one may summarize from a given set of input output pairs, which the target function has. Much discussions have been given to discuss why and how these properties may be useful and very little real experiments are conducted quantitatively compared with existing works. Although this paper is quite interesting, I think this paper is in its very early stage and there are a lot of serious concerns I have for using this approach to synthesize the real complex programs. 1) First of all, the notion of property signatures are easy to understand and is very natural. However, this is also the hard part of this idea. Potentially it could have an exponential number of possible properties as the program goes more complex and complex. 3) There are very little baselines to compare against even though authors listed "substantial prior work on program synthesis". I understand the existing works may have their limitation in both what they can do and how well they can do. Otherwise, it is hard to be convincing that this approach is indeed superior compared to existing ones.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>This paper proposes a reranking architecture with a LogicForm to NaturalLanguage preprocessing step for semantic parsing. The authors experiment their method on three datasets and get the state of the art results. Why do the authors use the Quora dataset in particular? 2.The error analysis might be better to be a bit more quantitative. Other designs include beam size, whether or not to use a pretrained model, etc. These are not weakness, but I think some work in this direction may help improve the paper.<BRK>This paper proposes a framework for semantic parsing, which includes a neural generator that synthesizes the logical forms from natural language utterances, and a neural reranker that re ranks the top predictions generated by beam search decoding using the neural generator. In their evaluation, they indeed show that this transformation helps improve the performance of the reranker. First, although they already evaluate on 3 datasets, all of them are not among the most challenging benchmarks in semantic parsing. It will be helpful if the authors can at least provide results with a smaller beam size, and would be better if they can provide results that are directly comparable to [1]. However, I don t think my concerns are addressed; e.g., without a comparison with previous re ranking methods, it is hard to justify their proposed approach, given that other re ranking methods are also able to improve over an existing well performed generator.<BRK>In this paper, a method for re ranking beam search results for semantic parsing is introduced and experimentally evaluated. In general, the paper is well written. I would suggest to reduce the size of the introduction and dedicate this space to more detailed explanation how reranking works and the experimental details. The error analysis part is great, but not very methodical. Typos:  [CLS] is not defined in text  Shaw et al.should be in Previous methods in Table 3
Reject. rating score: 3. rating score: 3. <BRK>The paper is well written and the experiments are very comprehensive. Even though the authors site this work, they don t discuss the connection very clearly. These two loss behave very differently. Therefore, it is not surprising that there is high correlation between the output variance and the cross entropy loss but it is not clear if this has anything to do with the test error. I increase my score to "weak reject" but not higher because of my concern about the novelty of the work in light of Novak et al.2018.<BRK>This paper examines generalization performance of various neural network architectures in terms of a sensitivity metric that approximates how the error responds to perturbations of the input. A number of experimental results are presented that show strong correlation between the sensitivity metric and the empirical test loss. All told, if taken in isolation from prior work, I think the insights and empirical results presented in this paper are quite interesting and certainly sufficient for acceptance to ICLR. [1] Novak, Roman, et al."Sensitivity and generalization in neural networks: an empirical study."
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>Edit:Thank you for your response and your comments. Overall, the paper is clearly written and easy to read.<BRK>It is also unclear from the writing how this assumption is enforced.<BRK>This is an extremely well studied problem, and many important references are missing in the discussion of related work [1]. "Learning visual feature descriptors for dynamic lighting conditions."
Reject. rating score: 1. rating score: 6. rating score: 6. <BRK>The authors explore different ways to generate questions about the current state of a “Battleship” game. While the problem of question generation is quite interesting, this work is limited in several ways.<BRK>I feel that this justification needs expanding. The length of the submission is 9 pages in content. That said, I think there is still a lot to commend in this work: the setting is an interesting one for question generation, the motivation for using programs is well made, and the work appears technically sound. Some more minor comments I wonder about the log likelihood numbers on the synthetic questions.<BRK>Also, it is not clear to me how the setup evaluated in this paper can be extended to a setting that allows an agent to iteratively ask questions. The problem is not entirely novel as [1 3] have explored asking questions with neural networks learning to generate programmatic questions. Figure 1 illustrates the Battleship task and Figure 2 presents a clear overview of the proposed framework.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>The paper proposes a method for combining continuous Q learning and linear MPC. They propose learning a continuous control policy for long term behavior trained with standard model free reinforcement learning and a short term linear control model implemented as a linear dynamical system. At test time a combined controller can be used to infer actions by solving small optimization problem. The paper is well written and mostly clear. * the algorithm seems to be be setup to with the dynamics model being learnt on the transitions coming from an epsilon greedy with respect to the optimal policy. * There would be some benefit in trying the model in some other domain maybe reacher with some constraints ?<BRK>This paper proposes a Locally Linear Q Learning (LLQL) method for continuous action control. It uses a short term prediction model and a long term prediction model to generate actions that achieve short term and long term goals simultaneously. The proposed method is more like hybrid of model based and model free RL method. Second, the proposed method is not sufficiently evaluated. In order to justify the performance of an RL algorithm for continuous action space, it should be at least evaluated on the set of MuJoCo tasks. In Table 1, LLQL is compared to DDPG (a model free method), and is shown to achieve better performance. However, this seems to be unfair because the proposed method is in fact a model based RL algorithm. Therefore, it should at least compare to other model based algorithms (and also other riche set of safe exploration RL methods).<BRK>Thank the authors for the response. SummaryIn this paper, the author proposes LLQL (Locally Linear Q Learning), which separates the action design from prediction models, such that the model can have short term and long term goals. The short term network takes the current state and the action, and predicts the next state (to be specific, the status change) under the assumption that the output is linear to the action. Strengths  The proposed model is novel, which can take a trajectory or a constraint as a short term goal. As a result, we can control the behavior of the model easily. As the authors showed in Tables 1 & 2, LLQL outperforms this approach. The paper is clearly written. Only compared to one baseline. In order to demonstrate the effectiveness of LLQL taking a short term trajectory or constraint, the authors compared it to only one method (i.e., DDPG) with a few manually designed reward function.
Reject. rating score: 3. rating score: 6. rating score: 8. <BRK>The method covers both L_inf and L_2 perturbations, and the optimization problem posed are solved using Gurobi. This results in the standard properties from taking a lagrangian dual: any choice of dual variables will produce a lower bound. I m confused at the upper bound finding method. Also, I don t understand the motivation for why repeatedly solving the QP will lead to a good violation on the decision boundary. I know that the paper says that "analytic investigation of this algorithm including a convergence proof remains future work." but at the moment there is not even an intuition for why it might be a good idea. FGSM is a very very weak baseline for the use that is employed here. It s better to report results clearly than only trying to show the good points of the algorithm.<BRK>Z.(2018).Scaling provable adversarial defenses. Many previous papers have been using PGD based attacks to obtain the upper bound. 2.The use of FGSM as an upper bound is inappropriate, as FGSM is known to be a very weak attack. This epsilon value is too small for L2 norm. The per neuron lower and upper bounds can be obtained using CROWN efficiently, so there is no too much computation cost. 2.Improving the scalability of QP relaxation is another challenge. Overall I am positive with this paper, however before accepting it I think the authors should at least make their claims clearer (the relaxation performs well mainly in L2 norm, and the concept of "bi directional verification" is also not entirely new), replacing FGSM by a 200 step PGD and compare the upper bound found by PGD with QPRel, and test the proposed algorithm in models trained with a larger epsilon (eps 1.58 to align with previous works, if possible) and deeper models.<BRK>This paper proposes a method to compute the distance to the decision boundary for a given network, where the network is composed of linear layers followed by a RELU activation. The authors provide a lower bound and an upper bound for the distance of a sample from the decision boundary. The method is useful to verify robustness of neural networks. The experiments show the improvement of the proposed method over existing certificates. I am not referring to a convergence proof here, but simply a guarantee that the value returned by Algorithm 1 is indeed an upper bound. It would also be helpful to provide intuition for the iterative procedure to compute the upper bound.
Reject. rating score: 1. rating score: 1. rating score: 1. rating score: 1. <BRK>This paper claims to analyze the global convergence of large scale neural networks (NNs). this is not a new mathematical toolSection 2   a standard formulation of neural networks, followed by undergraduate level Fourier analysis. The introduction of Fourier analysis as a new mathematical tool, and devotion of a whole page to this “canonical space model” is almost laughable. Furthermore, this statement in the introduction is not only incorrect but it is absurd.<BRK>Summary:This paper presents an argument that massively overparameterized neural networks trained with gradient descent on a supervised learning problem with convex loss function will converge. It argues that by mapping each model to a truncated Fourier series we can recover a canonical representation for the functions in the model space. Viewing this as a linear map at each point in parameter space and assuming that this matrix is always full rank, they claim convergence of gradient descent.<BRK>The paper studies the problem of optimization for neural networks. It compares the optimization problem in parameter space with the corresponding problem in function space.<BRK>This paper looks at the neural net training problem in a "canonical space" which is parameterized by the Fourier coefficients of the function. The paper shows that in the canonical space, the training problem is always convex. Going back to the literal space (original parameter space for a neural network), it is shown that as long as a "disparity matrix" remains full rank, gradient descent will converge to a global minimum. The paper claims that the matrix can be made full rank. The authors would need to provide a rigorous proof in order to claim this.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>This paper studies the teacher student models in semi supervised learning. The paper achieves some good empirical results compared to other baselines. However, it is still not clear why the proposed method work and how does it prevents overfitting. I vote for a clear rejection of the paper.<BRK>In the second sentence of Introduction, the authors mention "Although coaches do not play as well as the players". The authors propose a novel policy gradient update for the Teacher network. The authors evaluate the coaching method on several different semi supervised learning dataset CIFAR 10, SVHN and ImageNet. The authors  response does not answer the questions about motivation and why the method works, which is also questioned by the two other reviewers.<BRK>The paper proposes Coaching for semi supervised learning. The empirical results are very impressive. First, the method is not well motivated in the Introduction section. I suggest adding this to the ablation study as well. We need to understand why it works apart from adding a bunch of tricks together.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>The model proposed in this paper outperforms it without being combined with any classical approach, though it does utilize ensembling.<BRK>The paper investigates a pure deep learning architecture for Univariate time series analysis by simply ensembling feed forward networks, along with the residual stacking mechanism for fluid learning.<BRK>The paper proposes a DL architecture that achieves better performance on time series prediction.
Accept (Poster). rating score: 8. rating score: 8. rating score: 6. rating score: 1. <BRK>This paper presents a new deep reinforcement learning method that can efficiently trade off exploration and exploitation. The paper is well written and easy to follow. On Gridworld the performance of the proposed algorithm is close to the performance of the Bayes optimal policy. This can add additional computation complexity to Bayesian RL, which is not explained or mentioned in neither the method part nor the experiment. I hope the authors can add some discussions on this aspects<BRK>While it s always easy to dig into the rabbit holes of related research and distract from the overall objective of a paper, I thought that there was sufficient overlap with these other lines of research that the authors may find interesting. Further clarity along any of these questions would greatly improve the presentation of the paper as well as further convince me of the paper s suitability for publication. The primary contribution of this paper is in how variBAD learns the variational inference procedure. Can one make the same claims about the overall approach or procedure in the MuJoCo domains?<BRK>Summary: This paper considers a version of reinforcement learning problem where an unknown prior distribution over Markov decision processes are assumed and the learner can sample from it. After sampling a MDP, a standard reinforcement learning is done. Comments: Considering a Bayesian setting of reinforcement learning is sound and well motivated in a mathematical or statistical sense. Unfortunately, I don’t have any examples in mind and the paper also shows some artificial experiments. Comments after Rebuttal:I modified my score according to authors  comments.<BRK>On these grounds, given a set of tasks sampled from a distribution, the method jointly trains: (1) a variational auto encoder that can infer the posterior distribution over the postulated latent variable when it encounters a new task while interacting with the environment, and (2) a policy that conditions on this posterior distribution over the MDP embeddings, and thus learns how to trade off exploration and exploitation when selecting actions. Such variational inference arguments for transfer learning in the context of MDPs are not new. The authors have not made a good job reviewing the related literature. This is totally disappointing.
Reject. rating score: 3. rating score: 3. rating score: 3. rating score: 8. <BRK>This papers proposed an interesting idea for distributed decentralized training with quantized communication. 4.The experiments are not convincing. There is no convincing explanation why modulo operation makes the algorithm better.<BRK>This paper studies an important problem in the decentralized optimization, i.e., communication compression. 3.The modular hyperparameter $\theta$ is not easy to choose and seems cannot help achieve consensus. Overall, the idea of Moniqua is interesting and the authors provide useful extensions based on it.<BRK>The method is interesting and elegant, doesn’t require additional memory, theoretically convergent with a good speed and allows asynchronous communication. However, it looks a bit incremental. In contrast to the baselines, MONIQUA does not support arbitrary communication compression. Experimental comparison is shown only for the beginning of the optimization where the algorithm doesn’t achieve state of the art accuracy. why some equations are numbered and some are not?<BRK>This work is about the use of quantized communication in decentralized stochastic gradient descent. In summary, this work addresses a highly relevant problem and it nicely combines formal asymptotic analysis with experimental validation. The proposed Moniqua algorithm is an attempt to overcome these shortcomings. The motivation for the Moniqua algorithm   which is designed to solve this problem of local models   is rather intuitive, and the algorithm can be implemented quite easily in practice.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>In addition, the paper proposes a tiling approach to further reduce storage requirements. The organization of the paper is also confusing. To my understanding, the experiments are not very convincing. If for pruning, why not applying to all the layers in the network? How do we distinguish between the relevance of magnitude pruning and the proposed method?<BRK>The idea of converting the binary low rank factorization problem into a real valued non negative factorization problem is interesting but could have been better justified (from an intuitive/theoretical and computational perspective). The paper addresses the problem of reducing the computational complexity of neural network pruning. As low rank decomposition of binary matrices is a hard problem, the authors propose a method to approximate the solution by computing a more standard non negative matrix factorization. In the experiments, the value of the pruning objective seems to decrease as the rank of the factorization increases.<BRK>This paper proposed a new network pruning method that generates a low rank binary index matrix to compress index data, and a tile based factorization technique to save memory. The results for various networks, including DNN, CNN and LSTM, have shown the effectiveness of the propsoed method. The paper is well written and easy to follow. The experiments are not convincing, e.g.only pruning FC5 and FC6 layers in AlexNet on ImageNet dataset.
Accept (Poster). rating score: 8. rating score: 8. rating score: 6. <BRK> The paper proposes a neural network architecture to address the problem of estimating a sparse precision matrix from data (and therefore inferring conditional independence if the random variables are gaussian).<BRK>The authors propose an AM procedure for solving the l1 regularized maximum likelihood which can be unrolled and parameterized. This method is shown to converge faster at inference time than other methods and it is also far more effective in terms of training time compared to an existing data driven method.<BRK>The authors propose a new method for graph recovery, which is a more data driven approach by deep learning. It makes an original approach to this problem. Good attention is also paid to hyper parameter tuning. However, some parts can be clarified and improved:  In the introduction a number of phrases should be clarified: it is not entirely clear what the meaning is of the input and output of the problem, input covariance and output precision matrix. Additional explanation and references are needed at this point.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>This paper investigates the impact of using a reduced precision (i.e., quantization) in different deep reinforcement learning (DRL) algorithms. In my opinion, for this paper be relevant, it should have a very thorough evaluation of these different dimensions of reinforcement learning algorithms, with explicit discussions about it. The result that is interesting, in my opinion, is not properly explored. The paper is well written but it is a bit repetitive. Aside from typos, below are some other comments on the presentation. The rebuttal did acknowledge some points I made to me the paper took a gradient update towards the right direction. These are questions I would like to see answered because they also inform us about the impact of the proposed idea.<BRK>Training and deployment of DRL models is expensive. The paper indicates that quantization can indeed lower resource consumption without quality decline in realistic DRL tasks and for various algorithms. The idea is simple and carries over from (image based) supervised learning. The results are also not entirely surprising or impactful: how is quantization impacting reinforcement learning in a different way than supervised learning? What secondary effects does quantization have on the learning procedure: e.g., does it boost exploration behavior or does it regularize training? These could be investigated in more detail.<BRK>This paper studies the effect of quantization on training reinforcement learning tasks. On several tasks, the authors showed that quantization can significantly reduce memory usage and speed up the inference time. While it is expected that quantization should decrease the accuracy of the trained model, it is not entirely clear how one should evaluate the trade off presented in the work. Some natural questions that I believe deserve more discussions are:  Are the kinds of accuracy cost the best one could hope for using these methods? In Figure 5: your results show that the "int8" method has a significantly lower success rate than "fp32".
Reject. rating score: 1. rating score: 1. rating score: 8. <BRK>This paper is about learning word embeddings. There is therefore not a meaningful comparison to the most relevant previous work. Word similarity experiments are not enough to justify this approach. There is no such analysis here. The claim that the resulting representations are more "interpretable" is not backed up by any evidence at all, even though the word "interpretable" is in the title and the list of contributions.<BRK>Summary: This paper proposed a variational word embedding method, by using vMF distribution as prior and adding an entropy regularization term. Weaknesses:[ ] Template: It seems that the authors use the wrong template, which is not the template for ICLR2020. The authors argue  interpretable  in their title and abstract, but their method and experiments do not show this point explicitly. The vocabulary size is 10K and the corpus is not so big, and I wonder whether the performance of the proposed method will be better for large corpus and longer training time. Is it still true for vMF distribution?<BRK>The new approach to training word embeddings addresses interpretability in the sense of having a theoretically grounded interpretation for the good properties that the inner products should possess   namely that they capture the PMI between words. and situated in the literature. The results seem to be fairly interpreted. It will catch a large number of problems that weren t ever big enough to hurt my appreciation of the paper. Write one or two more sentences about the fate of \kappa_c   is it ever updated or am I just missing something? Watch out that readers/reviewers of similar work may try to read the word "interpretable" in the title as a reference to the much broader topic of interpretability in ML related to explaining a model s behavior.
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>I appreciate your point that sport applications can be interesting to this community, and your paper makes an important contribution in that direction. With that said, for a paper to be appealing to the ICLR audience, there should be more clear novelty in the method, and stronger experimental evaluation showing novel insights or out performance over previous baselines. The paper addresses a problem in the context of understanding formations of sport player in a play field. General: The paper is very clearly written, the method makes sense and the related work are both well explained. I have two main concerns: First, the scope of the paper may be too narrow for a conference like ICLR, as the method part is fundamentally a clustering method, and the application is very specific. Wouldnt its distribution change?<BRK>if this was the case, it is really hard to see how each of the proposed steps guarantees the same outputs as previous approaches, while at the same time only affecting speed. Paper, in its current form, lacks quantitative evaluation, comparison to other methods (heavily cited in the paper), and any well established applications that can be quantified.<BRK>  *Synopsis*:  The paper proposes a new algorithm for template discovery and representation learning for unstructured multi agent data with strong group roles (i.e.sports data). Main Contributions:    A key insight into the underlying structure of the data, enabling an algorithm with orders of magnitude speed up. A new framing of the problem. *Review*:  The paper is well written, and seems to be a nice improvement over prior art in terms of runtime. Q1 It seems the key insight is that you are modeling the occupancy of space by an agent as a mixture of independent gaussian distributions. If not, why?
Accept (Poster). rating score: 8. rating score: 6. rating score: 3. <BRK>This paper proposes applying random convolutions to the observation space to improve the ability of deep RL agents to generalize to unseen environments. To encourage the learning of invariant features, the authors further include a loss term to align features of perturbed and unperturbed observations. Thorough experiments on multiple generalization benchmarks show that this method outperforms many previously used regularization and data augmentation techniques. Although the proposed method is simple, it represents a useful contribution. The clear need for agents to be invariant to these low level transformations well motivates the proposed approach, as does the failure of many existing methods to provide this invariance. The authors could more explicitly discuss the main drawbacks of this approach. As with any data augmentation, there is an assumption that the applied transformation generally won’t destroy information pertinent to the task. Encountering such MDPs is not farfetched, so this weakness seems worth acknowledging.<BRK>This paper proposes methods to improve generalization in deep reinforcement learning with an emphasis on unseen environments. The main contribution is essentially a data augmentation technique that perturbs the input observations using a noise generated from the range space of a random convolutional network. The empirical results look impressive and demonstrate the effectiveness of the method. Otherwise, please provide some intuition on why this works so well on RL but not as well on computer vision tasks. 3) While proposed method performs well on the benchmarks, it is not clear whether authors compare to the state of the art algorithms. I also found the new experimental results (Fig 5 and 7) very insightful. For future improvement: More realistic experiments on computer vision tasks (besides cats and dogs) would be welcome. Otherwise, please justify why proposed strategy is particularly good for RL (rather than traditional computer vision benchmarks) in boosting robustness to new domains.<BRK>This work proposes using a randomly parameterized convolutional layer as additional processing of the input observation to provide data augmentation to make policies more robust to environments with different observation spaces. The empirical results are thorough, comparing with other regularization techniques, including dropout, L2 regularization, and batch normalization with the same policy gradient method, PPO on a variety of generalization in RL benchmarks. There are additional experiments of this method to check that it actually removes visual bias in a computer vision problem better than other methods. They also incorporate a feature matching loss that explicitly forces the learned representations of equivalent states to be close in L2 distance. Why would this perform better than grayscaling? The comparison of PPO is also unfair in that the author s method uses an ensemble of policies to act, which other methods do not.
Reject. rating score: 1. rating score: 3. rating score: 3. rating score: 6. <BRK>This paper develops variations on the Donsker Varadhan (DV) lower bound on KL divergence which yields a lower bound on mutual information as a special case. The paper is primarily theoretical with an emphasis on the case where the witness function f is drawn from an RKHS (a support vector machine). First, the authors ignore fundamental limitations on the measurement of mutual information from finite samples. So meaningful lower bounds for "high dimensional data" are simply not possible for feasible samples. They should be compared to those in "Learning Representations by Maximizing Mutual Information Across Views" by Philip Bachman, R Devon Hjelm, William BuchwalterResponse to the author response:This was written earlier but there was a mishap when I attempted to submit it and it was not actually submitted until comments were no longer available to the authors so I am putting this in the review. Bounding the ratio of the densities already bounds the mutual information. I see no reason to believe that the empirical estimate is meaningful in a real application such as vision. Regarding the experiments, I do not have much interest in experiments on synthetic Gaussians. baselines rather than performance numbers reported by, for example, Hjelm et al.or van den Oord et al.(CPC).<BRK>The paper contains one main contribution, the unbiased version of MINE obtained using the eta trick, however a lot of theory is presented and not always very clearly. The section on “What Do Neural Estimators of LK or MI Learn” is a collection of different remarks without much coherence, some of which are imprecisely stated. The comparison with the estimator from Pool et al.(2019) could also be much simplified, in particular I would review the list of remarks below theorem 2. Another weakness of the paper is that two important aspects in assessing the quality of an estimator are overlooked:  the variance of the estimator and the performance on finite data. The experiment comparing different MI estimators on synthetic Gaussian data is interesting. The plots are however difficult to read, it would be good to make them larger or split the results in different panels. For the 2D and the 20D case, the results reported in the MINE paper are much closer to the true MI than what is reported here, could the authors explain this difference? that the performance on downstream supervised tasks often does not clearly depend on the quality of MI estimation. It starts with a typo in the second line (E_y~Q should be replaced by an integral).<BRK>The paper presents to use \eta trick for log(.) in Donsker Varadhan representation of the KL divergence. Nevertheless, in experiments, we see that it outperforms the original neural estimation of mutual information. <Appendix>I understand most of the people would not read the Appendix, but I do. Cons:1.I don t agree with some claims in the paper. Nevertheless, these claims are some of the main stories supporting the paper. Including the presentation flow between sections, and also misleading part in experiments. I feel the paper should be a strong paper after a good amount of revision. Nevertheless, the author doesn t present an evaluation using the dual form. This paragraph is misleading and can be moved entirely to the Appendix. The author s claim is based on the comparisons between eq.(13) and eq.(15) when assuming only the MMD term reaches zero. <Section 4>Similar to Section 3, this section is cluttered. <MI Estimation Experiment>Can the author discuss the standard deviation for various MI estimation approaches?<BRK>The paper propose a variational bound on the Mutual Information and showed how it can be used to improve the estimation of mutual information. I am afraid I cannot judge of the quality and correctness of the method introduced by the authors. Nevertheless I find that the presentation of the paper could be improved. For instance,  while I enjoyed Fig.3 that showed the performances of different estimators of the entropy, i add the zoom out on a big screen to be able to see anything at all! It is also not entirely clear how this figure supports the claim of superiority of the proposed method. The only comment I may have is that it would be interesting  since the authors want to apply their bound to the case of neural networks  to compare with, the rigorous estimation of the entropy of NN with random weights in Gabrie et al, NeurIPS 2018, Fig.2 .It would be a much challenging task, albeit a synthetic one, than the Gaussian dataset one presented in Fig.3.
Accept (Spotlight). rating score: 8. rating score: 8. rating score: 6. <BRK>The stable rank is the ratio of the squared frobenius norm to the squared spectral norm (the top singular value). The authors should also indicate their hardware setup and overall training time. My Take:This paper motivates and presents an interesting extension of spectral norm, and evaluates it quite well with thorough experiments in a range of settings.<BRK>Thispaper shows how to implement these "stable rank" normalizations with littlecomputational overhead. The authors then apply the method to a wide variety ofclassification and GAN problems to show the benefits of stable ranknormalization. For CNNs with only a few linear layers is there any observabledifference by lightly deviating from this?<BRK>This paper proposes normalizing the stable rank (ratio of the Frobenius norm to the spectral norm) of weight matrices in neural networks. They propose an algorithm that provably finds the optimal solution efficiently and perform experiments to show the effectiveness of this normalization technique. My main issue is with the empirical evaluation of the normalization technique. 2) The current result is with training with a fixed number of epochs.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>This paper contributes a probabilistic framework for multi agent RL and demonstrates a derivation of multi agent SAC using it. On Page 9, the conclusion is reiterated and claimed to be in comparison to a state of the art algorithm.<BRK>The paper extends soft actor critic (SAC) to Markov games, or in other words multi agent reinforcement learning setting. Discussion of advantages/disadvantages and comparison with the previous work I see as necessary.<BRK>Summary:This paper proposes a new algorithm named Multi Agent Soft Actor Critic (MA SAC) based on the off policy maximum entropy actor critic algorithm Soft Actor Critic (SAC). Based on variational inference framework, the authors derive the objectives for multi agent reinforcement learning. Comments:  Based on inference, the authors derive the objectives as the equation (8) and (9).
Reject. rating score: 3. rating score: 6. rating score: 6. rating score: 6. <BRK>2.The toy example in the paper is simply 1D Gaussian. The intuition is straightforward and makes sense to me. I am not sure the details of the implementation in this paper, but I also have a naive question for high dimensional Gaussian. should be discussed as well.<BRK>The paper proposes to improve standard variational inference by increasing the flexibility of the variational posterior by introducing a finite set of auxiliary variables. As noted by the authors this is a variant of auxiliary variables introduced by Barber & Agakov. Overall i find the motivation and theoretical contribution interesting. How sensitive is the method to sequence of variances for a?<BRK>Summary.This paper describes a method for training flexible variational posterior distributions, which consists in making iterative locale refinements to an initial mean field approximation, using auxiliary variables. Overall, this paper is well written and easy to follow. Important baselines are missing in the experiments.<BRK>The paper proposes a new way to improving the variational posterior. The experiments are carefully designed. The idea is interesting and useful. They also compare with the state of art variational approximation methods.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>This paper proposes a new method for geometric matrix completion based on functional maps. The paper would also be much better if the clearance issues can be addressed. Is it because we have the functional maps technique motivated from shape correspondence, and we can see some connection of such technique with matric completion? The introduction of the paper is poorly written. The introduction part needs to be re organized to provide more useful information about the paper rather than a literature review. For Q1, it clearly explains how does the method work. However, it is still not clear why does the method work. I also have another concern after reading the rebuttal, if the shape correspondence is not that important, why make it an important motivation in the paper? For Q2, it is interesting to see some theoretical results on the sample complexity, rather than an experimental one.<BRK>This paper aims to solve the matrix completion problem by incorporating geometric information. While the geometric approach looks interesting and the experimental results seem promising, it is unclear why the proposed approach works, and the comparison with [Arora et al.(2019)] is not fair. This also raises the question of how practical the proposed approach is. However, in the experiments, both P and Q are initialized as the identity, which is not close to zero. Though the authors include the connection between [Arora et al.(2019)], this is not convincing enough since as explained above, the implicit regularization there depends on the smallness of the initialization.<BRK>This paper proposes a novel approach for the loss function of matrix completion when geometric information is available. In addition, the zoomout loss is motivated by the approach for shape correspondence and can be a generalization of the recent matrix completion method (deep matrix factorization). Overall, this paper presents a novel approach utilizing graph spectral information with empirical improvements. In the paper, the authors mention that it promotes smooth functions on the graph nodes, but not fully clear why smooth functions are good. It would be better to give more details. 4.Why results of FM are not reported under other datasets?
Reject. rating score: 1. rating score: 1. rating score: 6. <BRK>The authors propose a semi supervised learning model, named as Flow Gaussian Mixture Model (FlowGMM). Overall the paper is fine written. Specifically, “giving us insight into the workings of the model” is not clear; what exactly insight can we get and what exactly are the workings can we get?<BRK>The method, FlowGMM, maps each class of the dataset to a Gaussian distribution in the latent space by optimising the joint likelihood of both labelled and unlabelled data, thus making the method useful for semi supervised problems. I am not convinced by the novelty of this paper.<BRK>The papers also shows how to incorporate a consistency based regularisation within the method. I encourage the authors to carry out more convincing numerical comparisons ing tabular/NLP/etc.. settings in order to strengthen the message of the paper. I agree with the authors that there are many situations where it is not possible to find good perturbation (eg.NLP / tabular / genomics / etc...).
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>This paper proposed SE SNN, a type of stochastic neural networks that maximize the entropy in stochastic neurons along with the prediction accuracy. Note that in Table 1 the best accuracy is actually achieved by SBP and L0. The numbers for different methods in Table 1 are very close to each other.<BRK>Major comments:   Overall, I find the paper is easy to follow and the experimental evaluation shows promising results, but my major concern is about the novelty of this work, given the fact that the structure of the proposed stochastic layers is quite similar to VIBNet. The authors suggest using a Gaussian with a finite mean and an infinite variance as the non informative prior for the produced Gaussian random variable z (in Eq.1), and then minimize the KL divergence between the produced Gaussian and the infinite variance Gaussian. This is not discussed and needs to be clarified in Sect.<BRK>This paper presents a simple stochastic neural network, which makes each neuron output Gaussian random variables. The model is trained with reparameterization trick. (Though I am less positive due to the concern of novelty raised by other reviewers.) The claims are well supported: the model is indeed simple, and the effectiveness is well supported by experimental results.
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>This is an interesting topic with a relatively scarce literature. After reading (1), it is clear that the novelty of the paper us much less than what I had initially thought. The approach is elegant, and appears to work empirically well. Why is it a sensible idea?<BRK>Did you run experiments with the consistency loss? As fixing this would require large modifications to the paper, I am keeping my score at weak reject. This is not an obvious use of the Mean Teacher method, and it seems like a nice idea.<BRK>Experimental results show that UMN outpuroms several state of the art methods on multiple benchmark datasets. However, it is subjectively uncertain to define whether it is a large or small dataset without considering application context and model complexity.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>My concern is that the contribution of the paper on the theoretical or methodological side seems a bit weak. The proposed method relies on the VAE framework for contrastive disentanglement.<BRK>Overall, I think this paper does make some changes regarding previous works on contrastive disentanglement. A more reasonable solution is to replace the KL divergence with the Wasserstein distance.<BRK>This concern is also related to beta VAE, the paper showed that large coefficient for prior regularization simply makes the disentanglement effect for VAE. To resolve this issue, the authors propose new regularizations still based on VAE.
Accept (Talk). rating score: 8. rating score: 8. rating score: 8. rating score: 8. <BRK>"Optimal Strategies Against Generative Attacks" describes just what the title implies   various dimensions of the problem of defending against a generative adversary, with theoretical discussion under limited settings, as well as practical experiments extending on the intuitions gained using the theoretical exploration under limited conditions. I am unclear on how the data augmentation experiment fits into the overall picture   perhaps a more detailed explanation of how and why this would be used to form an "attack" would help. The other experiments are sensible, and demonstrate reasonable and expected results. This is a solid paper, and most of my critiques are "out of scope" and revolve around experiments that would be nice to see. Though GAN for text is not simple, showing this type of setup for text would be interesting for a number of reasons, same for audio.<BRK># SummaryThe authors investigate an attack defense problem in which an attacker attempts to pass authentication by generating a faked input, while an authenticator attempts to detect the fraud. Furthermore, they reveal a more insightful closed form of the optimal strategies in the Gaussian case. This result clarifies the relationship between the success rate of the attacker and the numbers of the source, registration, and leaked observations. Based on this insight, the authors propose a new learning algorithm for the authenticator and demonstrate by some empirical evaluations that the proposed algorithm is robust against the faked input. I recommend acceptance of this paper.<BRK>This paper proposes a new threat model for generative impersonation attacks: The attacker has access to several leaked images of a person; the authenticator knows several registration images per person and decides a person s identify by comparing some newly sampled images from that person with corresponding registration images. The authors formulate this threat model as a minimax game and analyzed its Nash equilibrium. In the simplified case that observations are multivariate Gaussian, the authors are able to characterize the optimal strategies of the attacker and authenticator explicitly, which gives a nice intuition on how the theoretical optimum changes with respect to data dimension, number of leaked images, etc. The threat model nicely captures the most important aspects of impersonation attacks and is relatively realistic. The data augmentation experiment can be naturally fit into the framework of impersonation attacks and the application of their techniques in this direction is very exciting. 2.There is a minor issue in the proof of Lemma D.2 in page 16.<BRK>This paper addresses the issue of malicious use of generative models to fool authentication/anomaly detection systems that rely on sensor data. The authors formulate the scenario as a maxmin game between an authenticator and an attacker, with limitations on the number of samples available to the authenticator to fix a decision rule, the number of samples required at test time for the authenticator to take a decision and the number of leaked samples the attacker has access to. The authors prove that the game admits a Nash equilibrium and derive a closed form solution for the case of multivariate Gaussian data. Finally, the authors propose an algorithm called "GAN In the Middle" and perform experiments to show consistency with the theoretical results, better authentication performance than state of the art methods and usability for data augmentation.
Accept (Spotlight). rating score: 8. rating score: 8. rating score: 8. <BRK>The method addresses this issue by allowing the agent to select two actions: one (the possibly exploratory action) is applied to the environment and the other (the greedy action) is presented to other agents as part of their observations for the next turn. For this reason, I recommend the paper to be accepted. Typos/language issues:Introduction: “spend vast amounts of time coordinate”  > coordinatingSection 3.1: “While our method are general”  > methods"accomplish a state of the art in Hanabi"I see what you mean but this is a strange phrasing.<BRK>That being said, I have some issues with the presentation of the content in the paper. At a high level, I think that the paper is too concerned with 1) justifying greedy input with Bayesian reasoning and 2) promoting state of the art results. In its current state, I feel that this work is a rejection. But the results of these experiments should be presented clearly. The paper should report the mean or the median.<BRK>The paper examines the problem of epsilon greedy exploration in cooperative multi agent reinforcement learning. The suggested solution is to consider two actions: one action is epsilon greedy and it is passed to the environment, while another is fully greedy according to the agent’s strategy, and it is shown to another agents. 4.\eps greedy is written with a hyphen in some places of the paper and somewhere without. The suggested method is claimed to show state of art results in 2 5 players Hanabi. However, considering the results, it seems there is no clear winner for different number of players in Hanabi. should be higher.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>The core idea is to design and to learn a neural model (the ROLE network) able to analyse a target neural network (e.g.an encoder in an seq2seq architecture) by identifying the symbolic structures the target network manipulates (the symbols and their roles) in its representations and the compositional rules it has learned on these. This is a kind of sanity check, that ROLE may uncover the ground truth from the data, while no prior information is provided on the nature of the roles. The experiments on the SCAN dataset concern a standard RNN model learned from data. As far as in understand, beyond the understanding of the learned representations in RNNs, the paper motivates the work with the expectation that the gained knowledge might be useful for designing better neural nets, with improved generalization ability. Yet i don’t  see clearly what could be done on this line.<BRK>In this paper, the authors study the problem of understanding the compositional generalization abilities of NNs. A new type of NN, called ROLE, is proposed to learns to approximate the representations of a target NN E by learning a symbolic constituent structure and an embedding of that structure intoE’s representational vector space. A number of tasks are conducted, including a simple fully compositional task, a SCAN task, a partially compositional NLP task. The experiment results show that the proposed approach can help to understand how NNs achieve strong generalization on partially compositional tasks, and good performance on fully compositional task. Pros:1.This work studies an important problem of fundamental AI. 2.Authors conduct experiments on multiple task to evaluate the effectiveness of the proposed technique and show how it helps to understand the generalization of NNs. Should "0.828 be  82.80". Cons:1.Regarding the Q2 raised in the paper, only simple suggestions are given. It is suggested to evaluate its effectiveness on some real experiments.<BRK>The paper introduces an approach, called ROLE, that extract symbolic structure from seq2seq networks. It also provides an interpretable symbolic structure and examines the causal information in the symbolic structure. The approach is inspired by the Tensor Product Encoder architecture. The scan role analysis part seemed the most hand wavy with lots of positions in A.7. None of the accuracy results have variances attached to them. I am not an expert on this topic (hence the weak accept), but I liked the paper.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>In J_cons, does the expectation need to be over p? ***After author response:Thank you for answering my questions! Although I have a better understanding of the paper now, I still have the same concerns and would like to keep my score.<BRK>The results reported could be more clear. With all of the above uncertainty, I do not have confidence to have the paper accepted in the current format based on my preliminary assessment. It looks to me that the major contribution claimed is the novel loss function that combines the proportion loss and the consistency loss, but both seem to be from off the shelf solutions from literature with slight variation.<BRK>1.It s a bit harder to appreciate some of the performance gains here without understanding the error rates around the accuracy.
Reject. rating score: 3. rating score: 6. rating score: 8. <BRK>Summary: The paper presents approximation power results for deep, but narrow networks with various activation functions. In particular, the authors target the minimum width possible, s.t. the class of networks considered remain universal approximators. The authors consider ReLU activation functions, polynomial activations, as well as some non differentiable activations. They cite the paper by Lu et al  17 which essentially uses this proof technique). While there are some technically interesting parts (e.g.the polynomial activation part has some trickiness in maintaining the width at n+m+1), I don t think will be very interesting to the ICLR community at large, and I think it is fairly incremental.<BRK>      This paper complement of the fundamental Universal approximation theorem variants      Based of the Register model, that the authors seem to have developed themselves from the scratch, elegant, although non obvious      Proof is straightforward, although the pictural description can be enhanced. In reality the width neurons are unfolded horizontally in the n+m+1 layer      As of now, single point continuous function does not seem to have been proven to be sufficient to build universal single layer approximator networks in the 1999 paper. The third part of the paper relies on Stone Weierstrass theorem and a manipulations around the concept of "enhanced neurons", carefully constrcutred to fit in the n+m+1 and n+m+2 budgets      However, the proof of relaxing the Polynomial functional constraint in Theorem 4.8 is not entirely clear. While it seems to be a two staged proof (convergence for non linear function x^2, then convergence of a class of polynomial functions to x^2), it is unclear how the $\rho_h$ neurons can be assembled with the registry neuron budget from the initial polynomial function. Although inspired by prior work, the author s contribution is novel, original and important.<BRK>This paper proves universal approximation theorems for fully connected networks with fixed width and unbounded depth. According to Remark 4.9, it seems that the proof strategy for polynomials can also be applied to nonpolynomials. I would like to vote for acceptance of this paper because the authors develop nontrivial techniques that extend existing universal approximation results on width bounded ReLU networks to essentially “all” other activation functions.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>Summary:The paper proposes two new regularizers for adversarial robustness inspired by literature on verification of ReLU neural networks for resilience to epsilon perturbations using convex relaxations. The paper from Salman et.al. Making that more clear would be useful. In general, it seems very unclear why this should work based on the evidence presented in the paper. Thus it is not clear to me if this is an approach for verification or a regularizer based on verification. Overall, I am not an expert in the area but a lot of details from the writing (such as point 1 under weakness) and the theoretical justification of the regularizer are unclear to me.<BRK>Summary:The aim of the paper is to improve verified training. See the work by Anderson et al.for some examples Page 5, section 4: "We investigate the gap between the optimal convex relaxationin Eq.O" There is a bit of confusion in this section. > There is a subtlety here that I think the authors don t address. The whole section is quite convoluted and makes very strong assumption. The comparison is included in table 2, when the baseline is beaten, but this is with using the training method of CROWN IBP and it seems like most of the improvements is due to CROWN IBP. I think that there might be a few parallels to identify between the regularizer proposed and the ReLU stability one of Xiao et al.(ICLR2019) from that aspect. The experimental results are not entirely convicing due to the lack of certain baselines.<BRK>Strengths:This work proposed two regularizers that can be used to train neural networks that yield convex relaxations with tighter bounds. The problem is interesting, and this work seems to be useful for many NLP pair wise works. More datasets need to be added to the experiments in this paper. Overall, the paper solves an interesting problem. 1.There are some presentation issues that can be addressed. 2.In the experiments, the dataset is not a good one for evaluating the performance of the proposed idea. In conclusion,  at this stage, my opinion on this paper is Weak Accept.
Accept (Spotlight). rating score: 8. rating score: 6. rating score: 6. <BRK>There are several good contributions of the paper, but the main one is to design a language of instructions that fix a program and to formulate the prediction to be a sequence of such instructions. The model, however, is insightful in other ways as well. Instead, the proposed model only builds embeddings from the structure around the variables. The kind of bugs addressed by the work was also not considered in previous papers. So, I also have questions for the authors:1.<BRK>In this interesting work the authors aim to provide a novel data driven system for detecting and automatically fixing bugs in Javascript. These actions are reasonable, and are able to fix many bugs assuming the right sequence of actions is performed. The paper contains a solid engineering effort, starting from the dataset collection and its preprocessing, to using state of the art machinery to develop Hoppity. Therefore, I support its acceptance. How is it set in the experiments? Is it the case that bug free programs are treated as such? Have you tried Hoppity on other programming language(s)?<BRK>This paper proposes a graph tranformation based code repair tool. By representing source code as a graph a network is asked to take a series of simple graph edit operations to edit the code. The authors show that their method better predicts edits from existing code. Overall, I find the problem interesting and the neural approach of the authors reasonable, principled and interesting. It is unclear if the authors have taken any steps to detect and remove duplicates that would affect their results. * It has been recently found that code corpora collected by scraping GitHub may contain a disproportionate amount of duplicates (Lopes et al.2017, Allamanis 2018).
Reject. rating score: 1. rating score: 6. rating score: 8. <BRK>The paper proposes to use residual learning as an auxiliary to compensate for the sub optimal expressiveness of the source policies, which is novel and interesting. The paper performs experiments on multiple environments. The domain gap seems small for these experiments. The paper needs a metric to measure the domain gap between source and target dynamics and report how the domain gap influences the proposed method and the baselines according to the metric. This problem can be impractical for real world applications with restrict limitations. Post rebuttal:My major concern is that the method is a naive combination of previous works and the paper is more like an engineering work. This is like learning a policy from scratch by reinforcement learning. With better source policies, we can achieve better initialization for RL. The work still requires lots of steps to train in the target domain, which does not fit to the real application of transfer RL. We hope transfer learning can adapt to the target environment fast.<BRK>In this paper authors propose a method for transfer reinforcement learning (RL). In order to showcase their approach they have come up with a new transfer RL task that makes use of some source policies trained under a diverse set of environment dynamics. Their key contributions to solve the task involve a decision aggregation framework that is able to build on top of relevant policies while suppressing irrelevant ones and an auxiliary network that predicts the residuals around the aggregated actions. I recommend the paper to be accepted since they have an innovative contribution that pushes the needle on the transfer RL literature although I do not think the contribution is substantial. The set of experiments covers a wide range of different standard RL tasks and they provide enough evidence that the approach works. I find it interesting that they are able to extend the approach to the discrete action tasks. I would however recommend providing more experimental results that provides evidence that the target policy can recover the right policy when the target environment dynamics is the same as one of the source environments.<BRK>This paper presents a transfer reinforcement learning method that learns from existing source policies. The method aggregates deterministic actions produced by a collection of source policies to maximize expected return in the target environment. The authors show results on a collection of different environments that include continuous and discrete action spaces. I appreciate the additional work put in to evaluate the distribution of performance. The method is well ablated and addresses variants in which there is no reweighting and in which the residual is estimated independently of the state. I d like to see results comparing MULTIPOLAR with only bad sources with a randomly initialized policy  Given that source policies are needed for this to work, I d like to see comparisons in which one continues to finetune an existing source policy. I know that the assumption here is that one does not have access to the internals of the source policies, but it would be nice to see how the performance compares. My main concern has to do with the applicability of this method, since it seems to make strong assumptions on how different the domain dynamics are between source and target environments.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>An interesting point of the paper is that (i) the boundedness assumption on the domain or gradient is not required and that (ii) shows faster convergence rates under KL condition for non descent methods.<BRK>If not, how useful it is to use ADAM for this class of functions? The authors should clarify this point in the paper.<BRK>However, I have a few concerns as follows. 1. the convergence in Theorem 4.2 is not standard. it should be more clearly stated in the introduction.
Accept (Spotlight). rating score: 8. rating score: 6. rating score: 6. <BRK>Minor comments:There are some typos in the paper in both main paper and supplementary document  causal vs. casual. The authors may need to explain more clearly at this point in the implementation details.<BRK>How can this be generalized to a more real world setting ? Equation 2, in the appendix the subscripts are not proper. The main contribution of the paper is to show the incompetence of existing models to capture dynamics. It is shown that,  learning dynamics of the objects the model can achieve better performance.<BRK>I have strong doubts that this kind of approach extends to real life scenarios. It also favors solutions of the type presented in the paper.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>This paper proposes a “concise” version of the well established Transformer model. I re read this paper multiple times and the only concluding finding I have is that this paper proposes an explicit way of setting the projection dimension regardless of the number of heads. The authors kept teasing a “different” way to do this, but this left the reader completely unsatisfied when the different way refers to explicitly setting each head to 128 and using a smaller model overall. I’m not very convinced by the argument. P here represents the affinity matrix between tokens in a sequence.<BRK>It argues and formally establishes that (1) the expressivity of an attention head is determined by its dimension and (b) fixing the head dimension, one gains additional expressive power by using more heads. Can the authors comment on this?<BRK>This work discusses how to set the projection size for each head (head size) in multi head attention module, especially Transformer. Therefore, the proposed method is more like a tuning of hyper parameters. The proposed method is to decouple the dependency between the head size and the embedding size. The experiments show that the proposed method is able to achieve comparable performance to BERT with fewer training cost.
Reject. rating score: 6. rating score: 8. rating score: 8. <BRK>The authors propose to improve abstractive summarization models by using pretrained embeddings, theme modeling and denoising. Experiments are conducted on 3 datasets. The proposed model outperforms the other unsupervized abstractive models and provides results closed to unsupervized extractive models, with a metrics which favors extractive models. Ablation study shows that pretraining yields most of the impact, whereas improvements due to theme modeling and denoising loss are marginal. In the Article example : "in the wold"  ? Conclusion :   dataset agnostic : I don t see why since the approach take advantage of the lead bias. "outperforms previous systems by significant margins" : excessive.<BRK>2) Fine tune on other datasets using so called theme modeling, and separately a denoising loss. section 2.2: You mention that you pick the model with the best ROUGE L score on the validation set. DecisionEdit: After revisions and discussions, I recommend we accept this paper. I am leaning towards accepting this paper mostly because of the contribution #1 above. That the performance is improved compared to other unsupervised abstractive summarization confirms the importance of this approach. The most clever contribution is in leveraging un labeled text using the first few sentences as the target summary for pretraining. Second, why not perform the theme modeling and denoising also   or rather only   on the unlabelled pretraining data?<BRK>"BPE for X", with X being an NLP task can hardly count as a contribution today. This is a great idea! However, this seems to be covered by an accompanying paper (ICLR submission ryxAY34YwB) which is not referenced. Because of common paragraphs and experimental setting I am assuming there is an overlap of the author sets in two papers. Contribution2: the use of combining reconstruction loss and theme loss for summarization is another great idea. There are significant differences in the different implementations being used. However this is not the case for NYT, where LEAD 3 actually beats any of your approach.
Reject. rating score: 3. rating score: 3. rating score: 8. <BRK>The paper is overall well written and conveys an interesting new formulation of GANs.<BRK>Also there is a few papers about the mode collapse issue in GANs. The later uses a Lyp function to analysis the global convergence of a GAN.<BRK>The primary question I am left with after reading the paper is: is there a probabilistic interpretation of the new loss function (equation 4a).
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>This paper can be viewed as being related to two bodies of work:(A) The first is training programmatic policies (e.g., https://arxiv.org/abs/1907.05431). The idea is to use a step wise model based controller to design a good trajectory that maximizes reward, while not deviating too far from the current policy. Then the new policy is learned from this trajectory. The authors contrast with (B) in part by claiming that "the teacher must mirror the structure of the student", which is supposedly harder. However, I m having a hard time appreciating this aspect of the proposed approach. I m also confused by how the "student does not learn based on examples provided by the teacher" if it s doing imitation learning on trajectory level demonstrations. The idea of training programmatic polices that "inductively generalize" has been done before on arguably more difficult tasks (see Table 2 in https://arxiv.org/abs/1907.05431). Updates after Author Response I increased my score to accept. I think this is a worthy contribution, and the authors did an excellent job addressing my concerns.<BRK># SummaryThis paper proposes a technique for synthesis of state machine policies for a simple continuous agent, with a goal ofthem being generalizable to out of distribution test conditions. The technique is evaluated on 7 classic control environments, and foundto outperform pure RL baselines under "test" conditions in most of them. # ReviewI am not an expert in RL based control, although I m familiar with the recent literature that applies formal methods tothese domains. Inductive generalization is an important problem, and the authors  approach oflimiting the agent structure to a particular class of state machine policies is a reasonable solution strategy. That, I m assuming, limits the set of applicable controlenvironments where optimization is still feasible. Section 4.2 needs an example, to link it to the introductory example in Figure 1.<BRK>This work proposes a framework for structuring policies using finite state machines, training a teacher student setup using variational inference. The method is tested on a suite of standard control problems against PPO with / without memory and against simple numerical optimisation, analysing both performance and some degree of generalisation. Overall, I like both the problem setting (constraining / structuring policies using SMs), and the proposed modeling and optimisation. I have however a few major issues that prevent me from recommending acceptance of the work:1. The authors don t specify anything about models structure or details about the employed state machines, and do not seem to have included details about their direct optimisation baseline, environment featurisation, hyperparameters used across their experiments, and so on. 3.Casting the problem as a POMDP, while technically fine (and in most cases reasonable), doesn t seem to provide any significant advantage to the method, and seems to only be adding noise in the formalisms described across the paper. Since the method introduces notation that a lot of RL researchers are not necessarily familiar with, I would suggest the author to try to simplify it where possible.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>3.The claim that RL with options “can be viewed as a two layer HRL” needs much elaboration if not correction. Relatedly, regardless of the stationarity of the transitions, there may not be an optimal _stationary_ policy in an episodic MDP contrary to the claim in the paper. A variant of UCRL2 [JOA10] is proposed to solve these hMDPs and some results from its regret analysis are provided. However, in 3.1 the transitions are stationary.<BRK>Additionally, the main comparison the authors seem to make is between HRL and naive RL, which does not provide sufficient context to properly analyse their algorithm. The proposed algorithm and the regret analysis performed seem rigorous and well thought out. Such errors appear throughout the paper. What is an example of an algorithm that does planning in a standard RL setting?<BRK>This paper studies the theoretical aspects of HRL. It provides theoretical analysis for the complexity of Deep HRL. The final result is an exponential improvement of HRL to flat RL. Overall, the paper pursues an ambitious goal that analyses the complexity of Deep HRL.
Reject. rating score: 3. rating score: 3. rating score: 6. rating score: 6. <BRK>The authors propose using influence functions to efficiently estimate pointwise confidence intervals for regression models. Their technical innovation is to combine a marginal error term that does not depend on $x$ (which ensures coverage) with a local variability error term that does depend on $x$ (to allow for greater variability in areas where the model is more uncertain and there is less data). In my opinion, the ideas in the paper are exciting; the paper is clear and well written; and the experimental evaluation is quite comprehensive in terms of baselines. 2) The paper refers repeatedly to how their proposed method can be applied to deep learning models and, in particular, state of the art deep learning models. In my opinion, the evidence in the paper does not support these claims. The paper is otherwise compelling to me, and I believe that the above points can be remedied by being more careful and circumspect with the claims in the paper.<BRK>This paper studies how to construct confidence intervals for deep neural networks with guaranteed coverage. The main reasons for this are: (i) A potential failure to cite and acknowledge the prior contribution of [1] which seems to have non trivial overlap with this paper (on arxiv since end of July which is more than 30 days before the ICLR submission deadline and thus should be treated as prior work); (ii) The claims of guaranteed frequentist coverage are not backed up as, according to thm.2, they only hold when n >> 0 and the number of influence functions used goes to infinity (ideally, the authors would provide non asymptotic bounds as in [1], but at the very least, these limitations should have been clearly pointed out and their practical implications discussed). Major comments:  Can you please explain the relation of this work to [1]? On a related note, Giordano et al.provide a careful analysis and discussion of the assumptions in their sect.4. Can you please clarify if and how the use of the algorithm from (Agarwal et al., 2016) for approximation of the Hessian products affects accuracy of your confidence intervals? In fig.3, it seems like some of the methods are not properly tuned. For example, MC dropout should not have zero uncertainty around zero (did you by any chance set bias variance to zero?!), and BNN SGLD does not seem to have converged (can you please provide plots providing some evidence that the MCMC sampler has mixed + information about how the hyperparameters were selected?).<BRK>The authors provide an interesting study on uncertainty estimation for deep learning for regression problems. The submission is well written and well structured w.r.t.the motivation and underlying theory, which are accompanied by extensive derivations/proofs in the annexes. However, the submission specifically is limited to regression, which is only mentioned scarcely throughout the paper and only as early as Sec.2.This limitation should be mentioned in title and abstract. Also, even though deep learning is addressed and covered in principle by the theory, the experiments do not really seem to cover deep models, being limited to two layer networks of limited size. In Annex D.3 and specifically Fig.5, network depth is addressed, but virtually no further details or performance measures are given for these experiments. It would be interesting to see a discussion on how the proposed approach is expected to scale w.r.t.the size of the data set and w.r.t.the complexity of the modeling.<BRK>In this work, the authors develop the discriminative jackknife (DJ), which is a novel way to compute estimates of predictive uncertainty. This is an important open question in machine learning and the authors have made a substantial contribution towards answering the question of "can you trust a model?" DJ constructs frequentist confidence intervals via a posthoc procedure. Throughout, the authors provide excellent background and exposition. They develop an exact construction of the DJ confidence intervals in Section 3.1. This is an intuitive approach that the authors explain well. Section 3.4 provides the theoretical guarantees for DJ. The related work section is extensive and thorough. I suggest that this paper is weak accepted. In addition, the theoretical exposition is very clear and compelling. In Equation 6: Looks like there is a misplaced parentheses. DJ(m ?)?Major issues: Why weren t the other jackknife procedures used as baselines as well? For some researchers, LOO CV might not be prohibitive. This could be a chance to really sell your method: if it does well enough compared to more expensive LOO jackknife procedures, that would be a compelling reason to choose DJ.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>As this kind of reuse reduces the quality of trees, the paper proposes to (greatly) increase the number of trees in the forest. The paper also introduces a sensible "beta similarity" which is based on average tree distance between leafs into which the two data points fall, rather than fraction of trees in which they fall into the same leaf node. RP trees have been introduced over a decade ago (Dasgupta and Freund, 2008), and the authors cite a reference to RP forests from (Yan et al, 2019, IEEE Big data). I would ask to clearly state what is existing work, and what is new, and what are the key contributions. The experiments do not provide enough details on the implementation to judge their significance   e.g.2x gain of speed could be achieved by better software implementation of the same algorithm.<BRK>This paper proposes the similarity measure called  beta similarity  generated by an ensemble of Random projection trees (RP trees) by Dasgupta & Freund (2008). However, this paper also has several problems 1) novelty and 2) confusing and imprecise statements. Also, there exists a highly cited paper by Yan et al KDD 09 proposed a fast clustering method based on RP trees as "fast approximate spectral clustering" in their title. It naturally defines the spatial closeness of data points, and thus the use of RP trees to define the similarity, and applying them to clustering (kernel k means, DBSCAN, spectral) is not new. 2b) The three goals are set: accuracy, efficiency, and independence from prior knowledge. It would be a kind of hyperparameters but not like  dependence on prior knowledge .<BRK>This paper proposes a new method for measuring pairwise similarity between data points. The idea is to define the similarity between two data points to be the probability (over the randomness in constructing the trees) that they are close in an RP tree.
Reject. rating score: 1. rating score: 6. rating score: 6. <BRK>The paper proposes a way of reducing the number of parameters in Transformer by splitting some of the linear layers into multiple separate groups. Small scale experiments on language modeling compared the proposed model to vanilla transformers. I think the motivation of the paper is good and important for real world applications of Transformers. In thinking this way, the proposed “group attention” feels more like multiplying the number of heads. The figure 1c is not exactly consistent with the text. I know a summation of two linear layers can be written as concat + linear, but it would be easier to understand if the figure was consistent with the text. The introduction suggests that Transformers only works with large sizes, which is bit misleading.<BRK>Summary: This paper proposes a lightweight alternative to the design of self attention based Transformers on character level language modeling (LM). Via experiments on two large scale char level LM datasets as well as a relatively extensive set of ablative experiments, the authors demonstrated the effectiveness of their approach. Overall, I think this is a promising strategy that seems to work very well on character level language modeling.<BRK>This paper proposes a lightweight Transformer model (Grouped Transformer) for character level LM tasks. Personally, I find the experiments a little lacking and it is particularly puzzling to me why the authors restricted the scope of this work to only character level LM tasks. (I note that there are some negative results on word level LM in the appendix section)Another particularly peculiar point in comparison with the standard Transformer model. This is the appendix so I don’t think space is an issue.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>ContentThe paper can be hard to read, due to multiple writing mistakes, abrupt phrasing, not well articulated sentences. However, the idea is easy to understand and interesting but the contribution does not seem strong enough in its actual state. My main concern is that the method seems to be designed only to answer the sanity checks: the resulting saliency maps can hardly be seen as more informative as other existing methods (eg figure 1). The claim is a little abrupt and could be detailed a little more"destroy the saliency map"  > destroy is a very strong word"These random variables are complicated." As for the writing, it is not always clear and can impede the understanding of the paper.<BRK>Summary:The paper proposes a simple technique to address the problem introduced by Adebayo et al.that several saliency approaches do not pass sanity checks. The proposed approach computes the saliency maps for all the classes and removes the pixels that play a role in predicting several classes. Simple and intuitive approach. For any interpretability technique, passing the sanity check is a must, but just because a saliency technique passes the sanity checks, it doesn’t mean that these maps explain the network’s decision well. 9.How does CGI look for the original 3 on standard model?<BRK>It addresses a problem posed for existing methods for characterizing saliency in activation subject to sanity checks which measure the degree to which the activation (saliency) map changes subject to different randomization tests. The proposed solution involves a simple competition mechanism across saliency maps produced when different logits are considered such that small values are zeroed out in favor of larger values across the logits. Overall, I find this paper to be interesting and to address a problem worthy of further consideration. While the mechanism for competition is very simple, the resulting activation maps subject to randomization tests are reasonably convincing.
Reject. rating score: 1. rating score: 3. rating score: 8. <BRK>This paper proposes the use of macro (i.e.aggregated) actions to address reinforcement learning tasks. The inspiration presented is from hierarchical grammar representations, and the method is tested on a subset of Atari games. The main idea pursued in the work is extremely interesting and with likely important implications to recent DRL.<BRK>Overall, I m conflicted by this paper. other macro action papers. In this case, what is traded is learning complexity for a hyperparameter and a significant restriction in how the macro actions terminate. I would love to see the method trained for a more reasonable amount of frames without pre training. Are macro actions used most of the times after some full iterations?<BRK>The authors trained agents that executes both primitive actions and meta actions, resulting in better performance on Atari games. The most effective one is HAR (hindsight action replay), without which the agent s performance reduces to that of the baseline. Overall, this paper could be a great contribution for the following reasons: 1.
Accept (Poster). rating score: 6. rating score: 6. rating score: 3. <BRK>The paper proposes a black box attack method that optimises both the adversarial perturbation and the optimal dimensionaity reduction in a Bayesian Optimization framework. The formulation seem sound and the experiments show improvements wrt competitors in terms of performance and query efficiency with comparable attack success rates.<BRK>This paper studied the problem of black box adversarial attack generation by leveraging Bayesian optimization (BO). Merits of this paper:1) The combination of BO and dimension reduction, which makes BO more efficient under a low dimensional space. 2) Good experiment results. Comments/questions about this paper:1) Comment on "Finally, to the best of our knowledge, the only prior work that uses Bayesian optimisation is a workshop paper by...". Please explicitly state the acquisition function. And how to tune the hyperparameter in the acquisition function?<BRK>In this paper, the authors propose to use Bayesian optimization with a GP surrogate for adversarial image generation. In addition to the standard BayesOpt algorithm, the authors use a variant that exploits additive structure, as well as a variant that uses Bayesian model selection to determine an optimal dimensionality reduction. This is particularly true for methods that require Bayesian model selection and therefore training multiple GPs in each iteration of BayesOpt.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>This function can then be used, for example, as an intrinsic reward signal; indeed, there may be cases where state transitions should be avoided if they are not reversible. The authors tie these ideas into the notion of the arrow of time. This paper was an absolute pleasure to read. The authors anticipate many questions and do well to explain the various subtleties of their method. Overall the experiments are a nice demonstration of the presented ideas. I am inclined to give this paper a high rating, as there was very little that I felt was “wrong” or inaccurate. I have a few questions that I hope the authors can address. 1) The method depends on a random policy (or, more accurately, was empirically validated mainly using a random policy, aside from some very simple environments as far as I can see). 2) Related to the first point, how does this method scale to environments whose state space can only be sparsely covered with a random policy? It seems in this case a task relevant policy would be needed to explore more of the state space, which would place pressure on the h potential function approximator as it has to learn with sequentially correlated inputs. The appeal to the arrow of time is nice and reads well, but it’s also the case that this work can simply be interpreted as “learned state transition reversibility”, with the links to the arrow of time being more of a point of discussion.<BRK>This paper proposes that we learn the “arrow of time” for an MDP: that is, a function (called the h potential) that tends to increase as the MDP steps forward. Similarly, how does your intrinsic reward compare to existing exploration methods (of which there are many, but consider count based methods, curiosity (Pathak et al), random network distillation (Burda et al))? Perhaps this has to be normalized against the log probability of reaching other states from s. This would be very interesting as a potential definition of reachability. I am conflicted on this paper. I like the novelty of the suggestion; it is not something I would have expected to see in an ML paper. However, it’s not clear to me whether or not the method would scale to more complex environments, the current experiments are more like demonstrations (there are no baselines), and the paper is hard to understand without a background in physics. Overall, given the novelty of the suggestion, I lean towards a weak accept. Perhaps move the experiment with the free energy functional to the appendix, and move the experimental details for the other experiments from the appendix to the main paper. This should be equivalent. (If trajectories are all the same length, you could also take a sum over the timesteps.) Similarly, in the algorithm, why do you sample from the dataset? (This is standard practice in supervised learning.) I think it would significantly improve this paper to demonstrate a solution to this problem. In Overcooked, we would hope that this policy learns to pick up onions. Hopefully, this would include states where the onion is placed in a pot, and the h potential would learn that placing an onion in a pot is “irreversible”.<BRK>The paper draws on a wide range of ideas, and proposes novel perspectives on how these ideas might apply in RL. I found many of the ideas thought provoking. The paper is also well written and a pleasure to read. But unfortunately the work falls short of its objective in the experiment section. Not a single baseline is included. I would expect to see comparison to a simple model based method for all the experiments on p.7. Similarly in Mountain car, it seems possible to directly estimate the terrain from the data, without the h potential. As a more minor concern, the fact that the method uses a batch of uniformly random state transitions (as per Sec.4), rather than randomly sampled trajectories is a definite concerned with respect to real world application. It would be interesting to expand on this point. But I do appreciate the insights provided by connecting these through the broader notion of arrow of time developed in this paper, and its connection to reachability and safety. Therefore I am raising my score to weak accept.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>This paper aims at solving graph based combinatorial optimization problems using a new paradigm for Deep Reinforcement Learning. For the camera ready version, it would be nice to use a spell/grammar checker. On the one hand, the MIS problem is already taking an important place in many areas of computer science, and I would suggest concentrating on this task   by changing the title and the summary of the paper, and by just pointing out in the conclusion that the present DRL approach might be applicable to other problems. Besides heuristic algorithms, very little is said about deep learning approaches for solving MIS. For such huge MDPs, it is not clear that we can converge to a stable policy in polynomial time.<BRK>The paper introduces auto deferring policies (ADPs) for deep reinforcement learning (RL). The paper is in principle well written and structured. For instance, saying that deep RL approaches "can automatically learn the design of a good solver without using any sophisticated knowledge or hand crafted heuristic specialized for the target problem" is misleading as thee designer of the RL setup is putting a lot of knowledge into the design. It would be great to acknowledge this by softening this statement. However, it does not really improve upon this well known heuristic.<BRK>Without such a comparison, it is not clear that the improvements are really due to the new ideas like auto deferring, diversity regularizer, etc. The paper proposes a Deep RL approach called Auto Deferring Policy (ADP) to learning a policy for constructing solutions for the Maximum Independent Set (MIS) problem. The ablation and generalization experiments are particularly valuable for getting insight into the performance of the algorithm.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>This work studies factors which promote combinatorial generalization in a "neural network agent" embodied in a 3d simulation environment. While the paper is far from perfect, it is still a very thought provoking work and I believe that it would make a valuable contribution to the line of works on systematic generalization in embodied agents.<BRK>This paper studies systematic generalization in a situated agent. The experiments are well done and worthwhile, and identifying the key factors that affect generalization is a strength of the paper. The title of the paper is "Emergent systematic generalization in a situated agent," which of course implies that the agent has "systematic generalization." The authors go on to say, in the abstract, that "we demonstrate strong emergent systematic generalisation in a neural network agent". The paper s title should also be supported by the findings; to offer a suggestion, something like "Richer environments promote systematic generalization in situated agents".<BRK>It is a bit premature to declare your results as systematic generalization if you can’t show that it actually works for a much larger set of test objects (ideally for all possible objects). The authors present a systematic study of generalization in agents embedded in a simulated 3d environment. For the final version please make sure to go through the paper thoroughly a couple of times and fix all the typos. Why not use all possible objects in the test set?
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>The paper proposes fine tune methodologies for BERT like models (namely, SeasameBERT). This includes a method that considers all BERT layers and captures local information via Gaussian blurring. *  SesameBERT improves performance on some GLUE metrics and on HANS dataset. Weaknesses:* In my opinion, the paper novelty is not significant enough. * Since the suggested methods are generic, It can be more convincing to see results on recent models, and not only BERT. also the first sentences of the section discusses GLUE results not HANS. The performance does not significantly improves, and the methods are applied only to BERT model.<BRK>I have no experience with these kinds of NLU models, so I can t say with confidence whether the architectural additions proposed are well motivated, but to me it feels like there is not a strong justification for adding these particular features to the BERT architecture, and the results do not clearly demonstrate their utility except in the "lexical_overlap" case. Summary:The paper proposes adding two mechanisms to the BERT architecture for NLU. I learn toward rejecting this paper. The method shows some performance gains over BERT on some GLUE tasks, but these are fairly small for the most part, and BERT outperforms the proposed method by a similar amount on a similar number of tasks.<BRK>This paper proposes a novel BERT based neural architecture, SESAME BERT, which consists of “Squeeze and Excitation” method and Gaussian blurring. To capture the local context of a word, they apply Gaussian blurring on output layers of the self attention layer in BERT. It would be nice if the authors provide some evidence that self attention can t learn such a local context feature. *In table 1, their experimental results show a slight improvement by using their method, but it s not significant. More explanation about the relation between local context and adopting heuristics is required.
Reject. rating score: 6. rating score: 6. rating score: 8. <BRK>Summary: In ES the goal is to find a distribution pi_theta(x) such that the expected value of f(x) under this distribution is high. This can be optimized with REINFORCE or with more sophisticated methods based on the natural gradient. In response, the authors advocate for using a flexible family of generative neural networks for pi_theta. Using NICE as a generative model is desirable because it maintains volumes. Can t the Gaussian become very concentrated? The exploitation phase consists in updating the search distribution, and exploration happens when samples are drawn from the search distribution’s tails." The search distribution s tails will have low probability mass, so exploration unlikely. box in the main text for your proposed method, instead of having it in the appendix. In the results, I was disappointed that you required restart strategies. What do you mean by the  global volume of the distribution? What is the volume of a distribution?<BRK>Since this algorithm is proposed to "improve evolution strategy" as a black box optimizer (not for specific tasks), I expect to improve the state of the art performance. Summary:As the title of the paper states, this paper tries to improve evolution strategies (ES) using a generative neural network. I am curious to know if the proposed approach outperforms the CMA ES on Rosenbrock functions. If not, the authors should state that it has been observed the authors preliminary study. P7: "By using fη instead of gη as the push forward map of the NICE model, we ensure that the flexibility brought by the GNN only impacts the tails of the search distribution. Please make is clearer. P8: Experimental results are not very convincing. The experiments are limited to dimension 2, 5, 10 and only a few functions are selected from the BBOB test function suite. What happens if the target is 1e 8, which is the default setting in BBOB? However, this is only 2D. From these results, I am not convinced that the proposed strategy really achieved more flexible distribution than the classical methods, and whether the flexibility contributes to improve the performance.<BRK>Review of “Improving Evolutionary Strategies with Generative Neural Networks”Typically in ES, the distribution of solution candidates come from a hand engineered distribution (i.e.multivariate Gaussian, or other parametrized distributions). The core idea is to model the density function using Generative Neural Networks (GNN, MacKay 1995), and find the parameters of this GNN using tools from the normalizing flows literature for their NICE invertible properties (okay pun intended :) along with GAN style training using historical data from the ES process. They demonstrate their method on traditional blackbox optimization toy tasks (such as Rosenbrok and Rastrigin functions), and also on a few continuous control RL benchmark tasks, to demonstrate improved performance over a strong representative ES algorithm (XNES). Overall, I liked the work as it provides a fresh way of using GANs with another subfield (ES/GA). Although the experiments chosen are not difficult ones, I believe they were chosen for clarity to showcase the method, so I think that is fine (in case there are complaints that they experiments are too simple). (For the record, I was looking to give a score of 7, but the ICLR system made me choose between 6 and 8, and I chose 8.)
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>This paper proposes a simple and one shot approach on neural architecture search for the number of channels to achieve better accuracy. Rather than training a lot of network samples, the proposed method trains a single slimmable network to approximate the network accuracy of different channel configurations. According to this paper, the notable difference between the proposed method and the existing pruning methods is that the pruning methods are grounded on the importance of trained weights, but the proposed method focuses more on the importance of channel numbers.<BRK>The paper targets on learning the number of channels across all layers, under computation/model size/memory constraints. The method is simple and the results seems promising. The main method is based on published "slimmable networks," such that the novelty is limited;2. The method is very simpler to DropPath in [1], which uses DropPath to learn important branches while this paper uses it to learn channels. They are similar. "Understanding and simplifying one shot architecture search."<BRK>In this paper, the authors propose a method to perform architecture search on the number of channels in convolutional layers. The proposed method, called AutoSlim, is a one shot approach based on previous work of Slimmable Networks [2,3]. The paper is well written and easy to follow. Is there any justification for this? Is it that more channels in deep layers benefit the accuracy? If it is the first case, can the authors justify why? Are there any results? Zhuang et al.ICLR 2019[2] Slimmable neural networks.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>This is an analysis paper of pretraining with the tool “influence function”. First, the authors calculate the influence score for the models with/without pretraining, and then propose some implementation details (i.e., use CG to estimate the inversed Hessian). The experiments are conducted on MNIST and CIFAR. 1.The idea of converting a pre trained model with f(w)+||w w*|| is interesting. Also, I am not quite sure about the practical value of calculating influence scores. 2.The experiments are conduct on small scale datasets. I am not sure whether the conclusion holds for larger dataset. 3.Page 7, last paragraph, “we replace all inverse Hessians in (11) with identity matrice” >why? 4.In figure 3, what is the relationship between the two MNIST images, and the relationship between the two CIFAR images?<BRK>The authors derive the influence function of models that are first pre trained and then fine tuned. This extends influence functions beyond the standard supervised setting that they have been primarily considered in. To do so, the authors make two methodological contributions: 1) working through the calculus for the pre training setting and deriving a corresponding efficient algorithm, and 2) adding $L_2$ regularization to approximate the effect of fine tuning for a limited number of gradient steps. I have some questions and reservations about the current paper:1) Does pretraining actually help in the MNIST/CIFAR settings considered? Can we verify those claims using these multi stage influence functions? 3) It d be helpful to get a better understanding of the technical contributions of this paper. What is the impact of $\alpha$ in equation 12 and how does it interact with the number of fine tuning steps taken?<BRK>This paper proposes a multi stage influence function for transfer learning to identify the impact of source samples to the performance of the learned target model on the target domain. They should be replaced with ‘pretrained’ and ‘finetuned’. Even using the conjugate gradient method to reduce the complexity, the total complexity is still high as the number of parameters in a deep neural network is large. In this case, can influence function be used?
Reject. rating score: 3. rating score: 3. rating score: 6. rating score: 8. <BRK>The corpus has been released. The authors use a variety of pre existing techniques applied at large scale with substantial engineering effort to extract a large number of sentence pairs in 1620 language pairs from 85 languages. Structural metadata of Wikipedia, such as cross lingual document alignments, is deliberately not exploited (some discussion is provided but I would have preferred an empirical comparison of local vs global extraction). Overall the methodology presented in the paper is strong and the corpus is likely going to become a valuable tool to build machine translation systems and other multi lingual applications.<BRK>This ICLR submission deals with an strategy for the automatic extraction of parallel sentences from Wikipedia articles in 85 languages, based on multilingual sentence embeddings. The review is delivered with the caveat that I am not an expert in this particulat field. The paper is well written and structured, being within the scope of the conference. I reckon this is a very interesting piece of work, but also that it draws too heavily on previous work from which the study is just an incremntal extension.<BRK>The paper presents WikiMatrix, an approach to automatically extract parallel sentences from the free text content of Wikipedia. The paper considers 1620 languages and the final dataset contains 135M parallel sentences. The language pairs are general and therefore the data does not require the use of English as a common language between two other languages. However, without access to the data and, more importantly, extensive testing of it, it is difficult to say how and how much it would help the advancement of the field. An example of this is on page 6, section 4.2, where the article says that its purpose is to compare different mining parameters, but I do not see any real comparison.<BRK>The paper creates a large dataset for machine translation, called WikiMatrix, that contains 135M parallel sentences in 1620 language pairs from Wikipedia. Training NMT systems based on the mined dataset, and comparing with those trained based on existing dataset, the authors claim that the quality of the dataset is good. Since the data is huge, dimension reduction and data compression techniques are used for efficient mining. The study is the first one that systematically mine for parallel sentences of Wikipedia for a large number of languages.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>The authors propose an adaptive loss scaling method during the backpropagation stage for the mix precision training to reduce the underflow. Compared with the previous work, which scales the loss by human design, and needs to be consistent in all layers. Figures 4a and 4b can be aligned better. Pros:   The method is straight forward and easy to understand.<BRK>Why dynamic loss scaling fails on this case? More detailed analysis are recommended to show the advantage of the proposed method. Instead of using a fixed value or dynamic value proposed by a previous work, this paper adopts a more elaborate way to minimize underflowin every layer simultaneously and automatically based on the current layer statistics.<BRK>It proposes to use statistics from previous activations to compute and adaptive scaling of the loss such that the amount of underflow is minimized.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>The authors propose an approach to cluster subjects into K clusters according to their underlying, often unknown, life distribution. Minor:  A_i^(u) is missing from the definition in the training data. based on the friendster results for K 2,3,4,5 they all seem to produce distinct clusters, so which one should be used? This raises a question: how are the clusters, their members or the number of clusters informing the use case?<BRK>This paper proposes a method to cluster subjects based on the latent lifetime distribution. For example, in the Friendster experiment, the data of 5 months from joining is used for clustering.<BRK>It is doubtful whether such “useful” clusters can be found using the proposed algorithm. (The inclusion of cluster size information in the objective function avoids degenerate clustering results.) Clustering is done in a discriminative manner where the objective function considers cluster sizes besides between cluster differences in lifetime distribution. Were those two covariates included in the analysis?
Accept (Poster). rating score: 6. rating score: 6. <BRK>I found the paper simple to follow and well structured.<BRK>Is there any situation where one of the approximations should be preferred? 1.Section 4 of the paper can be improved.
Reject. rating score: 1. rating score: 8. rating score: 8. <BRK>3.Under what conditions does the proposed algorithm converge and to what does it converge to? I highly recommend making these assumptions clear near the beginning of the paper. Using their notation: P(Y \hat{Y}|\hat{P} p)   p. Importantly, this is not conditioned on \hat{Y} or X. 2.The other scenario considered by the authors is when there are multiple annotators; however, there is substantial literature on learning from multiple noisy annotations which the authors do not review.<BRK>The authors are encouraged to polish this section. This paper focuses on instance dependent label noise problem, which is a new and important area in learning with noisy labels. Section 3 is a bit dense in understanding the estimation of transition matrix.<BRK>This paper also introduces an assumption that the confidence score for each data is given. Given the confidence score, the authors proposed to learn the flip function. Can you explain this? Overall, the paper is well motivated and well written.
Reject. rating score: 1. rating score: 1. rating score: 1. <BRK>For the low resource pair English Amharic, the authors propose to combine context based machine translation (CNMT), which is built by using a bilingual dictionary and then connecting the resulting n grams, with a neural MT system. The CBMT system is built on top of the Google Translate English Amharic system. I vote for rejection because the paper makes some unfounded claims, misses important related work, has some methodological issues and presents unconvincing results.<BRK>This paper aims to combine a traditional CBMT system with an NMT system. Cons:  A lot of the techniques described for building the traditional CBMT system are obsolete these days and people prefer neural methods. Pros:  The idea of using additional outputs to the NMT system and outputs from a context aware system is neat.<BRK>This paper presents a machine translation system based on a combination of a neural machine translation system (NMT) and a context based machine translation (CBMT). In light of the relatively low novelty and the lack of compelling empirical performance for the proposed combined MT system, I do not feel that this paper is appropriate for ICLR at this time.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>This paper focuses on non spiking Hudghkin Huxley model, which is different from existing works on spiking neural network based Hudghkin Huxley model. There are many ways of using neuron firing model as unit to construct neural networks. They don’t include any other SNN model in the paper for experimental comparison. They also mention a few SNN works that work well on MNIST in the related work section which actually have better accuracies than their model. So it is inappropriate to say this proposed method is a state of art neuro inspired method, Because others perform well on MNIST as well, and their limited experiments only investigate MNIST and CIFAR 10, which are less interesting generally. Overall, the idea is somehow interesting, but the experiments are weak.<BRK>The paper overall reads nicely. Now this may or may not be the claim of the paper. It’s ok if it is not; still showing competitive performance is somewhat acceptable, but certainly further insight would make the paper stronger. Therefore, one can conjecture that CWA plays a normalization role in biological neural networks.” Therefore, I was expecting CWA+BN to work similarly as CWA for CIFAR10.<BRK>Using a few simplifying assumptions, the authors use conventional backpropagation to train DNN  and  CNN based models and demonstrate that their accuracies are not much lower than the state of the art results. The paper is well written, sufficiently detailed and understandable. It is also inspiring to see that this model can be derived based on a relatively accurate biological neuron model. My main question is actually related to the potential impact of this study.
Accept (Poster). rating score: 8. rating score: 8. rating score: 6. rating score: 1. <BRK>The authors propose a new method for model agnostic meta learning (MAML) based on evolution strategies (ES) rather than policy gradients (PG). Empirical results are convincing: ES MAML consistently outperforms PG MAML (or is at least not worse) on various tasks. The paper is well motivated and well written. Comment/questions:  PG MAML is known to be very sensitive w.r.t.hyperparameters, is this also the case for ES MAML? How were good hyperparameters found for ES MAML? While this work focuses on RL, it would be interesint to see if ES MAML is also advantages over vanilla MAML for common few shot learning image classification problems.<BRK>The paper introduces a new MAML algorithm based on evolutionary strategies (ES) for reinforcement learning tasks. Compared to prior MAML algorithms requiring an estimation of the Hessian, ES MAML demonstrated to be more stable and efficient. Furthermore, also other papers [1,2] showed that very simple ES algorithm can perform very well on weight optimization of policies. By now, it is well known that hyperparameter tuning can improve the performance of RL algorithm quite a bit and is sometimes even the main factor for superior performance. I would like to reply: In fact, this is not a very useful answer.<BRK>This paper proposes a method, ES MAML, for optimizing the Model Agnostic Meta Learning (MAML) objective by using Evolution Strategies (ES) gradients instead of policy gradients (PG) as in the previous approaches in the literature. As a result, the use of ES avoids the need of second order derivative estimation resulted from PG in computing the gradients of the MAML objective; second order derivatives in MAML are known to be tricky for proper estimation. The experimental results are rigorous and promising. However, given that the paper attempts to address an important problem (stably optimizing the MAML objective) with interesting perspective (using ES), that the proposed methods are well developed and extended, and that rigorous experiments to evaluate the proposed methods are provided, this paper could be an interesting contribution to the conference where it can encourage different perspective beyond the gradient policy view for MAML problems. 1.On page 3, with reference to the text “These issues: the difficulty of estimating the Hessian term (3), the typically high variance of ∇θJ(θ) for policy gradient algorithms in general, and the unsuitability of stochastic policies in some domains, lead us to the proposed method ES MAML in Section 3.” I agree that the use of ES gradients avoids the need of second order derivative estimation; however I am not very sure if we could say that ES MAML here can address the high variance issue of PG given that ES can also suffer from high variance and that there is a rich literature in reducing variance of PG.<BRK>The approach is validated on a number of experiments. Unfortunatly, I am unable to accept this paper for a number of reasons. Experiments:  I am not an expert of MAML, but i would not consider this as different tasks, just as different environments for the same task. Since ES are central to the paper, an algorithm that would not even be considered a baseline at any conference in that field is difficult to accept. Without this, it can be very difficult to find reasonable solutions. In this case, the result would be pretty artificial, because real ES would adapt their step size. "Neuroevolution strategies for episodic reinforcement learning." Reducing the time complexity of the derandomized evolution strategy with covariance matrix adaptation (CMA ES). the only curve which is is available for both algorithms has the same performance. CMA ES with optimal covariance update and storage complexity.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>The only way then to make risks equal is by *increasing* the risk in all the other subgroups. This is not always desirable, so this paper presents a method for finding a model that is as fair as possible without doing harm. Furthermore, we have two classifiers $h_1$ and $h_2$. So how can you claim that the optimal Pareto fair classifier does no harm? Minor comments:  the plots don t seem to be vector graphics<BRK># 1403GeneralThe paper proposes a method to achieve the no harm fair model that will lie on the Pareto optimal front, but has the minimum risk discrimination gap. While the problem formulation is interesting, the paper is not very easy to follow and there are some aspects that the paper needs to get improved to get published, in my opinion. Where is the information about the risk disparity? The quality of the figures is very poor.<BRK>This paper considers the notion of "no harm" group fairness, i.e.trying to reduce the risk gap between minority and majority groups without excessive reduction in performance on the majority groups. The mathematical formulation of the problem around the notion of Pareto optimality also seems reasonable. Cons:My concerns are related to counter intuitive experimental results and lack of clarity in parts of the presentation. Next, it appears that "Naive+Zafar" (it also would be helpful to have a brief discussion of the baselines considered) approach was not configured to eliminate A/S disparity as suggested by poor results on the D/A/NW and D/A/W, while it performs very well on other subpopulations. Results on the Adult and German Credit datasets are very similar across competing methods.
Accept (Talk). rating score: 8. rating score: 8. rating score: 8. <BRK>The model otherwise makes use of a fixed number of object slots and a GNN transition model, similarly to prior approaches. The authors back up their method with nice results on 3D cubes and 3 body physics domains, and reasonable initial results on two Atari games, with ablations on the different components showing their contributions, so I would give this paper an accept.<BRK>This paper tackles the problem of learning an encoder and transition model of an environment, such that the representation learnt uses an object centric representation which could favor compositionality and generalisation. This is trained using a contrastive max margin loss, instead of a generative loss as previously explored. I found the presentation of the contrastive loss with margin to be clear, and the GraphNet is also well supported (although see question below).<BRK>This paper aims to learn a structured latent space for images, which is made up of objects and their relations. I worry that all the evaluation has shown so far is that this model can efficiently represent the state transitions that it has observed. This paper has a simple, well motivated method. The authors note that it was beneficial to only use the hinge on the negative energy term.
Reject. rating score: 3. rating score: 6. rating score: 8. <BRK>This paper investigated the GNN based solvers for the 2 Quantified Boolean Formula satisfiability problem. This paper points out that GNN has limitations in reasoning about unsatisfiability of SAT problems possibly due to the simple message passing scheme. To extend the GNN based SAT solvers to 2 QBF solvers, this paper then turns to learn GNN based heuristics that work with traditional decision procedure, and proposes a CEGAR based 2QBF algorithm. Overall, the topic of combining logic reasoning and graph neural networks is interesting. But it is not clear how important is the targeted 2 QBF problem, except for testing and finding the limitations of GNN. In other words, this paper picks up a specific class of model for a very specific class of problem, which lacks sufficient and convincing motivations. Although GNN achieves success in solving SAT problems, it is not necessary that GNN is a must for solving the 2 QBF problems. Also, when analyzing the limitations of GNN, the paper makes conjecture only based on empirical results. It would be much more insightful to provide some theoretical analysis so that the paper can inspire other researchers working on different problems. Based on the above reasons, I would like to recommend a weak reject for this paper.<BRK>This paper first presents GNN architectures to solve 2 QBFs. They show that similar GNN architectures which work for propositional logic do not transfer to 2 QBFs, and provide some explanation for the result. Finally, they show how GNN modules can be used to speed up existing 2 QBF solvers instead. The claims of the paper are well presented and empirically validated. It will be good to have more overview of 2 QBFs and existing solvers. How popular is CEGAR and why the improvements to its performance is important ? Is there a reason to use such small datasets ? From the results, I don t think any of the conclusions will change significantly from the dataset size, but still its better to use larger datasets. There are too many dataset splits and captions of tables do not provide any information.<BRK>Instead, they show that GNNs can be useful as a heuristic candidate  or counterexample  ranking model which improves the efficiency of the CEGAR algorithm for solving 2QBF. This is a clear, well written, and well structured paper, and I support accepting it to ICLR. That being said, I am not as familiar with the literature on neural solvers for logic problems, so I base my review on the content within the paper more than its context in the field. I can’t find much to fault with the writing and arguments. The GNN architecture for 2QBF (Section 2) is simple, elegant, and well motivated as a minimal extension of successful SAT solvers. The arguments in Section 3 are convincing, and make a good case for why an algorithm such as CEGAR is necessary. Finally, the metrics in Section 4 are clearly interpretable and well justified. A couple questions and concerns:In Section 3, The amount of training data (up to 160 pairs of formulas for predicting satisfiability) seems to be very small for a machine learning problem. In Section 4.6, are the models re trained on these new distributions, or on the data described in Section 4.2? And minor points on clarity:* “ ” for the baseline seems a bit awkward; consider spelling out “vanilla”? Similarly, I wonder if there could be more informative names for GNN1, GNN2, GNN3, and GNN4?
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>The paper proposes a set of rules for the design and initialization of well conditioned neural networks by naturally balancing the diagonal blocks of the Hessian at the start of training. Are the experiment results sensitive to the choice of different models with different width and layers or different batch sizes?<BRK>The authors propose a new initialization scheme for training neural networks. The initialization considers fan in and fan out, to regularize the range of singular values of the Hessian matrix, under several assumptions. Since these methods are highly related to the proposed method, it would be great if the authors could show time complexities and performance differences of these methods as well. However, it lacks comprehensive comparison and consideration of more recent neural network layers. 1.The authors agree that batch norm requires different initialization schemes that are not included in this paper.<BRK>I think the topic of the paper is interesting, though I think in its current form the paper is not ready. While the authors attempt to formalize their intuition, as they mention in the work itself, such works are somewhat outside mathematical proof. This is due to the many approximations needed, and assumptions that can not hold in practice. The extended Gauss Newton approximation is indeed the Fisher matrix, I think as discussed in Martens  work (which is heavily cited) though in other works as well. Relying on the expected squared singular value should be motivated better. Some statistics over multiple runs. Overall this is a repeating theme in the work. More empirical evidence for any such choice. Table 2 is not referenced in the text. And definitely we have not heard the last word on initialization. But I think the paper needs to be written more carefully, with a more thorough empirical exploration, showing different architectures, different datasets.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>(3) The authors  finding that the agent is conservative and does not bid high appears interesting. The authors propose a deep learning agent for automatic bidding in the bridge game. Experiment results demonstrate state of the art performance with a simpler model. More study on whether the agent should bid high could greatly enrich this paper. I ve read the rebuttal. It is recommended to weak reject the paper. There is an obvious contribution of using a simple model to reach state of the art performance.<BRK>The paper presents a bidding agent for the card game contract bridge trained through selfplay. Contract bridge is an imperfect information game which has a bidding and a playing phase. A strength of the paper is the interpretation of the training process and its statistical visualization. The authors plan to publish their code, the trained model and the experimental data so the results will be reproduceable for future work. Overall, I have troubles in assessing the novelty of the system, since it is not my area of expertise. A concern is that there might be better fitting venues for this topic than ICLR.<BRK>Simple is Better This paper develops a method to train agents to bid competitively in the game of Bridge. The authors focus on the bidding phase of the game and develop a model to predict the best bid to make at each turn of the phase. While the application is interesting, there is not much novelty in the method and factoring that, the empirical study is lacking as well. Pros:1.Interesting application of self play to a multi agent setting with limited communication! Also, the training curves are missing error bars. Given that they build the representation using knowledge of bridge, I m not sure if this is an appropriate statement to make.
Reject. rating score: 3. rating score: 3. rating score: 8. <BRK>Summary :The paper discusses the use of maximum entropy in Reinforcement Learning. Specifically, it relates the solution of the maximum entropy RL problem to the solutions of two different settings, 1) a ‘meta POMDP’ regret minimization problem and 2) a ‘robust reward control’ problem. Both cases follow with simple experiments. I feel the paper could have been written more clearly. There seem to be too many definitions and descriptive examples that diverge the attention of the reader from the main problem setting. There are quite a bit of grammatical errors in the paper, making it even harder to follow. Moreover, the experiments are restricted to the bandit setting and do not provide any empirical evidence on the MDP centered theory. Overall, although the paper does well in motivating the problem, the lack of rigorous experiments and poorly structured writing advocate for a weak rejection. Comments/questions:  Can the authors comment on why it makes intuitive sense to study the meta POMDP and robust reward control problem settings together? I see the commonality being the reward variability, but is there something else? It would be more intuitive to note the optimal solution as pi* and not pi (Lemma 4.1).<BRK>I’d encourage the authors to more clearly formalize the meta POMDP as well as the relevant assumptions that lead to the results of Section 4.2. It suggests that MaxEnt RL works well in the setting where there is uncertainty about the reward function. This paper aims to theoretically understand the reason that MaxEnt RL (RL with an entropy bonus) works so well. First, for any instance of a class of “meta POMDPs” where the agent only has a *belief* over the goal trajectory, there exists a reward function for which MaxEnt RL on that reward function is the optimal solution to the meta POMDP. As currently defined, I don’t agree with Section 4.1, though I do think there is a formalization which makes everything work (though that formalization does not seem realistic to me). I don’t understand how the goal reaching problem is reduced to the single goal trajectory problem: I believe the current reduction is *not* solving a goal reaching problem. However, I question the applicability of the theorems to the success of MaxEnt RL. I’m also confused about Section 4.3. It proves two main theorems to support this. However, the meta POMDP defined in the reduction assigns 1/6 probability to each such trajectory, which by the semantics of the meta POMDP means that the agent “actually” wants to choose one of those trajectories in particular, but doesn’t know which one is appropriate. The paper is not very clear. The quality of exposition could be improved significantly. It seems quite likely that some of my critiques are misguided (especially the one about Section 4.2), and I encourage the authors to point this out in the rebuttal. This general problem persists even if you have a belief over the goal state, rather than being certain about the goal state. My primary complaint is that these theorems don’t apply to the case they are meant to explain: the authors say they want to explain why MaxEnt RL works in practice, but their explanations and theorems center on cases in which the reward is unknown. For the rest of the review, I’ll evaluate the paper from that perspective.<BRK>The paper investigates the reason behind the success of MaxEntropy in reinforcement learning theoretically, connecting it to  robust control. I think that the robust reward is an interesting perspective and the paper is also well written. I disagree with the exploration paragraph in sec.2.While the final applied agent might be deterministic, using a stochastic agent for exploration during learning is helpful. You write "Only the oracle version of fictitious play, which makes assumptions not made by MaxEnt", maybe I missed it but I didn t see what assumptions the oracle made. MaxEnt has been very successful in inverse RL where we try to find the reward, which seems connected to the conclusions here about robustness to reward perturbations. While adding analysis on IRL might be outside the scope of this paper, something at least should be said about maxEnt and IRL and the connection to the current results.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>This paper investigates the problem of modeling insideness using neural networks. To this end, the authors carefully designed both feedforward and recurrent neural networks, which are, in principle, able to learn the insideness in its global optima. This paper presents an interesting problem of learning to predict insideness using neural networks, and experiments are well executed. It is still weak to support the claim that learning to predict insideness is useful to improve segmentation. To summarize, although the problem and some experiment results presented in the paper are interesting, I feel that the paper lacks justifications on the importance of the problem and insights/discussions of the results.<BRK>This work is not like other segmentation publications that just propose a network and start training, but perform some deep analysis about the generalization capability of the existing network architectures. (2) What representations do DNNs use to address the long range relationships of insideness? (4) The results are interesting and useful. I think this work will have an impact in semantic segmentation field.<BRK>The paper shows that deep nets can actually learn to solve the problem of "what is inside a curve" by using a sort of progressive filling of the space outside the curve. The paper suceeds in explaining that and in pointing out the limitations if standard learning to address this problem. What is the gain of using deep networks with regard to rather old techniques?. Advantages are not clear in the text. It seems that these recent techniques already solved the "insideness" problem and even learnt how to fill the inside in sensible ways...Then, what is the gain of the proposed approach?.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>In this paper, the author derived a tight ell_1, which is not the symmetric norm, robustness certificates under isotropic Laplace distributions.<BRK>The authors show that this bound is tight for binary classifiers. 1) The major contribution of this paper is the tightness under the \ell_1 norm for a binary classifier. 4) Experiments on the undefended classifier has to be in Figures 6  7 and 8.<BRK>Therefore, although I agree that a tighter certified bound compared to (Lecuyer et al) is new, the paper seems to be a bit incremental.
Accept (Poster). rating score: 8. rating score: 8. rating score: 6. <BRK>The second contribution is to propose a dictionary learning algorithm that uses ISTC and can be trained with gradient descent. Results show that the model outperforms AlexNet on the Imagenet benchmark. The paper is well written. While this is an interesting result, it is not very closely linked to the main focus of the work.<BRK>## CommentsThe paper is well written and the exposition is clear. However, this approach has been previously explored in the literature (Mahdizadehaghdam et al.2018), the authors just apply it on top the extracted features.<BRK>Does it mean that you would actually have blocks per each \alpha_n for some N indices (this again refers to previous comment on clarity)? The scattering operator of the second and higher orders tends to produce a large number of coefficients.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>The method is based on finding prototype numbers, and then representing numbers as a weighted average of the prototype embeddings, where the weights are based on numeric proximity. I think the paper could use a better motivation for the prototype based approach. For example, I would expect 1960 and 1960.1 to behave very differently in text, because one is a year and the other isn’t. I was not able to understand the SOM portion of the method, it is not self contained within this paper. It is true that the submission s approach produces general purpose embeddings that can be re used, unlike (Spithourakis & Riedel, 2018).<BRK>Then, each numeral is represented as a weighted average of prototype numeral embeddings. There are two basic motivations of the paper: (1) Most of the word embedding methods do not embed numerals correctly. The second one is well addressed but for the former one, it has been shown in recent work [1] that most of the embedding methods do have numerical reasoning capabilities. So, it would be great if, for the results in Section 4.3 instead of using cosine distance, some neural models could be utilized for evaluation (3 layer MLP similar to [1]). It would be better if mean and variance across multiple runs are reported.<BRK>The paper proposes a novel method for embedding numerals which can be learned by using neural word embedding learning techniques. A series of 4 empirical studies have been presented. First, the paper confirms that the proposed method does not negatively affect non numeral embeddings. Overall, this paper has a novel contribution. In terms of training, I think it is not hard to extend the method to full language model training (using softmax). Minor comments and questions:1. The log sigmoid in equation 6 is a bit strange, isn’t it log sum exp(). Why do you create a new dataset for the experiment in section 4.3?
Accept (Poster). rating score: 8. rating score: 6. rating score: 3. <BRK>The paper proposes that in these circumstances one may use a generative model that learns the data distribution using federated learning methods with provable differentiable privacy guarantees. Thus one has simply traded the problem of needing to inspect data to model the final algorithm (whcih could be discriminative) and has to deal with the problem of needing data to inspect the intermediate, generative model (which is also learned using federates, DP guaranteeing ways).<BRK>This work presents a method for using generative models to gain insight into sensitive user data, while maintaining guarantees about the privacy of that data via differential privacy (DP) techniques. The authors do a good job of fleshing out the intended use cases of their training scheme, and present a pair of experiments that are well chosen for illustrating the utility of generative models when dealing with private data. Cons:Although likely of practical use, the work seems to be lacking in novelty in several respects.<BRK>The paper is well written. However, the readers should have reasonable background on DP, GAN, federated learning, and generative models, or it will be hard to read through.
Reject. rating score: 1. rating score: 6. rating score: 8. <BRK>However, I do not think that learning an upper bound of the target error helps to determine the value of H, as there is no justification that the gap between the target error and the model error is small theoretically. The authors claim that it is expensive to retrain the model error for the current policy at every step, thus they use some reference policy. Overall the paper is well written. The paper proposes an interesting question: how to adaptively change the planning horizon based on the state dependent model error?<BRK>However, if we want to drastically reduce the sample complexity, we need longer planning horizons. Therefore, we should be looking further in this direction but this is out of scope for this paper. Model Learning:  Good idea to update the conclusion and treat the online model learning as future work. Axes g   i can be reshaped in a separate figure. Conclusion: The problem of learning good policies from partially correct models is very interesting and important. The proposed approach is technically sound and reasonable. Furthermore, the quantitative performance is compared to state of the art methods. This horizon is really short especially for problems with strong non linearities and high sampling frequencies. The specialized online model learning algorithm seems quite hacky. It feels like it was introduced last minute to make it work. Could the authors please update figure 3 as the figure has too much whitespace.<BRK>Pros  I think the novelty in this paper is most appealing for me to vote for a clear acceptance. The growth of model based reinforcement learning is in a big need of a framework to work with the planning horizon. Still, I think there is a lot of room for improvement, as summarized below. Cons  One thing that concerns me is that the maximum horizon H looks very small. A max horizon of 3, 5 or even 10 is still much smaller than the value we usually use in planning based reinforcement learning (MPC in your case). Or maybe that scale of horizon is not common in Steve and thus not tried in the experimental section? AlgorithmsThe used baselines in the paper are generally not considered to be state of the art.
Accept (Poster). rating score: 6. rating score: 6. rating score: 3. <BRK>This paper focuses on the problem of  neural network compression, and proposes a new scheme, the neural epitome search. The learned weight tensors are independent of the architecture design. It can incur less performance drop. However, there are some concerns to be addressed. Authors stated that the proposed method is independent of the architecture design.<BRK>In this work, the authors describe a technique for compressing neural networks by learning a so called Epitome (E), and a transformation function (\theta) such that the weights for each layer can be constructed using \theta(E). I think it would be useful to mention that this is implemented using neural networks in your work for clarity. The main idea of this paper is really interesting, and the experimental results which compare against other recent techniques also validate the proposed technique.<BRK>In this paper, the authors learn epitomes, which are small weight tensors which can be used with a learnt transform to produce tensors of an appropriate size (e.g.the sizes used in MobileNet v2). The results look good, but error bars,on the CIFAR experiments at the very least, would be appreciated. The main sell of the methods appears to be on the basis of MAdd reduction. "for fair comparisons"  > "for a fair comparison"The method is poorly explained; I have read Section 3.2 several times, and I m still not entirely certain of what s going on.
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>The idea sounds reasonable. Actually there quite a few papers  on mining parallel sentences from comparable corpora such as Wikipedia, as shown below. Without such comparisons, it is difficult to judge the effectiveness of the proposed method and the quality of this work. Similar idea, mutual boosting between data selection and model training, has been explored in the following paper, although not for machine translation. What s the difference between these two papers?<BRK>This paper analyzes the following aspects of self supervised machine translation (SS NMT):1. 2.Closeness to translation tasks: For the extracted sentences, as training goes on, the complexity decreases to the average level of potential bilingual corpus; the similarly of extracted sentences becomes closer. The authors also find that a joint process of extracting data and training models outperforms training a model with the extracted data. The analysis is solid, but the findings are in general not quite surprising to readers. Besides, how should we leverage the findings in the paper?<BRK>This paper describes a method for training self supervised neural machine translation systems from a document aligned comparable corpus (Wikipedia in en, fr, de and es). The main issue with the paper is the lack of proper baseline comparison. The authors compare only with supervised and unsupervised systems trained on different corpora, and not with other approaches based on pseudo parallel data extraction from Wikipedia. EDIT:I have increased my score based on the author s response.
Accept (Poster). rating score: 6. rating score: 6. rating score: 3. <BRK>I understand that "warp" is the combined Rt matrix that is estimated using the two views and Equation 3, assuming that the "d"s are correct. DECISION: Very clearly written paper, simple idea executed wellThe paper is clearly written and well organized. It uses a simple idea, and performs sufficient number of experiments to explore the idea. It is not very novel, but the paper shows its applicability with multiple architectures as a bonus. The figures showed results almost only from their method. Good attempt though.<BRK>Comments from other reviewers and revisions have deliberately not been taken into account. After publishing this review, this reviewer will participate in the forum discussion and help the authors improve the paper. ## OverallThe article proposes a method of modifying image generating networks to also produce depth maps in an unsupervised way by enforcing rotational consistency. The fix for this is simple and two fold: for each depth image, subtract the minimum value and divide by the range (to normalize it and increase contrast), then write in the caption or as a legend that white is closer to the camera and black is further back. ### Intro  Fig.1 normalize image   The literature section in intro mentions "For all methods, 3D annotations must be used..."   that s not true. ### ConclusionAll good, albeit a bit short.<BRK>The submission proposes a technique to learn RGBD image synthesis from RGB images. The technique can be used in conjunction with various models, such as PGGAN, StyleGAN, and DeepVoxels. The main issue I see with the paper is the number of results provided. Sec.3.3 states that “the depth of the background is smaller than that of the face [for DeepVoxels]; however, this does not occur when the proposed loss is used”, however fig. Sec.3.3, “[...] use the 2D CNN”: I would replace “the” by “a”. Sec.B “the later voxels are ignore[d]”
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>This paper introduces a new upper bound of unsupervised domain adaptation, which takes the adaptability term lambda into consideration. The new theory can be expanded into a novel algorithm. Specifically, the authors assume that f_s and f_t are from some hypothesis space H. Then relaxing f_s and f_t to f_1 and f_2, we can turn the problem into a minimax game between f_1, f_2 and feature extractor g. To further implement their method, the authors propose to constrain f_1 and f_2 with source accuracy and target pseudo label accuracy. Based on the margin theory, the authors also introduce the cross margin discrepancy, which increase the reliability of adversarial adaptation. However, I have several concerns:*The proposed theory of equation (4), (5), and (6) is problematic. h is the hypothesis which belongs to a hypothesis class H. f_s and f_t are true labeling functions, and do not necessarily belong to the hypothesis space H. In this sense, the inequality of equation (4) does not hold. Thus, in spite of the good performance of the proposed method, the proposed upper bound is not reliable. Besides, how does each part contribute to the performance gain? Is it from the novel loss function or just the new adversarial adaptation method itself? A proper ablation study would be helpful.<BRK>The authors propose an approach based on an upper bound on target domain error for the taskof unsupervised domain adaptation (where one does not have access toany labels in the target domain). In my opinion, not ready for publication. * abstract:  .. to address the problem for unsupervised domain  adaptation. >>  to address a major problem facing many unsupervised  domain adaptation techniques . * page 2, several rewordings in: "The reason is obvious, as marginal  distributions being matched for source and target, it is possible  that samples from different classes are aligned together, where the  joint error becomes non negligible since no hypothesis can classify  source and target at the same time." Also, I wouldn t use "The reason is  obvious"... * page 2:  our proposal can degrade to some other methods  >>  .. can reduce  to several other methods .. * in lines 1 and 2 on pg 3, the simplification from line 1 to 2,  explain the major reasoning (perhaps in the appendix if you don t  have space): there are number of terms added and subtracted (which  is understandable), but hard to keep track of what simplifications  are being carried and where the terms move (too many terms)...*  the following theorem holds  >>  the following bound holds  (or  inequality, etc.) * Is derivation 3 from triangle inequality? (add that explanation to  line 3)* hard to parse (missing pronoun):  the above upper bound in minimized when h f_s thus  equivalent to .. *  is capable of  >>  is capable to do so  (and at this point, is not  yet clear how the bound helps avoid the problems with distribution  matching.. )* Figure 1 (and subsequent figures): suggest put A, B and A  and B   for the two classes and domains, inside the circles, so it s easier to see what  the source and target domain classes are (dotted boundary is hard to discern).<BRK>Summary This paper presents a novel theoretical analysis for unsupervised domain adaptation by revisiting the \lambda joint error term charactering adaptability in the seminal analysis of Ben David et al.They propose to replace it by considering discrepancy between information on constrained class hypothesis and a possible discrepancy term that related the learned model with the class A cross margin discrepancy is proposed in the multiclass context. The experimental evaluation is interesting with good results reported on the two problems considered. I think that some parts could be improved in terms of presentation, in particular The paper contains many typos that make sometimes the reading difficult. I think the authors should expand this by also taking into consideration the bound of Mansour et al., COLT 09 which has some links with the proposed approach (check their comparison to Ben David s bound). About original proposal. I am wondering if the authors could discuss the relationship between the value of \gamma and the expressiveness of the considered model. Indeed, since the pseudo labels are obtained from a classifier that make use a lot of source information, one may think that their performance is rather related. In the experimental evaluation, the tuning of the different parameters, in particular \gamma and \mu, is not particularly discussed and there is probably an issue. A discussion on this point would be welcomed. ": I would expect an inequality somewhere, otherwise everything can be added to the general objective function. Table 1 and Table 2: use a third identifier different from the second for the last version of your method.
Accept (Poster). rating score: 8. rating score: 6. rating score: 3. <BRK>The paper gives theoretical analyses, in terms of the reduction in the overestimation bias, as well as the convergence of a class of generalized Q learning methods including Maxmin Q learning. Overall this is a well balanced paper which proposes a reasonable new idea, simple but effective, backed by sound theoretical analysis and well executed experimental evaluation.<BRK>Overall, I believe the idea of the paper is novel and interesting, but further improvements should be added in order to improve the score the paper. The main contributions of this paper are three folds: 1) It provides an inspiring example on overestimation/underestimation of Q learning.<BRK>The paper tackles the problem of bias in target Q values when performing Q learning. The method is motivated as a way to control over/under estimation. The paper proposes a technique for computing target Q values, by first taking the min over an ensemble of learned Q values and then taking the max over actions. The idea of computing a target value as the minimum of an ensemble is well known in continuous control.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>Summary   The paper proposes a verification method for instance wise feature explanations. The verification framework uses an RCNN to identify two types of tokens a) the tokens that are not predictive of outcome b) the subset of clearly relevant tokens for prediction. The data used for RCNN is a pruned version of the data used to train the  black box. a) % instances for which the most important tokes provided by the explainer is among the non selected tokens, b) % of instances for which at least one non selected token is ranked higher than a relevant token, and c) Average number of non selected tokens ranked higher than any obviously relevant tokens. I can train the RCNN neural network with half the data (and satisfy the properties the authors mention) and my evaluation would change significantly. That said, I think the assumptions of the framework should be much more explicitly mentioned. 3.The std deviations in the experiments are very high. 2.Page 3   typo   "....explainer should provide different explanations for the trained model on real data than when the data..." Update  I have read the authors response. If the pruned dataset is created using an RCNN, then it is not clear if the RCNN is used to just explain itself or all other methods as well. It is also unclear how generalizable this verification process is to other domains.<BRK>"We do not introduce an explanation generation framework, as explainers do. " The proposed evaluation requires the explainer of the NLP model to agree with the RCNN in terms of relevant or irrelevant words, to be considered a good explainer. The RCNN model which is defining the relevant and irrelevant tokens for a prediction task is in fact stating that we can explain the decision of an NLP model in terms of relevant and irrelevant tokens. •	The example used to explain the difference between feature additive and feature selection based explainer methods, is confusing. Hence, the proposed RCNN can also be considered as an explainer. " Hence, with our current instantiations, any domain agnostic explainer can be evaluated"   The experiment to validate this claim are missing. "The novelty of our paper consists in the fact that, to our knowledge, it is the first to (1) shed light over a fundamental difference"   This is not a technical novelty. The authors did not have any experiments on images or tabular data. Authors assume for each input text, there is a subset of tokens that are most relevant and that are completely irrelevant to the final prediction task. The performance of an explainer is evaluated in terms of overlap between the RCNN most relevant tokens and the most relevant tokens provided by the explainer as an explanation.<BRK>Overview/Contribution: The authors present a explanation generation framework that help validate post hoc explanations when the explanations are generated based on feature selection. Overall, the paper is not ready to be accepted to the conference and I describe my rational with the following strengths and weaknesses. Strength: + Explanations make models more transparent and easy to understand for end users of the decision made by complex models such as deep neural networks [1]. + The paper is easy to read and follow. Explanation generation is gaining traction in the deep learning community especially for critical applications such as healthcare and security. However, the authors claim that post hoc explanations currently are only evaluated for only simple non neural model. As a generalized pos hoc explanation generators verification framework, the experiments are seriously lacking and are not well designed to illicit broad applicability.
Accept (Talk). rating score: 8. rating score: 8. rating score: 6. <BRK>  Summary This paper considers the problem of developing neural processes whichare translation equivariant. The authors derive a necessary and sufficientfunctional form that the neural process \Phi function must exhibitin order to be permutation invariant, continuous and translationequivariant. Results in several experimental settings are given: 1d syntheticexperiments, an astronomical time series modelling experiment, asim2real experiment, and several image completion experiments.<BRK>The paper introduces ConvCNP, a new member of the neural process(NP) family that models translational equivariance in the data, which uses convolutions and stationary kernels to aggregate the context data into a functional representation. The evaluation is extensive, and the results are significant. This inductive bias was never built into NPs, and it remained unanswered whether the NP can learn such a behaviour. Even with the latent variable, if the encoder is seen as part of the model, then the NP isn’t consistent (pointed out in the last paragraph of section 2.1 in the ANP paper).<BRK>The paper describes a method for model neural for neural processes considering  translation equivariant embeddings. Maybe, the author could add more empirical results to it to show the impact on translation equivariant examples. The empirical results are also narrow as there is not much other competitive work. State of the art is quite relative if authors come from a quit narrow area which not much papers on the topic and data sets. Could you add some examples where this improves results. Maybe the authors might address this in their introduction more.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>From my point of view, this work is in a too preliminary state to be published at ICLR<BRK>The paper says “in standard MBRL framework”, what is the standard MBRL framework?<BRK>Still, the experiments are interesting in that they reveal that the magnitude of the mismatch is probably more serious than most RL researchers believed. I like the topic of this paper but there are several aspects which I see as making it weaker than my acceptance threshold.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>This paper introduces a transductive learning baseline for few shot image classification. The proposed approach includes a standard cross entropy loss on the labeled support samples and a Shannon entropy loss on the unlabeled query samples. Overall, I think this paper has significant contributions of proposing a novel few shot baseline that establishes a new state of the art and would recommend weak accept. An additional large scale benchmark is also introduced to facilitate  the few shot learning research.<BRK>This paper provided a baseline method for few shot learning. The experimental results on several benchmarks show the improvements over state of the art approaches. It is a comprehensive study of the methods and datasets in this domain. How can the simple baseline work sowell? However, I think the acceptance of the paper could benefit the community and I encourage the author can try this on some new benchmark.<BRK>The authors propose a fine tune based few shot classification baseline, which has been validated effectively on several datasets, including Mini Imagenet, Tiered Imagenet, CIFAR FS, FC 100, and Imagenet 21k. In addition to the method, the authors also provide concrete experimental setting and new evaluation proposals. Does it mean we represent novel classes based on the properties of the meta train classes? How will the method perform when working on few shot learning problems with a large distribution shift? 4.It s better for the authors to emphasize and differentiate the transductive fine tune and the inductive counterpart in the paper.
Accept (Spotlight). rating score: 8. rating score: 8. rating score: 6. <BRK>The paper proposes a Sequential Latent Model which represents the knowledge history as some latent representation. Additionally there is human evaluation that also shows significant improvement. The contribution of the paper is the novel approach to selecting knowledge for open domain dialogue. This work is significant in that by improving knowledge selection we see a subsequent improvement in response generation quality which is the overall downstream task within this problem space. I believe this paper should be accepted because of the significant and novel approach of modeling previous knowledge sentences selected. > "which subsequently improves knowledge grounded chit chat."<BRK>Post author response edit: The authors did a good job of addressing many of the concerns of reviewers. I believe with these new results (esp to reviewer 4), they will have a stronger version for the camera ready. The authors propose a novel architecture for selecting knowledge in knowledge grounded multi turn dialogue. Their knowledge selection module uses a sequential latent variable scheme, and is claimed to be able to both handle diversity of knowledge selection in conversation as well as leverage the information from the response. A few things bother me with the paper. Are they generally indicative of what is seen throughout the human evaluation?<BRK>This paper presents a sequential latent variable model for knowledge selection in dialogue generation. The proposed model achieved higher performances than previous state of the art knowledge grounded dialogue models on Wizard of Wikipedia and Holl E datasets.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>The authors prove optimal regret bounds for a proposed decentralized algorithm and experimentally evaluate the performance of their algorithms on distributed online regularized linear regression problems. The main weakness of the paper is the limited experimental evaluation and applicability of the assumptions and the theoretical setting that underpins this work.<BRK>This paper considers distributed online convex optimization with long term constraints, which extends Yuan & Lamperski (2018)’s work to decentralized case with time varying directed network. They also provide the corresponding regret bounds for both strongly and non strongly convex cases. The problem setting of this paper is interesting and the theoretical contribution is nice, but the empirical studies could be improved:1.<BRK>Summary: The paper considers a distributed variant of online convex optimization problem over multiple players, where, at each trial t, convex loss_l_t.i is revealed to player i and but evaluated by sum of loss functions sum_i 1^n l_t,i. Under the problems setting and some assumption on the neighborhood graph structure, the authors prove regret bounds for convex/strongly convex losses and full info/bandit settings. They also show the violation bounds simultaneously. The theoretical results are non trivial.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>It is a clean mathematical observation but the consequences of the connection are not explored and fleshed out. Hard to locate in current draft. I believe it is an interesting direction that the paper probes and with a more deeper look into the phenomenon and related directions can be ready for publishing in a venue such as ICLR.<BRK>I also appreciate the effort made to improve the paper. As such, I am not certain of its real contribution. In Section 2, what does it mean by "the Fisher metric of the family"? The section titles also read like bullet points in a note. Not certain about the significance of this paper.<BRK>In this paper, firstly, a useful expression of the class of f divergences is proposed. In the paper "On topological properties of f divergences" (1967), Csiszar intensively studied non saturating properties of f divergencesin the paper. Moreover, the numerical experiment is not sufficient to support some new expressions. Detailed theoretical analysis of the non saturating training based on the proposed expression would be required for publication from ICLR.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>In overall, I agree that improving generalization over unforeseen adversaries is a very important problem in adversarial training, and the paper addresses this problem with a novel approach. The key idea is to impose uniform confidence on the adversarial examples depending on the distance from the original example, based on a pre determined distance metric, e.g.L infinity distance. In general, the results are not that clear as claimed, especially when tau 0, to show that CCAT improves robustness: At the original threat model (L inf with the smallest epsilon), CCAT shows much inferior results across all the datasets.<BRK>Summary:This paper proposes the "confidence calibrated adversarial training (CCAT)" to train robust DNNs against adversarial examples. I can hardly agree that "standard adversarial training strongly depends on the training attack". It needs more concrete evidence to make such a claim. 2.Related work can be improved. The paper reads much better now. It is not fair to directly compare AT with CCAT, as AT does not have the detection component. Overall, the authors have done a good rebuttal, but it still requires much improvement to be accepted.<BRK>*Edit after rebuttal*See the comment below for a response to the author s rebuttal. Summary This paper proposes a more granular adversarial training scheme, where the model is trained to have decaying confidence as the size of the adversarial perturbations increase. While this is true, it is not clear how CCAT supposedly remedies this. The considered adaptive attack, that optimizes (4) seems natural given that the defense thresholds on the model s confidence. It seems the authors know this and have done an effort to explain their choices, but I feel like this could still be improved further. The idea is simple and well explained.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>The paper suggests that one common problem encountered by reinforcement learning algorithms in open environments is "data confusion", which essentially means showing the same input data with different  possibly contradictory  labels/targets. The proposed solution to this conceptual problem is to split the original MDP "M" up into multiple simpler MDPs "Mk", where M does contain possibly contradictory ("confusing") data, while each individual Mk does not contain any such problem and, even better, is stationary. Finally, and this is not a deciding factor in my rating, the paper has quite some writing problems. The whole gist of the framework can be crudely summarized as "if data contradicts, split up into non contradictory sets using extra info."<BRK>This paper introduces a new framework for reinforcement learning (named subjective reinforcement learning) which aims to resolve some of the inherent problems with RL in open environments. They propose a “subjective reinforcement learning framework” which, as I understand it, can be described as an ensemble of traditional MDP’s subject to external factors k.  The paper evaluates how this subjective policy compares to traditional MDP’s in terms of theoretical bounds on performance. It may be helpful for the authors to explain a bit more about how these things can be determined in a truly agnostic way. Could you explain what is meant by that and the intuition here a bit more?<BRK>The paper introduces the Subjective Reinforcement Learning framework to formalize the problem of using extra information to split large, nonstationary environments into separate, simple, stationary MDPs. It does not actually present a concrete solution method, instead simply giving brief guidelines for the reader to design algorithms by. A policy is maintained for each subjective MDP, and the overall policy is the vector product of h and the vector of subjective policies.
Accept (Poster). rating score: 8. rating score: 6. rating score: 3. <BRK>The approach is novel and relevant to ICLR. Reference to related work are appropriate. Overall this is a good paper that gives an extra tool applicable to many practical settings. To me, the paper would be much better if you simply added an FCNN and a NODE column to Table 2 and 3 of the catboost paper. Third, I feel you need to report results over CPU as well.<BRK>NODE is an architecture consisting of differentiable oblivious decision trees that can be trained end to end via back propagation. The paper is readable and the experiments are well presented. They make use of an alpha entmax transformation to obtain a differentiable architecture.<BRK>This paper introduces a new method to make ensembles of decision trees differentiable, and trainable with (stochastic) gradient descent. In particular, the improvement over vanilla feed forward neural networks seem small in the experimental section. To conclude, I believe that this is a well written paper, proposing a differentiable version of decision trees which is interesting.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>Nevertheless, the rebuttal and the comments of the other reviewers did not convince me that this paper is ready for publication at ICLR and I keep my vote with weak reject. Summary:The paper proposes a hierarchical reinforcement learning scheme to search for objects specified by an image. The proposed learning approach is applied to a virtual house setting and compared against multiple baselines. My main concern is the setup with the task, which seems quite artificial. By now we can generate maps, planners and low level control policies to navigate within these maps. There is quite some work on subgoal generation within HRL.<BRK>This paper proposed a hierarchical approach to perform robotic object search (ROS). It is very specific to ROS problem and House3D dataset and doesn t seem to propose a general algorithm which can be broadly applicable elsewhere. The mechanism for generating subgoals and training the low level policy is very task dependent (subgoals are constrained to be objects in the field of view, the intrinsic reward for training the low level policy is dependent on the size of the bounding box of the object defining the subgoal). Sparsity of the rewards is mentioned as a main motivation for the hierarchical approach. Saying the method is similar to how humans behave is a fairly big claim that should be substantiated by appropriate references, or not made at all.<BRK>Summary:The paper proposes an intuitive 2 layer hierarchy for robotic object search. Notably, the low level policy is trained to be aware of both the subgoal and the final goal. I think the acceptability of the paper is contingent on whether the tuning of alpha is considered a sufficiently significant contribution. The authors themselves noted that their method (alpha   1) is similar to HRL differing only in the introduction of a termination signal. This in and of itself suggests that the main contribution of the paper boils down to learning a suitable choice of alpha to manage the termination signal. I would also like to better understand the distinction between the author’s method versus HRL with Stop. How, then, is the termination signal for HRL with Stop trained? If the authors can convincingly demonstrate the novelty of the proposal to learn the terminal signal via extrinsic reward supervision, and if the other reviewers feel similarly convinced, then I would feel more comfortable re evaluating my concerns about the significance of this work.
Reject. rating score: 6. rating score: 6. rating score: 6. <BRK>Update (in light of rebuttal)I appreciate the authors lengthly and considered response. This paper is also missing a related work section! the authors found the imagenet categorical representations were most predictive of human judgements in the odd one out task. What categories had the least inter rater agreement.. was there any relationship between these categories and the similarity of representations learned by the convnet? The authors claim "Surprisingly, the kind of supervised input that proved most effective in matching human performance on the triplet odd one out task was training with superordinate labels". I m surprised more space isn t given to discussing the wordvec representations since these should capture some of the semantic information that the 1 hot encodings might miss.<BRK>The authors conduct a comparative study of several variants of CNNs trained on imagenent things category with different types of labeling schemes (direct, superordinate, word2vec embedding targets, etc.) Not suprisingly, training with the word2vec targets produced the best representations for similarity between/within category. Interestingly, the autoencoder failed to learn representations that are easily interpretable by the analysis tools they were using. This is an interesting study. The core claim being made as follows:"The representations learned by the models are shaped enormously by the kinds of supervision the models get suggesting that much of the categorical structure is not present in the visual input, but requires top down guidance in the formof category labels. " However, it is not clear that the representations being learned can be exhaustively interpreted by convenient visualization tools. However, I still think these are interesting analyses so I am giving weak accept.<BRK>Summary: This paper demonstrates the importance of labels at various levels (no label, basic level label, and superordinate level) as well as in combination to determine the importance of semantic information in classification problems. The authors find that superordinate labels are helpful and important for classification problems. Significant work on writing and experimental side should be complete, but because this is novel and important work for classification, with some serious revisions, I would suggest accepting this paper.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>In this work, a novel graph similarity learning framework SEED is proposed. Experimentally, simulation on DEEZE and MUTAG datasets validated the effectivety of the proposed graph learning framework. Pro:The paper is well structured and easy to follow.<BRK>The authors propose a general framework SEED (Sampling, Encoding, and Embedding Distributions) for inductive and unsupervised representation learning on graph structured objects. Then, the group of encoding results from all WEAVEs are aggregated with kernel functions, generating the final embedding of a graph. This method uses an elegant way to embed graphs in an unsupervised manner, and the new random walk approach provides insights into graph structure encoding.<BRK>The authors propose a method for learning graph embeddings and focus specifically on a setting where not all graphs are part of the training data (the inductive setting). The core problem of graph embedding methods is to find a learnable function that maps arbitrary graphs into a fixed sized vector representation.
Reject. rating score: 3. rating score: 3. <BRK>This paper works on the problem of improving object detection and instance segmentation. It also requires a larger RoI feature map, which makes the contribution less clear.<BRK>Then, two modifications which simply increase capacity and could explain all improved scores are not ablated: increased resolution of RoI crops, and added "boundary refinement", which is really just a residual block. Finally, I think the paper is much better suited for a conference like ICCV/ECCV or CVPR and will get better reviewers than me there.
Reject. rating score: 1. rating score: 3. rating score: 6. rating score: 8. <BRK>*Summary*This paper considers the effect of partial models in RL, authors claim that these models can be causally wrong and hence result in a wrong policy (sub optimal set of actions). Authors demonstrate this issue with a simple MDP model, and emphasize the importance of behavior policy and data generation process. *Decision*I vote for rejection of this paper, based on the following argument:To my understanding authors are basically solving the “off policy policy evaluation” problem, without relating to this literature. For example, the MDP example is just an off policy policy evaluation problem, and it is very well known that in this case you need to consider the behavior policy, for example with importance sampling. Even authors definition of the problem at the end of the page 4, and beginning of page 5, is the problem of “off policy policy evaluation” when y_t   r_t Authors have not cited any paper in this literature, and did not situate their work with respect to this literature. To my understanding, the proposed solution is basically importance sampling, that is very well known and studied in the field.<BRK>The novel contribution was a framework for learning better partial models based on models learning an interventional conditional, rather than an observational conditional. The paper tried to provide both theoretical and experimental reasoning for this framework. Furthermore, the paper hard or at times almost impossible to understand as too many assumptions are made and too little is explained. This is causing a number of issues with notation and lack of clarity in the argument you re making. Given the bridging of disciplines in the paper, it would be useful to provide more detail on notation in Section 3. 3.Add a section on reinforcement learning in Section 3. This would further clarify how you re bridging these subtopics. 5.Correct the following sentences,"Mathematically, the model with learn the following conditional probability:""In Section 3, we review relevant concepts from causal reasoning based on which we propose solutions that address the problem." This is not enough to be statistically significant   furthermore, there are no error bars in the Figure. If so, make this clearer, this currently requires a lot of work by the reader to make sense of it. Make this clear.<BRK>The paper considers the problem of predicting a variable y given x where x may suffer from a policy change, e.g., x may follow a different distribution than the original data or suffer from a confounding variable. The flow of the paper proceeds in learning a causally correct model in the sense that the model is robust to any intervention changes. To make the partial model causally correct, the paper considers the partial model conditioned on the backdoor that blocks all paths from the confounding variables. 1.The problem that this paper addresses seems to be new and interesting. The approach makes much sense: the problem is due to the confounding effect which can be addressed by introducing some other variables that implicitly blocks the confouders. 2.The  paper assumes the existence of the backdoor variable which is crucial for causal correctness.<BRK>They show that models typically learned in this context can be problematic when used for planning. The authors then reformulate the model learning problem using a causal learning framework and propose a solution to the above mentioned problem using the concept of "backdoors." MAJOR COMMENTS:Overall, I m positive about the submission, though I think there s room for improvement. That said, I think the paper as written could be substantially improved with a little extra effort. Is more data required for learning compared to non causal approaches? If such a price is incurred, how was this made clear in the presented results? From much of the paper, I would have expected the red dots to live entirely on the horizontal dotted line $V^*_{env}$, but instead this only happens when the behavior policy has the same value. Moreover, why do *better* behavior policies result in *worse* performance for the optimal model evaluation policies? POST RESPONSE COMMENTS:In my opinion, the authors adequately addressed both my own concerns, and also several valid concerns from the other reviewers.
Accept (Poster). rating score: 8. rating score: 8. rating score: 6. <BRK>The authors propose to learn variables z_1 and z_2, which are consistent, contain view invariant information but discard as much view specific information as possible. The paper relies on mutual information estimation and is reconstruction free. Comparing to existing multiview representation learning approaches that try to maximize the mutual information between learned representation and the view(s), this paper clearly defines superfluous information that we should try to throw away and figure out how to obtain sufficiency learned representation for output. The authors also draw clear connections between a few existing (multiview) representation learning methods to their proposed approaches. In the paper, the authors said the original formulation of IB is only applicable to supervised learning. That is true, but the variational information bottleneck paper [Alexander A. Alem et al.2017] already showed the connection of unsupervised VIB to VAE in the appendix. This has been done before (e.g.in the multiview MNIST experiment part of the paper "On Deep Multi View Representation Learning"). You listed a few of them: (Ji et al., 2019; Henaff et al., ´ 2019; Tian et al., 2019; Bachman et al., 2019) in the related work section. In Figure 4, it seems that VAE (with beta 4) outperforms MV InfoMax.<BRK>In this paper, the authors extend the Information Bottleneck method (to build robust representations by removing information unrelated to the target labels) to the unsupervised setting. The representation should then focus on capturing the information shared by both views and discarding the rest. A loss function for learning such representations is proposed. The effectiveness of the proposed technique is confirmed on two datasets. Overall the paper is well motivated, well placed in the literature and well written. Mathematical derivations are provided. This is however not my research area and have only a limited knowledge of the existing body of work. Comments/Questions:  How limiting is the multi view assumption?<BRK>This paper extends the information bottleneck method of Tishby et al.(2000) to the unsupervised setting. Experimetal results on two standard multi view datasets validate the efficacy of the proposed method.
Accept (Poster). rating score: 8. rating score: 8. rating score: 6. <BRK>Does this property remain in curved spaces? It follows the current trend of learning representations on curved spaces by proposing a formulation of the latent distributions of the VAE in a variety of fixed curvature spaces, and introduces an approach to learn the curvature of the space itself. This paper provides extensive and detailed theoretical grounding for their work, ensuring that it is a well founded extension the VAE formalism. The appendices provided a much welcome refreshing on non euclidean geometry, as well as more details & experimental results.<BRK>Summary: This paper is about developing VAEs in non Euclidean spaces. These ideas were developed for embeddings, and recent attempts have been made to build entire models that operate in non Euclidean spaces. The authors push forward the machinery needed to do this, and the results seem like there s something there. On the other hand, the entire work seems quite preliminary. A better way to define curvature is just to talk about the sectional curvature, instead of the Gaussian curvature the authors mention at the beginning of section 2.<BRK>Summary: This paper devised a framework towards modeling probability distributions in products of spaces with constant curvature and showed how to generalize the VAE to learn latent representations on such product spaces using Gaussian like priors generalized for this case. Evaluation:Overall this seems to be a nice work, with balanced discussion of the empirical results, and is clearly written. It was interesting to see the variability in best performing models, e.g.cases in which the mixed curvature models did well vs. the Euclidean one.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>In this work, the authors propose a domain invariant variational autoencoder for domain generalization problem. However, I have the following concerns. In another words, the proposed DIVA is not specific to domain generalization problem, but can be used for domain adaptation, multiple source transfer learning etc. The significance of the paper is moderate as the key idea of learning disentangled latent variables has been studied, and the paper lacks of evidence to show the pure benefits of introducing Z_x as well as the comparison with the related work [ref1]. Two baselines are necessary for comparisons: (1) [ref1], and (2) DIVA without the residual variation variable. (6)	Regarding 4.1.3, it seems that the domain similarity plays an important role in the performance, comparing the results of M_{30} with M_{60}. For a given patient, it makes more sense that all the cells belongs to one category, either infected or healthy.<BRK>This work proposes to solve domain generalization problem in a Bayesian way. The idea is relatively simple: use three hidden variables to encode the domain related, label related and the residual information from the original signal. Some questions: 	My major concern is the intuition for the proposed algorithm. In other words, why Figure 2 can be derived from this setting is not well explained. However, it seems that the cluster center between 30 and 60 is closer than 30 and 45. Is there any justification? My further concern is whether z_d is meaningful at all. (Figure 6 should plot in the context with training domains.) I would like to improve my score if the author can give a reasonable intuition on why the model can generalize on new domains.<BRK>The paper introduces a VAE that can be used in problems in which domain information is available at training time to increase the classification performances on unseen domains. To allow the classification of data from any domain, in the inference network the labels d are not used to infer the latent states, but only as an auxiliary loss that forces z_d to capture domain specific information. However, this makes me wonder if z_d is needed at all? I wouldn t be surprised if the model performed equally well if domain information d was not passed to the model even during training, in which case z_x would also capture domain specific information. Overall I liked the paper and I think it is relevant for the ICLR community, therefore I am voting towards acceptance.
Accept (Poster). rating score: 6. rating score: 6. rating score: 3. <BRK>SummaryThis paper provides an interesting application of GAN which can generate the outlier distribution of training data which forces generator to learn the distribution of the low probability density area of given data. Additionally, this approach reaches a comparable performance on semi supervised learning and novelty detection task. The idea of this paper is novel, and the implementation of this method is easily interacted with any GAN model.<BRK>This paper proposed the DSGAN model to generate unseen data. The intuition based on standard GAN is straightforward and makes sense. The paper is well written, especially the case studies illustrate the idea clearly. As a generative model for unseen data, I would like to see the generated results, which is more convincing. Only the 1/7 examples of MNIST dataset are provided in case studies.<BRK>The “unseen data” is the one that appears in p_{\hat d} but not in p_d. DSGAN is trained to generate such data. Although the idea seems to be interesting, the paper seems to be a bit incremental and is a simple application of existing GAN techniques.
Accept (Spotlight). rating score: 8. rating score: 6. rating score: 6. <BRK>The paper introduces Space2Vec, a space representation learning model. On one hand, utilize the position information and the context associated with the position. The experimental results turn out that the whole model is good at predicting features using only location information but does not outperform the RBF kernel (on validation) in terms of using spatial context modeling. This is very well motivated at the beginning. See comments on experiments. I have some comments/questions about model architecture and also experimental results/analysis. Overall, unlike many existing pre training models in NLP with deep encoders, the full model of this paper is with very local encoder, while the decoder does the most work of “gathering contextual information". As you claim your model to be "a general purpose space representation model", can you describe/specify how you would use your model for other tasks?<BRK>For ex   https://arxiv.org/abs/1505.03873 uses location information to improve image classification, similarly can we use the representation learned through this method instead of positional coordinates and show that it helps the final task. The paper presents a model that learns an embedding/representation for spatial points (POI s). The experiments are performed on Yelp Data challenge which has 21,830 POI s with 1191 POI types. One thing I would like to have seen to strengthen the paper further is the application of these representations in other tasks like image classification or recommendation systems or retrieval.<BRK>This paper presents a new method called "Space2Vec" to compute spatial embeddings of a pixel in a spatial data. Space2Vec is trained as a part of an encoder decoder framework, where Space2Vec encodes the spatial features of all the points that are fed as input to the framework. They conducted experiments on real world geographic data where they predict types of point of interests (POIs) at given positions based on their 1) locations (location modeling) and 2) spatial neighborhood (spatial context modeling). I am giving this paper a weak reject rating mainly because of weak results and lack of motivation for location modeling problem (where their approach performs significantly better than baselines). Authors should try out more datasets to convincingly justify the superiority of their approach over other methods.
Reject. rating score: 1. rating score: 3. rating score: 3. rating score: 3. <BRK>This paper introduces a new step size adaptation algorithm called AdaX. AdaX builds on the ideas of the Adam algorithm to address instability and non convergence issues. Convergence of AdaX is proven in both convex and non convex settings. I recommend the paper be rejected. My main issue with the paper is the experimental design.<BRK>This paper proposed a new adaptive gradient descent algorithm with exponential long term memory. The authors analyzed the non convergence issue in Adam into a simple non convex case. The authors also presented the convergence of the proposed AdaX in both convex and non convex settings.<BRK>In this paper, the authors propose a new adaptive gradient algorithm AdaX, which the authors claim results in better convergence and generalization properties compared to previous adaptive gradient methods. 4.How sensitive is performance to the values of these hyperparameters?<BRK>This paper points out that existing adaptive methods (especially for the methods designing second order momentum estimates in a exponentially moving average fashion) do not consider gradient decrease information and this might lead to suboptimal convergences via simple non cvx toy example. Based on this observation, the authors provide a novel optimization algorithm for long term memory of past gradients by modifying second order momentum design. Also, they provide aconvex regret analysis and convergence analysis for non convex optimization. Significance/Novelty: While there have been many studies on non convergence of Adam, raising an issue on ignoring the gradient decrease information seems novel. 3.Empirical studies show superiority to original Adam (Section 5).
Reject. rating score: 3. rating score: 3. <BRK>Main reservation: the specific problem is not clearly formalized. In this case, what is the information on the target label space that enables unsupervised adaptation from the source one? Compared with the pseudo labels, the class prototypes are more robust and reliable in terms of representing the distribution of different semantic classes." Nonetheless, the expected benefits of prototypes is still not entirely clear enough here, for instance regarding the main statistical assumptions that the method needs to make to get robust prototypes (e.g., in the presence of outliers or specific forms of "inaccuracies" in the pseudo labels or "domain misalignment"). Therefore, due to the overall lack of mathematical clarity in the text and rebuttal, my main reservation remains, and I will change my "weak accept / borderline" score to weak reject.<BRK>This paper proposes to leverage prototypes to solve the mismatch problem in unsupervised domain adaptation. pros:+ intra class compactness to help ambiguous classesconcerns:  Prototypes does not come from nowhere. If you worry about the quality of target predictions (pseudo labels), then Eq.8 and Eq.9 are questionable. The intra class compactness relies on p_t, too. The authors should explain why prototypes are superior than pseudo labels in [1]. How does the authors select hyper parameters? It is confusing that \lambda^{f}_{adv} both is a constant and changes continuously.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>Firstly, the paper excludes any comparison to similar problems and already existing methods of RL used by similar fields, which can be expressed as planning with constraints (for example, path planning in mobile robot navigation), thus will be more valuable to ML community than specific application of graph expansion problem, limited to line by line addition. What is the reason by choosing the 1 dimensional CNN layer to represent candidate stations and what is the concrete input information? (Answer: Yes) What is the motivation to use this concrete architecture? The mentioning of these methods in the literature review is enough to answer this issue. What are the batches B used in the actor critic training procedure? Questions to answerIntroduction	What is the reason by constructing the city metro networks line by line, not iteratively adding stations to the existing network on the grid? Do traditional methods expand metro networks only line by line and can this be there a limitation?<BRK>Review of “City Metro Network Expansion with Reinforcement Learning”In this work, they investigate the use of RL (actor critic) for planning the expansion of a metro subway network in a City.<BRK>Additionally, the paper would benefit from a careful spell and grammar check. The paper is interesting but could use a more extensive comparison to alternative approaches or ablated  version of the same approach. Additionally, the baseline method the approach is compared against is not explained in enough detail. The authors show that different objectives can be satisfied with this approach, such as the accessibility to different areas (something the authors call social equity indicator) or maximising origin destination trips.
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>In the paper, the authors propose a variance reduced local SGD and prove its convergence rate. 3) It is not clear in algorithm 1 how the \delta^{t } is updated.<BRK>The paper proposes the variance reduction to the local SGD algorithm and shows the proposed VRL SGD can achieve better convergence than local SGD when the data are not identical over workers. The idea is interesting and the paper is easy to follow.<BRK>To that end, the authors contribute:· A novel algorithm and its asymptotic communication complexity. weaknesses of the paper: · The algorithm, while having differences, is quite reminiscent of Elastic Averaging SGD (EASGD) [1]. I have not thoroughly checked the full proof though. However I m willing to change my opinion after reading other more qualified reviewers in the sub area of variance reduction techniques.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>The "adversarial" interpolation part is from $(x , y )$ in the sense that $\tilde y$ is away from $y $. The paper provides an interpretation of the proposed approach from the perspective of robust and non robust features. Although the results are impressive, I still have some concerns on the method itself:1. I did not find the definition above the sentence.<BRK>This is an interesting work proposing a new robust training method using the adversarial example generated from adversarial interpolation. The experimental results seem surprisingly promising. It seems that the proposed interpolating method has a similar amount of computation as PGD, so the training should take similar time as Madry s if it can converge quickly. Since this is a new way of robust training and there is no certified guarantee, I would be very conservative and suggest the authors refer the checklist in [1] to evaluate the effectiveness of the defense more thoroughly to convince the readers that it really works.<BRK>Below are some Related works on using interpolation in deep nets to improve their robustness1). 2.This work lack of interpretation of why the proposed method is more effective than PGD adversarial training. 4.Can the authors provide the black box attack results also?
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. rating score: 6. <BRK>This paper addresses the problem of optimizing high dimensional functions lying in low dimensional manifolds in a derivative free setting. The authors develop an online learning framework which jointly learns the nonlinear manifold and solves the optimization. Moreover, the authors present a bound on the convergence rate of their algorithm which improves the sample complexity upon vanilla random search. The paper is overall well written and the core idea seems interesting. However, the reviewer has a few concerns which needs to be addressed. 1) Methodology: This work depends on deep networks to learn the nonlinear manifolds which is justifiable by the power of deep nets. Again, the overhead cost of finding a good deep network through cross validation or any other method of choice (such as Bayesian optimization or Hyperband) should be considered towards the total cost of the algorithm. Thus, for a thorough examination, reporting the performance over wall clock time is recommended and required, ideally in both serial and parallel settings .<BRK>The larger the problem, the longer it takes to perform a single iteration. Thus, I think the idea in this paper is novel and may have influence on the literature (maybe an encouragement for a shift from deep reinforcement learning to derivative free optimization methods). So, it might be the case that their iterations take longer to compute than the iterations of the ARS and thereby making it slower. The authors have showed that their method has a lower sample complexity, which is their goal of the research (“Our major objective is to improve the sample efficiency of random search.”). They address this issue briefly by stating that “Our method increases the amount of computation since we need to learn a model while performing the optimization. If we thus assume that this is the case, then their results are sound. However, I do not see this reduced complexity reflected in the results. In that case, the computation time would not reduce by a “fixed” ratio and would therefore decrease relatively much on the tasks with a higher dimension.<BRK>Contributions: 	 Authors have proposed a methodology to optimise high dimensional functions in a derivative free setup by reducing the sample complexity by simultaneously learning and optimising the low dimensional manifolds for the given high dimensional problem. Although, performing dimensionality reduction to learn the low dimensional manifolds is popular in the research community, the extensions made and the approach authors have considered seems to be novel. "High dimensional Bayesian optimization with elastic gaussian process." Authors have said that they are specifically interested in random search methods. Was that supposed to be “t”? Author might want to discuss more on this as this is an important metric. “ ….total time spent on learning the manifold is negligible…. But according to the initial claim, method was supposed to work better in low dimensional problems. “Although BO methods typically do not scale…… ” – Authors have made a strong assumption here. In the literature, we see active research in the context of high dimensional optimisation.<BRK>In this paper, the authors first improve the gradient estimator in (Flaxman et al., 2004) zeroth order optimization by exploiting low rank structure. Then, the authors exploit machine learning to automatically discover the lower dimensional space in which the optimization is actually conducted. The authors justified the proposed algorithm both theoretically and empirically. The empirical performances of the proposed estimator outperforms the current derivative free optimization algorithms on MuJoCo for policy optimization. The paper is well motivated and well organized. For the empirical experiment, it is a pity that the algorithm is not compared with Bayesian optimization, which is also an important baseline. Following the notations in the paper, I was wondering the unbiased gradient should be $E_{S}[f(x + \delta U^*s)U^*s]$Then, the lemma should characterize the difference between $E_{S}[f(x + \delta Us)Us]$ and $E_{S}[f(x + \delta U^*s)U^*s]$.
Reject. rating score: 3. rating score: 3. rating score: 6. rating score: 6. <BRK>I read the authors response. I am satisfied with the explanations on the privacy party. Hence, I am not sure how to understand the distributed domain adaptation experiments. In summary, the submission is addressing an important problem. Moreover, the contribution on collaborator selection is interesting and seems to be working well. The manuscript is proposing a method for domain adaptation in a private and distributed setting where there are multiple target domains and they are added in a sequential manner. In this setting, existing adapted models can be used as a source domain since a trained model suffices for adaptation. One major contribution of the paper is proposing a straightforward but successful method to choose which domain to adapt from. The main algorithmic tool is estimating Wasserstein distance and choosing the closest domain. Moreover, results suggest that it also results in significant performance improvement. Privacy and decentralized learning part has major issues. Authors do not discuss any of these existing work. Only guarantee the  algorithm provides is not passing data around. However, this is clearly not enough. Passing gradients might result in sharing sensitive data.<BRK>###Summary###This paper tackles unsupervised domain adaptation in a decentralized setting. The paper proposes Multi Step Decentralized Domain Adaptation (MDDA) to transfer the knowledge learned from the source domain to the target domain without sharing the data. The source domain discriminator D_s target domain discriminator D_t are synchronized by exchanging and averaging the gradients. The paper also proposes Wasserstein distance guided collaborator selection schema to perform the domain adaptation task. The experimental results demonstrate that the proposed method can outperform the baselines on some of the experimental settings. ### Novelty ###This paper does not propose a new domain adaptation algorithm. For example, the D_s cannot get access to the features from the target domain, how to train D_s? 3) As far as I understand, the domain discriminator is this paper is trained adversarially. I would like to discuss the final rating with other reviewers, ACs.<BRK>The paper focuses on the problem of domain adaptation among multiple domains when some domains are not available on the same machine. The paper builds a decentralized algorithm based on previous domain adaptation methods. 3.The paper proposes to use Wasserstein distance to select the optimal domain as the source domain for the target domain. It has been used in other communities such as reinforcement learning. The contribution is not significant to the community but providing a new perspective for domain adaptation. I vote for weak accept. I think the paper still has some novelty and the comments address my concerns. It is more like a borderline paper.<BRK>To address the problems in current unsupervised domain adaptation methods, the authors propose to a novel multi step framework which works in a decentralized and distributed manner. This paper is well motivated and the proposed method is novel for unsupervised domain adaptation. The paper is well supported by theoretical analysis, however, the improvements are not that significant on some experimental results. For the above reasons, I tend to accept this paper but wouldn t mind rejecting it. The experiments do not really show the superiority of the proposed method compared to the common centralized approaches as they have similar performances on both collaborator selection and distributed domain adaptation. Can you convince the readers more with some other experiments?
Reject. rating score: 3. rating score: 3. rating score: 8. <BRK>Summary: This paper focuses on the semi supervised learning problem, and proposes a way to improve previous pseudo labeling methods. In pseudo labeling, there is an issue called confirmation bias, which accumulates the early errors of wrong pseudo labels. Experiments demonstrate that the additional tricks are meaningful and makes pseudo labeling better than many baseline methods for semi superivsed learning, including state of the art consistency regularization methods. Pros: This is an interesting paper with a clear motivation, which is to fix the so called confirmation bias that appears in pseudo labeling methods for semi supervised learning. Although the tricks introduced in the paper (mixup and changing the mini batch selection rules) themselves are not novel, they make the proposed method simple. It is also shown to be meaningful in reducing the confirmation bias in Table 1 and Figure 2, achieving the original goal of the paper. This is partially answered with Figure 2, but it would make this easier to see if the experiments included stronger baselines, e.g., by adding the same regularization tricks to consistency regularization methods, perhaps in Table 3. In Section 4.4, "The table" in the second sentence can be changed to "Table 3". I suggest using commas instead.<BRK>This paper proposes to combine pseudo labelling with MixUp to tackle the semi supervised classification problem. My problem is that "MixMatch: A Holistic Approach to Semi Supervised Learning" by Berthelot et al.is very similar with just a few differences on the pseudo labelling part. Could you stress more the difference between your paper and their paper ? Because I might be wrong about it. Pros:* Good results on C10* A clear related work section that divides the existing works in pseudo labelling vs consistency* Interesting results about the effects of using different architectures. Weaknesses:* Usually, SVHN is also among the tested datasets* The pseudo labelling part is a bit unclear.For example, do you just refresh the pseudo labels at the end of each epoch ? You can still motivate the differences with the MixMatch paper.<BRK>OVERALL:I think this paper is worth accepting. I would change the framing slightly. You re not showing that pseudo labeling can be useful, because many techniques already incorporate a form of pseudo labeling. A potential improvement:If you add up this techique with some of the most recent SLL techniques based on consistency regularization somehow,does it do better, or are they both acting via the same mechanism? > n (Berthelo et al., 2019) It s Berthelot> and are the mechanisms proposed in Subsection 3.1Doesn t quite parse> Network predictions are, of course, sometimes incorrect. > , we add the 5K samples back to the training set for comparisonwith the state of the art in Subsection 4.4,This is *allowed* from the perspective of reporting a valid test accuracy,but if other papers don t do that, it kind of mucks up the comparison, no? Fig 1 is nice, but why does the effect not seem to be symmetric about theblue and the red blobs? I am surprised that the change from WRN  > 13 CNN matters so much.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>The paper improves adversarial training by introducing two modifications to the loss function: (i) a "boosted" version of the cross entropy loss that involves a term similar to a large margin loss, and (ii) weighting the adversarial loss differently depending on how correctly classified an example is. When put together, these modifications achieve state of the art robustness on CIFAR 10, improving over the previously best robust accuracy by about 3.5%.<BRK>This paper first shows empirically that the adversarial examples generated from misclassified examples by the model h_{\theta} are as important as the ones generated from correctly classified examples on the CIFAR dataset. Quality: The paper is technically sound and is a solid contribution to the literature on adversarial robustness.<BRK>4.I am curious to know if outliers would be over emphasized by the proposed idea. Some discussion or even some illustrations on a synthetic case would be interesting. It is suspected that different samples within the set of mis classified samples (or even in the set correctly classified samples) could also have a different influence. Empirical validations seemed to support the idea and indicated that the proposed approach could improve the adversarial robustness.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>This paper proposes a self supervised reinforcement learning approach, Mutual Information based State Control (MISC), which maximizes the mutual information between the context states (i.e.robot states) and the states of interest (i.e.states of an object to manipulate). Then, the neural discriminator is trained to estimate the (lower bound of) mutual information between the two states. The (mutual information) intrinsic reward is computed by the trained neural discriminator, which is used for policy pre training. Can the learned MI discriminator be transferred to different tasks even when the state space is different? Experimental results show that MISC helps to improve the performance of DDPG/SAC and the learned discriminator can be transferred to different environments. For MISC, the additional assumption is required: the agent should know that which parts of the states are its own controllable state and object s state respectively. Is this additional assumption realistic enough and has it been adopted in other previous works? Can MISC deal with the problems where the number of objects of interest is more than two? e.g.network architecture, hyper parameters (e.g.I_tran^max), and how they were searched. How was the discriminator trained? It seems that the MI discriminator learns to estimate the  proximity  between the robot and the object.<BRK>Can the authors elaborate on why this choice should intuitively be better than the proposed method alone? The paper assumes that the state space can be divided into two parts   the state of the robot (“context states”) which is controllable via actions and the state of an object (“states of interest”) which must be manipulated by the robot. Given these two categories of states, the proposed algorithm maximizes a lower bound on the mutual information between the two categories of states such that a policy is learnt that is able to manipulate the object with the robot meaningfully. The paper does not talk about settings where states of interest are not known, so all of the experiments are based on this strong assumption.<BRK>I take issue with the usage of the phrase "skill discovery". Rather than "skill discovery", I suggest the authors position MISC relative to earlier work on empowerment, wherein a single policy was used to maximize mutual information of the form I(a; s_t | s_{t 1}). Indeed, an appendix would be greatly appreciated, as many experimental details were omitted. That said, the claims should be weakened to reflect this gap, and domain knowledge should be mentioned more prominently (e.g.states of interest vs context are given, not learned). Needing new environment variations to obtain new skills is a large step backwards from things like DIAYN (the MISC/DIAYN combination needs more evidence to be considered a possible solution), and the s_i/s_c distinction is non trivial to specify or learn for harder problems (e.g.pixel observations). That said, in the sort of settings under consideration (low dimensional state variables and environmental variations are simple to create) MISC does appear to be superior to prior work. The empowerment baseline is much appreciated, and while modifications of PER and VIME that incorporate prior knowledge would ve also been nice, the experimental results pass the bar for acceptance in my view.
Accept (Spotlight). rating score: 8. rating score: 8. rating score: 6. <BRK>The paper introduces an efficient, unbiased contrastive divergence like algorithm for training energy based generative models on the example of Restricted Boltzmann Machine. The proposed algorithm is built upon a very interesting work on unbiased finite step MCMC approximations by Jacob et al, 2017. Authors evaluate their method on rather toyish datasets (by modern standards), however, their empirical analysis is thorough. The improvement upon the standard CD and persistent CD is clear. The only question I have is why CD has only been tried with k 1 steps? Even though I do not expect a significant improvement to be obtained, this would separate the effect of the number of steps chosen “right” from unbiasedness of the gradient estimator. I would also suggest including https://arxiv.org/abs/1905.04062, as it seems to be relevant in the spirit.<BRK>The paper proposes an algorithmic improvement that significantly simplifies training of energy based models, such as the Restricted Boltzmann Machine. The key issue in training such models is computing the gradient of the log partition function, which can be framed as computing the expected value of f(x)   dE(x; theta) / d theta over the model distribution p(x). The canonical algorithm for this problem is Contrastive Divergence which approximates x ~ p(x) with k steps of Gibbs sampling, resulting in biased gradients. In this paper, the authors apply the recently introduced unbiased MCMC framework of Jacob et al.to completely remove the bias. The key idea is to (1) rewrite the expectation as a limit of a telescopic sum: E f(x_0) + \sum_t E f(x_t)   E f(x_{t 1}); (2) run two coupled MCMC chains, one for the “positive” part of the telescopic sum and one for the “negative” part until they converge. After convergence, all remaining terms of the sum are zero and we can stop iterating. However, the number of time steps until convergence is now random. Other contributions of the paper are:1. Proof that Bernoulli RBMs and other models satisfying certain conditions have finite expected number of steps and finite variance of the unbiased gradient estimator. 2.A shared random variables method for the coupled Gibbs chains that should result in faster convergence of the chains. 3.Verification of the proposed method on two synthetic datasets and a subset of MNIST, demonstrating more stable training compared to contrastive divergence and persistent contrastive divergence. I am very excited about this paper and strongly support its acceptance, since the proposed method should revitalize research in energy based models.<BRK>Based on recent progress in unbiased MCMC sampling the paper proposes an unbiased contrastive divergence (UCD) algorithm for training energy based models. The authors demonstrate their method on a toy dataset, simulated data, as well as a reduced version (only the zero digits) of the MNIST dataset and compare the results with the standard Contrastive divergence and Persistent Contrastive Divergence methods. Can you comment a bit on the variance of your method which seems to be higher, Is there a Bias/Variance trade off between UCD and e.g PCD? Q1.4) I highly value enlightening small scale experiments and do understand that computational resources are not available everywhere however I think it would benefit the paper greatly if the proposed method is demonstrated on some reasonably sized dataset (at the very least one of full MNIST, Fashion MNIST, FreyFaces). Q1.5) In Figure 2 you show some interesting figures for the average stopping time and number of rejected samples on the BAS toy dataset. [Tieleman 2008], Training Restricted Boltzmann Machines using Approximations to the Likelihood Gradient,[Hinton 2006] Reducing the Dimensionality of Data with Neural Networks
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>Paper summary: The paper proposes a general framework to improve the optimization and generalization performance of several communication efficient algorithms, including local SGD, SGP. It is confusing to talk about the \tau in the main paper and the same \tau notation in Algorithm 3 (default parameter in OSGP). The experimental setup description, as well as the ablation study, provide a clear guideline to use this framework in practice. * The extensive empirical experiments in this paper justify the effectiveness of the proposed methods.<BRK>The literature survey of this paper is quite good and the experimental results are convincing. However, they should modify their claim that "BMUF is a special case of SlowMomentum". The author should not narrow down the definition of BMUF as BMUF with SGD as local optimizer and \alpha 1. Actually, \alpha 1 is used in all experiments of this paper. I will give a weak accept to this paper. Scalable training of deep learning machines by incremental block training with intra block parallel optimization and blockwise model update filtering.<BRK>The paper presents a simple momentum scheme which can be applied to distributed and decentralized SGD schemes. The main question for me is on the significance of the contribution. The benefits of momentum are well known in practice in the single machine case, and theoretically not well understood. The paper here translates this type of results also to the decentralized case. UPDATE AFTER REBUTTALThe discussion and other reviews were helpful, for instance that the paper should still clarify better the fact that the proposed method is just a very minor generalization of BMUF, to some more SGD variants (including decentralized). I keep the current score.
Accept (Poster). rating score: 8. rating score: 8. rating score: 1. <BRK>These weights are then used to query a larger, discrete architecture from NAS Bench for the corresponding evaluation errors. The authors motivate the soundness of a unique framework by showing minimal differences between three NAS optimizers. In addition, the authors provide empirical analyses that reflect generalization and regularization issues with current methods and that could lead towards designing more robust algorithms.<BRK>This paper proposes a benchmark dataset for evaluating One Short Neural Architecture Search models. I think this is important work. The paper is well written and the design decisions are clearly explained. The comparison of NAS methods is also interesting to read.<BRK>In this submission, the authors present a benchmark NAS Bench 1Shot1 for one shot Network Architecture Search. It would be a true general framework if it can also work with other one shot NAS methods such as ENAS and the rest ones. 2) The authors claim that they introduce a general framework for one shot NAS methods.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>Paper summary: This paper proposes a new normalization technique specially designed for settings with small mini batch sizes (where previous methods like BatchNorm are known to suffer). The paper is clearly written and explores an interesting idea aggregating mini batch statistics across iterations. That being said, I am not convinced by the utility of the proposed approach since it doesn’t offer over significant benefits over prior approaches designed for the small mini batch setting (e.g., Group Normalization) either in terms of empirical performance, implementation complexity, or lower computational/memory requirements. Based on my understanding, it is also designed for the low sample regime (and the original paper also conducts experiments on ImageNet/COCO).<BRK>The paper tackles the problem of batch normalization (BN) instability when using small batch sizes. Paper also shows that the proposed method does not work well for the beginning of the training and use "burn in" period when standard BN is used instead of proposed CBN. This could be a killer feature. 3) Paper reports results for "validation set", yet "hyper parameters were set by cross validation". Overall I think that paper is OK, but don` t see practical applications where it is beneficial to use CBN instead of BN (for big batches) or GN (for small batches, even bs   1).<BRK>This paper proposes a novel Cross Iteration Batch Normalization (CBN) to address the limitation of BN in the case of small mini batch sizes. Different from existing methods, CBN exploits the statistics cross different iterations to obtain more accurate estimates of the data statistics. The experiments on both image classification and object detection tasks demonstrate the effectiveness of the proposed method. The authors propose a novel method that exploits the information from different iterations to estimate the normalization statistics more accurately. The proposed method is theoretically sound. 6.The differences from a closely related work [3] should be discussed. This paper exploits the similar idea of computing the statistics of the current iteration by exploiting the statistics of multiple recent iterations. ICLR, 2019.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>The submission proposes to train a GAN on discrete sequences using the straight through Gumbel estimator introduced in Jang et al.(2016) in combination with gradient centering. The proposed approach is evaluated on COCO and EMNLP News in terms of BLEU and Self BLEU scores, Fréchet Embedding Distance, Language Model Score, and Reverse Language Model Score. The proposed approach does have empirical backing, but I would argue that it is a very straightforward application of the straight through Gumbel estimator to GANs, which is itself similar to existing work on applying the Gumbel softmax estimator to GANs (Kusner & Hernández Lobato, 2016). The submission does not feel self contained. GANs for sequences of discrete elements with the Gumbel softmax distribution.<BRK>The authors propose CaptainGAN, a method using the straight through gradient estimator to improve training of the generator for text generation. The paper is well written and the evaluation seems thorough, comparing to relevant baselines. The citation is given in the opening part of the introduction, in an enumeration, but isn’t revisited later in the text   not even here where the results of the model are introduced. Given that it seems, according to the presented results, to be the most competitive of the GAN models that the authors are comparing to, maybe it’s worth adding more contextual information on RelGAN to the Background section?<BRK>This paper attempts to solve the problem of non differentiable connection between the generation and discriminator of a GAN. The authors come up with an estimator of the gradient for the generator from the gradient of the discriminator, which was disconnected previously. The experiment results on both COCO Image Captions and EMNLP 2017 News datasets justify the authors  argument.
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>The paper proposes a discriminative Gaussian mixture model with a sparsity prior over the decoding weight. 1.I think the model is just ARD prior over discriminative GMM which is not that novel. Adding ARD sparsity prior over the decoding weight is also a classic routine. [1] Discriminative gaussian mixture models for speaker verification[2] Discriminative Gaussian mixture models: A comparison with kernel classifiers2. I don t think differentiating between discriminative GMM and generative GMM would make such a big deal. DGMM is basically Gaussian mixtures existing for each class. Any skill applied to GMM can be applied to DGMM. There are many works for component number selection for GMM with non parametric Bayesian methods. For example, Dirichlet Process Mixture Model can automatically learn the number of components without predefining. So SDGM should be better than LR if the data has structures.<BRK>The paper presents an alternative to densely connected shallow classifiers or the conventional penultimate layers (softmax) of conventional deep network classifiers. This is formulated as a Gaussian mixture model trained via gradient descent arguments. The Gaussian mixture model formulation allows for inducing sparsity, thus (potentially) considerably reducing the trainable model (layer) parameters. However, it is unfortunate that the paper does not take into account recent related advances in the field, e.g.https://icml.cc/Conferences/2019/ScheduleMultitrack?event 4566The paper should make this sort of related work review, discuss the differences from it, and perform extensive experimental comparisons.<BRK>This paper proposes a classifier, called SDGM, based on discriminative Gaussian mixture and its sparse parameter estimation. While the method incorporates distinct ideas in the literature such as increased model complexity and use of a sparse prior, the paper needs more clearer explanation of the method design and careful empirical investigation. My major concerns are as follows. (T, z are one hot representation of c, m.) * The objective is to maximize the conditional probability of equation (1) given labeled data (x, t). * This maximization is carried out in a similar way to the EM algorithm where m (or z) is regarded as a latent variable. Assuming the points above, I am still unsure about the following points: 1 a) How is the sparsity induced? 1 b) How is the update of \alpha (17) derived? Then, this point should be emphasized. How are these parameters made sparse in the end to end learning? Section 4 describes SDGM incorporates disciminative model, mixture model, and sparse Bayesian parameter estimation. It is more informative to provide empirical results to see the impact of each property by comparing SDGM with, for example, RVM, discriminative GMM and sparse GMM.
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>It is very similar to a GCN + GAT. The methods are evaluated on both node classification and graph classification problems. I have major concerns about the novelty, and experiments in this work. The performance of GAT is too low and even lower than that reported in GAT.<BRK>I ve read all discussions and changed my score. The novely of this work is not enough as R4 pointed out. Experimental results show that the proposed attention based algorithm outperforms other algorithms. I think this paper attacks a very important issue "graph attention" and have a very nice algorithm and results.<BRK>Nothing is related to each other? The paper proposes a novel attention approach to graph neural networks which is applicable to both of node and graph classification. One of the main claims of the paper is that considering a subgraph (not a node) increases the performance. These two are independent approaches?
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>And claims that the paper analyzes the practical behavior of AII both theoretically and empirically, indicating that AII has theoretical difficulty as it maximizes variational upper bound of the actual conditional entropy. Then it argues an ugly modification based on a wrong property of conditional entropy. The paper says that it analyzes AII theoretically and empirically. And I want to ask why the caption of Figure 2 (b) is IIDM ?<BRK>*Summary*The paper proposes a new method to learn data driven representations, being invariant to some specific nuisance factors which are detrimental for the selected (supervised) classification task. They claim to explore it under a both theoretical and practical point of view, demonstrating the limitations of maximizing a variational upper bound on conditional entropy as a proxy to achieve invariance. The paper is hard to get, if the reader is not familiar with related literature2. I would also encourage authors to add a pseudo code2.b. 3.Although already convincing, the experimental part can be improved:3.a. But, maybe, the reason for this is that I am not an expert of the specific related field   but, even so, I think that the paper needs to be understood from the broadest audience possible.<BRK>** SummaryThe paper studies the problem of representation learning under invariance constraints (i.e., the representation should be invariant wrt some attributes). The authors support the modified objective function both from a formal point of view and with an extensive empirical validation** EvaluationThe paper lies a bit outside my area of expertise. Detailed comments:1  In many parts of the paper the notation is not very rigorous and sometimes it may create confusion.
Accept (Poster). rating score: 8. rating score: 6. <BRK>The distance measures for both the control network and for fine tuning are higher. The core concept behind the authors  work is novel and interesting, and the experimental design is thorough and well controlled. It seems like fine tuning should be the one bolded. Although the results are (I would argue) somewhat mixed, they are nonetheless positive enough to encourage more work in applying "sleep" and other relevant ideas from neuroscience to the problem of robustness in deep neural networks. I think the authors should consider rephrasing this statement to better reflect the actual results. This is a significant difference. 6.In the analysis of JSMA, as noted before,, it s rather dubious to claim that sleep had any kind of significant effect on the attack success rate (or distance) for CUB 200. Sectioin 4: Sleep algorithm1.<BRK>The paper proposes an ANN training method for improving adversarial robustness and generalization, inspired by biological sleep. I m leaning towards accepting as it seems to be an original concept and has fairly extensive empirical results that are somewhat promising. The idea of a sleep phase as an alternative to explicit adversarial or generalization training is interesting. The results suggest that the approach works reasonably well in many cases.
Accept (Talk). rating score: 8. rating score: 8. rating score: 8. <BRK>Summary This paper introduces a mechanism for gradient based meta learning models for few shot classification to be able to adapt to diverse tasks that are imbalanced and heterogeneous. It describes Prototypical Networks (Snell et al) but not, for example, Matching Networks (Vinyals et al) nor many others that like Matching Networks perform example based comparisons and don’t aggregate a class’ examples into a prototype. In a nutshell I think this work is a useful contribution for moving towards a more realistic setting in few shot classification. This sentence does not describe all metric based approaches. Experimentally, this method outperforms others on a setting of imbalanced tasks (the shot is sampled uniformly at random from a designated range). Comments (in decreasing order of importance) A) The Bayesian framework helps because it offers an elegant way to use a prior. For the case of diverse datasets, this would behave as the current z (updates a lot the dimensions of \theta that are irrelevant for the given task due to the dataset shift). Less important D) which dataset is used in Tables 4 and 5? I assume it’s Omniglot (due to the numbers being in the 90s) but it would be good to say this explicitly. How exactly are these computed? F) In the Related Work section, in the Meta learning paragraph there is a sentence that’s not accurate: “Metric based approaches learn a shared metric space [...] such that the instances are closer to their correct prototypes than to others”.<BRK>The paper proposes a Bayesian approach for meta learning in settings were the tasks might be OOD or have imbalanced class distribution. The proposed approach has 3 task specific balancing variables with a prior and an inference network. The paper is well written and well motivated. I only have some minor comments and questions:  Can you add the standard errors for the results in Section 5.2 (maybe at least in the Appendix)? Specifically it would be interesting to see if the results for analyzing the class imbalance variable are statistically significant; specially in light of the recent work on the effects of importance weighting in DL (see “What is the Effect of Importance Weighting in Deep Learning?” by Byrd and Lipton) which essentially question the value of importance weighting for handling class imbalance in various DL settings.<BRK>Starting from the model agnostic meta learning (MAML) algorithm (Finn et al.2017), to tackle task imbalance, where the number of training examples of varies across different tasks, a task dependent learning rate decaying factor was learned to be large for large tasks and small for small tasks. In this way, the small task can benefit more from the meta knowledge and the large task can benefit more from task specific training. To tackle class imbalance, a class specific scaling factor was applied to the class specific gradient. The scaling factor was large for small class and small for large class so that different classes can be treated equally. Additional model parameters are learned through variational inference. Analysis of each component confirm they work as expected. Comments This paper is well motivated and clearly written. The empirical evaluation also support major claims in the paper. Can the author provide more details on the inference of the model? The class specific scaling factor made use of the SoftPlus() function, for the same purpose of scaling learning rate, why do these two different options of functions were applied? For the scaling vector of the initial parameters g(z^{\tau}), for its zero entries, the initialization of the corresponding entries in task specific parameter \theta would be zero. Would it be better to apply a linear interpolation between \theta and a randomly initialized vector in Eq (2)? Edits after reading the author s rebuttal The author s reply well addressed my questions.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>Summary: The paper proposes a layer wise method for training the weights of a binary tree structured neural network such that it correctly reproduces certain classes of Boolean functions defined by binary tree structured Boolean circuits. Specifically, this paper shows analytically that if a circuit satisfies a property termed “local correlation” where there is sufficient correlation between every gate in the circuit and the true output label of the circuit, then this circuit can be learned by a neural network with the same structure as the circuit by training it one layer at a time from the input to the output. However, I do not have a problem with the quality of the paper, and think it would find a more appropriate audience at a different venue. Appendix.It would be nice if this read as well as the main paper. I agree that it would be nice if our methods were not so limited but this seems to simply reiterate the fact that they are. This is a well written section that does a good job of situating this work. The assumption that the circuit must be a binary tree is quite restrictive and excludes pretty much all common deep learning architectures.<BRK>##############################This paper proposes to use neural networks for learning binary tree structured boolean circuits. On the one hand, "local correlation" requires every influential node in the circuit have strong correlations with the target label, which makes the network trainable to exploit this correlation for minimizing losses. Strengths,1, This paper points out the two key factors "local correlation" and "label bias" for the learnability of a boolean circuit. 2, The paper puts their theoretical findings to the setup of k parity problem, proving that their proposed algorithm can faithfully tackle the k parity problem. I think it is necessary that the authors give some estimates on the total number of representable functions and compare it with their |S|.<BRK>This paper aims to study the correlation between the neural network s input and output by abstracting the network as a binary tree Boolean circuit problem. The paper is well written, motivations are clearly presented, and literature reviews are well placed. To mimic the Boolean circuits network, the authors have focused the analysis on a layerwise gradient based training, which might be a potential drawback because modern deep models are much more complex (e.g., the Residual network architecture shares connections between layers) and this over simplified analysis may be too restricted. Overall, I believe this is a fine theoretical foundation paper that should attract the attention of the researchers in deep learning community.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>In particular, in addition to points raised by reviewer 2 there are concerns with regard to lack of ablation studies, and major clarity issues.] This paper proposes content based sparse attention to reduce the time/memory complexity of attention layers in Transformer networks. The method essentially boils down to keep a set of K mean vectors (which are learned/updated during training), which are used to provide clusters to be attended over. How does the model do if it only uses routing attention? Finally, what about full attention with O(n^2)? I understand some of the listed baselines are already working with local attention, but there are differences in setup that could contribute to differing performance. Therefore it would be good to ablate on these aspects, holding the other parts (layers/initialization/optimization algorithm etc.) constant.What is the *actual* running time/memory for local/routing/full attention layers? My guess is that the actual, rather than theoretical, difference would not be that great. It seems like the routing layer requires additional operations (i.e.online k means) which could increase running time.<BRK>Summary: This paper proposes a new mechanism for computing the attention scores efficiently in Transformers to avoid the quadratic computational cost in conventional Transformers (i.e., when computing the QK^T for self attention). Pros:+ The math notations are generally clear (e.g., dimensionality) and the paper is well organized. Why not just use all of the heads with routing attention? The routing Transformer seems to be able to do very well on the WikiText 103 word level language modeling task. Without ablations on this, it s hard to tell which part is contributing how much exactly. So in a certain sense, are they like the "anchors" in the (transformed) word embedding space? Picking the initial centers for k means clustering has been long known as an interesting/challenging problem, especially in a high dimensional space (which tasks like language modeling deal with). 12.While the theoretical complexity may be lower, how does the wall clock time of an L layer routing Transformer compare to an L layer conventional Transformer (on the same sequence length, batch size)? Minor issues that didn t impact the score:13. Therefore, I m not sure why it is a >  relation here. I think this would be an interesting ablation study to make. I think the paper can be improved by including more elements, such as ablative experiments and runtime benchmarking. Also, there seem to be some problems with the derivations that the authors made in the current version of the paper. How does the number of cluster centers influence the performance of the model?<BRK>This paper proposes a novel way to increase efficiency for self attention based sequence modeling neural networks. The proposed approach is incremental by combining content based sparse attention with local/temporal sparse attention. While the extension is incremental, they are able to reduce the overall complexity and achieve new state of the art on wiki text 103 dataset. The paper is also very well written and easy to follow and understand. I find the discussions around NMF to be somewhat orthogonal, especially considering the paper does not use NMF techniques for their clustering algorithm in section 4.2. Would sparse coding in general be a good high level motivation for the proposed clustering? It is also appreciated that the authors have released demo code for reproducibility.
Accept (Poster). rating score: 8. rating score: 6. rating score: 3. <BRK>This paper investigates the possibility of using hypermodels in improving the exploration of bandit problems. By using SGD for training the hypermodel parameters, this paper introduces a computationally efficient alternative to ensemble methods. The idea of the paper is novel and interesting; however, I do have several concerns, mainly from numerical experiments that I would like the authors to address those in the rebuttal. 1) My first and the most important concern is that the numerical experiments do not evaluate different aspects of the method. 3) P4, "it is natural to consider linear hypermodels in which parameters a and B are linearly constrained." This sentence needs to be clarified. I didn t comprehend how you are dealing with large neural network issues. * I think that the summation in computing the variance of IDS should be over $\tilde{Z}_{x^*}$.<BRK>The authors demonstrate advantages of a linear hypermodel over an ensemble method in exploration guided by epistemic uncertainty. They perform an empirical study in the bandit setting and claim that their approach both outperforms the ensemble method and offers a significant increase in computational efficiency. The theoretical contribution is that they prove universality in the sense that an arbitrary distribution over functions can be represented by a linear hypermodel. The experiments support their claims.<BRK>The paper builds on a classical idea of sampling model parameters apart from learning them. Specifically, it combines hierarchical sampling with neural networks and proposes models that can help explore the parameter space efficiently. What exactly do we mean by intelligent exploration? The paper is clearly written and the idea makes sense. However the experiments are essentially based on simulated data. It is not entirely clear as to how this would translate to real setups. Is it possible that the linear hypermodel is performing well because the data was generated according to a linear model in section 5? In other words, does the proposed hyper sampling allow for better weak learners in general as well?
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>The authors present an algorithm for postprocessing neural networks to ensure calibration under domain shift. Calibration under domain shift is an interesting challenge that has been receiving increasing attention and tackling this in an unsupervised manner is an interesting approach. However, I have 2 major concerns regarding the approach presented by the authors. In addition to doubts on practical applicability, my second major concern is regarding the depth of the evaluation.<BRK>#########################The paper proposes an unsupervised calibration method in a domain adaptation setting. The approach is based on the well known temperature scaling and does not require labels for the calibration set. To summarize, the paper addresses an important problem of calibration under domain shift but it needs some more empirical work to show the real advantage and limitations of the proposed method in a practical setting.<BRK>The authors propose an approach for calibrated predictions under domain shift scenarios. This is vaguely addressed in Section 6. I enjoyed reading the paper, the proposed reinterpretation of NLL in terms of a weighted average and its approximation based on weights that do not depend on the labels but the (assumed known) labels marginal is interesting and seems to yield good results.
Reject. rating score: 3. rating score: 3. rating score: 8. <BRK>1.SummaryThe paper theoretically investigates the role of “local optima” of the variational objective in ignoring latent variables (leading to posterior collapse) in variational autoencoders. 2.Opinion and rationalesI thank the authors for a good discussion paper on this important topic. The points below are all related. I think the paper specifically investigate local optima of the likelihood noise variance, and there are potentially other local optima. b. I think there is one paper that the paper should discuss: Two problems with variational expectation maximisation for time series models by Turner and Sahani.<BRK>This paper tries to establish an explanation for the posterior collapse by linking the phenomenon to local minima. They also provide some experimental data to suggest that when the reconstruction error is high, the distribution of the latents tend to follow the prior distribution more closely. Do you have any insights with regards to whether the explanations in this paper would still hold with more expressive prior distributions? I think the authors should think about the cases where the reconstruction error is low, and see if there is an issue of posterior collapse in those setups.<BRK>The authors then extended further to the deep VAE setting and showed that issues with the VAE may be accounted for by issues in the network architecture itself which would present when training an autoencoder. This stemmed mostly from the fact that many of the arguments were far less precise and less rigorous than those preceding. I believe this is a sensible restriction which enables analysis beyond the setting of primary concern in Alemi et al.(and other related work). I feel that this doesn t align well with the discussion in this section. In particular, I believe it would be more accurate to say that IF the autoencoder has bad local minima then the VAE is also likely to have category (v) posterior collapse. It is inherently difficult to reason about the optimization trajectories of deep auto encoding models and is potentially dangerous to do so.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>This paper proposes a complicated NAS approach, with a lot more ops, a larger search space and an extra teacher network. However, the results on CIFAR10 and ImageNet are both not competitive to other SOTA results. Despite that, NOS is still not competitive to other SOTA results (prroxylessNAS on CIFAR 10 and MnasNet A3 on ImageNet).<BRK>This paper proposes a new method for neural architecture search that searches architectures with not only feature transformational components but also self calibration and dynamic convolution ones. In the Imagenet results, the proposed method is behind many of the state of the art methods, casting concerns on the effectiveness of the proposed approach considering its added search space.<BRK>Summary:Often in (neural architecture search) NAS papers on vision datasets, only feature transform operations (e.g.convolution, pooling, etc) are considered while operations like attention and dynamic convolution are left out. This paper attempts to incorporate these operations into the search space of NAS. The main novelty is the design of the cell such that attention and dynamic convolution operations can be incorporated. I was hoping that the results in terms of error would be much better due to the more expressive search space but they are not at the moment. Do we have a negative result (an important one though) that attention and dynamic convolutions don t really help?
Reject. rating score: 1. rating score: 3. rating score: 3. <BRK>This paper proposes a framework to model the evolution of dynamic graphs for the task of predicting the topology of next graph given a sequence of graphs. This paper should be rejected due to following reasons: (1) The authors do not justify/discuss the motivation and importance of the task and corresponding applications that would require to predict topology of complete graph in the next step. (2) The proposed techniques are an adhoc combination of existing techniques with major concerns (details below) but also with little novelty (if any) for achieving this combination. It is not clear what the authors contributed to address such a challenge. When such methods can be used to do future predictions required for most applications, why does one need to predict the topology of complete next graph? Why are the two Bitcoin datasets different from each other?<BRK>This paper presents a system for predicting evolution of graphs. The contribution of the paper seems to be a system of combining these to achieve graph evolution prediction. The main objection I have in this paper is that they have only used two real datasets (both of which are from the same domain). It is not possible to conclude the empirical superiority of a system based on such little evidence.<BRK>In this paper, the authors propose a new neural network architecture for predicting the next graph conditioned on a past graph sequence. It seems that the proposed model is the first deep learning model for graph sequence prediction. There are two main concerns I have with this paper:  The model has some inherent limitations in the graph embedding step. First, the graph encoder embeds a graph into a feature vector that represents the topology of the graph. The model does not output a graph with the right size for very simple synthetic graphs. A better model should be proposed to address this challenge. Evaluation is not convincing enough. I believe this can be done for simple graphs like circles, paths, and ladders.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>This paper proposes to model various uncertainty measures in Graph Convolutional Networks (GCN) by Bayesian MC Dropout. Training/inference roughly follows MC Dropout, with two additional priors/teachers: 1) the prediction task is guided by a deterministic teacher network (via KL(model || teacher)), and 2) the Dirichlet parameters are guided by a kernel based prior (via KL(model || prior)).<BRK>Also, the main motivation of this work is that it is modeling the uncertainty in model predictions. The main issue with this paper is the motivation of the framework.<BRK>The authors proposed a Bayesian graph neural network framework for node classification. The main contribution is to evaluate various uncertainty measures for the uncertainty analysis of Bayesian graph neural networks. Experiments are insufficient in the uncertainty analysis (section 5).
Reject. rating score: 1. rating score: 1. rating score: 1. <BRK>I would encourage the authors to continue to polish and investigate their method and submit to a future conference. This paper proposes an approach to learning embeddings associated with nodes in a graph. Inspired by Hebbian learning, the representations of a node are iteratively updated to be similar to representations of its neighbors. There are several significant concerns with the paper as it currently stands. * What are baseline results for related algorithms on the datasets experimented upon? The paper suggests that the proposed algorithm is a form of Hebbian learning because the representation of nearby nodes in the graph are encouraged to be similar. * What is the role of the variance scaling? * Equation 3 is not consistent with equations 4 5. But Algorithm 1 suggests that nodes are updated based on only a single neighbor at a time.<BRK>In this paper, the authors proposed a simple but effective node embedding method for large scale graphs. The proposed method is based on Hebbian learning, enhancing the connections between neighbor nodes iteratively. The idea is very straightforward and suitable for large scale applications. The authors tested the proposed method on multiple real world datasets under different configurations. Additionally, for conceptual proof, the authors can consider a synthetic/real world dataset with relatively small size and compare their method with state of the art methods. Additionally, the notations in Eqs. (1 3) as Eqs. (4 6).<BRK>[Summary]This paper proposes an error free rule update method for graph embedding. The authors employ the Hebbian learning concept iteratively using the pre calculated transition probability. [Pros]  Very simple and fast by using an error free update rule. No comparison with conventional methods such as PageRank and NN based models such as SEAL [1] and VGAE [2]. Even if this method is not learning based, the proposed model should be compared. At least, the author describes what is recommended, the data size, how large performance is improved, etc. It is required to be evaluated on conventional datasets.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>Is the label (number) of each is used as an element of a multiset? The problem to be solved is not mathematically formulated. More detailed explanation of the data preparation would be required.<BRK>It would be good to isolate the contribution of the two. The definitions and arguments are quite clear and helpful. I found these technical contributions to be a bit small.<BRK>Authors of this paper propose train a model by predicting the size of the symmetric difference between pairs of multisets. With the motivation from fuzzy set theory, both the multiset representation and predicting symmetric difference sizes given these representations are formulated. The statement seems not so straightforward, and how it works as the learning criterion for semi supervised clustering in the experiments.
Accept (Poster). rating score: 6. rating score: 6. rating score: 6. <BRK>This paper proposes an approach, named SAVE, which combines model free RL (e.g.Q learning) with model based search (e.g.MCTS).SAVE includes the value estimates obtained for all actions available in the root node in MCTS in the loss function that is used to train a value function. L_Q is a loss function though, whereas Q learning, TD(0) and TD(lambda) are algorithms, they re not loss functions.<BRK>This paper proposes SAVE that combines Q learning with MCTS. In particular, the estimated Q values are used as a prior in the selection and backup phase of MCTS, while the Q values estimated during MCTS are later used, together with the real experience, to train the Q function.<BRK>This paper proposes Search with Amortized Value Estimates (SAVE), which combines Q learning and Monte Carlo Tree Search (MCTS). SAVE makes use of the estimated Q values obtained by MCTS at the root node (Q_MCTS), rather than using only the resulting action or counts to learn a policy.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>Methods  Given the set of fixed convolutional filters, the method dynamically selects the (weighted sum) kernels by given a kind of channel attention. The author slightly revises the baseline networks to set the networks integrated with the proposed method to have smaller Flops. But we cannot find the number of parameters in this paper. Concerns  The main concern of the reviewer is that the model shares the core contribution to the existing method; squeeze and excitation network (SEnet, Hu et.al.). The reviewer thinks that it is a critical part because one of the primal reasons for training the network is to use them as the pre trained backbone for the other tasks. As in the question, the reviewer thinks that the number of parameters would be increased. The reviewer agrees that some recent works focus more on Flops, but the number of parameters is also discussed in general, when telling about the  model size . Conclusion  The author proposed a dynamic kernel selection method (add on), which can enhance the classification accuracy of the baseline network.<BRK>This paper proposed dynamic convolution (DyNet) to accelerating convolution networks. The additional segmentation experiment on the Cityscapes dataset also shows the new module can save computation a lot while maintaining similar segmentation accuracy. Clarity:The novelty of the paper is limited and the experimental results are weird for me. 2.As shown in Equation (2), the proposed method contains the normal computation of fixed kernels. How can this method save computations compared to classical convolution? Is the computation flops calculated in the right way?<BRK>  Summary  The authors propose to use dynamic convolutional kernels as a means to reduce the computation cost in static CNNs while maintaining their performance. The dynamic kernels are obtained by a linear combination of static kernels where the weights of the linear combination are input dependent (they are obtained similarly to the coefficients in squeeze and excite). My main issue with the paper is the lack of novelty. The use of dynamic convolutions is by no means a novel idea and has been studied in multiple previous works in vision (mixture of experts, soft conditional computation, pay less attention with dynamic convolutions, ...) which the authors fail to cite/compare against. However, most previous work focuses on leveraging dynamic kernels to use more parameters so the focus on accelerating CNNs is novel. Questions/Comments    Figure 5: how are the models constrained to have same FLOPS?
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>The authors introduce a novel self attention operator for neural networks. Attention has been empirically shown to bring improvements in many visual tasks but certain methods (such as self attention) can be quite expensive in computations and memory. Self attention is incorrectly described as "a special case of the attention operator with Q   K   V", instead of Q   XW^Q, K XW^K, V   XW^V.<BRK>The proposed Siamese attention operator is much more efficient than prior attention methods in terms of speed. It would be great if the authors can resolve my concerns. It is faster and performs equally well as other attention operators. Is attention an operator that significantly slows the speed of the whole network?<BRK>Literature review was sufficient to explain the problem and underlying theory. Reasonable direction of exploration   there are several possible similarity functions, this paper explores one of them that offers significantly less computational resources, which are essential for on device applications. Thorough exploration of this idea was done and I am convinced this is a good alternative to regular attention.
Reject. rating score: 6. rating score: 6. <BRK>The paper proposes a novel training scheme for GANs, which leads to improved scores w.r.t.state of the art. The idea is to update the sampled latent code in a direction improving the inner maximization in the min max problem. The work considers both, the gradient direction and a direction motivated by the natural gradient which is shown to yield excellent performance. The overall scheme is motivated as an approximation to the (prohibitively expensive) symplectic gradient adjustment method. The connection to SGA is a bit hand wavy, as terms are dropped or approximated with the only reasoning that they are difficult to compute. In some approximations (e.g.Gauss Newton approximation of the Hessian) one can argue quite well that certain second order terms can be dropped under some assumptions (e.g.mild nonlinearity, or vanishing near the optimum). (a) What is p(t | z)? There are also some typos which made it hard to follow the arguments there. It probably should read "an ideal generator can perfectly fool the discriminator" (not perfectly fool the generator). presribed  > prescribed  Eqs.<BRK>Summary:LOGAN optimizes the sampled latent generative vector z in conjunction with the generator and discriminator. By exploiting second order updates, z is optimized to allow for better training and performance of the generator and discriminator. Pros:+ A relatively efficient way of exploiting second order dynamics in GAN training via latent space optimization. + A good set of experiments demonstrating the superior performance of the proposed method on both large and small scale models and datasets. The lack of open source code accompanying the paper (in this day and age) does it a serious disservice. There appears to be some nuance in implementation that would probably clear up if the authors release their code along with the paper.
Accept (Poster). rating score: 8. rating score: 3. <BRK>This paper proposed PairNorm, which is a normalization layer for GNNs to tackle this problem. The authors discussed that this is because GCN and GAT are easier to overfit. The paper conducted empirical studies to evaluate the effectiveness of the method. Therefore, I think there is another hypothesis that simply the choice $s$ was misspecified.<BRK>The authors propose the special NN layer "PairNorm", which aims to battle with this issue. The proposed PairNorm approach boils down to the recentering and normalization of all the representations after each graph convolutional layer of the network. However, the reasons why it is a good idea or not are not discussed in the paper.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>This paper s contribution is a method for automatically growing the depth of a neural network during training. My current decision for this paper is a weak rejection due to the points below.<BRK>The main framework here is to interleave training a shallower network and adding new layers. Comments/Questions:Section 2 of the paper describes the proposed method is good details. Perhaps, the reason past NM works didn’t use a GauInit was also due to the fact that past sub modules didn’t work with GauInit.<BRK>The paper presents a meta learning algorithm to automatically detemine the depth of neural network through a policy to add depth if this bring improvement on accuracy.
Accept (Poster). rating score: 8. rating score: 6. rating score: 6. <BRK>This paper considers from a high level the problem of learning a latent representation of high dimensional observations with underlying dynamics for control. The paper overall is clear, however there is many equations in 4.2  with heavy subscritping making it sometimes difficult to read.<BRK>This work proposes a regularization strategy for learning optimal policy for a dynamic control problem in a latent low dimensional domain. The paper is well written and pleasant to read.<BRK>This paper considers learning low dimensional representations from high dimensional observations for control purposes. If the authors can address my comments, I will be willing to increase my score. Overall, I think the idea in this paper is interesting. The paper is well written.
Reject. rating score: 3. rating score: 3. rating score: 8. <BRK>Overall, I think the empirical results appear very strong, but think this paper is below the acceptance threshold due to three factors, in ranked order:  (1) The theoretical guarantee, which is positioned as a core contribution of the paper (and in fact claims it as "the first to correct labels with theoretical guarantees", which is not true), is based on assumptions that seem overly strong; these are somewhat relaxed in a "Remark", but this seems unproven and is a confusing presentation regardless. (ii) I also have a high level question for understanding: how is it possible for the various approaches to do so well with 0.6 and 0.8 noise level of uniform flipping?<BRK>This paper proposes a label correction approach based on a likelihood ratio test, for robust training of deep neural networks against label noise. What is the difference in computation costs between Standard and the proposed label correction approach? Overall, this paper proposes a new label correction approach based on a likelihood ratio test. Standard experiments show that the proposed AdaCorr is superior to several existing methods.<BRK>This paper proposes a novel approach that directly cleans labels in order to train a high quality model. The experimental results on several benchmark data sets show that the proposed method is promising. Overall, this paper could be a significant algorithmic contribution. If the authors can show the time cost in the paper, I will much more agree with the paper. [3]The details of the compared methods should be given, and it will be better to give the results without any noise labels.
Accept (Spotlight). rating score: 8. rating score: 8. rating score: 6. <BRK>The paper proposes an imitation learning algorithm that combines behavioral cloning with a regularizer that encourages the agent to visit states similar to the demonstrated states. Thank you for the clarification. It proposes a relatively simple imitation method with compelling empirical results.<BRK>The authors addressed my comments in the response and the updated paper. I vote for acceptance. This approach leads to a method called disagreement regularized imitation learning (DRIL). These approaches and quantities have different pros and cons and they should be discussed in the paper.<BRK>Summary of what the paper claims and contributes This paper proposes a new interactive imitation learning algorithm to address the covariate shift problem in imitation learning. Example 1: citation should be Ross 2010, not Ross 2011. The method is new. Yes.>Significance:Are the results important? Unique theoretical approach.
Reject. rating score: 1. rating score: 3. rating score: 6. <BRK>Summary: This paper proposes two machine learning adaptations of the Bayesian truth serum approach to aggregating predictions from human experts. 2.The paper contains some simple experiments, but I do not believe they are an adequate enough evaluation of the proposed approaches. Pros:+ The core idea of adapting Bayesian truth serum to ensemble prediction in machine learning seems sensible+ There is some evidence that the methods have an advantage over other common ensemble approaches in practice+ Although there are quite a few small English mistakes, the paper is well structured and generally quite easy to followCons & questions:  1. I feel that stacking is probably the most interesting baseline to compare with, as this is a method for learning how to aggregate predictions from ensemble members.<BRK>Inspired by work in ensembling human decisions, the authors propose an ensembling technique called "Machine Truth Serum" (based off "Bayesian Truth Serum"). It seems to me that the reason the experiments show that DMTS/HMTS work is that some/many of the underlying classifiers are weaker than the model that is used to ensemble the predictions (an assumption that doesn t hold in practice). * "In this paper, each of the datasets we used has a small size   we chose to focus on the small data regime where the classifiers are likely to make mistakes." This approach seems simpler but equivalent to the approach currently taken.<BRK>In this paper, the authors propose a way to measure a notion of surprise (disparity between prior and posterior) and using that as a classification rule. The authors show that such methods can do better than majority voting and some ensemble methods on a few datasets. The strong points of the paper:1. 4.What are the weights in the weighted majority? Since HMTS uses more complex intermediate models (MLPs), I am not convinced whether the small improvement is from the proposed method or just more expressive models. In summary, I think the paper has an interesting approach to an important problem, but with results that are only marginally convincing.
Reject. rating score: 3. rating score: 3. rating score: 3. <BRK>This is demonstrated experimentally and subsequently a second order method is used for incorporating this in training. I still think an experimental comparison with the related methods would be more convincing than verbal. The concept is sensible, intuitive, and simple. 5. why there is no single task baseline in table 1? Their observation seems related to the pitch of this paper that orthogonal gradients (ie tasks with dissimilar updates) can be optimized better.<BRK>This paper embraces the idea that better multi task/lifelong learning can be achieved if tasks produce gradients that are orthogonal to the gradients produced by other tasks. Given my continued concerns, I am inclined to keep my score the same. The idea of producing orthogonal gradients across tasks or examples is not new in the context of lifelong/multi task learning. Why would we like gradients to be orthogonal if there would otherwise be transfer? ICLR 19.Given my major concerns about the theoretical motivation and comparisons to past work, I do not find the experiments comprehensive enough to prove the value of the proposed approach to the community. At the very least, I would be interested in comparison with additional very relevant baselines and in experiments with more tasks.<BRK>Then they proposed a new gradient regularization to enforce the gradient for each task be orthogonal. Empirical results (on Multi digits MNIST and NYUv2 data sets) indicate a marginal improvement, comparing with baselines. Main Comments:The discovering in the paper sounds interesting while the work looks like preliminary and unpolished. Particularly I have the following technical and conceptual concerns:1. Overall, I feel it is an interesting and promising direction to consider gradient regularization based approach in multi task learning. The main reason that I still keep the decision toward rejection is the experimental part. Since it is an empirical paper, I suggest the author either systematically show more comparisons and more datasets.
Reject. rating score: 3. rating score: 3. rating score: 8. <BRK>The authors propose a novel GAN based method to tackle PML problem. By using Encoder Decoder architecture, the authors combine four neural networks including disambiguator, predictor, generator, and discriminator to implement the integrated model and get an overall good performance in various experiment settings and datasets. The model works better than other state of art models overall. Cons:  The novelty of this paper is limited to some extent. It seems that the model just combines ideas of GAN and PML. Under the condition when the dimension of labels is small enough, it will be hard to generate good samples because the information which can be utilized for the generator mightn t be sufficient. However, when the dimension of labels is large, there will be some combinations of labels that aren t in the training set, which may harm the performance of the generator. Because the relations between instances and labels aren t one to one in most cases, I wonder whether the five layer perceptron still works well as a generator if one setting of labels can correspond to various kinds of instances. It will be better to compare the generator part proposed in this paper with a simple interpolation method in the process of extending the dataset.<BRK>The motivation of this paper is to handle noise candidate multi labels by co training two networks. The work trains the disambiguation network, which learns to predict the probability of each class label being the additive irrelevant label and then is used to get the disambiguated label confidence vector, and the prediction network, which learns to predict the probability of the disambiguated labels. The additional adversarial loss and generation loss is aimed to enhance the label disambiguation by learning the mapping from the disambiguated labels to the input features. The experiments in this paper are complete and thorough. The authors have tested the model in many datasets and designed the ablation study to verify the effect of each loss. It is doubtful that the generation is helpful. 3) In the appendix, the variant of PML GAN, which considers an auxiliary classification loss on the generated data, has little improvement compared to PML GAN. I think it can somehow verify the effect of the generation. About the writing of this paper, the motivation of the work is not clearly defined. Although we can get what the work was done, we cannot get why the work did this.<BRK>The partial multi label learning is the problem that one instance is associated with several ground truth labels simultaneously, but we are given a superset of the ground truth labels for training. The four network are concatenated, and the paper proposed to optimize the sum of generation loss, the classification loss, and the adversarial loss. The paper is the first paper to proposes a GAN style algorithm for the partial multi label learning problem. I agree with the paper on this aspect. However, in the paper, it also learns something similar to the “confidence” score in the disambiguation network \tilde D, so why the proposed method is better than previous baselines? But the paper fails to give clear intuition why the adversarial training part can lead to better performance. I am also wondering will the proposed model leads to a trivial solution. In this way, the classification error can always be zero, and we can train the generation network to give a ground truth instance x, given that the generation network G is strong enough. In the related work part, the arguments on “weak label learning” cannot be used for partial multi label learning is not accurate. In fact, “weak label learning” studies the problem when positive labels are missing, and partial multi label learning studies the problem when negative labels are missing. So in general, the methods for “weak label learning” can be used for “partial multi label learning” if we exchange the role of positive labels and negative labels in both problems. So why we need to study partial multi label learning? So “partial multi label” is actually more strong supervision information than “weak labels” because positive labels are more important. Although the paper has some deficiencies, it does a good job of introducing GAN into partial multi label learning, and it is also the first paper to use the powerful deep neural networks into this problem, which may trigger some interesting studies given the booming of neural networks these days. And thorough empirical studies are done by comparing to not only baselines but also different loss parts of the proposal it owes. It is worth reading especially it may have an impact on further studies. I am satisfied with the rebuttal and tend to increase my score. Partial multi class learning may be easier since you know only one label is true, but partial multi label learning is difficult since you do not know how many true labels there are. It makes no point to require a perfect solution for such a dirty problem.
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>The authors propose a local label propagation approach for large scale semi supervised learning. Some further computational speedup is done with a memory cache described in an earlier work (Wu 2018b). Experimental results seem significantly superior to the competitors. (3) For label propagation methods, it is important to understand whether the pseudo labels are accurate and/or whether the methods might be mis guided by the pseudo labels. But it is not clear how the validation set is formed, and what performance is measured. Is it a performance based on a labeled validation set (and if so, how large is the set) or unlabeled one? While it does not change my assessment, I thank the authors for clarifying some issues.<BRK>The paper introduces an approach for semi supervised learning based on local label propagation. Also, the experiments seem to be extensive with additional analysis to the behavior of the proposed method. I wonder how important it is to have this initialization and would like to see ablation studies on whether using this as initialization or not. I like the idea of learning a consistent embedding space for prediction and label propagation seems interesting and novel to my knowledge.<BRK>The paper discusses a new strategy for deep semi supervised learning that seems related to the deep label propagation method of Iscen et al.2019, but is more scalable and has a different loss function. This is in contrast to Iscen et al.2019 which takes O(N^2). Experiments show that the authors  approach performs consistently better on ImageNet than existing approaches. With suboptimal preprocessing, it also performs comparable / slightly better than UDA (Xie et al.2019) (The authors speculate it could do better with the preprocessing that UDA uses)I am not from this area but found the paper well written and easy to understand.
Accept (Spotlight). rating score: 8. rating score: 8. rating score: 6. <BRK>The paper proposes an approach to incrementally learn hierarchical representations using a variational autoencoder (VAE). This is shown to be useful qualitatively and quantitatively in terms of disentanglement in the representations. A vanilla VAE is first trained. Each level of the hierarchy, the representations are disentangled. Ablation studies by varying/removing fadeout compared to incremental learning will be useful. The results look impressive and the learned hierarchy and latent traversals are convincing. A more thorough comparison with VLAE will make the paper stronger.<BRK>This paper introduce pro VLAE, an extension to VAE that promotes disentangled representation learning in a hierarchical fashion. Results suggest that this is a promising direction for disentangling representations as pointed out by the authors in the conclusions. In sec 3.1 "z from different abstraction" is too vague and should be better formalized. The novelty introduced is enough, provided that not much literature has explored progressive representation learning in the context of disentanglement.<BRK>This paper proposed a method for training Variational Ladder Autoencoder (VLAE) using a progressive learning strategy. Overall, I think the purpose of this paper should be written clearly. It is not clear whether the purpose is learning the disentangled representation or the hierarchical representation. I think this work is similar to [3] in that both learn disentangled representations by progressively increasing the capacity of the model. I think the authors need to discuss about this work. The authors  comments and further experiments address most of my concerns.
Reject. rating score: 3. rating score: 3. rating score: 6. <BRK>This paper proposes a new way to benchmark DRL algorithms using the Atari environment which is twofold, one part is a set of emulator recommendations, the other part is what quantity we should consider as a "human reference". The paper also compares Rainbow and Rainbow IQN, where the IQN improvement matches the proposed human normalized score improvment. The line between environment design and algorithm design can be blurry, but in Atari s case, the weird peculiarities of each game are known to make it an inconvenient benchmark. We should only work on improving a benchmark if it is a useful benchmark, yet, we have many clues that Atari is not. The link to TwinGalaxies should be a proper reference with the time of visit, especially if humans break new records in the future. and tested these games with a bunch of DRL algorithms.<BRK>The paper proposes an extension to the work of Machado et al.(2018) for standardizing training and evaluation procedures in the Arcade Learning Environment (ALE). They proceed to evaluate Rainbow under their proposed evaluation procedures, as well as introduce a new algorithm, Rainbow IQN, with similar evaluations made based on their proposal. In particular, I d like the authors to comment on the following:1) The key difference between their evaluation benchmark and the recommendations in Machado et al.(2018) are that episodes should not have a time limit. The justification for this is that many algorithms might achieve practically optimal performance within this time limit, and so one wouldn t be able to compare algorithms on certain games within significance. They further emphasize that human high scores were achieved without limiting to 30 minutes of play. 2) The paper gathered a list of human world records for the Atari games in the ALE. Beyond this though, I think an alternative conclusion would be to use this information in support of not comparing results to human scores, and to focus on comparisons between algorithms.<BRK>This paper revisits the way RL algorithms are typically evaluated on the ALE benchmark, advocating for several key changes that contribute to more robust and reliable comparisons between algorithms. I do have a few concerns / questions though:1. I am not convinced by the recommendation to use performance during training for evaluation purpose. In Machado et al.(2018) it is argued that « this better aligns the performance metric with the goal of continual learning », but most deep RL algorithms trained on Atari games have not been intended to be used in a continual learning setting. As a result, I am currently reluctant to see the proposed performance measure become the standard evaluation metric on ALE, and I would appreciate some additional justification from the authors on this point. As mentioned in Section 6, reward clipping can prevent RL algorithms from properly playing some games, and thus in my opinion should be removed if the goal is to reach the highest score possible on all games. It seems to me that the choice of clipping the reward should be part of the algorithm (if it is not able to handle the high variety of « raw » rewards) and not of the benchmark environment, thus enabling further advancements towards algorithms that are robust to a wide range of rewards. •	The « infinite reward loop » point at the end of Section 6 does not seem relevant in the list of reasons why Deep RL algorithms are far from the best human performance, since with infinite playtime and an infinite reward loop, the algorithm should be guaranteed to outperform humans.
Accept (Poster). rating score: 8. rating score: 8. rating score: 6. <BRK>The paper addresses an important question in RL:  generalization in the observational space. The paper proposes a metric to measure this generalization error and this can be applied to non toyish environments.<BRK>Perhaps a plot that shows the generalization gap as the y axis would be more clear. The paper presents relevant bounds on overfitting depending on the dimensionality of the signal and noise. The framework and definition of family of MDPs are interesting and useful, and the focus on the implicit regularization provided by overparameterization when dealing with high dimensional observations with correlated noise is important and useful to decouple from varying dynamics.<BRK>A strength of this paper is to deepen our understanding of the phenomenon of overfitting in RL. Theoretical properties of generalization for the specific case of LQR and linear policies.
Accept (Spotlight). rating score: 8. rating score: 6. rating score: 6. <BRK>This paper provides an approach to use visual information to improve text only neural machine translation systems. The approach creates a "topic word to images" map using an existing image aligned translation corpora. One of the claims of the paper was to be able to use monolingual image aligned data. It would make sense to use image captioning data to create the image lookup. What is M in Algorithm 1 ?<BRK>The intuition is clear and the premise is very tempting. The key architectural choice is to allow the transformer to use language embeddings to attend into a topic image lookup table.<BRK>Summary: This paper uses visual representation learned over monolingual corpora with image annotations, which overcomes the lack of large scale bilingual sentence image pairs for multimodal NMT. Their approach enables visual information to be integrated into large scale text only NMT. Experiments on four widely used translation datasets show that the proposed approach achieves significant improvements over strong baselines. I like how low resource translation is included as a priority in their experiments.
Reject. rating score: 1. rating score: 1. rating score: 3. <BRK>The paper proposes a memory network architecture with a sparse memory. The policy pi_theta is trained using policy gradient with the reward being the increase in the policy s certainty (measured as entopy). The model is evaluated on an online NER task that mimics the meta learning setting of http://proceedings.mlr.press/v48/santoro16.html. The method description is either incomplete or incorrect. The current training loss only encourages the entropy to reduce, so unless the LSTM is pre trained, there is no guarantee that the key s will address the right memory entry. The experiment section does not explain the details of the experiments, leaving the reader to look at Santoro et al., 2016 for context. Even then, some statements in the experiment section are confusing. The task used in the paper is non standard. The paper could have used meta learning tasks from previous papers, including the ones in Santoro et al., 2016. Other comments:  The citations should be written as "xxx (author, year)" and not "xxx, author (year)".<BRK>The authors build on work regarding few shot learning with memory augmented networks, specifically [Kaiser, et al., ICLR17] where the goal is to learn a memory address mapping such that generalization is achieved by finding the nearest neighbor memory address when predicting the label. Whereas [Kaiser, et al., ICLR17] follows a LRU like procedure for replacing memory, the current work proposes performing policy gradient RL where the action space is the memory locations and the reward is reduction of entropy over the memory address assignment distribution over the memory locations. A second point of interest is the NER task. However, this is not the determining factor in the paper. Basically, I think the contribution is insufficient in terms of scope and convincingness of the contribution.<BRK>In this paper, the authors present a method, Learning to Control (LTC), that enables a reinforcement learning agent to learn to read and write external memory. The proposed method can be applied to a few shot setting. Weakness: There is no ablation study for the proposed method to fully understand why the proposed method is superior. The authors use REINFORCE as the RL algorithm which is no longer useful in most of the complex RL tasks. More advanced RL algorithms are encouraged to be tried. It seems the LTC only refers to the REINFORCE agent. I believe the authors need major changes to the experiments section as well as the method description section. Hence, I cannot recommend this paper to acceptance.