Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>The gradients of the von Neumann divergence are provided for learning via backpropagation. Pros: 1.The use of von Neumann divergence as a loss for this task is perhaps novel. The paper should also include and perhaps compare to their datasets. I do not think the use of von Neumann divergence as a loss is the best choice one could have, esp. for a deep neural network learning setting. This divergence includes the matrix logarithm, which is perhaps computationally expensive. It is unclear why the paper decided to use von Neumann. 4.The experiments are not compelling, there are no comparisons to alternative models and the datasets used are small scale. Thus, it is unclear if the design choices in the paper have any strong bearing in the empirical performances. Overall, the paper makes an attempt at designing neural networks for learning SPD matrices. While, there are some components in the model that are perhaps new, the paper lacks any justifications for their choices, and as such these choices seem inferior to alternatives that have been proposed earlier.<BRK>This paper generalized neural networks into case where a semidefinite positive matrix is learned at the output. The paper presents theoretical derivations that look sound, and validating experiments on synthetic and real data. I must say my expertise does not really correspond to what is done in this paper, but I do not see any obvious flaws and the results look solid. I appreciated the discussion of limitations in section 6. I vote for acceptance with the weakest possible confidence level since it is likely I missed many important points.<BRK>While the field has had methods for years to estimate SPD matrices (such as the covariance matrix estimate in the reparameterization trick), this manuscript proposes a markedly different approach based on a different layer structure and repeated normalization steps based on Mercer Kernels. This loss appears to give significantly better solutions on synthetic data. While there is some interesting and potentially useful novelty in the approach, I have some concerns about the empirical evidence and modeling to truly determine the mMLP s utility. Why does mMLP/l_QRE outperform on E_quad? The network structure as a whole needs greater validation. Can the authors validate this structure versus the simpler structure of simply using left multiplications? I think that the heteroscedastic regression experiments don t evaluate on one of the key issues, which is uncertainty estimation. Also, heteroscedastic regression has a long history in neural networks, dating back to at least Nix and Wiegand in 1994. Please check Table 5(a), which states that you are only using a small number of training samples. How confident are you that the methods actually improve the prediction? How were the competing models tuned and optimized?
Reject. rating score: 3. rating score: 6. rating score: 6. <BRK>[Summary]This paper studies the convergence of Q Learning when a wide multi layer network in the Neural Tangent Kernel (NTK) regime is used as the function approximator. Concretely, it shows that Q learning converges with rate O(1/T) with data sampled from a single trajectory (non i.i.d.) [Cons]The result in this paper seems more or less like a direct combination of existing techniques, and thus may be limited in bringing in new techniques / messages. Key technical bottlenecks that are assumed out in prior work are still assumed out in this paper with potentially different forms but essentially the same thing. But still I tend to think the above adaptations are rather straightforward and technically not quite novel. [Potential improvements]I would like to hear more from the authors about the technical novelty in this paper, specifically how Lemma 6.1   6.3 compare with prior work.<BRK>When the neural function is sufficiently over parameterized, the O(1/T) convergence rate is attained. This is an important but difficult task. Cons: In spite of its theoretical contributions, this paper has a few major issues. It would be of practical interests to seek other proof techniques to avoid such projection step. 2.Assumption 5.3 is problematic for the considered neural Q learning setting. Moreover, it is unclear how to verify this condition in practice. A typically practical observation is that a larger $L$ is better.<BRK>[Cons]+ The novelty is a bit unclear other than the non iid assumption. We note that modern Q learning tends to use batching so doesn t require much of an iid assumption anyways, but this allows for more robust proofs in TD settings with non iid training. + The paper was a bit dense and hard to follow, we suggest reducing p.8 to have more discussion with references to proofs in the Appendix as in Chen2019. + As the authors admit in open commentary, there is a mistake to be fixed which needs to be reviewed before acceptance. I think there is value to this work, however, would require seeing the change to assess a revision.
Accept. rating score: 3. rating score: 6. rating score: 6. <BRK>The gradients of the von Neumann divergence are provided for learning via backpropagation. Pros: 1.The use of von Neumann divergence as a loss for this task is perhaps novel. The paper should also include and perhaps compare to their datasets. I do not think the use of von Neumann divergence as a loss is the best choice one could have, esp. for a deep neural network learning setting. This divergence includes the matrix logarithm, which is perhaps computationally expensive. It is unclear why the paper decided to use von Neumann. 4.The experiments are not compelling, there are no comparisons to alternative models and the datasets used are small scale. Thus, it is unclear if the design choices in the paper have any strong bearing in the empirical performances. Overall, the paper makes an attempt at designing neural networks for learning SPD matrices. While, there are some components in the model that are perhaps new, the paper lacks any justifications for their choices, and as such these choices seem inferior to alternatives that have been proposed earlier.<BRK>This paper generalized neural networks into case where a semidefinite positive matrix is learned at the output. The paper presents theoretical derivations that look sound, and validating experiments on synthetic and real data. I must say my expertise does not really correspond to what is done in this paper, but I do not see any obvious flaws and the results look solid. I appreciated the discussion of limitations in section 6. I vote for acceptance with the weakest possible confidence level since it is likely I missed many important points.<BRK>While the field has had methods for years to estimate SPD matrices (such as the covariance matrix estimate in the reparameterization trick), this manuscript proposes a markedly different approach based on a different layer structure and repeated normalization steps based on Mercer Kernels. This loss appears to give significantly better solutions on synthetic data. While there is some interesting and potentially useful novelty in the approach, I have some concerns about the empirical evidence and modeling to truly determine the mMLP s utility. Why does mMLP/l_QRE outperform on E_quad? The network structure as a whole needs greater validation. Can the authors validate this structure versus the simpler structure of simply using left multiplications? I think that the heteroscedastic regression experiments don t evaluate on one of the key issues, which is uncertainty estimation. Also, heteroscedastic regression has a long history in neural networks, dating back to at least Nix and Wiegand in 1994. Please check Table 5(a), which states that you are only using a small number of training samples. How confident are you that the methods actually improve the prediction? How were the competing models tuned and optimized?
Accept. rating score: 3. rating score: 6. rating score: 6. <BRK>[Summary]This paper studies the convergence of Q Learning when a wide multi layer network in the Neural Tangent Kernel (NTK) regime is used as the function approximator. Concretely, it shows that Q learning converges with rate O(1/T) with data sampled from a single trajectory (non i.i.d.) [Cons]The result in this paper seems more or less like a direct combination of existing techniques, and thus may be limited in bringing in new techniques / messages. Key technical bottlenecks that are assumed out in prior work are still assumed out in this paper with potentially different forms but essentially the same thing. But still I tend to think the above adaptations are rather straightforward and technically not quite novel. [Potential improvements]I would like to hear more from the authors about the technical novelty in this paper, specifically how Lemma 6.1   6.3 compare with prior work.<BRK>When the neural function is sufficiently over parameterized, the O(1/T) convergence rate is attained. This is an important but difficult task. Cons: In spite of its theoretical contributions, this paper has a few major issues. It would be of practical interests to seek other proof techniques to avoid such projection step. 2.Assumption 5.3 is problematic for the considered neural Q learning setting. Moreover, it is unclear how to verify this condition in practice. A typically practical observation is that a larger $L$ is better.<BRK>[Cons]+ The novelty is a bit unclear other than the non iid assumption. We note that modern Q learning tends to use batching so doesn t require much of an iid assumption anyways, but this allows for more robust proofs in TD settings with non iid training. + The paper was a bit dense and hard to follow, we suggest reducing p.8 to have more discussion with references to proofs in the Appendix as in Chen2019. + As the authors admit in open commentary, there is a mistake to be fixed which needs to be reviewed before acceptance. I think there is value to this work, however, would require seeing the change to assess a revision.